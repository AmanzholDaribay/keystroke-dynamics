{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "The dataset is taken from http://www.vmonaco.com/keystroke-datasets.\n",
    "Specifically from https://ms.sapientia.ro/~manyi/keystroke.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read:\n",
    "* https://appliedmachinelearning.blog/2017/07/26/user-verification-based-on-keystroke-dynamics-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('dataset2_norm.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 72)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['user_id'].values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.mean(a == b'37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As it can be seen the number of samples per user are 51. Since the user are 42 users, there in total 51 * 42 = 2142 samples. Number of features is 71."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the dataset is 2142 * 72."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good source for Pandas: https://chrisalbon.com/python/data_wrangling/pandas_replace_values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_unique = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b'10', b'20',\n",
       "       b'21', b'24', b'25', b'26', b'27', b'28', b'29', b'35', b'36',\n",
       "       b'37', b'38', b'40', b'41', b'50', b'51', b'53', b'54', b'55',\n",
       "       b'65', b'66', b'68', b'69', b'70', b'71', b'73', b'80', b'81',\n",
       "       b'82', b'83', b'84', b'85'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_id[user_id == b'20'] = b'11'\\nuser_id[user_id == b'21'] = b'12'\\nuser_id[user_id == b'24'] = b'13'\\nuser_id[user_id == b'25'] = b'14'\\nuser_id[user_id == b'26'] = b'15'\\nuser_id[user_id == b'27'] = b'16'\\nuser_id[user_id == b'28'] = b'17'\\nuser_id[user_id == b'29'] = b'18'\\nuser_id[user_id == b'35'] = b'19'\\nuser_id[user_id == b'35'] = b'20'\\nuser_id[user_id == b'37'] = b'21'\\nuser_id[user_id == b'38'] = b'22'\\nuser_id[user_id == b'20'] = b'11'\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "user_id[user_id == b'21'] = b'12'\n",
    "user_id[user_id == b'24'] = b'13'\n",
    "user_id[user_id == b'25'] = b'14'\n",
    "user_id[user_id == b'26'] = b'15'\n",
    "user_id[user_id == b'27'] = b'16'\n",
    "user_id[user_id == b'28'] = b'17'\n",
    "user_id[user_id == b'29'] = b'18'\n",
    "user_id[user_id == b'35'] = b'19'\n",
    "user_id[user_id == b'35'] = b'20'\n",
    "user_id[user_id == b'37'] = b'21'\n",
    "user_id[user_id == b'38'] = b'22'\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Creating Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 1e+03 ns, total: 3 Âµs\n",
      "Wall time: 5.48 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "label = []\n",
    "for i in range(42):\n",
    "    for j in range(51):\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == 0) * 2142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Input Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea5</th>\n",
       "      <th>fingerarea6</th>\n",
       "      <th>fingerarea7</th>\n",
       "      <th>fingerarea8</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.239631</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377880</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.239631</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343318</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343318</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.239631</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10      ...       fingerarea5  \\\n",
       "0   0.430147   0.467290      0.240    0.374429      ...          0.274194   \n",
       "1   0.363971   0.485981      0.344    0.365297      ...          0.377880   \n",
       "2   0.338235   0.345794      0.296    0.365297      ...          0.274194   \n",
       "3   0.404412   0.640187      0.276    0.410959      ...          0.343318   \n",
       "4   0.408088   0.635514      0.324    0.378995      ...          0.343318   \n",
       "\n",
       "   fingerarea6  fingerarea7  fingerarea8  fingerarea9  fingerarea10  \\\n",
       "0     0.296296     0.239631     0.222222     0.296296      0.296296   \n",
       "1     0.296296     0.239631     0.185185     0.259259      0.185185   \n",
       "2     0.259259     0.308756     0.259259     0.296296      0.333333   \n",
       "3     0.296296     0.274194     0.296296     0.370370      0.185185   \n",
       "4     0.296296     0.239631     0.296296     0.333333      0.222222   \n",
       "\n",
       "   fingerarea11  fingerarea12  fingerarea13  fingerarea14  \n",
       "0      0.222222      0.211470      0.283154      0.185185  \n",
       "1      0.185185      0.354839      0.211470      0.148148  \n",
       "2      0.222222      0.283154      0.175627      0.185185  \n",
       "3      0.222222      0.283154      0.247312      0.296296  \n",
       "4      0.222222      0.211470      0.318996      0.074074  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 68)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Feature Engineering (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree = 2,\n",
    "                        interaction_only = True,\n",
    "                        include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=1, include_bias=False, interaction_only=True)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 68)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 42)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[51].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the dataset into the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(res, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 2346)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.6000000000001"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, train_test_split splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "#model.add(Dense(units = 10, \n",
    "               # input_dim = 2346, \n",
    "               # activation = 'tanh',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "#model.add(Dense(units = 10, \n",
    "               # activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the third hidden layer\n",
    "#model.add(Dense(units = 10, \n",
    "               # activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "model.add(Dense(units = 42,\n",
    "                input_dim = 2346,\n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 42)                98574     \n",
      "=================================================================\n",
      "Total params: 98,574\n",
      "Trainable params: 98,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.3, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       Congratulations for myself, I have build my first Deep Learning Neural Network model using Keras with understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "#                              #verbose=1, \n",
    "#                              monitor='val_acc',\n",
    "#                              save_best_only=True, \n",
    "#                              mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', \n",
    "                   mode = 'auto', \n",
    "                   patience=50, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1e+03 ns, total: 5 Âµs\n",
      "Wall time: 7.87 Âµs\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/1500\n",
      " - 1s - loss: 3.6305 - acc: 0.0445 - val_loss: 3.5597 - val_acc: 0.0321\n",
      "Epoch 2/1500\n",
      " - 0s - loss: 3.4273 - acc: 0.0847 - val_loss: 3.4147 - val_acc: 0.0816\n",
      "Epoch 3/1500\n",
      " - 0s - loss: 3.2644 - acc: 0.1854 - val_loss: 3.2533 - val_acc: 0.2070\n",
      "Epoch 4/1500\n",
      " - 0s - loss: 3.1130 - acc: 0.2788 - val_loss: 3.1289 - val_acc: 0.2828\n",
      "Epoch 5/1500\n",
      " - 0s - loss: 2.9775 - acc: 0.4153 - val_loss: 3.0083 - val_acc: 0.3644\n",
      "Epoch 6/1500\n",
      " - 0s - loss: 2.8585 - acc: 0.4876 - val_loss: 2.8925 - val_acc: 0.4402\n",
      "Epoch 7/1500\n",
      " - 0s - loss: 2.7483 - acc: 0.5095 - val_loss: 2.8087 - val_acc: 0.4257\n",
      "Epoch 8/1500\n",
      " - 0s - loss: 2.6419 - acc: 0.5891 - val_loss: 2.7047 - val_acc: 0.5394\n",
      "Epoch 9/1500\n",
      " - 0s - loss: 2.5476 - acc: 0.6460 - val_loss: 2.6292 - val_acc: 0.5335\n",
      "Epoch 10/1500\n",
      " - 0s - loss: 2.4583 - acc: 0.6810 - val_loss: 2.5540 - val_acc: 0.6035\n",
      "Epoch 11/1500\n",
      " - 0s - loss: 2.3756 - acc: 0.7168 - val_loss: 2.4813 - val_acc: 0.6472\n",
      "Epoch 12/1500\n",
      " - 0s - loss: 2.3019 - acc: 0.7504 - val_loss: 2.4049 - val_acc: 0.6764\n",
      "Epoch 13/1500\n",
      " - 0s - loss: 2.2283 - acc: 0.7635 - val_loss: 2.3516 - val_acc: 0.6822\n",
      "Epoch 14/1500\n",
      " - 0s - loss: 2.1640 - acc: 0.7898 - val_loss: 2.2878 - val_acc: 0.7230\n",
      "Epoch 15/1500\n",
      " - 0s - loss: 2.1044 - acc: 0.7839 - val_loss: 2.2376 - val_acc: 0.6939\n",
      "Epoch 16/1500\n",
      " - 0s - loss: 2.0419 - acc: 0.8073 - val_loss: 2.1853 - val_acc: 0.7055\n",
      "Epoch 17/1500\n",
      " - 0s - loss: 1.9867 - acc: 0.8241 - val_loss: 2.1377 - val_acc: 0.7143\n",
      "Epoch 18/1500\n",
      " - 0s - loss: 1.9327 - acc: 0.8292 - val_loss: 2.0867 - val_acc: 0.7580\n",
      "Epoch 19/1500\n",
      " - 0s - loss: 1.8822 - acc: 0.8416 - val_loss: 2.0483 - val_acc: 0.7434\n",
      "Epoch 20/1500\n",
      " - 0s - loss: 1.8344 - acc: 0.8372 - val_loss: 2.0050 - val_acc: 0.7522\n",
      "Epoch 21/1500\n",
      " - 0s - loss: 1.7893 - acc: 0.8496 - val_loss: 1.9641 - val_acc: 0.7638\n",
      "Epoch 22/1500\n",
      " - 0s - loss: 1.7485 - acc: 0.8518 - val_loss: 1.9316 - val_acc: 0.7697\n",
      "Epoch 23/1500\n",
      " - 0s - loss: 1.7081 - acc: 0.8672 - val_loss: 1.8975 - val_acc: 0.7872\n",
      "Epoch 24/1500\n",
      " - 0s - loss: 1.6669 - acc: 0.8708 - val_loss: 1.8602 - val_acc: 0.7813\n",
      "Epoch 25/1500\n",
      " - 0s - loss: 1.6334 - acc: 0.8672 - val_loss: 1.8277 - val_acc: 0.7726\n",
      "Epoch 26/1500\n",
      " - 0s - loss: 1.5971 - acc: 0.8642 - val_loss: 1.8052 - val_acc: 0.7872\n",
      "Epoch 27/1500\n",
      " - 0s - loss: 1.5609 - acc: 0.8737 - val_loss: 1.7675 - val_acc: 0.7930\n",
      "Epoch 28/1500\n",
      " - 0s - loss: 1.5301 - acc: 0.8708 - val_loss: 1.7447 - val_acc: 0.7930\n",
      "Epoch 29/1500\n",
      " - 0s - loss: 1.4996 - acc: 0.8861 - val_loss: 1.7159 - val_acc: 0.7988\n",
      "Epoch 30/1500\n",
      " - 0s - loss: 1.4673 - acc: 0.8883 - val_loss: 1.6916 - val_acc: 0.8047\n",
      "Epoch 31/1500\n",
      " - 0s - loss: 1.4381 - acc: 0.8839 - val_loss: 1.6639 - val_acc: 0.8017\n",
      "Epoch 32/1500\n",
      " - 0s - loss: 1.4124 - acc: 0.8876 - val_loss: 1.6410 - val_acc: 0.8134\n",
      "Epoch 33/1500\n",
      " - 0s - loss: 1.3863 - acc: 0.8883 - val_loss: 1.6182 - val_acc: 0.8017\n",
      "Epoch 34/1500\n",
      " - 0s - loss: 1.3598 - acc: 0.8934 - val_loss: 1.6010 - val_acc: 0.8047\n",
      "Epoch 35/1500\n",
      " - 0s - loss: 1.3370 - acc: 0.8956 - val_loss: 1.5761 - val_acc: 0.8076\n",
      "Epoch 36/1500\n",
      " - 0s - loss: 1.3115 - acc: 0.8949 - val_loss: 1.5538 - val_acc: 0.8192\n",
      "Epoch 37/1500\n",
      " - 0s - loss: 1.2919 - acc: 0.8912 - val_loss: 1.5358 - val_acc: 0.8192\n",
      "Epoch 38/1500\n",
      " - 0s - loss: 1.2671 - acc: 0.8964 - val_loss: 1.5225 - val_acc: 0.8192\n",
      "Epoch 39/1500\n",
      " - 0s - loss: 1.2444 - acc: 0.8971 - val_loss: 1.5000 - val_acc: 0.8105\n",
      "Epoch 40/1500\n",
      " - 0s - loss: 1.2251 - acc: 0.9022 - val_loss: 1.4804 - val_acc: 0.8163\n",
      "Epoch 41/1500\n",
      " - 0s - loss: 1.2050 - acc: 0.9066 - val_loss: 1.4658 - val_acc: 0.8222\n",
      "Epoch 42/1500\n",
      " - 0s - loss: 1.1856 - acc: 0.9051 - val_loss: 1.4498 - val_acc: 0.8251\n",
      "Epoch 43/1500\n",
      " - 0s - loss: 1.1686 - acc: 0.9044 - val_loss: 1.4382 - val_acc: 0.8192\n",
      "Epoch 44/1500\n",
      " - 0s - loss: 1.1494 - acc: 0.9051 - val_loss: 1.4182 - val_acc: 0.8192\n",
      "Epoch 45/1500\n",
      " - 0s - loss: 1.1311 - acc: 0.9044 - val_loss: 1.4038 - val_acc: 0.8222\n",
      "Epoch 46/1500\n",
      " - 0s - loss: 1.1153 - acc: 0.9153 - val_loss: 1.3893 - val_acc: 0.8251\n",
      "Epoch 47/1500\n",
      " - 0s - loss: 1.0981 - acc: 0.9146 - val_loss: 1.3763 - val_acc: 0.8251\n",
      "Epoch 48/1500\n",
      " - 0s - loss: 1.0830 - acc: 0.9124 - val_loss: 1.3612 - val_acc: 0.8251\n",
      "Epoch 49/1500\n",
      " - 0s - loss: 1.0662 - acc: 0.9124 - val_loss: 1.3507 - val_acc: 0.8222\n",
      "Epoch 50/1500\n",
      " - 0s - loss: 1.0517 - acc: 0.9219 - val_loss: 1.3371 - val_acc: 0.8222\n",
      "Epoch 51/1500\n",
      " - 0s - loss: 1.0375 - acc: 0.9226 - val_loss: 1.3221 - val_acc: 0.8397\n",
      "Epoch 52/1500\n",
      " - 0s - loss: 1.0220 - acc: 0.9161 - val_loss: 1.3127 - val_acc: 0.8105\n",
      "Epoch 53/1500\n",
      " - 0s - loss: 1.0083 - acc: 0.9161 - val_loss: 1.3026 - val_acc: 0.8251\n",
      "Epoch 54/1500\n",
      " - 0s - loss: 0.9959 - acc: 0.9234 - val_loss: 1.2921 - val_acc: 0.8280\n",
      "Epoch 55/1500\n",
      " - 0s - loss: 0.9809 - acc: 0.9212 - val_loss: 1.2753 - val_acc: 0.8251\n",
      "Epoch 56/1500\n",
      " - 0s - loss: 0.9693 - acc: 0.9255 - val_loss: 1.2666 - val_acc: 0.8309\n",
      "Epoch 57/1500\n",
      " - 0s - loss: 0.9553 - acc: 0.9234 - val_loss: 1.2546 - val_acc: 0.8309\n",
      "Epoch 58/1500\n",
      " - 0s - loss: 0.9447 - acc: 0.9241 - val_loss: 1.2507 - val_acc: 0.8251\n",
      "Epoch 59/1500\n",
      " - 0s - loss: 0.9317 - acc: 0.9263 - val_loss: 1.2355 - val_acc: 0.8251\n",
      "Epoch 60/1500\n",
      " - 0s - loss: 0.9199 - acc: 0.9285 - val_loss: 1.2268 - val_acc: 0.8280\n",
      "Epoch 61/1500\n",
      " - 0s - loss: 0.9089 - acc: 0.9299 - val_loss: 1.2157 - val_acc: 0.8222\n",
      "Epoch 62/1500\n",
      " - 0s - loss: 0.8973 - acc: 0.9292 - val_loss: 1.2078 - val_acc: 0.8338\n",
      "Epoch 63/1500\n",
      " - 0s - loss: 0.8866 - acc: 0.9314 - val_loss: 1.2001 - val_acc: 0.8338\n",
      "Epoch 64/1500\n",
      " - 0s - loss: 0.8769 - acc: 0.9277 - val_loss: 1.1870 - val_acc: 0.8251\n",
      "Epoch 65/1500\n",
      " - 0s - loss: 0.8660 - acc: 0.9299 - val_loss: 1.1858 - val_acc: 0.8309\n",
      "Epoch 66/1500\n",
      " - 0s - loss: 0.8551 - acc: 0.9321 - val_loss: 1.1718 - val_acc: 0.8309\n",
      "Epoch 67/1500\n",
      " - 0s - loss: 0.8466 - acc: 0.9394 - val_loss: 1.1605 - val_acc: 0.8309\n",
      "Epoch 68/1500\n",
      " - 0s - loss: 0.8375 - acc: 0.9350 - val_loss: 1.1590 - val_acc: 0.8280\n",
      "Epoch 69/1500\n",
      " - 0s - loss: 0.8275 - acc: 0.9350 - val_loss: 1.1482 - val_acc: 0.8192\n",
      "Epoch 70/1500\n",
      " - 0s - loss: 0.8175 - acc: 0.9380 - val_loss: 1.1388 - val_acc: 0.8367\n",
      "Epoch 71/1500\n",
      " - 0s - loss: 0.8077 - acc: 0.9431 - val_loss: 1.1338 - val_acc: 0.8367\n",
      "Epoch 72/1500\n",
      " - 0s - loss: 0.8001 - acc: 0.9394 - val_loss: 1.1288 - val_acc: 0.8338\n",
      "Epoch 73/1500\n",
      " - 0s - loss: 0.7917 - acc: 0.9431 - val_loss: 1.1195 - val_acc: 0.8222\n",
      "Epoch 74/1500\n",
      " - 0s - loss: 0.7841 - acc: 0.9409 - val_loss: 1.1137 - val_acc: 0.8280\n",
      "Epoch 75/1500\n",
      " - 0s - loss: 0.7735 - acc: 0.9460 - val_loss: 1.1028 - val_acc: 0.8397\n",
      "Epoch 76/1500\n",
      " - 0s - loss: 0.7660 - acc: 0.9453 - val_loss: 1.0998 - val_acc: 0.8280\n",
      "Epoch 77/1500\n",
      " - 0s - loss: 0.7578 - acc: 0.9445 - val_loss: 1.0927 - val_acc: 0.8280\n",
      "Epoch 78/1500\n",
      " - 0s - loss: 0.7503 - acc: 0.9445 - val_loss: 1.0859 - val_acc: 0.8338\n",
      "Epoch 79/1500\n",
      " - 0s - loss: 0.7420 - acc: 0.9474 - val_loss: 1.0759 - val_acc: 0.8309\n",
      "Epoch 80/1500\n",
      " - 0s - loss: 0.7352 - acc: 0.9460 - val_loss: 1.0726 - val_acc: 0.8338\n",
      "Epoch 81/1500\n",
      " - 0s - loss: 0.7268 - acc: 0.9474 - val_loss: 1.0721 - val_acc: 0.8309\n",
      "Epoch 82/1500\n",
      " - 0s - loss: 0.7211 - acc: 0.9511 - val_loss: 1.0605 - val_acc: 0.8280\n",
      "Epoch 83/1500\n",
      " - 0s - loss: 0.7128 - acc: 0.9489 - val_loss: 1.0541 - val_acc: 0.8338\n",
      "Epoch 84/1500\n",
      " - 0s - loss: 0.7051 - acc: 0.9460 - val_loss: 1.0500 - val_acc: 0.8280\n",
      "Epoch 85/1500\n",
      " - 0s - loss: 0.6996 - acc: 0.9482 - val_loss: 1.0465 - val_acc: 0.8309\n",
      "Epoch 86/1500\n",
      " - 0s - loss: 0.6916 - acc: 0.9489 - val_loss: 1.0354 - val_acc: 0.8280\n",
      "Epoch 87/1500\n",
      " - 0s - loss: 0.6866 - acc: 0.9489 - val_loss: 1.0310 - val_acc: 0.8309\n",
      "Epoch 88/1500\n",
      " - 0s - loss: 0.6781 - acc: 0.9511 - val_loss: 1.0307 - val_acc: 0.8309\n",
      "Epoch 89/1500\n",
      " - 0s - loss: 0.6730 - acc: 0.9467 - val_loss: 1.0226 - val_acc: 0.8338\n",
      "Epoch 90/1500\n",
      " - 0s - loss: 0.6661 - acc: 0.9489 - val_loss: 1.0192 - val_acc: 0.8309\n",
      "Epoch 91/1500\n",
      " - 0s - loss: 0.6602 - acc: 0.9511 - val_loss: 1.0100 - val_acc: 0.8251\n",
      "Epoch 92/1500\n",
      " - 0s - loss: 0.6543 - acc: 0.9526 - val_loss: 1.0068 - val_acc: 0.8309\n",
      "Epoch 93/1500\n",
      " - 0s - loss: 0.6488 - acc: 0.9511 - val_loss: 1.0039 - val_acc: 0.8338\n",
      "Epoch 94/1500\n",
      " - 0s - loss: 0.6427 - acc: 0.9511 - val_loss: 0.9983 - val_acc: 0.8309\n",
      "Epoch 95/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6367 - acc: 0.9511 - val_loss: 0.9938 - val_acc: 0.8367\n",
      "Epoch 96/1500\n",
      " - 0s - loss: 0.6314 - acc: 0.9526 - val_loss: 0.9883 - val_acc: 0.8338\n",
      "Epoch 97/1500\n",
      " - 0s - loss: 0.6262 - acc: 0.9540 - val_loss: 0.9836 - val_acc: 0.8309\n",
      "Epoch 98/1500\n",
      " - 0s - loss: 0.6199 - acc: 0.9511 - val_loss: 0.9794 - val_acc: 0.8309\n",
      "Epoch 99/1500\n",
      " - 0s - loss: 0.6144 - acc: 0.9562 - val_loss: 0.9742 - val_acc: 0.8309\n",
      "Epoch 100/1500\n",
      " - 0s - loss: 0.6101 - acc: 0.9533 - val_loss: 0.9713 - val_acc: 0.8338\n",
      "Epoch 101/1500\n",
      " - 0s - loss: 0.6038 - acc: 0.9533 - val_loss: 0.9684 - val_acc: 0.8280\n",
      "Epoch 102/1500\n",
      " - 0s - loss: 0.5986 - acc: 0.9540 - val_loss: 0.9632 - val_acc: 0.8309\n",
      "Epoch 103/1500\n",
      " - 0s - loss: 0.5942 - acc: 0.9540 - val_loss: 0.9556 - val_acc: 0.8309\n",
      "Epoch 104/1500\n",
      " - 0s - loss: 0.5904 - acc: 0.9518 - val_loss: 0.9561 - val_acc: 0.8309\n",
      "Epoch 105/1500\n",
      " - 0s - loss: 0.5842 - acc: 0.9547 - val_loss: 0.9502 - val_acc: 0.8338\n",
      "Epoch 106/1500\n",
      " - 0s - loss: 0.5800 - acc: 0.9555 - val_loss: 0.9464 - val_acc: 0.8309\n",
      "Epoch 107/1500\n",
      " - 0s - loss: 0.5738 - acc: 0.9562 - val_loss: 0.9466 - val_acc: 0.8338\n",
      "Epoch 108/1500\n",
      " - 0s - loss: 0.5691 - acc: 0.9540 - val_loss: 0.9372 - val_acc: 0.8309\n",
      "Epoch 109/1500\n",
      " - 0s - loss: 0.5643 - acc: 0.9562 - val_loss: 0.9363 - val_acc: 0.8309\n",
      "Epoch 110/1500\n",
      " - 0s - loss: 0.5606 - acc: 0.9562 - val_loss: 0.9330 - val_acc: 0.8309\n",
      "Epoch 111/1500\n",
      " - 0s - loss: 0.5559 - acc: 0.9555 - val_loss: 0.9272 - val_acc: 0.8309\n",
      "Epoch 112/1500\n",
      " - 0s - loss: 0.5514 - acc: 0.9591 - val_loss: 0.9255 - val_acc: 0.8367\n",
      "Epoch 113/1500\n",
      " - 0s - loss: 0.5471 - acc: 0.9569 - val_loss: 0.9216 - val_acc: 0.8338\n",
      "Epoch 114/1500\n",
      " - 0s - loss: 0.5432 - acc: 0.9577 - val_loss: 0.9175 - val_acc: 0.8280\n",
      "Epoch 115/1500\n",
      " - 0s - loss: 0.5382 - acc: 0.9562 - val_loss: 0.9144 - val_acc: 0.8367\n",
      "Epoch 116/1500\n",
      " - 0s - loss: 0.5346 - acc: 0.9569 - val_loss: 0.9133 - val_acc: 0.8309\n",
      "Epoch 117/1500\n",
      " - 0s - loss: 0.5299 - acc: 0.9577 - val_loss: 0.9085 - val_acc: 0.8309\n",
      "Epoch 118/1500\n",
      " - 0s - loss: 0.5259 - acc: 0.9569 - val_loss: 0.9027 - val_acc: 0.8367\n",
      "Epoch 119/1500\n",
      " - 0s - loss: 0.5223 - acc: 0.9577 - val_loss: 0.9046 - val_acc: 0.8338\n",
      "Epoch 120/1500\n",
      " - 0s - loss: 0.5191 - acc: 0.9584 - val_loss: 0.8970 - val_acc: 0.8251\n",
      "Epoch 121/1500\n",
      " - 0s - loss: 0.5142 - acc: 0.9591 - val_loss: 0.8955 - val_acc: 0.8367\n",
      "Epoch 122/1500\n",
      " - 0s - loss: 0.5099 - acc: 0.9591 - val_loss: 0.8924 - val_acc: 0.8338\n",
      "Epoch 123/1500\n",
      " - 0s - loss: 0.5068 - acc: 0.9591 - val_loss: 0.8873 - val_acc: 0.8367\n",
      "Epoch 124/1500\n",
      " - 0s - loss: 0.5023 - acc: 0.9606 - val_loss: 0.8886 - val_acc: 0.8367\n",
      "Epoch 125/1500\n",
      " - 0s - loss: 0.4992 - acc: 0.9591 - val_loss: 0.8850 - val_acc: 0.8280\n",
      "Epoch 126/1500\n",
      " - 0s - loss: 0.4949 - acc: 0.9591 - val_loss: 0.8796 - val_acc: 0.8367\n",
      "Epoch 127/1500\n",
      " - 0s - loss: 0.4923 - acc: 0.9591 - val_loss: 0.8783 - val_acc: 0.8367\n",
      "Epoch 128/1500\n",
      " - 0s - loss: 0.4878 - acc: 0.9613 - val_loss: 0.8743 - val_acc: 0.8309\n",
      "Epoch 129/1500\n",
      " - 0s - loss: 0.4845 - acc: 0.9620 - val_loss: 0.8689 - val_acc: 0.8338\n",
      "Epoch 130/1500\n",
      " - 0s - loss: 0.4828 - acc: 0.9620 - val_loss: 0.8745 - val_acc: 0.8367\n",
      "Epoch 131/1500\n",
      " - 0s - loss: 0.4785 - acc: 0.9613 - val_loss: 0.8640 - val_acc: 0.8338\n",
      "Epoch 132/1500\n",
      " - 0s - loss: 0.4754 - acc: 0.9613 - val_loss: 0.8644 - val_acc: 0.8338\n",
      "Epoch 133/1500\n",
      " - 0s - loss: 0.4717 - acc: 0.9599 - val_loss: 0.8609 - val_acc: 0.8338\n",
      "Epoch 134/1500\n",
      " - 0s - loss: 0.4686 - acc: 0.9620 - val_loss: 0.8623 - val_acc: 0.8309\n",
      "Epoch 135/1500\n",
      " - 0s - loss: 0.4658 - acc: 0.9642 - val_loss: 0.8577 - val_acc: 0.8338\n",
      "Epoch 136/1500\n",
      " - 0s - loss: 0.4613 - acc: 0.9628 - val_loss: 0.8510 - val_acc: 0.8309\n",
      "Epoch 137/1500\n",
      " - 0s - loss: 0.4586 - acc: 0.9613 - val_loss: 0.8510 - val_acc: 0.8367\n",
      "Epoch 138/1500\n",
      " - 0s - loss: 0.4549 - acc: 0.9628 - val_loss: 0.8514 - val_acc: 0.8309\n",
      "Epoch 139/1500\n",
      " - 0s - loss: 0.4527 - acc: 0.9620 - val_loss: 0.8430 - val_acc: 0.8367\n",
      "Epoch 140/1500\n",
      " - 0s - loss: 0.4490 - acc: 0.9620 - val_loss: 0.8467 - val_acc: 0.8367\n",
      "Epoch 141/1500\n",
      " - 0s - loss: 0.4458 - acc: 0.9650 - val_loss: 0.8435 - val_acc: 0.8309\n",
      "Epoch 142/1500\n",
      " - 0s - loss: 0.4429 - acc: 0.9642 - val_loss: 0.8382 - val_acc: 0.8367\n",
      "Epoch 143/1500\n",
      " - 0s - loss: 0.4414 - acc: 0.9613 - val_loss: 0.8370 - val_acc: 0.8309\n",
      "Epoch 144/1500\n",
      " - 0s - loss: 0.4367 - acc: 0.9635 - val_loss: 0.8346 - val_acc: 0.8338\n",
      "Epoch 145/1500\n",
      " - 0s - loss: 0.4343 - acc: 0.9650 - val_loss: 0.8339 - val_acc: 0.8397\n",
      "Epoch 146/1500\n",
      " - 0s - loss: 0.4317 - acc: 0.9657 - val_loss: 0.8307 - val_acc: 0.8426\n",
      "Epoch 147/1500\n",
      " - 0s - loss: 0.4284 - acc: 0.9672 - val_loss: 0.8269 - val_acc: 0.8397\n",
      "Epoch 148/1500\n",
      " - 0s - loss: 0.4268 - acc: 0.9650 - val_loss: 0.8262 - val_acc: 0.8338\n",
      "Epoch 149/1500\n",
      " - 0s - loss: 0.4234 - acc: 0.9664 - val_loss: 0.8257 - val_acc: 0.8338\n",
      "Epoch 150/1500\n",
      " - 0s - loss: 0.4195 - acc: 0.9672 - val_loss: 0.8219 - val_acc: 0.8367\n",
      "Epoch 151/1500\n",
      " - 0s - loss: 0.4172 - acc: 0.9672 - val_loss: 0.8202 - val_acc: 0.8397\n",
      "Epoch 152/1500\n",
      " - 0s - loss: 0.4147 - acc: 0.9672 - val_loss: 0.8163 - val_acc: 0.8397\n",
      "Epoch 153/1500\n",
      " - 0s - loss: 0.4120 - acc: 0.9635 - val_loss: 0.8161 - val_acc: 0.8251\n",
      "Epoch 154/1500\n",
      " - 0s - loss: 0.4090 - acc: 0.9686 - val_loss: 0.8134 - val_acc: 0.8338\n",
      "Epoch 155/1500\n",
      " - 0s - loss: 0.4071 - acc: 0.9693 - val_loss: 0.8123 - val_acc: 0.8367\n",
      "Epoch 156/1500\n",
      " - 0s - loss: 0.4063 - acc: 0.9650 - val_loss: 0.8107 - val_acc: 0.8309\n",
      "Epoch 157/1500\n",
      " - 0s - loss: 0.4019 - acc: 0.9686 - val_loss: 0.8085 - val_acc: 0.8397\n",
      "Epoch 158/1500\n",
      " - 0s - loss: 0.3997 - acc: 0.9693 - val_loss: 0.8076 - val_acc: 0.8397\n",
      "Epoch 159/1500\n",
      " - 0s - loss: 0.3974 - acc: 0.9679 - val_loss: 0.8032 - val_acc: 0.8367\n",
      "Epoch 160/1500\n",
      " - 0s - loss: 0.3941 - acc: 0.9686 - val_loss: 0.8012 - val_acc: 0.8338\n",
      "Epoch 161/1500\n",
      " - 0s - loss: 0.3920 - acc: 0.9679 - val_loss: 0.8025 - val_acc: 0.8367\n",
      "Epoch 162/1500\n",
      " - 0s - loss: 0.3898 - acc: 0.9701 - val_loss: 0.7999 - val_acc: 0.8309\n",
      "Epoch 163/1500\n",
      " - 0s - loss: 0.3876 - acc: 0.9708 - val_loss: 0.7972 - val_acc: 0.8338\n",
      "Epoch 164/1500\n",
      " - 0s - loss: 0.3846 - acc: 0.9693 - val_loss: 0.7936 - val_acc: 0.8280\n",
      "Epoch 165/1500\n",
      " - 0s - loss: 0.3826 - acc: 0.9693 - val_loss: 0.7923 - val_acc: 0.8367\n",
      "Epoch 166/1500\n",
      " - 0s - loss: 0.3797 - acc: 0.9686 - val_loss: 0.7940 - val_acc: 0.8309\n",
      "Epoch 167/1500\n",
      " - 0s - loss: 0.3782 - acc: 0.9708 - val_loss: 0.7895 - val_acc: 0.8338\n",
      "Epoch 168/1500\n",
      " - 0s - loss: 0.3765 - acc: 0.9708 - val_loss: 0.7890 - val_acc: 0.8367\n",
      "Epoch 169/1500\n",
      " - 0s - loss: 0.3735 - acc: 0.9715 - val_loss: 0.7871 - val_acc: 0.8338\n",
      "Epoch 170/1500\n",
      " - 0s - loss: 0.3711 - acc: 0.9701 - val_loss: 0.7870 - val_acc: 0.8309\n",
      "Epoch 171/1500\n",
      " - 0s - loss: 0.3689 - acc: 0.9715 - val_loss: 0.7834 - val_acc: 0.8367\n",
      "Epoch 172/1500\n",
      " - 0s - loss: 0.3669 - acc: 0.9715 - val_loss: 0.7830 - val_acc: 0.8338\n",
      "Epoch 173/1500\n",
      " - 0s - loss: 0.3646 - acc: 0.9701 - val_loss: 0.7805 - val_acc: 0.8367\n",
      "Epoch 174/1500\n",
      " - 0s - loss: 0.3625 - acc: 0.9715 - val_loss: 0.7784 - val_acc: 0.8367\n",
      "Epoch 175/1500\n",
      " - 0s - loss: 0.3611 - acc: 0.9708 - val_loss: 0.7784 - val_acc: 0.8309\n",
      "Epoch 176/1500\n",
      " - 0s - loss: 0.3579 - acc: 0.9715 - val_loss: 0.7754 - val_acc: 0.8338\n",
      "Epoch 177/1500\n",
      " - 0s - loss: 0.3565 - acc: 0.9715 - val_loss: 0.7759 - val_acc: 0.8397\n",
      "Epoch 178/1500\n",
      " - 0s - loss: 0.3543 - acc: 0.9701 - val_loss: 0.7720 - val_acc: 0.8309\n",
      "Epoch 179/1500\n",
      " - 0s - loss: 0.3520 - acc: 0.9723 - val_loss: 0.7709 - val_acc: 0.8397\n",
      "Epoch 180/1500\n",
      " - 0s - loss: 0.3501 - acc: 0.9708 - val_loss: 0.7708 - val_acc: 0.8367\n",
      "Epoch 181/1500\n",
      " - 0s - loss: 0.3478 - acc: 0.9723 - val_loss: 0.7687 - val_acc: 0.8338\n",
      "Epoch 182/1500\n",
      " - 0s - loss: 0.3467 - acc: 0.9730 - val_loss: 0.7696 - val_acc: 0.8397\n",
      "Epoch 183/1500\n",
      " - 0s - loss: 0.3447 - acc: 0.9708 - val_loss: 0.7633 - val_acc: 0.8280\n",
      "Epoch 184/1500\n",
      " - 0s - loss: 0.3422 - acc: 0.9708 - val_loss: 0.7639 - val_acc: 0.8367\n",
      "Epoch 185/1500\n",
      " - 0s - loss: 0.3406 - acc: 0.9723 - val_loss: 0.7635 - val_acc: 0.8280\n",
      "Epoch 186/1500\n",
      " - 0s - loss: 0.3383 - acc: 0.9723 - val_loss: 0.7615 - val_acc: 0.8338\n",
      "Epoch 187/1500\n",
      " - 0s - loss: 0.3366 - acc: 0.9715 - val_loss: 0.7599 - val_acc: 0.8367\n",
      "Epoch 188/1500\n",
      " - 0s - loss: 0.3345 - acc: 0.9701 - val_loss: 0.7604 - val_acc: 0.8338\n",
      "Epoch 189/1500\n",
      " - 0s - loss: 0.3330 - acc: 0.9708 - val_loss: 0.7569 - val_acc: 0.8309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1500\n",
      " - 0s - loss: 0.3313 - acc: 0.9723 - val_loss: 0.7565 - val_acc: 0.8367\n",
      "Epoch 191/1500\n",
      " - 0s - loss: 0.3294 - acc: 0.9737 - val_loss: 0.7549 - val_acc: 0.8426\n",
      "Epoch 192/1500\n",
      " - 0s - loss: 0.3278 - acc: 0.9730 - val_loss: 0.7539 - val_acc: 0.8367\n",
      "Epoch 193/1500\n",
      " - 0s - loss: 0.3260 - acc: 0.9708 - val_loss: 0.7527 - val_acc: 0.8367\n",
      "Epoch 194/1500\n",
      " - 0s - loss: 0.3241 - acc: 0.9737 - val_loss: 0.7530 - val_acc: 0.8309\n",
      "Epoch 195/1500\n",
      " - 0s - loss: 0.3228 - acc: 0.9737 - val_loss: 0.7476 - val_acc: 0.8309\n",
      "Epoch 196/1500\n",
      " - 0s - loss: 0.3205 - acc: 0.9737 - val_loss: 0.7490 - val_acc: 0.8397\n",
      "Epoch 197/1500\n",
      " - 0s - loss: 0.3193 - acc: 0.9723 - val_loss: 0.7483 - val_acc: 0.8251\n",
      "Epoch 198/1500\n",
      " - 0s - loss: 0.3171 - acc: 0.9723 - val_loss: 0.7492 - val_acc: 0.8338\n",
      "Epoch 199/1500\n",
      " - 0s - loss: 0.3161 - acc: 0.9737 - val_loss: 0.7448 - val_acc: 0.8338\n",
      "Epoch 200/1500\n",
      " - 0s - loss: 0.3136 - acc: 0.9745 - val_loss: 0.7423 - val_acc: 0.8338\n",
      "Epoch 201/1500\n",
      " - 0s - loss: 0.3121 - acc: 0.9745 - val_loss: 0.7405 - val_acc: 0.8338\n",
      "Epoch 202/1500\n",
      " - 0s - loss: 0.3109 - acc: 0.9737 - val_loss: 0.7432 - val_acc: 0.8338\n",
      "Epoch 203/1500\n",
      " - 0s - loss: 0.3086 - acc: 0.9730 - val_loss: 0.7400 - val_acc: 0.8367\n",
      "Epoch 204/1500\n",
      " - 0s - loss: 0.3072 - acc: 0.9745 - val_loss: 0.7387 - val_acc: 0.8455\n",
      "Epoch 205/1500\n",
      " - 0s - loss: 0.3057 - acc: 0.9730 - val_loss: 0.7390 - val_acc: 0.8367\n",
      "Epoch 206/1500\n",
      " - 0s - loss: 0.3040 - acc: 0.9745 - val_loss: 0.7367 - val_acc: 0.8309\n",
      "Epoch 207/1500\n",
      " - 0s - loss: 0.3024 - acc: 0.9745 - val_loss: 0.7359 - val_acc: 0.8397\n",
      "Epoch 208/1500\n",
      " - 0s - loss: 0.3003 - acc: 0.9730 - val_loss: 0.7360 - val_acc: 0.8338\n",
      "Epoch 209/1500\n",
      " - 0s - loss: 0.2993 - acc: 0.9752 - val_loss: 0.7359 - val_acc: 0.8338\n",
      "Epoch 210/1500\n",
      " - 0s - loss: 0.2974 - acc: 0.9752 - val_loss: 0.7334 - val_acc: 0.8397\n",
      "Epoch 211/1500\n",
      " - 0s - loss: 0.2961 - acc: 0.9745 - val_loss: 0.7315 - val_acc: 0.8397\n",
      "Epoch 212/1500\n",
      " - 0s - loss: 0.2950 - acc: 0.9737 - val_loss: 0.7303 - val_acc: 0.8280\n",
      "Epoch 213/1500\n",
      " - 0s - loss: 0.2931 - acc: 0.9752 - val_loss: 0.7297 - val_acc: 0.8309\n",
      "Epoch 214/1500\n",
      " - 0s - loss: 0.2915 - acc: 0.9752 - val_loss: 0.7277 - val_acc: 0.8426\n",
      "Epoch 215/1500\n",
      " - 0s - loss: 0.2897 - acc: 0.9752 - val_loss: 0.7284 - val_acc: 0.8338\n",
      "Epoch 216/1500\n",
      " - 0s - loss: 0.2892 - acc: 0.9737 - val_loss: 0.7281 - val_acc: 0.8367\n",
      "Epoch 217/1500\n",
      " - 0s - loss: 0.2872 - acc: 0.9745 - val_loss: 0.7249 - val_acc: 0.8309\n",
      "Epoch 218/1500\n",
      " - 0s - loss: 0.2862 - acc: 0.9752 - val_loss: 0.7271 - val_acc: 0.8367\n",
      "Epoch 219/1500\n",
      " - 0s - loss: 0.2843 - acc: 0.9752 - val_loss: 0.7224 - val_acc: 0.8367\n",
      "Epoch 220/1500\n",
      " - 0s - loss: 0.2831 - acc: 0.9774 - val_loss: 0.7235 - val_acc: 0.8367\n",
      "Epoch 221/1500\n",
      " - 0s - loss: 0.2821 - acc: 0.9745 - val_loss: 0.7233 - val_acc: 0.8338\n",
      "Epoch 222/1500\n",
      " - 0s - loss: 0.2803 - acc: 0.9766 - val_loss: 0.7201 - val_acc: 0.8309\n",
      "Epoch 223/1500\n",
      " - 0s - loss: 0.2787 - acc: 0.9774 - val_loss: 0.7198 - val_acc: 0.8338\n",
      "Epoch 224/1500\n",
      " - 0s - loss: 0.2774 - acc: 0.9745 - val_loss: 0.7174 - val_acc: 0.8338\n",
      "Epoch 225/1500\n",
      " - 0s - loss: 0.2762 - acc: 0.9759 - val_loss: 0.7205 - val_acc: 0.8367\n",
      "Epoch 226/1500\n",
      " - 0s - loss: 0.2749 - acc: 0.9766 - val_loss: 0.7179 - val_acc: 0.8397\n",
      "Epoch 227/1500\n",
      " - 0s - loss: 0.2740 - acc: 0.9766 - val_loss: 0.7167 - val_acc: 0.8309\n",
      "Epoch 228/1500\n",
      " - 0s - loss: 0.2721 - acc: 0.9774 - val_loss: 0.7138 - val_acc: 0.8338\n",
      "Epoch 229/1500\n",
      " - 0s - loss: 0.2707 - acc: 0.9752 - val_loss: 0.7136 - val_acc: 0.8338\n",
      "Epoch 230/1500\n",
      " - 0s - loss: 0.2692 - acc: 0.9759 - val_loss: 0.7144 - val_acc: 0.8367\n",
      "Epoch 231/1500\n",
      " - 0s - loss: 0.2689 - acc: 0.9774 - val_loss: 0.7166 - val_acc: 0.8280\n",
      "Epoch 232/1500\n",
      " - 0s - loss: 0.2667 - acc: 0.9788 - val_loss: 0.7130 - val_acc: 0.8309\n",
      "Epoch 233/1500\n",
      " - 0s - loss: 0.2654 - acc: 0.9766 - val_loss: 0.7072 - val_acc: 0.8397\n",
      "Epoch 234/1500\n",
      " - 0s - loss: 0.2641 - acc: 0.9774 - val_loss: 0.7109 - val_acc: 0.8280\n",
      "Epoch 235/1500\n",
      " - 0s - loss: 0.2637 - acc: 0.9803 - val_loss: 0.7127 - val_acc: 0.8251\n",
      "Epoch 236/1500\n",
      " - 0s - loss: 0.2616 - acc: 0.9781 - val_loss: 0.7089 - val_acc: 0.8309\n",
      "Epoch 237/1500\n",
      " - 0s - loss: 0.2607 - acc: 0.9788 - val_loss: 0.7052 - val_acc: 0.8338\n",
      "Epoch 238/1500\n",
      " - 0s - loss: 0.2588 - acc: 0.9788 - val_loss: 0.7073 - val_acc: 0.8280\n",
      "Epoch 239/1500\n",
      " - 0s - loss: 0.2577 - acc: 0.9766 - val_loss: 0.7074 - val_acc: 0.8338\n",
      "Epoch 240/1500\n",
      " - 0s - loss: 0.2571 - acc: 0.9774 - val_loss: 0.7074 - val_acc: 0.8280\n",
      "Epoch 241/1500\n",
      " - 0s - loss: 0.2550 - acc: 0.9781 - val_loss: 0.7082 - val_acc: 0.8309\n",
      "Epoch 242/1500\n",
      " - 0s - loss: 0.2540 - acc: 0.9796 - val_loss: 0.7040 - val_acc: 0.8309\n",
      "Epoch 243/1500\n",
      " - 0s - loss: 0.2529 - acc: 0.9796 - val_loss: 0.7035 - val_acc: 0.8309\n",
      "Epoch 244/1500\n",
      " - 0s - loss: 0.2517 - acc: 0.9796 - val_loss: 0.7036 - val_acc: 0.8309\n",
      "Epoch 245/1500\n",
      " - 0s - loss: 0.2507 - acc: 0.9803 - val_loss: 0.7040 - val_acc: 0.8309\n",
      "Epoch 246/1500\n",
      " - 0s - loss: 0.2502 - acc: 0.9796 - val_loss: 0.7023 - val_acc: 0.8338\n",
      "Epoch 247/1500\n",
      " - 0s - loss: 0.2482 - acc: 0.9796 - val_loss: 0.7009 - val_acc: 0.8338\n",
      "Epoch 248/1500\n",
      " - 0s - loss: 0.2478 - acc: 0.9796 - val_loss: 0.6984 - val_acc: 0.8280\n",
      "Epoch 249/1500\n",
      " - 0s - loss: 0.2463 - acc: 0.9803 - val_loss: 0.7021 - val_acc: 0.8309\n",
      "Epoch 250/1500\n",
      " - 0s - loss: 0.2458 - acc: 0.9810 - val_loss: 0.6989 - val_acc: 0.8367\n",
      "Epoch 251/1500\n",
      " - 0s - loss: 0.2437 - acc: 0.9796 - val_loss: 0.6989 - val_acc: 0.8251\n",
      "Epoch 252/1500\n",
      " - 0s - loss: 0.2421 - acc: 0.9796 - val_loss: 0.6976 - val_acc: 0.8367\n",
      "Epoch 253/1500\n",
      " - 0s - loss: 0.2425 - acc: 0.9810 - val_loss: 0.6967 - val_acc: 0.8280\n",
      "Epoch 254/1500\n",
      " - 0s - loss: 0.2411 - acc: 0.9796 - val_loss: 0.6988 - val_acc: 0.8309\n",
      "Epoch 255/1500\n",
      " - 0s - loss: 0.2390 - acc: 0.9818 - val_loss: 0.6978 - val_acc: 0.8309\n",
      "Epoch 256/1500\n",
      " - 0s - loss: 0.2385 - acc: 0.9810 - val_loss: 0.6953 - val_acc: 0.8309\n",
      "Epoch 257/1500\n",
      " - 0s - loss: 0.2376 - acc: 0.9796 - val_loss: 0.6928 - val_acc: 0.8280\n",
      "Epoch 258/1500\n",
      " - 0s - loss: 0.2360 - acc: 0.9810 - val_loss: 0.6936 - val_acc: 0.8367\n",
      "Epoch 259/1500\n",
      " - 0s - loss: 0.2347 - acc: 0.9818 - val_loss: 0.6950 - val_acc: 0.8280\n",
      "Epoch 260/1500\n",
      " - 0s - loss: 0.2343 - acc: 0.9818 - val_loss: 0.6908 - val_acc: 0.8280\n",
      "Epoch 261/1500\n",
      " - 0s - loss: 0.2326 - acc: 0.9810 - val_loss: 0.6943 - val_acc: 0.8251\n",
      "Epoch 262/1500\n",
      " - 0s - loss: 0.2320 - acc: 0.9803 - val_loss: 0.6901 - val_acc: 0.8367\n",
      "Epoch 263/1500\n",
      " - 0s - loss: 0.2312 - acc: 0.9803 - val_loss: 0.6917 - val_acc: 0.8309\n",
      "Epoch 264/1500\n",
      " - 0s - loss: 0.2297 - acc: 0.9796 - val_loss: 0.6896 - val_acc: 0.8367\n",
      "Epoch 265/1500\n",
      " - 0s - loss: 0.2291 - acc: 0.9810 - val_loss: 0.6878 - val_acc: 0.8309\n",
      "Epoch 266/1500\n",
      " - 0s - loss: 0.2275 - acc: 0.9818 - val_loss: 0.6893 - val_acc: 0.8309\n",
      "Epoch 267/1500\n",
      " - 0s - loss: 0.2267 - acc: 0.9810 - val_loss: 0.6874 - val_acc: 0.8338\n",
      "Epoch 268/1500\n",
      " - 0s - loss: 0.2259 - acc: 0.9818 - val_loss: 0.6913 - val_acc: 0.8309\n",
      "Epoch 269/1500\n",
      " - 0s - loss: 0.2246 - acc: 0.9825 - val_loss: 0.6847 - val_acc: 0.8338\n",
      "Epoch 270/1500\n",
      " - 0s - loss: 0.2236 - acc: 0.9810 - val_loss: 0.6833 - val_acc: 0.8338\n",
      "Epoch 271/1500\n",
      " - 0s - loss: 0.2227 - acc: 0.9810 - val_loss: 0.6885 - val_acc: 0.8338\n",
      "Epoch 272/1500\n",
      " - 0s - loss: 0.2217 - acc: 0.9818 - val_loss: 0.6878 - val_acc: 0.8251\n",
      "Epoch 273/1500\n",
      " - 0s - loss: 0.2206 - acc: 0.9825 - val_loss: 0.6865 - val_acc: 0.8367\n",
      "Epoch 274/1500\n",
      " - 0s - loss: 0.2201 - acc: 0.9810 - val_loss: 0.6854 - val_acc: 0.8309\n",
      "Epoch 275/1500\n",
      " - 0s - loss: 0.2188 - acc: 0.9818 - val_loss: 0.6825 - val_acc: 0.8309\n",
      "Epoch 276/1500\n",
      " - 0s - loss: 0.2179 - acc: 0.9825 - val_loss: 0.6832 - val_acc: 0.8309\n",
      "Epoch 277/1500\n",
      " - 0s - loss: 0.2167 - acc: 0.9818 - val_loss: 0.6824 - val_acc: 0.8367\n",
      "Epoch 278/1500\n",
      " - 0s - loss: 0.2159 - acc: 0.9818 - val_loss: 0.6800 - val_acc: 0.8309\n",
      "Epoch 279/1500\n",
      " - 0s - loss: 0.2154 - acc: 0.9810 - val_loss: 0.6869 - val_acc: 0.8309\n",
      "Epoch 280/1500\n",
      " - 0s - loss: 0.2139 - acc: 0.9818 - val_loss: 0.6800 - val_acc: 0.8338\n",
      "Epoch 281/1500\n",
      " - 0s - loss: 0.2129 - acc: 0.9825 - val_loss: 0.6797 - val_acc: 0.8367\n",
      "Epoch 282/1500\n",
      " - 0s - loss: 0.2119 - acc: 0.9818 - val_loss: 0.6798 - val_acc: 0.8309\n",
      "Epoch 283/1500\n",
      " - 0s - loss: 0.2114 - acc: 0.9818 - val_loss: 0.6828 - val_acc: 0.8280\n",
      "Epoch 284/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2101 - acc: 0.9825 - val_loss: 0.6782 - val_acc: 0.8338\n",
      "Epoch 285/1500\n",
      " - 0s - loss: 0.2090 - acc: 0.9818 - val_loss: 0.6796 - val_acc: 0.8397\n",
      "Epoch 286/1500\n",
      " - 0s - loss: 0.2082 - acc: 0.9818 - val_loss: 0.6783 - val_acc: 0.8309\n",
      "Epoch 287/1500\n",
      " - 0s - loss: 0.2077 - acc: 0.9825 - val_loss: 0.6821 - val_acc: 0.8280\n",
      "Epoch 288/1500\n",
      " - 0s - loss: 0.2068 - acc: 0.9810 - val_loss: 0.6750 - val_acc: 0.8309\n",
      "Epoch 289/1500\n",
      " - 0s - loss: 0.2057 - acc: 0.9825 - val_loss: 0.6771 - val_acc: 0.8309\n",
      "Epoch 290/1500\n",
      " - 0s - loss: 0.2046 - acc: 0.9818 - val_loss: 0.6749 - val_acc: 0.8367\n",
      "Epoch 291/1500\n",
      " - 0s - loss: 0.2039 - acc: 0.9818 - val_loss: 0.6752 - val_acc: 0.8309\n",
      "Epoch 292/1500\n",
      " - 0s - loss: 0.2032 - acc: 0.9818 - val_loss: 0.6766 - val_acc: 0.8309\n",
      "Epoch 293/1500\n",
      " - 0s - loss: 0.2027 - acc: 0.9825 - val_loss: 0.6787 - val_acc: 0.8280\n",
      "Epoch 294/1500\n",
      " - 0s - loss: 0.2016 - acc: 0.9825 - val_loss: 0.6752 - val_acc: 0.8280\n",
      "Epoch 295/1500\n",
      " - 0s - loss: 0.2007 - acc: 0.9818 - val_loss: 0.6732 - val_acc: 0.8367\n",
      "Epoch 296/1500\n",
      " - 0s - loss: 0.1997 - acc: 0.9832 - val_loss: 0.6735 - val_acc: 0.8251\n",
      "Epoch 297/1500\n",
      " - 0s - loss: 0.1988 - acc: 0.9825 - val_loss: 0.6742 - val_acc: 0.8338\n",
      "Epoch 298/1500\n",
      " - 0s - loss: 0.1984 - acc: 0.9825 - val_loss: 0.6739 - val_acc: 0.8309\n",
      "Epoch 299/1500\n",
      " - 0s - loss: 0.1972 - acc: 0.9839 - val_loss: 0.6711 - val_acc: 0.8309\n",
      "Epoch 300/1500\n",
      " - 0s - loss: 0.1968 - acc: 0.9825 - val_loss: 0.6740 - val_acc: 0.8338\n",
      "Epoch 301/1500\n",
      " - 0s - loss: 0.1957 - acc: 0.9832 - val_loss: 0.6714 - val_acc: 0.8338\n",
      "Epoch 302/1500\n",
      " - 0s - loss: 0.1950 - acc: 0.9825 - val_loss: 0.6722 - val_acc: 0.8251\n",
      "Epoch 303/1500\n",
      " - 0s - loss: 0.1938 - acc: 0.9825 - val_loss: 0.6733 - val_acc: 0.8280\n",
      "Epoch 304/1500\n",
      " - 0s - loss: 0.1932 - acc: 0.9832 - val_loss: 0.6703 - val_acc: 0.8309\n",
      "Epoch 305/1500\n",
      " - 0s - loss: 0.1920 - acc: 0.9832 - val_loss: 0.6703 - val_acc: 0.8338\n",
      "Epoch 306/1500\n",
      " - 0s - loss: 0.1916 - acc: 0.9839 - val_loss: 0.6693 - val_acc: 0.8309\n",
      "Epoch 307/1500\n",
      " - 0s - loss: 0.1912 - acc: 0.9839 - val_loss: 0.6705 - val_acc: 0.8280\n",
      "Epoch 308/1500\n",
      " - 0s - loss: 0.1897 - acc: 0.9832 - val_loss: 0.6684 - val_acc: 0.8338\n",
      "Epoch 309/1500\n",
      " - 0s - loss: 0.1890 - acc: 0.9839 - val_loss: 0.6695 - val_acc: 0.8367\n",
      "Epoch 310/1500\n",
      " - 0s - loss: 0.1884 - acc: 0.9839 - val_loss: 0.6673 - val_acc: 0.8309\n",
      "Epoch 311/1500\n",
      " - 0s - loss: 0.1878 - acc: 0.9847 - val_loss: 0.6670 - val_acc: 0.8309\n",
      "Epoch 312/1500\n",
      " - 0s - loss: 0.1869 - acc: 0.9847 - val_loss: 0.6707 - val_acc: 0.8251\n",
      "Epoch 313/1500\n",
      " - 0s - loss: 0.1859 - acc: 0.9854 - val_loss: 0.6688 - val_acc: 0.8280\n",
      "Epoch 314/1500\n",
      " - 0s - loss: 0.1853 - acc: 0.9839 - val_loss: 0.6673 - val_acc: 0.8251\n",
      "Epoch 315/1500\n",
      " - 0s - loss: 0.1846 - acc: 0.9847 - val_loss: 0.6702 - val_acc: 0.8251\n",
      "Epoch 316/1500\n",
      " - 0s - loss: 0.1838 - acc: 0.9847 - val_loss: 0.6674 - val_acc: 0.8251\n",
      "Epoch 317/1500\n",
      " - 0s - loss: 0.1830 - acc: 0.9847 - val_loss: 0.6677 - val_acc: 0.8309\n",
      "Epoch 318/1500\n",
      " - 0s - loss: 0.1826 - acc: 0.9847 - val_loss: 0.6660 - val_acc: 0.8309\n",
      "Epoch 319/1500\n",
      " - 0s - loss: 0.1816 - acc: 0.9861 - val_loss: 0.6654 - val_acc: 0.8280\n",
      "Epoch 320/1500\n",
      " - 0s - loss: 0.1814 - acc: 0.9839 - val_loss: 0.6667 - val_acc: 0.8222\n",
      "Epoch 321/1500\n",
      " - 0s - loss: 0.1803 - acc: 0.9861 - val_loss: 0.6648 - val_acc: 0.8251\n",
      "Epoch 322/1500\n",
      " - 0s - loss: 0.1788 - acc: 0.9876 - val_loss: 0.6642 - val_acc: 0.8280\n",
      "Epoch 323/1500\n",
      " - 0s - loss: 0.1789 - acc: 0.9861 - val_loss: 0.6652 - val_acc: 0.8309\n",
      "Epoch 324/1500\n",
      " - 0s - loss: 0.1779 - acc: 0.9854 - val_loss: 0.6675 - val_acc: 0.8222\n",
      "Epoch 325/1500\n",
      " - 0s - loss: 0.1770 - acc: 0.9854 - val_loss: 0.6676 - val_acc: 0.8192\n",
      "Epoch 326/1500\n",
      " - 0s - loss: 0.1762 - acc: 0.9869 - val_loss: 0.6639 - val_acc: 0.8251\n",
      "Epoch 327/1500\n",
      " - 0s - loss: 0.1762 - acc: 0.9876 - val_loss: 0.6633 - val_acc: 0.8309\n",
      "Epoch 328/1500\n",
      " - 0s - loss: 0.1758 - acc: 0.9847 - val_loss: 0.6632 - val_acc: 0.8222\n",
      "Epoch 329/1500\n",
      " - 0s - loss: 0.1741 - acc: 0.9861 - val_loss: 0.6617 - val_acc: 0.8280\n",
      "Epoch 330/1500\n",
      " - 0s - loss: 0.1739 - acc: 0.9861 - val_loss: 0.6647 - val_acc: 0.8222\n",
      "Epoch 331/1500\n",
      " - 0s - loss: 0.1733 - acc: 0.9876 - val_loss: 0.6622 - val_acc: 0.8309\n",
      "Epoch 332/1500\n",
      " - 0s - loss: 0.1721 - acc: 0.9883 - val_loss: 0.6621 - val_acc: 0.8280\n",
      "Epoch 333/1500\n",
      " - 0s - loss: 0.1715 - acc: 0.9876 - val_loss: 0.6609 - val_acc: 0.8280\n",
      "Epoch 334/1500\n",
      " - 0s - loss: 0.1707 - acc: 0.9861 - val_loss: 0.6631 - val_acc: 0.8222\n",
      "Epoch 335/1500\n",
      " - 0s - loss: 0.1702 - acc: 0.9891 - val_loss: 0.6630 - val_acc: 0.8251\n",
      "Epoch 336/1500\n",
      " - 0s - loss: 0.1695 - acc: 0.9876 - val_loss: 0.6601 - val_acc: 0.8251\n",
      "Epoch 337/1500\n",
      " - 0s - loss: 0.1687 - acc: 0.9876 - val_loss: 0.6621 - val_acc: 0.8280\n",
      "Epoch 338/1500\n",
      " - 0s - loss: 0.1680 - acc: 0.9891 - val_loss: 0.6598 - val_acc: 0.8222\n",
      "Epoch 339/1500\n",
      " - 0s - loss: 0.1677 - acc: 0.9876 - val_loss: 0.6616 - val_acc: 0.8251\n",
      "Epoch 340/1500\n",
      " - 0s - loss: 0.1672 - acc: 0.9883 - val_loss: 0.6639 - val_acc: 0.8222\n",
      "Epoch 341/1500\n",
      " - 0s - loss: 0.1667 - acc: 0.9883 - val_loss: 0.6590 - val_acc: 0.8251\n",
      "Epoch 342/1500\n",
      " - 0s - loss: 0.1653 - acc: 0.9891 - val_loss: 0.6600 - val_acc: 0.8222\n",
      "Epoch 343/1500\n",
      " - 0s - loss: 0.1650 - acc: 0.9883 - val_loss: 0.6588 - val_acc: 0.8251\n",
      "Epoch 344/1500\n",
      " - 0s - loss: 0.1638 - acc: 0.9891 - val_loss: 0.6593 - val_acc: 0.8222\n",
      "Epoch 345/1500\n",
      " - 0s - loss: 0.1636 - acc: 0.9891 - val_loss: 0.6595 - val_acc: 0.8280\n",
      "Epoch 346/1500\n",
      " - 0s - loss: 0.1628 - acc: 0.9898 - val_loss: 0.6599 - val_acc: 0.8280\n",
      "Epoch 347/1500\n",
      " - 0s - loss: 0.1623 - acc: 0.9876 - val_loss: 0.6594 - val_acc: 0.8280\n",
      "Epoch 348/1500\n",
      " - 0s - loss: 0.1613 - acc: 0.9883 - val_loss: 0.6575 - val_acc: 0.8251\n",
      "Epoch 349/1500\n",
      " - 0s - loss: 0.1612 - acc: 0.9891 - val_loss: 0.6593 - val_acc: 0.8251\n",
      "Epoch 350/1500\n",
      " - 0s - loss: 0.1600 - acc: 0.9891 - val_loss: 0.6600 - val_acc: 0.8309\n",
      "Epoch 351/1500\n",
      " - 0s - loss: 0.1597 - acc: 0.9898 - val_loss: 0.6578 - val_acc: 0.8251\n",
      "Epoch 352/1500\n",
      " - 0s - loss: 0.1598 - acc: 0.9898 - val_loss: 0.6592 - val_acc: 0.8222\n",
      "Epoch 353/1500\n",
      " - 0s - loss: 0.1591 - acc: 0.9898 - val_loss: 0.6613 - val_acc: 0.8222\n",
      "Epoch 354/1500\n",
      " - 0s - loss: 0.1576 - acc: 0.9905 - val_loss: 0.6583 - val_acc: 0.8251\n",
      "Epoch 355/1500\n",
      " - 0s - loss: 0.1571 - acc: 0.9898 - val_loss: 0.6565 - val_acc: 0.8251\n",
      "Epoch 356/1500\n",
      " - 0s - loss: 0.1570 - acc: 0.9891 - val_loss: 0.6556 - val_acc: 0.8251\n",
      "Epoch 357/1500\n",
      " - 0s - loss: 0.1558 - acc: 0.9905 - val_loss: 0.6576 - val_acc: 0.8222\n",
      "Epoch 358/1500\n",
      " - 0s - loss: 0.1552 - acc: 0.9912 - val_loss: 0.6589 - val_acc: 0.8222\n",
      "Epoch 359/1500\n",
      " - 0s - loss: 0.1548 - acc: 0.9920 - val_loss: 0.6572 - val_acc: 0.8280\n",
      "Epoch 360/1500\n",
      " - 0s - loss: 0.1539 - acc: 0.9905 - val_loss: 0.6560 - val_acc: 0.8280\n",
      "Epoch 361/1500\n",
      " - 0s - loss: 0.1544 - acc: 0.9912 - val_loss: 0.6546 - val_acc: 0.8338\n",
      "Epoch 362/1500\n",
      " - 0s - loss: 0.1532 - acc: 0.9920 - val_loss: 0.6567 - val_acc: 0.8280\n",
      "Epoch 363/1500\n",
      " - 0s - loss: 0.1525 - acc: 0.9912 - val_loss: 0.6581 - val_acc: 0.8222\n",
      "Epoch 364/1500\n",
      " - 0s - loss: 0.1517 - acc: 0.9912 - val_loss: 0.6567 - val_acc: 0.8222\n",
      "Epoch 365/1500\n",
      " - 0s - loss: 0.1515 - acc: 0.9905 - val_loss: 0.6572 - val_acc: 0.8280\n",
      "Epoch 366/1500\n",
      " - 0s - loss: 0.1507 - acc: 0.9920 - val_loss: 0.6560 - val_acc: 0.8280\n",
      "Epoch 367/1500\n",
      " - 0s - loss: 0.1499 - acc: 0.9927 - val_loss: 0.6536 - val_acc: 0.8309\n",
      "Epoch 368/1500\n",
      " - 0s - loss: 0.1496 - acc: 0.9912 - val_loss: 0.6573 - val_acc: 0.8280\n",
      "Epoch 369/1500\n",
      " - 0s - loss: 0.1489 - acc: 0.9898 - val_loss: 0.6554 - val_acc: 0.8251\n",
      "Epoch 370/1500\n",
      " - 0s - loss: 0.1486 - acc: 0.9912 - val_loss: 0.6533 - val_acc: 0.8251\n",
      "Epoch 371/1500\n",
      " - 0s - loss: 0.1479 - acc: 0.9898 - val_loss: 0.6564 - val_acc: 0.8222\n",
      "Epoch 372/1500\n",
      " - 0s - loss: 0.1474 - acc: 0.9927 - val_loss: 0.6540 - val_acc: 0.8280\n",
      "Epoch 373/1500\n",
      " - 0s - loss: 0.1471 - acc: 0.9920 - val_loss: 0.6537 - val_acc: 0.8251\n",
      "Epoch 374/1500\n",
      " - 0s - loss: 0.1463 - acc: 0.9927 - val_loss: 0.6591 - val_acc: 0.8222\n",
      "Epoch 375/1500\n",
      " - 0s - loss: 0.1457 - acc: 0.9912 - val_loss: 0.6531 - val_acc: 0.8280\n",
      "Epoch 376/1500\n",
      " - 0s - loss: 0.1453 - acc: 0.9920 - val_loss: 0.6563 - val_acc: 0.8251\n",
      "Epoch 377/1500\n",
      " - 0s - loss: 0.1444 - acc: 0.9920 - val_loss: 0.6592 - val_acc: 0.8280\n",
      "Epoch 378/1500\n",
      " - 0s - loss: 0.1440 - acc: 0.9905 - val_loss: 0.6542 - val_acc: 0.8309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1500\n",
      " - 0s - loss: 0.1431 - acc: 0.9927 - val_loss: 0.6535 - val_acc: 0.8280\n",
      "Epoch 380/1500\n",
      " - 0s - loss: 0.1426 - acc: 0.9920 - val_loss: 0.6539 - val_acc: 0.8280\n",
      "Epoch 381/1500\n",
      " - 0s - loss: 0.1420 - acc: 0.9920 - val_loss: 0.6540 - val_acc: 0.8280\n",
      "Epoch 382/1500\n",
      " - 0s - loss: 0.1418 - acc: 0.9934 - val_loss: 0.6558 - val_acc: 0.8251\n",
      "Epoch 383/1500\n",
      " - 0s - loss: 0.1410 - acc: 0.9927 - val_loss: 0.6537 - val_acc: 0.8251\n",
      "Epoch 384/1500\n",
      " - 0s - loss: 0.1406 - acc: 0.9934 - val_loss: 0.6553 - val_acc: 0.8251\n",
      "Epoch 385/1500\n",
      " - 0s - loss: 0.1403 - acc: 0.9905 - val_loss: 0.6558 - val_acc: 0.8222\n",
      "Epoch 386/1500\n",
      " - 0s - loss: 0.1394 - acc: 0.9920 - val_loss: 0.6524 - val_acc: 0.8280\n",
      "Epoch 387/1500\n",
      " - 0s - loss: 0.1392 - acc: 0.9927 - val_loss: 0.6557 - val_acc: 0.8251\n",
      "Epoch 388/1500\n",
      " - 0s - loss: 0.1386 - acc: 0.9934 - val_loss: 0.6532 - val_acc: 0.8280\n",
      "Epoch 389/1500\n",
      " - 0s - loss: 0.1378 - acc: 0.9927 - val_loss: 0.6528 - val_acc: 0.8251\n",
      "Epoch 390/1500\n",
      " - 0s - loss: 0.1378 - acc: 0.9934 - val_loss: 0.6528 - val_acc: 0.8280\n",
      "Epoch 391/1500\n",
      " - 0s - loss: 0.1369 - acc: 0.9927 - val_loss: 0.6565 - val_acc: 0.8251\n",
      "Epoch 392/1500\n",
      " - 0s - loss: 0.1361 - acc: 0.9927 - val_loss: 0.6549 - val_acc: 0.8280\n",
      "Epoch 393/1500\n",
      " - 0s - loss: 0.1358 - acc: 0.9934 - val_loss: 0.6536 - val_acc: 0.8251\n",
      "Epoch 394/1500\n",
      " - 0s - loss: 0.1355 - acc: 0.9934 - val_loss: 0.6536 - val_acc: 0.8251\n",
      "Epoch 395/1500\n",
      " - 0s - loss: 0.1348 - acc: 0.9934 - val_loss: 0.6555 - val_acc: 0.8280\n",
      "Epoch 396/1500\n",
      " - 0s - loss: 0.1345 - acc: 0.9927 - val_loss: 0.6519 - val_acc: 0.8280\n",
      "Epoch 397/1500\n",
      " - 0s - loss: 0.1336 - acc: 0.9927 - val_loss: 0.6547 - val_acc: 0.8280\n",
      "Epoch 398/1500\n",
      " - 0s - loss: 0.1333 - acc: 0.9934 - val_loss: 0.6539 - val_acc: 0.8280\n",
      "Epoch 399/1500\n",
      " - 0s - loss: 0.1328 - acc: 0.9934 - val_loss: 0.6532 - val_acc: 0.8280\n",
      "Epoch 400/1500\n",
      " - 0s - loss: 0.1325 - acc: 0.9934 - val_loss: 0.6530 - val_acc: 0.8251\n",
      "Epoch 401/1500\n",
      " - 0s - loss: 0.1325 - acc: 0.9927 - val_loss: 0.6546 - val_acc: 0.8280\n",
      "Epoch 402/1500\n",
      " - 0s - loss: 0.1318 - acc: 0.9934 - val_loss: 0.6561 - val_acc: 0.8251\n",
      "Epoch 403/1500\n",
      " - 0s - loss: 0.1314 - acc: 0.9934 - val_loss: 0.6520 - val_acc: 0.8251\n",
      "Epoch 404/1500\n",
      " - 0s - loss: 0.1304 - acc: 0.9934 - val_loss: 0.6529 - val_acc: 0.8280\n",
      "Epoch 405/1500\n",
      " - 0s - loss: 0.1301 - acc: 0.9934 - val_loss: 0.6548 - val_acc: 0.8280\n",
      "Epoch 406/1500\n",
      " - 0s - loss: 0.1297 - acc: 0.9934 - val_loss: 0.6554 - val_acc: 0.8251\n",
      "Epoch 407/1500\n",
      " - 0s - loss: 0.1289 - acc: 0.9934 - val_loss: 0.6527 - val_acc: 0.8280\n",
      "Epoch 408/1500\n",
      " - 0s - loss: 0.1288 - acc: 0.9934 - val_loss: 0.6543 - val_acc: 0.8251\n",
      "Epoch 409/1500\n",
      " - 0s - loss: 0.1280 - acc: 0.9934 - val_loss: 0.6550 - val_acc: 0.8309\n",
      "Epoch 410/1500\n",
      " - 0s - loss: 0.1275 - acc: 0.9934 - val_loss: 0.6539 - val_acc: 0.8280\n",
      "Epoch 411/1500\n",
      " - 0s - loss: 0.1274 - acc: 0.9934 - val_loss: 0.6544 - val_acc: 0.8251\n",
      "Epoch 412/1500\n",
      " - 0s - loss: 0.1268 - acc: 0.9934 - val_loss: 0.6506 - val_acc: 0.8251\n",
      "Epoch 413/1500\n",
      " - 0s - loss: 0.1261 - acc: 0.9934 - val_loss: 0.6512 - val_acc: 0.8309\n",
      "Epoch 414/1500\n",
      " - 0s - loss: 0.1256 - acc: 0.9934 - val_loss: 0.6557 - val_acc: 0.8251\n",
      "Epoch 415/1500\n",
      " - 0s - loss: 0.1254 - acc: 0.9934 - val_loss: 0.6528 - val_acc: 0.8251\n",
      "Epoch 416/1500\n",
      " - 0s - loss: 0.1247 - acc: 0.9934 - val_loss: 0.6546 - val_acc: 0.8280\n",
      "Epoch 417/1500\n",
      " - 0s - loss: 0.1243 - acc: 0.9934 - val_loss: 0.6547 - val_acc: 0.8280\n",
      "Epoch 418/1500\n",
      " - 0s - loss: 0.1242 - acc: 0.9927 - val_loss: 0.6529 - val_acc: 0.8280\n",
      "Epoch 419/1500\n",
      " - 0s - loss: 0.1235 - acc: 0.9934 - val_loss: 0.6530 - val_acc: 0.8251\n",
      "Epoch 420/1500\n",
      " - 0s - loss: 0.1230 - acc: 0.9934 - val_loss: 0.6544 - val_acc: 0.8309\n",
      "Epoch 421/1500\n",
      " - 0s - loss: 0.1229 - acc: 0.9934 - val_loss: 0.6528 - val_acc: 0.8222\n",
      "Epoch 422/1500\n",
      " - 0s - loss: 0.1224 - acc: 0.9934 - val_loss: 0.6534 - val_acc: 0.8280\n",
      "Epoch 423/1500\n",
      " - 0s - loss: 0.1217 - acc: 0.9934 - val_loss: 0.6576 - val_acc: 0.8280\n",
      "Epoch 424/1500\n",
      " - 0s - loss: 0.1211 - acc: 0.9934 - val_loss: 0.6533 - val_acc: 0.8280\n",
      "Epoch 425/1500\n",
      " - 0s - loss: 0.1210 - acc: 0.9934 - val_loss: 0.6521 - val_acc: 0.8222\n",
      "Epoch 426/1500\n",
      " - 0s - loss: 0.1202 - acc: 0.9934 - val_loss: 0.6550 - val_acc: 0.8338\n",
      "Epoch 427/1500\n",
      " - 0s - loss: 0.1199 - acc: 0.9942 - val_loss: 0.6544 - val_acc: 0.8251\n",
      "Epoch 428/1500\n",
      " - 0s - loss: 0.1198 - acc: 0.9934 - val_loss: 0.6507 - val_acc: 0.8309\n",
      "Epoch 429/1500\n",
      " - 0s - loss: 0.1190 - acc: 0.9942 - val_loss: 0.6543 - val_acc: 0.8309\n",
      "Epoch 430/1500\n",
      " - 0s - loss: 0.1187 - acc: 0.9934 - val_loss: 0.6570 - val_acc: 0.8280\n",
      "Epoch 431/1500\n",
      " - 0s - loss: 0.1185 - acc: 0.9934 - val_loss: 0.6524 - val_acc: 0.8251\n",
      "Epoch 432/1500\n",
      " - 0s - loss: 0.1176 - acc: 0.9942 - val_loss: 0.6531 - val_acc: 0.8280\n",
      "Epoch 433/1500\n",
      " - 0s - loss: 0.1174 - acc: 0.9942 - val_loss: 0.6548 - val_acc: 0.8251\n",
      "Epoch 434/1500\n",
      " - 0s - loss: 0.1168 - acc: 0.9942 - val_loss: 0.6551 - val_acc: 0.8251\n",
      "Epoch 435/1500\n",
      " - 0s - loss: 0.1167 - acc: 0.9934 - val_loss: 0.6535 - val_acc: 0.8280\n",
      "Epoch 436/1500\n",
      " - 0s - loss: 0.1161 - acc: 0.9934 - val_loss: 0.6525 - val_acc: 0.8280\n",
      "Epoch 437/1500\n",
      " - 0s - loss: 0.1159 - acc: 0.9942 - val_loss: 0.6513 - val_acc: 0.8280\n",
      "Epoch 438/1500\n",
      " - 0s - loss: 0.1153 - acc: 0.9942 - val_loss: 0.6567 - val_acc: 0.8280\n",
      "Epoch 439/1500\n",
      " - 0s - loss: 0.1153 - acc: 0.9942 - val_loss: 0.6523 - val_acc: 0.8280\n",
      "Epoch 440/1500\n",
      " - 0s - loss: 0.1148 - acc: 0.9942 - val_loss: 0.6555 - val_acc: 0.8222\n",
      "Epoch 441/1500\n",
      " - 0s - loss: 0.1142 - acc: 0.9934 - val_loss: 0.6514 - val_acc: 0.8309\n",
      "Epoch 442/1500\n",
      " - 0s - loss: 0.1136 - acc: 0.9942 - val_loss: 0.6547 - val_acc: 0.8251\n",
      "Epoch 443/1500\n",
      " - 0s - loss: 0.1132 - acc: 0.9942 - val_loss: 0.6538 - val_acc: 0.8280\n",
      "Epoch 444/1500\n",
      " - 0s - loss: 0.1129 - acc: 0.9942 - val_loss: 0.6512 - val_acc: 0.8280\n",
      "Epoch 445/1500\n",
      " - 0s - loss: 0.1125 - acc: 0.9942 - val_loss: 0.6548 - val_acc: 0.8309\n",
      "Epoch 446/1500\n",
      " - 0s - loss: 0.1122 - acc: 0.9942 - val_loss: 0.6507 - val_acc: 0.8338\n",
      "Epoch 447/1500\n",
      " - 0s - loss: 0.1116 - acc: 0.9942 - val_loss: 0.6570 - val_acc: 0.8280\n",
      "Epoch 448/1500\n",
      " - 0s - loss: 0.1109 - acc: 0.9942 - val_loss: 0.6530 - val_acc: 0.8280\n",
      "Epoch 449/1500\n",
      " - 0s - loss: 0.1109 - acc: 0.9942 - val_loss: 0.6510 - val_acc: 0.8309\n",
      "Epoch 450/1500\n",
      " - 0s - loss: 0.1107 - acc: 0.9942 - val_loss: 0.6516 - val_acc: 0.8280\n",
      "Epoch 451/1500\n",
      " - 0s - loss: 0.1101 - acc: 0.9942 - val_loss: 0.6537 - val_acc: 0.8309\n",
      "Epoch 452/1500\n",
      " - 0s - loss: 0.1099 - acc: 0.9942 - val_loss: 0.6546 - val_acc: 0.8280\n",
      "Epoch 453/1500\n",
      " - 0s - loss: 0.1092 - acc: 0.9949 - val_loss: 0.6542 - val_acc: 0.8338\n",
      "Epoch 454/1500\n",
      " - 0s - loss: 0.1090 - acc: 0.9942 - val_loss: 0.6547 - val_acc: 0.8280\n",
      "Epoch 455/1500\n",
      " - 0s - loss: 0.1084 - acc: 0.9942 - val_loss: 0.6524 - val_acc: 0.8280\n",
      "Epoch 456/1500\n",
      " - 0s - loss: 0.1084 - acc: 0.9942 - val_loss: 0.6551 - val_acc: 0.8367\n",
      "Epoch 457/1500\n",
      " - 0s - loss: 0.1076 - acc: 0.9942 - val_loss: 0.6530 - val_acc: 0.8251\n",
      "Epoch 458/1500\n",
      " - 0s - loss: 0.1073 - acc: 0.9942 - val_loss: 0.6523 - val_acc: 0.8280\n",
      "Epoch 459/1500\n",
      " - 0s - loss: 0.1074 - acc: 0.9942 - val_loss: 0.6523 - val_acc: 0.8251\n",
      "Epoch 460/1500\n",
      " - 0s - loss: 0.1065 - acc: 0.9942 - val_loss: 0.6537 - val_acc: 0.8280\n",
      "Epoch 461/1500\n",
      " - 0s - loss: 0.1063 - acc: 0.9942 - val_loss: 0.6547 - val_acc: 0.8222\n",
      "Epoch 462/1500\n",
      " - 0s - loss: 0.1058 - acc: 0.9942 - val_loss: 0.6545 - val_acc: 0.8309\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_history = model.fit(X_train, Y_train, \n",
    "                          batch_size = 100, \n",
    "                          epochs = 1500, \n",
    "                          verbose = 2,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [es]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XHW9//HXJzOTTPa9bZp0pQVK9xJKkX2VRUBWQVFQsIqi4HZFvVfFK169+kNEFARBUQHhggKyiCxlEyhtoXuB7m26Zmn2bWby+f3xPUnTNEnTNieTZj7Px2MeM3PO95z5zIHOO9+zfI+oKsYYYwxAUrwLMMYYM3hYKBhjjOlgoWCMMaaDhYIxxpgOFgrGGGM6WCgYY4zpYKFgEp6IBESkXkRG+7T+8SJS78e6jelvFgrmkOP9gLc/2kSkqdP7T+3v+lQ1pqoZqrrpAGqZICJ7XewjIn8RkR9661+nqhl9WNd1IvLK/tZgTH8KxrsAY/ZX5x9YEdkAXKeqL/bUXkSCqhodiNriKVG+p/GX9RTMkCMiPxaRR0TkYRGpA64SkeNE5G0RqRaRbSJyh4iEvPZBEVERGeu9/4s3/zkRqRORt0Rk3EHUs0dvQkSuFZEN3rrXicgVIjIVuBM40evxVHhtc7x6yr1lviMi4s27TkRe82qtAn7sfb9JnT6rSEQaRST/QOs3icVCwQxVFwEPAdnAI0AUuBEoAI4Hzga+0MvynwT+C8gDNgH/3R9FiUgWcBtwpqpmerUsVdVlwA3A696urAJvkd8CacB44DTgWuAznVb5EWAVUAjcAjwKXNXlezyvqpX9Ub8Z+iwUzFD1hqr+Q1XbVLVJVReo6nxVjarqOuAe4OReln9MVReqagR4EJjR24d5f6F3PIDLe2muwBQRCavqNlVd2cM6Q956blbVOq/uXwKf7tRsk6re5R0XaQIeAD7Z3pvw2v65t9qN6cxCwQxVmzu/EZEjReQZEdkuIrXAj3C9hp5s7/S6Eej1QLGq5nR+4P5i765dLXAl8GVgu4g8LSKH97DaYUAA2Nhp2kaguNP7Pb6nqv4b1ys6QUSmAKOBZ3qr3ZjOLBTMUNX1jKDfAcuBCaqaBXwfkL2WGgCq+pyqngEUAWu82mDvmncCMWBMp2mjgS2dV9fNR/wJtwvp08CjqtrSH3WbxGChYBJFJlADNHgHYns7nuAb78Dv+SKSBrQCDbgffoAdQEn7AXBv19VjwE9EJMM72P014C/7+Jg/A5fijif8yYevYYYwCwWTKL4BXA3U4f4yfyROdQSAbwHbgErcgeIbvHkvAKuBHSLSvvvqS7jwWA+8ijtm0OsPvapuAJYBrar6Zj/Xb4Y4sZvsGDP0iMifgHWq+sN412IOLXbxmjFDjIiMBy4Epsa7FnPosd1HxgwhIvI/wBLgJwcybIcxtvvIGGNMB+spGGOM6XDIHVMoKCjQsWPHxrsMY4w5pCxatKhCVQv31e6QC4WxY8eycOHCeJdhjDGHFBHZuO9WtvvIGGNMJxYKxhhjOlgoGGOM6XDIHVMwxgwtkUiEsrIympub413KkBAOhykpKSEUCh3Q8hYKxpi4KisrIzMzk7Fjx7L7NhDmQKgqlZWVlJWVMW7cgd0s0HYfGWPiqrm5mfz8fAuEfiAi5OfnH1Svy0LBGBN3Fgj952C3ZcKEwgfb6/jF8x9Q1dAa71KMMWbQSphQWFdez53z1rC9xg5mGWN2q66u5re//e1+L3fuuedSXV3tQ0XxlTChkBl2R+LrmiNxrsQYM5j0FAqxWKyb1rs9++yz5OTk+FVW3CTM2UeZYfdV65qjca7EGDOY3Hzzzaxdu5YZM2YQCoXIyMigqKiIxYsXs3LlSj7+8Y+zefNmmpubufHGG5k7dy6we8id+vp6zjnnHE444QTefPNNiouLefLJJ0lNTY3zNzswCRMK+fUf8L3gX2ipHQ0Mj3c5xphu3PKPFazcWtuv6zxqZBY/OH9yj/N/+tOfsnz5chYvXswrr7zCeeedx/LlyztO6bz//vvJy8ujqamJY445hksuuYT8/Pw91rF69Woefvhh7r33Xi6//HIef/xxrrrqqn79HgPFt91HIhIWkXdEZImIrBCRW7ppc42IlIvIYu9xnV/1ZDZt4fPBZ9GaMr8+whgzBMyePXuPc/zvuOMOpk+fzpw5c9i8eTOrV6/ea5lx48YxY8YMAI4++mg2bNgwUOX2Oz97Ci3AaapaLyIh4A0ReU5V3+7S7hFVvaGb5ftVOMf1Dtrqy/3+KGPMAertL/qBkp6e3vH6lVde4cUXX+Stt94iLS2NU045pdtrAFJSUjpeBwIBmpqaBqRWP/gWCupu6VbvvQ15j7jd5i050w0jLo2V8SrBGDMIZWZmUldX1+28mpoacnNzSUtL4/333+ftt7v+TTv0+HpMQUQCwCJgAvAbVZ3fTbNLROQk4EPga6q62Zda0gsASGqyUDDG7Jafn8/xxx/PlClTSE1NZfjw3ccczz77bO6++26mTZvGEUccwZw5c+JY6cDwNRRUNQbMEJEc4O8iMkVVl3dq8g/gYVVtEZEvAg8Ap3Vdj4jMBeYCjB49+sCKCecQJYlQc9WBLW+MGbIeeuihbqenpKTw3HPPdTuv/bhBQUEBy5fv/ln75je/2e/1DaQBuU5BVauBV4Czu0yvVNUW7+29wNE9LH+Pqpaqamlh4T7vJte9pCTqJIuUVgsFY4zpiZ9nHxV6PQREJBU4A3i/S5uiTm8vAFb5VQ9AXSCH1MjQuwLRGGP6i5+7j4qAB7zjCknAo6r6tIj8CFioqk8BXxWRC4AoUAVc42M9NAZzSLdQMMaYHvl59tFSYGY307/f6fV3gO/4VUNXLcm55Da/v++GxhiToBJm7COAaDifbK3FnS1rjDGmq4QKhba0fLKlgcYmGynVGGO6k1Ch0H6tQk3V9jhXYow5VGVkZACwdetWLr300m7bnHLKKSxcuLDX9dx+++00NjZ2vB8sQ3EnVCgEvauaG3btjHMlxphD3ciRI3nssccOePmuoTBYhuJOqFBIyXZXKjZV74hzJcaYweLb3/72HvdT+OEPf8gtt9zC6aefzqxZs5g6dSpPPvnkXstt2LCBKVOmANDU1MQVV1zBtGnT+MQnPrHH2EfXX389paWlTJ48mR/84AeAG2Rv69atnHrqqZx66qmAG4q7oqICgNtuu40pU6YwZcoUbr/99o7PmzRpEp///OeZPHkyZ511li9jLCXM0NkAaTnDAGittZ6CMYPSczfD9mX9u84RU+Gcn/Y4+4orruCmm27iS1/6EgCPPvoo//znP/na175GVlYWFRUVzJkzhwsuuKDH+x/fddddpKWlsXTpUpYuXcqsWbM65t16663k5eURi8U4/fTTWbp0KV/96le57bbbmDdvHgUFBXusa9GiRfzhD39g/vz5qCrHHnssJ598Mrm5uQMyRHdC9RTS80YAEKuzkVKNMc7MmTPZuXMnW7duZcmSJeTm5lJUVMR3v/tdpk2bxhlnnMGWLVvYsaPnPQyvvfZax4/ztGnTmDZtWse8Rx99lFmzZjFz5kxWrFjBypUre63njTfe4KKLLiI9PZ2MjAwuvvhiXn/9dWBghuhOqJ5Cdt5w2lSgwQbFM2ZQ6uUvej9deumlPPbYY2zfvp0rrriCBx98kPLychYtWkQoFGLs2LHdDpndWXe9iPXr1/OLX/yCBQsWkJubyzXXXLPP9fR2yvxADNGdUD2FUChEjWSQ1FQR71KMMYPIFVdcwV//+lcee+wxLr30Umpqahg2bBihUIh58+axcePGXpc/6aSTePDBBwFYvnw5S5cuBaC2tpb09HSys7PZsWPHHoPr9TRk90knncQTTzxBY2MjDQ0N/P3vf+fEE0/sx2/bu4TqKQDUSjbBFhsUzxiz2+TJk6mrq6O4uJiioiI+9alPcf7551NaWsqMGTM48sgje13++uuv57Of/SzTpk1jxowZzJ49G4Dp06czc+ZMJk+ezPjx4zn++OM7lpk7dy7nnHMORUVFzJs3r2P6rFmzuOaaazrWcd111zFz5swBu5ubHGpX95aWluq+zv/tzYoff4SkQIBJ33m9H6syxhyoVatWMWnSpHiXMaR0t01FZJGqlu5r2YTafQTQGMolPRr/C0SMMWYwSrhQaE3JJTNmoWCMMd1JuFCIhfPJ0jpoa4t3KcYYz6G2G3swO9htmXChoGkFBESJ2GmpxgwK4XCYyspKC4Z+oKpUVlYSDocPeB0Jd/ZRUoa7erCucht5mQd4a09jTL8pKSmhrKyM8nK7qLQ/hMNhSkpKDnj5hAuFQLa7A2hDxRbyxk7bR2tjjN9CoRDjxo2LdxnGk3C7j9LyXYI2VZXFuRJjjBl8Ei4UsgtHAdBavS3OlRhjzODjWyiISFhE3hGRJSKyQkRu6aZNiog8IiJrRGS+iIz1q552+fl51GsYrbVQMMaYrvzsKbQAp6nqdGAGcLaIzOnS5lpgl6pOAH4J/MzHegDITAlSTi6BRrungjHGdOVbKKhT770NeY+u55xdCDzgvX4MOF16GrC8n4gI1YE8wk12TwVjjOnK12MKIhIQkcXATuAFVZ3fpUkxsBlAVaNADZDvZ00AdaEC0iN2nYIxxnTlayioakxVZwAlwGwRmdKlSXe9gr2uYBGRuSKyUEQW9se5zM3hQrKjFWAXyxhjzB4G5OwjVa0GXgHO7jKrDBgFICJBIBvYa1xrVb1HVUtVtbSw8OAvOIumDSdMK7TUHvS6jDFmKPHz7KNCEcnxXqcCZwDvd2n2FHC19/pS4GUdiGvdM91tOaPVW33/KGOMOZT42VMoAuaJyFJgAe6YwtMi8iMRucBrcx+QLyJrgK8DN/tYT4dg9kgA6irsAjZjjOnMt2EuVHUpMLOb6d/v9LoZuMyvGnqSmudCoaGyjNyB/nBjjBnEEu6KZoCMQjfURYsNdWGMMXtIyFDIzy2gUjNhV+834zbGmESTkKFQmJnCRh1OSu2GeJdijDGDSkKGQmpygC1JRWQ0bIp3KcYYM6gkZCgA7EoZRVZkJ0Sa412KMcYMGgkbCk0Zo0hCoWZzvEsxxphBI2FDgaxi91xjZyAZY0y7hA2FUL672U50l4WCMca0S9hQyCwYDUBDhZ2Waowx7Xy7onmwK8zNolyzodLOQDLGmHYJ21Moyk5lq+ajNVviXYoxxgwaCRsKI7LDlGkBKXXWUzDGmHYJGwpZ4SCbkkrIbNoC0dZ4l2OMMYNCwoaCiFCVOoYkYlC1Lt7lGGPMoJCwoQDQmHWYe1HxYXwLMcaYQSKhQ0HyJ7gXFgrGGAMkeCgMLyhgi+YTK7dQMMYYSPBQKMlLZW3bSCLbu9462hhjElNCh8Ko3DTW6kiCu9aAarzLMcaYuPMtFERklIjME5FVIrJCRG7sps0pIlIjIou9x/e7W5dfRuV5oRBtgLptA/nRxhgzKPk5zEUU+IaqvisimcAiEXlBVVd2afe6qn7Mxzp6VJiRwqYkb7TUig8ha2Q8yjDGmEHDt56Cqm5T1Xe913XAKqDYr887EElJ0um01NXxLcYYYwaBATmmICJjgZnA/G5mHyciS0TkORGZPBD1dJaWV0yDpEH5BwP90cYYM+j4HgoikgE8DtykqrVdZr8LjFHV6cCvgSd6WMdcEVkoIgvLy8v7tb5ReWms05F2rYIxxuBzKIhICBcID6rq37rOV9VaVa33Xj8LhESkoJt296hqqaqWFhYW9muNo/LS+DBWRJuFgjHG+Hr2kQD3AatU9bYe2ozw2iEis716Kv2qqTtj8tJY2zaSpLpt0FI3kB9tjDGDjp9nHx0PfBpYJiKLvWnfBUYDqOrdwKXA9SISBZqAK1QH9oKB8YUZPKHeWUcVH0Lx0QP58cYYM6j4Fgqq+gYg+2hzJ3CnXzX0xZj8NNbghUK5hYIxJrEl9BXNAOFQgGjWWFolBbYtiXc5xhgTVwkfCgBjhuXwYWAilC2IdynGGBNXFgrA+IJ05kfGo9uWQKQ53uUYY0zcWCgA4wvTWRgZh7RFoHxVvMsxxpi4sVAAxhWks0pHuzfbl8e3GGOMiSMLBdxpqRt1OJFAKmxfFu9yjDEmbiwUgKKsMGnJIbaFJ9gZSMaYhGahgBstdeLwTJbK4bD1PYi2xLskY4yJCwsFz+HDM5jXeBjEWmDr4n0vYIwxQ5CFgufw4ZnMaxzv3mx6K77FGGNMnFgoeI4YkUkVWTRljYdNb8e7HGOMiQsLBc/hwzMB2Jw5HTa/DW1tca7IGGMGnoWCZ1hmCtmpIZYmTYKmXXbTHWNMQrJQ8IgIRwzP5OUGO65gjElcFgqdTCnO5uXydDR9mB1XMMYkJAuFTqaVZNMcUeqGl1pPwRiTkCwUOplakg3A2vBUqN4ItVvjXJExxgwsC4VOxuWnk5ES5O3oRDfBegvGmARjodBJUpIwpTiLf1UNh3A2rHk53iUZY8yAslDoYlpJDiu2NxAbfxqseQFU412SMcYMGN9CQURGicg8EVklIitE5MZu2oiI3CEia0RkqYjM8quevppanE1rtI1thSdC/Q7YvjTeJRljzIDxs6cQBb6hqpOAOcCXReSoLm3OASZ6j7nAXT7W0yfTS3IAeCcw001Y/a84VmOMMQPLt1BQ1W2q+q73ug5YBRR3aXYh8Cd13gZyRKTIr5r6YlReKtmpIRZUBGHkTPjQQsEYkzgG5JiCiIwFZgLzu8wqBjZ3el/G3sGBiMwVkYUisrC8vNyvMts/i2kl2Swtq4EJZ8KWhdBY5etnGmPMYNGnUBCRG0UkyzsGcJ+IvCsiZ/Vx2QzgceAmVa3tOrubRfY6squq96hqqaqWFhYW9uVjD8rU4mw+2F5Hy/jTQdtgzYu+f6YxxgwGfe0pfM77QT8LKAQ+C/x0XwuJSAgXCA+q6t+6aVIGjOr0vgSI+xVj00qyibYpq5IOh6xiWP54vEsyxpgB0ddQaP+L/lzgD6q6hO7/yt+9gIgA9wGrVPW2Hpo9BXzG64HMAWpUdVsfa/LNNO9g83uba2DKJa6n0FAZ56qMMcZ/fQ2FRSLyL1woPC8imcC+bjhwPPBp4DQRWew9zhWRL4rIF702zwLrgDXAvcCX9v8r9L+ROakU56TyzvoqmHoZtEVh5RPxLssYY3wX7GO7a4EZwDpVbRSRPNwupB6p6hvsozehqgp8uY81DKhjx+Xx6ofl6PDTkcIjYdljcMy18S7LGGN81deewnHAB6paLSJXAf8J1PhXVvwdOz6PyoZW1pQ3wOSL3ThItXHfs2WMMb7qayjcBTSKyHTgP4CNwJ98q2oQOHZcPgBvr6+CyRcBCiufjG9Rxhjjs76GQtTb1XMh8CtV/RWQ6V9Z8TcmP40RWWHmr6uEwsNh+BRY0d0JVMYYM3T0NRTqROQ7uAPHz4hIAAj5V1b8iQjHjs9j/voqVNWdhbR5PmxdHO/SjDHGN30NhU8ALbjrFbbjrjr+uW9VDRLHjsunvK6F9RUN7iBzOAfe+GW8yzLGGN/0KRS8IHgQyBaRjwHNqjqkjykAzBmfB8Cbayvd/RWmXAKrX4BIU5wrM8YYf/R1mIvLgXeAy4DLgfkicqmfhQ0G4wrSKclN5ZUPvPGWjjwPIg3w4T/jW5gxxvikr7uPvgcco6pXq+pngNnAf/lX1uAgIpx6xDDeXFtBSzQG406G/Anw6s+hbV/X7hljzKGnr6GQpKo7O72v3I9lD2mnHllIY2uMBet3QSAIJ30Ldq6AtS/FuzRjjOl3ff1h/6eIPC8i14jINcAzuCEqhrzjxheQHExi3gdeJk6+GDKL4K3fxLcwY4zxQV8PNH8LuAeYBkwH7lHVb/tZ2GCRmhzguPH5u0MhmAyzPw/r5sGOFfEtzhhj+lmfdwGp6uOq+nVV/Zqq/t3PogabU48oZF15A5sqG92Eoz8LoXT49x3xLcwYY/pZr6EgInUiUtvNo05Eut4wZ8g69chhAPxr5XY3IS0Pjr4alj8G1Zt7WdIYYw4tvYaCqmaqalY3j0xVzRqoIuNtTH4600qyeXJxp/v/HOcN7vrmr+NTlDHG+CAhziDqDxfOKGbZlhrWlte7CdklMP1KWPQHqN4U3+KMMaafWCj00fnTikgS9uwtnPxtSArCP24C3evW0sYYc8ixUOijYVlhPnJYAU8u3uIGyAPIGQWnf99ds7D+1fgWaIwx/cBCYT9cMGMkGysbWby5evfE0s9B5kh45afWWzDGHPIsFPbD2VNGkBxM2nMXUjAFTvy6uzPbh8/HrzhjjOkHvoWCiNwvIjtFZHkP808RkRoRWew9vu9XLf0lKxzijEnDeHrpVqKxTmMfzboaCifBP26Emi3xK9AYYw6Snz2FPwJn76PN66o6w3v8yMda+s0F04upqG91w2m3CybDJb+H1gZ48su2G8kYc8jyLRRU9TWgyq/1x8upRxaSGQ7yxOIuPYIRU+DU77rhL9a8GJ/ijDHmIMX7mMJxIrJERJ4Tkck9NRKRuSKyUEQWlpeXD2R9e0kJBjh3ShHPL99OcyS258xjroO88fDPm6E5YS74NsYMIfEMhXeBMao6Hfg18ERPDVX1HlUtVdXSwsLCASuwJxfOHElDa4x/Lt++54xgMpz/K6haD49fB22x7ldgjDGDVNxCQVVrVbXee/0sEBKRgnjVsz/mjMtnfEE6f3xzw94zx50E5/4vrH4eXvzBgNdmjDEHI26hICIjRES817O9Wip7X2pwSEoSrv7IWBZvrua9Tbv2bnDMdW4k1TfvhLJFA1+gMcYcID9PSX0YeAs4QkTKRORaEfmiiHzRa3IpsFxElgB3AFeoHjqn7VxydAkZKUHu//eG7huc+SPIHAGPfw4ah9zxdmPMEOXn2UdXqmqRqoZUtURV71PVu1X1bm/+nao6WVWnq+ocVX3Tr1r8kJES5JPHjuaZpVt332ehs3AWXP5nqN0Gj34GYpGBL9IYY/ZTvM8+OqR97vhxBJKEe19f132DUcfABXfAhtfhuf+w6xeMMYOehcJBGJEd5uKZJTy6cDMV9S3dN5p+BRx/Iyy8H/71nxYMxphBzULhIM09eTytsTYe6O5MpHan/xBmz4W37oR5Pxmo0owxZr9ZKBykwwoz+OhRI3jgzQ3Ut0S7b5SUBOf8L8z8NLz2v3a3NmPMoGWh0A+uP+Uwapuj3PXKmp4bibgL2476uNuN9ML3bVeSMWbQsVDoB9NH5XDxzGLufW0922uae26YFIBL7oPSa+Hfv4J37h24Io0xpg8sFPrJ1848nDZV7n51be8NA0E49xcw4Qx47lvw6v9CrIfdTsYYM8AsFPrJqLw0LplVwkPvbOq9twDuGMMnHoQpl8K8W+G+MyHSNDCFGmNMLywU+tENp00A4L+fXrnvxqEwXHwPnHcbbH0XHrgAasp8rtAYY3pnodCPRuWl8dXTJvDMsm3Me3/nvhdICsAx18Klf4Cdq+DuE+yWnsaYuLJQ6GdzTzqMCcMy+K8nl9PU2sehs6dcDF94FbJL4KFPwEv/DU3V/hZqjDHdsFDoZ8nBJG79+BTKdjXxq5dW933B/MPgc/+CcSfC67+AP38cWur8K9QYY7phoeCDY8fnc3lpCb9/fR3vb9+PO7Alp8FnnoLLHoBtS+EXR8CC3/tXqDHGdGGh4JPvnDOJrNQQ3/3bMtra9uMiNRGY/HG46jEYOQOe+Ya7i9v25f4Va4wxHgsFn+SmJ/Of503i3U3V3P3aPq5d6M5hp8HV/4ATvg7vPwO/OxFevAVaG/q/WGOM8Vgo+OiimcWcP30kv3j+A+avO4CbyiUF4IwfwNdXwtTL4Y3b4PdnwJJHoK2t/ws2xiQ8CwUfiQj/c/FUxuan85WH3+t5eO19Sc2Fi3/nLniLtsDf58Ifz4WKNdDWxzOcjDGmDywUfJaREuQ3n5pFTVOEm/66mNj+HF/oatLH4IaFcOFv3IHoO4+G26fC1sX9V7AxJqFZKAyASUVZ/OjCybyxpoJfv7wfp6l2JykJZl4FX3oTPvo/0BaFe06B+8+BNS/2S73GmMTlWyiIyP0islNEuj1tRpw7RGSNiCwVkVl+1TIYXF46iotnFvOrl1bz7zUVB7/C3LFw3JfgS2/DKTdD3TZ48DJ44Hw3+qqNpWSMOQB+9hT+CJzdy/xzgIneYy5wl4+1xJ2I8OOLpjChMIMbHnqXdeX1/bPitDwXCl98HY79ItRug2e/CbdPg/f+YldGG2P2i2+hoKqvAVW9NLkQ+JM6bwM5IlLkVz2DQVpykHs/U4qIcM0fFhz4gefupGTC2f8DNyyAqx6H9AJ48svw8wnw8JWw6h8Qbe2/zzPGDEnxPKZQDGzu9L7Mm7YXEZkrIgtFZGF5efmAFOeXsQXp3Hd1KTvrmrn2jwtobO3neymIuHs1XP8mXPcSHPsFKFsIj1wF/+8IePY/3IFpu+ubMaYb8QwF6WZat79UqnqPqpaqamlhYaHPZflv5uhcfn3lLJZtqeErD71HJObDNQciUFIKH70Vvr4KPvl/MP5kWPQHuOdkuPdUePXn7rRWY4zxxDMUyoBRnd6XAFvjVMuAO/Oo4dxy4RReen8nN/11MVE/gqFdIAiHnwWX/RG++aG781vddpj3Y3da68/GuTvAlS2yHoQxCS4Yx89+CrhBRP4KHAvUqOq2ONYz4D49ZwzNrTFufXYVsTbljitnkhz0OadTc2H25+GY66B+Jyz7P1j+mLsD3LxbIXccjD8FjvyYG3spvcDfeowxg4qoT38ZisjDwClAAbAD+AEQAlDVu0VEgDtxZyg1Ap9V1YX7Wm9paakuXLjPZoeU+99Yz4+eXsmpRxRy11VHEw4FBrYAVRcQq56CtS/Dulch0gAITDwTCo+A0s+5wJDu9voZYwY7EVmkqqX7bOdXKPhlKIYCwEPzN/G9J5YxZ1w+d3/6aLJTQ/ErJtIEG9+E9a/BkoehfoebnjECRkyFUce6kVwLJsavRmPMfrFQOAQ98d4WvvXYEkpy07j3M0czYVhmvEtydm2ANS+5R+UaqPjATc87DGIRmHqpuzlQVrHrVRhjBh0LhUPUgg1VXP+Xd2mOxLjt8umcNXlEvEvaW80Wt6tp1dOwZRGHeQ+JAAAVAUlEQVREO109PeZ4yBoJw45yATHuJHcNhTEmriwUDmHbapr4wp8XsbSshpvOmMhXT5tIUtIg3Zev6noSVWvdIH1LH3FXUddvd/ND6W43U+4YKJrhDl7nT4Cc0XEt25hEY6FwiGuOxPju35fxt3e3cNZRw7ntEzPISInnyWL7oS0GZQvcsYn3n4Gqde6xa/3uNpkjYeRMyBnlQiJ3nDtekTk8fnUbM4RZKAwBqsof/r2BW59dxfiCdH736aMZX5gR77IOXGMV7FgOO1bApreh/H2o3uyd6QRIkjsukZwBxUe7XkVyunudlg+peW6UWGPMfrNQGELeXFPBlx96l6ZIjJ9dMo0LZ3Q7GsihSdWd3VS1Hta94noUTbtgy0L33FlavhsddthRkDnCBUjRNMge5YIklGqnzBrTAwuFIWZbTRM3PryYdzZUceGMkfzXx46iICMl3mX5RxVqyqCxAipWu17G9mVQswl2rnLvtctd53LGQP5hkFbgQiN3rDuWkVbgQiN3DATieKqvMXFkoTAEtURj/HbeWn77yhrSkoN877xJXHZ0CZKIfx23NrgexvZl7sK7hgrY9KY3facbxqMtsucyKVkQSHbBMPo4KDjc3aSo4HB3hlR2MSSFILsEwlnx+V7G+MRCYQhbs7OO7/xtGQs27GLO+Dx+ctHUQ/tYgx/az4qq3wGNla5nsektCKa44Fj3ipsnSaDdjDuVMRzCOZCa44YGCedAwQQIpEDeeMgY5tYzbJLrlbS1QbQZktMG+psa0ycWCkNcW5vyyMLN/OTZVbRE2/jKqRP4wsmH+T920lCh6n7EJQl2bYSWOqjd4noOVWuhepM7tba5Gup2QEM5NPVwe5BQOsRaXbiMPg4ijS5ISo5xy0ca3YV+OaNdj6T9EWt1u7hSstznh7PtmIjxjYVCgthZ28wtT6/kmaXbmDgsg2+cdQQfnTw8MXcp+UkVmmvcD3/VOqjd6s6MqljtAiSY7K7uXvUPd+C7bpsLl5Qs1ztp6MN9QJIzXC+ktcGFSnKaO7iePcqFRXMtFM9yYSXiejP5EyCUBg07XTgNm+Q+O2eMqzXa5MLGJDwLhQTz8vs7+O+nV7G+ooHTjhzG1888nCnF9mMQN6ouJILJ7n3dDtfTaKl34VK3DYJhFxbN1e6HvXYLVK51Z1HVbIZIs+tN1Gx26+t6YL0vJOAOsKfmuuMu0RYomr77gHso1dURa3UhE0p1x1XCWa6m5mo3vy3qdqGFs1x4SZLbtdZQ4eYNm+TCp6HC3SI2KeTatD/aIu6zU3P6bxub/WKhkIBibcp9b6zjN/PWUtMU4fQjh3HDaROYOTo33qWZg9HmHfPQNti22A1nnprreiuVa9yPbXON+3FurYdgqtczURdGzTWux5Ca536gd6xw82KtbrdVW9QLpa0HFjx9JUmu55MUdGEFLkiaa1xvqn6nC5TCI9zpyJEmr5eU5AIzmOJOQ25tcLvf2qLuuWK1tz3KoPBINy3S7K5piba4oGuLueNAdTsg1uLOSGuLutexiNsW0Va3njQvQFNz3fYMJLu627dzUtDbZqmAuG2tbe7YUkstpA9zZ8jljXPLxlq93ly5W0cw2a0jNc+tr7ESQmF3qnVLnZsWaXTfuz2gW+rc9phwOhx14YFtfguFxFXbHOFPb27g92+sp7oxwokTC/jKaROZPS4v3qWZwUzV7ZaKNLkeTWu9++FTBdT9GLfWux8obXM/XumF7kdv1wb3PjkdWhtduKi6dqruPovNtbt3wbWvs7HKBUOk0f2o1u9wu+dSc1241ZS5dWWXuB/U6k2QFHA/5O3HhYJh1xPJHevqaIu5H+P2H+6Gctemtd7VF86Gxl2utxRIdj/SgWT3A1xT5taZlu96duFs9/2adgHilg+E3I96a6P7DsGwe26pd4HUVOXCq3araxcIuXUi7rWq+w6RJrdcUsjV2VLr/jukZLnlYq1umUgDJGe6NrM/Dyd984D+81ooGBpaovzl7Y3c+/o6KupbOXZcHjecNoETJhTYMQdjutPW5oKx67+PmNerSE7f97KtXji0h2z78hpzvZ22GCDuRz8p4IVE0O2qS8lyd0rsrPN6DoKFgunQ1Brj4Xc28bvX1rKjtoVJRVl85rgxfGxaEZlhu5jLmERgoWD20hyJ8dTirdz/7/W8v72OlGASl5WWMPfEwxidb+fXGzOUWSiYHqkq722u5tEFm/nbu1uItLVxwoQCLisdxVlHDR/424EaY3xnoWD6ZEdtMw/O38Tji8rYUt1EVjjI+dNH8vGZxRw9Onfw3sfBGLNfBkUoiMjZwK+AAPB7Vf1pl/nXAD8HtniT7lTV3/e2TgsFf7S1KW+tq+T/Fm7mnyu20xxpozgnlY9NL+KC6SM5qijLDk4bcwiLeyiISAD4EDgTKAMWAFeq6spOba4BSlX1hr6u10LBf/UtUV5YuZ2nFm/l9dUVRNuUCcMyOG9qEedOLeLw4RkWEMYcYvoaCn7eyms2sEZV13kF/RW4EFjZ61Im7jJSglw0s4SLZpZQ1dDKs8u28dSSrdzx8mp+9dJqxhem89HJIzj9yGHMGJVDMGDjLRkzVPgZCsXA5k7vy4Bju2l3iYichOtVfE1VN3dtICJzgbkAo0fbvX0HUl56MlfNGcNVc8aws66Zf63YwXPLt3HPa+u465W1ZIaDfOSwfE6YWMhJEwsYk9/LedzGmEHPz91HlwEfVdXrvPefBmar6lc6tckH6lW1RUS+CFyuqqf1tl7bfTQ41DRFeGN1BW+sKee1DyvYUt0EwOi8NE6YWMBJEws47rACslPtOghjBoPBsPuoDBjV6X0JsLVzA1Wt7PT2XuBnPtZj+lF2aojzphVx3rQiVJX1FQ28saaC1z6s4Mn3tvDQ/E0kCUwtyWHmqBzOmDScGaNzyEjx8385Y8zB8rOnEMTtEjodd3bRAuCTqrqiU5siVd3mvb4I+LaqzultvdZTGPwisTYWb67m9Q/LeXt9FUs2V9MSbSNJ4IgRWRwzNpePHJbPzNG5DM8Kx7tcYxJC3HsKqhoVkRuA53GnpN6vqitE5EfAQlV9CviqiFwARIEq4Bq/6jEDJxRI4pixeRwz1g3AV9cc4b1N1SzauIt3N+3isUVl/OmtjQAMz0phWkkO00uymVaSw7SSbHLSkuNZvjEJzS5eMwOuNdrGsi01LNlczdKyapaW1bCuoqFj/pj8NKZ7ATF9VA6TR2aRlmy7nYw5GHHvKRjTk+RgEkePyeXoMbvv81DTFGH5lhqWlFWzdHMNCzdU8dQSdwgqSeCwwgyOGpnFpCLvMSKTwswUu17CmH5moWAGhezUEMdPKOD4CQUd03bWNbN0cw3LttSwfEsNC9ZX8eTi3ecq5KSFOHx4JocPz+CI4ZkcPjyTI0Zk2u4nYw6ChYIZtIZlhjnjqDBnHDW8Y1p1Yysrt9Wyekc972+vY/WOOp5cvJW65mhHm8LMFMYVpDMuP50xBWnuOT+dsQVpthvKmH2wfyHmkJKTlsxHDivgI4ft7lGoKjtqW/hgRx0fbq/jgx11bKxs4KX3d1JR37LH8sMyUxhbkM7Y/DTv2T3G5KeRbqfLGmOhYA59IsKI7DAjssOcfHjhHvPqW6JsqGhgY2UjGyob2FDRwIbKBuZ9UE75wrI92g7LTHEhUZDGmPx0xhW4sBiZnUpOWsiOX5iEYKFghrSMlCBTirOZUpy917z6ligbKxvYUNFNYNTtGRjJgSSKcsKU5KYyKjeNkTmp3iNMcU4qRdmpJAdtDChz6LNQMAkrIyXI5JHZTB7Zc2BsrGxke00zO+ta2FLdxOaqRl5ctfduKYCCjGSGZ4UZkRVmeHaY4ZlhRmSnMMybNiIrbD0OM+hZKBjTjd4CA9ytTbfXNLO1uokt1U1srW5mW00TO2qb2VrTzOLN1VQ2tO61XHIwieFZKYzICneERX5GMhkpQYZlhhmWlUJhRgr5Gcl2UNzEhf1fZ8wBCIcC7kB1Qc+jwrZEY+ysbWFnXTPba1rYUdvMjtpmtnvPK7fW8vKqnTRFYt0un5YcoCAjhYKMZAozUyjMTKEgI4X89GRy05PJa3+kJZOTlmy7r0y/sFAwxicpwQCj8tIYlZfWYxtVpSXaRm1zhJ21LZTXtVBe30JFfQsVda3uub6F9RUNvLO+il2NkR7XlRkOkpeeTG5acsdzfkb7+xC5Xnhkp4bISQuRnRqy+3GbvVgoGBNHIkI4FCAcCjAsc9+DA0ZibexqbGVXQ4SqhlZ2NbZS1bD70f5+Z10zH2yvo6qhtceeCEBqKEBeejI5abuDIjs1RFZqiKzw7vedp2eGg2SFQ9YzGaIsFIw5hIQCSe7YQx8CpF1Ta4yqxlZ2NbRS3RihpilCdZN7Xd3YSlVDhF2NrVQ3trKjtoWaJtemNdrW63rDoSQywyGywkH33CkwssJBL1jcvIyUIOkpQTJSgmSEgx3zQ3bXvkHHQsGYIS41OUBxcirFOan7tVxzJNYREDVNEWoaI9S1RKhrjlLb5D03R6htcs81TRHKdjVS2xSlrjlCyz5CBdypvukpAdKSXWCkpQTISAmSGQ66nkk4REooQFpygPSUIOnJe7dNS25/DlrvpR9YKBhjutW+W+tA73nREo11BEh9S5T65ij1LVHqml1o1DZHaWyN0dASpaE1SkOLe1/fEmVrdRM1+xEu7UIBIS3ZBUV7kKQlB0hPDpLWKVTSU9x3S0sOkBoKkOo9pyUHSU1OIjXklktN3j0vUXo1FgrGGF+kBAOkZLgzqA6GqtIcaaO+JUpja9R7duHR2OJCpb4lSlMk1hEsja1RGlpjNLa45+21zTS1xmho9ZZpjdK2n3cNCAV2H/9J9R7h5ADhYFJHcKSGAqSEAoRDSa5tsNNr7zllj2kBUoKd5gcDpISSSAkGCCTF53oWCwVjzKAmIh1/scPBBUy79rO+miMxGltjNEViNLV2fu1CprHVTW9qjdEYidHsPZpaYzRH2lzbSIxdDa1sjbhpja0xWiIxmqMxIrEDv19NKCAdAZISdOHxyWNHc92J4/tlG/TEQsEYk3A6n/WV0/MZwwct1qYdQdLshVCzFx7twdEcaaMl2nlaGy2RNpqjsT2eW6Kxg+519YWFgjHG+CSQJO4A+SE0Am9iHDkxxhjTJ76GgoicLSIfiMgaEbm5m/kpIvKIN3++iIz1sx5jjDG98y0URCQA/AY4BzgKuFJEjurS7Fpgl6pOAH4J/Myveowxxuybnz2F2cAaVV2nqq3AX4ELu7S5EHjAe/0YcLrYuMLGGBM3foZCMbC50/syb1q3bVQ1CtQA+V1XJCJzRWShiCwsLy/3qVxjjDF+hkJ3f/F3PWm3L21Q1XtUtVRVSwsLC7tZxBhjTH/wMxTKgFGd3pcAW3tqIyJBIBuo8rEmY4wxvfAzFBYAE0VknIgkA1cAT3Vp8xRwtff6UuBlVT3wSwCNMcYcFPHzN1hEzgVuBwLA/ap6q4j8CFioqk+JSBj4MzAT10O4QlXX7WOd5cDGAyypAKg4wGWHEtsOjm0Hx7bDbkN5W4xR1X3uf/c1FAYbEVmoqqXxriPebDs4th0c2w672bawK5qNMcZ0YqFgjDGmQ6KFwj3xLmCQsO3g2HZwbDvslvDbIqGOKRhjjOldovUUjDHG9MJCwRhjTIeECYV9DeM9lIjI/SKyU0SWd5qWJyIviMhq7znXmy4icoe3XZaKyKz4Vd6/RGSUiMwTkVUiskJEbvSmJ9S2EJGwiLwjIku87XCLN32cN2T9am8I+2Rv+pAe0l5EAiLynog87b1PyO3Qk4QIhT4O4z2U/BE4u8u0m4GXVHUi8JL3Htw2meg95gJ3DVCNAyEKfENVJwFzgC97/90TbVu0AKep6nRgBnC2iMzBDVX/S2877MINZQ9Df0j7G4FVnd4n6nbonqoO+QdwHPB8p/ffAb4T77p8/s5jgeWd3n8AFHmvi4APvNe/A67srt1QewBPAmcm8rYA0oB3gWNxV+4Gvekd/0aA54HjvNdBr53Eu/Z++v4luD8ETgOexg3KmXDbobdHQvQU6Nsw3kPdcFXdBuA9D/OmJ8S28br+M4H5JOC28HaZLAZ2Ai8Aa4FqdUPWw57ftU9D2h+ibgf+A2jz3ueTmNuhR4kSCn0aojtBDfltIyIZwOPATapa21vTbqYNiW2hqjFVnYH7S3k2MKm7Zt7zkNwOIvIxYKeqLuo8uZumQ3o77EuihEJfhvEe6naISBGA97zTmz6kt42IhHCB8KCq/s2bnJDbAkBVq4FXcMdYcrwh62HP7zpUh7Q/HrhARDbg7gR5Gq7nkGjboVeJEgp9GcZ7qOs8TPnVuP3r7dM/4515Mweoad+1cqjzbu16H7BKVW/rNCuhtoWIFIpIjvc6FTgDd6B1Hm7Ieth7Owy5Ie1V9TuqWqKqY3G/AS+r6qdIsO2wT/E+qDFQD+Bc4EPcvtTvxbsen7/rw8A2IIL7a+da3L7Ql4DV3nOe11ZwZ2atBZYBpfGuvx+3wwm47v5SYLH3ODfRtgUwDXjP2w7Lge9708cD7wBrgP8DUrzpYe/9Gm/++Hh/Bx+2ySnA04m+Hbp72DAXxhhjOiTK7iNjjDF9YKFgjDGmg4WCMcaYDhYKxhhjOlgoGGOM6WChYEwXIhITkcWdHv02qq6IjO08eq0xg01w302MSThN6oaEMCbhWE/BmD4SkQ0i8jPv3gTviMgEb/oYEXnJuwfDSyIy2ps+XET+7t3HYImIfMRbVUBE7vXubfAv7ypjYwYFCwVj9pbaZffRJzrNq1XV2cCduHFz8F7/SVWnAQ8Cd3jT7wBeVXcfg1nACm/6ROA3qjoZqAYu8fn7GNNndkWzMV2ISL2qZnQzfQPuZjXrvIH2tqtqvohU4O67EPGmb1PVAhEpB0pUtaXTOsYCL6i7oQsi8m0gpKo/9v+bGbNv1lMwZv9oD697atOdlk6vY9ixPTOIWCgYs38+0en5Le/1m7hRNwE+BbzhvX4JuB46bnKTNVBFGnOg7C8UY/aW6t2lrN0/VbX9tNQUEZmP+4PqSm/aV4H7ReRbQDnwWW/6jcA9InItrkdwPW70WmMGLTumYEwfeccUSlW1It61GOMX231kjDGmg/UUjDHGdLCegjHGmA4WCsYYYzpYKBhjjOlgoWCMMaaDhYIxxpgO/x9d0F7+BtYzVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history, 'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 51us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.65268068046836"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before saving: are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_71_10_20_42_tanh_100_1000.h5\")\n",
    "#for this\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST-SEE: \n",
    "* https://www.kaggle.com/randyrose2017/for-beginners-using-keras-to-build-models\n",
    "* https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d\n",
    "* https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n",
    "## Just liked:\n",
    "* https://missinglink.ai/guides/neural-network-concepts/classification-neural-networks-neural-network-right-choice/\n",
    "## Full-house:\n",
    "https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why rerunning with same configuration gives different output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = Sequential()\n",
    "model_load.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))\n",
    "#model_load.add(Dense(units = 10, \n",
    "                #activation = 'tanh'))\n",
    "model_load.add(Dense(units = 20, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_weights('/home/amanzhol/Documents/Capstone/MAIN Work/models/model_10_10_20_tanh_100_1000_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to compile before evaluating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_load.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.35198137976907"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Ms. Asma Salem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='AsmaSalemResults.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "predictions = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing confustion matrix from source:\n",
    "https://stackoverflow.com/questions/50920908/get-confusion-matrix-from-a-keras-multiclass-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 9, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 7, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 7, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 7]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FAR, FRR and EER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stats.stackexchange.com/questions/272962/are-far-and-frr-the-same-as-fpr-and-fnr-respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ConfusionMatrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='PerformanceMetrics.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edit:\n",
    "this is the format for confusion_matrix():\n",
    "[[TP,FN]\n",
    "[FP,TN]]\n",
    "And classification report gives all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-86b2e0ad5146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-c62d2e9dae18>\u001b[0m in \u001b[0;36mperf_measure\u001b[0;34m(y_actual, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m            \u001b[0mTP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "perf_measure(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus\n",
    "TP = 6\n",
    "FP = 1\n",
    "TN = 11\n",
    "FN = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAR(FP, TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FRR(FN, TP):\n",
    "    return FN/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333332"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAR(FP, TN) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.78082191780823"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRR(FN, TP) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (Performance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ms. Asma Results\n",
    "* FAR = 0.3%\n",
    "* FRR = 1.5%\n",
    "* EER = 0.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* How to have several FAR, FRR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read for Confusion Matrix - Get Items FP/FN/TP/TN - Python\n",
    "* https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python\n",
    "* https://classeval.wordpress.com/introduction/basic-evaluation-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
