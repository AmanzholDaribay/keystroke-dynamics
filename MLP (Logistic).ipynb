{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "The dataset is taken from http://www.vmonaco.com/keystroke-datasets.\n",
    "Specifically from https://ms.sapientia.ro/~manyi/keystroke.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read:\n",
    "* https://appliedmachinelearning.blog/2017/07/26/user-verification-based-on-keystroke-dynamics-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('dataset2_norm.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['user_id'].values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.mean(a == b'37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As it can be seen the number of samples per user are 51. Since the user are 42 users, there in total 51 * 42 = 2142 samples. Number of features is 71."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the dataset is 2142 * 72."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good source for Pandas: https://chrisalbon.com/python/data_wrangling/pandas_replace_values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_unique = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b'10', b'20',\n",
       "       b'21', b'24', b'25', b'26', b'27', b'28', b'29', b'35', b'36',\n",
       "       b'37', b'38', b'40', b'41', b'50', b'51', b'53', b'54', b'55',\n",
       "       b'65', b'66', b'68', b'69', b'70', b'71', b'73', b'80', b'81',\n",
       "       b'82', b'83', b'84', b'85'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_id[user_id == b'20'] = b'11'\\nuser_id[user_id == b'21'] = b'12'\\nuser_id[user_id == b'24'] = b'13'\\nuser_id[user_id == b'25'] = b'14'\\nuser_id[user_id == b'26'] = b'15'\\nuser_id[user_id == b'27'] = b'16'\\nuser_id[user_id == b'28'] = b'17'\\nuser_id[user_id == b'29'] = b'18'\\nuser_id[user_id == b'35'] = b'19'\\nuser_id[user_id == b'35'] = b'20'\\nuser_id[user_id == b'37'] = b'21'\\nuser_id[user_id == b'38'] = b'22'\\nuser_id[user_id == b'20'] = b'11'\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "user_id[user_id == b'21'] = b'12'\n",
    "user_id[user_id == b'24'] = b'13'\n",
    "user_id[user_id == b'25'] = b'14'\n",
    "user_id[user_id == b'26'] = b'15'\n",
    "user_id[user_id == b'27'] = b'16'\n",
    "user_id[user_id == b'28'] = b'17'\n",
    "user_id[user_id == b'29'] = b'18'\n",
    "user_id[user_id == b'35'] = b'19'\n",
    "user_id[user_id == b'35'] = b'20'\n",
    "user_id[user_id == b'37'] = b'21'\n",
    "user_id[user_id == b'38'] = b'22'\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Creating Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 1 Âµs, total: 4 Âµs\n",
      "Wall time: 6.91 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "label = []\n",
    "for i in range(42):\n",
    "    for j in range(51):\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == 0) * 2142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Input Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea8</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10       ...        fingerarea8  \\\n",
       "0   0.430147   0.467290      0.240    0.374429       ...           0.222222   \n",
       "1   0.363971   0.485981      0.344    0.365297       ...           0.185185   \n",
       "2   0.338235   0.345794      0.296    0.365297       ...           0.259259   \n",
       "3   0.404412   0.640187      0.276    0.410959       ...           0.296296   \n",
       "4   0.408088   0.635514      0.324    0.378995       ...           0.296296   \n",
       "\n",
       "   fingerarea9  fingerarea10  fingerarea11  fingerarea12  fingerarea13  \\\n",
       "0     0.296296      0.296296      0.222222      0.211470      0.283154   \n",
       "1     0.259259      0.185185      0.185185      0.354839      0.211470   \n",
       "2     0.296296      0.333333      0.222222      0.283154      0.175627   \n",
       "3     0.370370      0.185185      0.222222      0.283154      0.247312   \n",
       "4     0.333333      0.222222      0.222222      0.211470      0.318996   \n",
       "\n",
       "   fingerarea14  meanholdtime  meanpressure  meanfingerarea  \n",
       "0      0.185185      0.447030      0.387546        0.364089  \n",
       "1      0.148148      0.423762      0.445704        0.369322  \n",
       "2      0.185185      0.454455      0.464092        0.371658  \n",
       "3      0.296296      0.522772      0.397230        0.396828  \n",
       "4      0.074074      0.493564      0.455577        0.365646  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 71)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[51].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the dataset into the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 71)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.6000000000001"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, train_test_split splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Logistic Regression with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(units = 42, \n",
    "                input_dim = 71, \n",
    "                activation = 'softmax',\n",
    "                #kernel_regularizer = L1L2(l1=0.0, l2=0.1)\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 42)                3024      \n",
      "=================================================================\n",
      "Total params: 3,024\n",
      "Trainable params: 3,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam = optimizers.Adam(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "#                              #verbose=1, \n",
    "#                              monitor='val_acc',\n",
    "#                              save_best_only=True, \n",
    "#                              mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = ReduceLROnPlateau(patience = 20, factor  = 0.8, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', \n",
    "                   mode = 'auto', \n",
    "                   patience=50, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 0 ns, total: 3 Âµs\n",
      "Wall time: 6.68 Âµs\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/2000\n",
      " - 0s - loss: 3.7850 - acc: 0.0241 - val_loss: 3.7557 - val_acc: 0.0379\n",
      "Epoch 2/2000\n",
      " - 0s - loss: 3.7386 - acc: 0.0328 - val_loss: 3.7231 - val_acc: 0.0204\n",
      "Epoch 3/2000\n",
      " - 0s - loss: 3.7035 - acc: 0.0372 - val_loss: 3.6987 - val_acc: 0.0408\n",
      "Epoch 4/2000\n",
      " - 0s - loss: 3.6767 - acc: 0.0569 - val_loss: 3.6778 - val_acc: 0.0496\n",
      "Epoch 5/2000\n",
      " - 0s - loss: 3.6534 - acc: 0.0766 - val_loss: 3.6602 - val_acc: 0.0525\n",
      "Epoch 6/2000\n",
      " - 0s - loss: 3.6334 - acc: 0.0752 - val_loss: 3.6443 - val_acc: 0.0466\n",
      "Epoch 7/2000\n",
      " - 0s - loss: 3.6148 - acc: 0.0737 - val_loss: 3.6287 - val_acc: 0.0408\n",
      "Epoch 8/2000\n",
      " - 0s - loss: 3.5973 - acc: 0.0715 - val_loss: 3.6139 - val_acc: 0.0408\n",
      "Epoch 9/2000\n",
      " - 0s - loss: 3.5804 - acc: 0.0693 - val_loss: 3.5978 - val_acc: 0.0350\n",
      "Epoch 10/2000\n",
      " - 0s - loss: 3.5639 - acc: 0.0737 - val_loss: 3.5833 - val_acc: 0.0408\n",
      "Epoch 11/2000\n",
      " - 0s - loss: 3.5477 - acc: 0.0781 - val_loss: 3.5679 - val_acc: 0.0525\n",
      "Epoch 12/2000\n",
      " - 0s - loss: 3.5316 - acc: 0.0847 - val_loss: 3.5531 - val_acc: 0.0583\n",
      "Epoch 13/2000\n",
      " - 0s - loss: 3.5157 - acc: 0.0927 - val_loss: 3.5393 - val_acc: 0.0612\n",
      "Epoch 14/2000\n",
      " - 0s - loss: 3.5001 - acc: 0.0942 - val_loss: 3.5246 - val_acc: 0.0700\n",
      "Epoch 15/2000\n",
      " - 0s - loss: 3.4848 - acc: 0.1051 - val_loss: 3.5099 - val_acc: 0.0875\n",
      "Epoch 16/2000\n",
      " - 0s - loss: 3.4691 - acc: 0.1168 - val_loss: 3.4959 - val_acc: 0.0904\n",
      "Epoch 17/2000\n",
      " - 0s - loss: 3.4538 - acc: 0.1248 - val_loss: 3.4811 - val_acc: 0.0962\n",
      "Epoch 18/2000\n",
      " - 0s - loss: 3.4388 - acc: 0.1307 - val_loss: 3.4656 - val_acc: 0.1050\n",
      "Epoch 19/2000\n",
      " - 0s - loss: 3.4233 - acc: 0.1387 - val_loss: 3.4525 - val_acc: 0.1166\n",
      "Epoch 20/2000\n",
      " - 0s - loss: 3.4087 - acc: 0.1445 - val_loss: 3.4379 - val_acc: 0.1254\n",
      "Epoch 21/2000\n",
      " - 0s - loss: 3.3940 - acc: 0.1606 - val_loss: 3.4238 - val_acc: 0.1254\n",
      "Epoch 22/2000\n",
      " - 0s - loss: 3.3790 - acc: 0.1752 - val_loss: 3.4088 - val_acc: 0.1429\n",
      "Epoch 23/2000\n",
      " - 0s - loss: 3.3645 - acc: 0.1905 - val_loss: 3.3960 - val_acc: 0.1487\n",
      "Epoch 24/2000\n",
      " - 0s - loss: 3.3502 - acc: 0.2080 - val_loss: 3.3825 - val_acc: 0.1574\n",
      "Epoch 25/2000\n",
      " - 0s - loss: 3.3360 - acc: 0.2124 - val_loss: 3.3686 - val_acc: 0.1662\n",
      "Epoch 26/2000\n",
      " - 0s - loss: 3.3216 - acc: 0.2212 - val_loss: 3.3561 - val_acc: 0.1808\n",
      "Epoch 27/2000\n",
      " - 0s - loss: 3.3078 - acc: 0.2263 - val_loss: 3.3430 - val_acc: 0.1866\n",
      "Epoch 28/2000\n",
      " - 0s - loss: 3.2936 - acc: 0.2431 - val_loss: 3.3295 - val_acc: 0.2012\n",
      "Epoch 29/2000\n",
      " - 0s - loss: 3.2797 - acc: 0.2533 - val_loss: 3.3162 - val_acc: 0.2012\n",
      "Epoch 30/2000\n",
      " - 0s - loss: 3.2661 - acc: 0.2620 - val_loss: 3.3037 - val_acc: 0.2099\n",
      "Epoch 31/2000\n",
      " - 0s - loss: 3.2521 - acc: 0.2679 - val_loss: 3.2910 - val_acc: 0.2128\n",
      "Epoch 32/2000\n",
      " - 0s - loss: 3.2388 - acc: 0.2708 - val_loss: 3.2773 - val_acc: 0.2274\n",
      "Epoch 33/2000\n",
      " - 0s - loss: 3.2257 - acc: 0.2905 - val_loss: 3.2644 - val_acc: 0.2449\n",
      "Epoch 34/2000\n",
      " - 0s - loss: 3.2123 - acc: 0.2971 - val_loss: 3.2515 - val_acc: 0.2536\n",
      "Epoch 35/2000\n",
      " - 0s - loss: 3.1988 - acc: 0.3036 - val_loss: 3.2393 - val_acc: 0.2536\n",
      "Epoch 36/2000\n",
      " - 0s - loss: 3.1857 - acc: 0.3117 - val_loss: 3.2286 - val_acc: 0.2536\n",
      "Epoch 37/2000\n",
      " - 0s - loss: 3.1731 - acc: 0.3226 - val_loss: 3.2156 - val_acc: 0.2770\n",
      "Epoch 38/2000\n",
      " - 0s - loss: 3.1601 - acc: 0.3343 - val_loss: 3.2035 - val_acc: 0.2886\n",
      "Epoch 39/2000\n",
      " - 0s - loss: 3.1473 - acc: 0.3438 - val_loss: 3.1915 - val_acc: 0.2974\n",
      "Epoch 40/2000\n",
      " - 0s - loss: 3.1352 - acc: 0.3547 - val_loss: 3.1785 - val_acc: 0.3032\n",
      "Epoch 41/2000\n",
      " - 0s - loss: 3.1226 - acc: 0.3650 - val_loss: 3.1667 - val_acc: 0.3120\n",
      "Epoch 42/2000\n",
      " - 0s - loss: 3.1099 - acc: 0.3664 - val_loss: 3.1562 - val_acc: 0.3061\n",
      "Epoch 43/2000\n",
      " - 0s - loss: 3.0970 - acc: 0.3803 - val_loss: 3.1436 - val_acc: 0.3353\n",
      "Epoch 44/2000\n",
      " - 0s - loss: 3.0851 - acc: 0.3861 - val_loss: 3.1325 - val_acc: 0.3207\n",
      "Epoch 45/2000\n",
      " - 0s - loss: 3.0729 - acc: 0.3964 - val_loss: 3.1206 - val_acc: 0.3528\n",
      "Epoch 46/2000\n",
      " - 0s - loss: 3.0611 - acc: 0.3956 - val_loss: 3.1094 - val_acc: 0.3411\n",
      "Epoch 47/2000\n",
      " - 0s - loss: 3.0489 - acc: 0.4117 - val_loss: 3.0979 - val_acc: 0.3586\n",
      "Epoch 48/2000\n",
      " - 0s - loss: 3.0372 - acc: 0.4255 - val_loss: 3.0860 - val_acc: 0.3673\n",
      "Epoch 49/2000\n",
      " - 0s - loss: 3.0255 - acc: 0.4277 - val_loss: 3.0748 - val_acc: 0.3732\n",
      "Epoch 50/2000\n",
      " - 0s - loss: 3.0138 - acc: 0.4416 - val_loss: 3.0655 - val_acc: 0.3936\n",
      "Epoch 51/2000\n",
      " - 0s - loss: 3.0021 - acc: 0.4533 - val_loss: 3.0537 - val_acc: 0.3965\n",
      "Epoch 52/2000\n",
      " - 0s - loss: 2.9909 - acc: 0.4511 - val_loss: 3.0441 - val_acc: 0.3965\n",
      "Epoch 53/2000\n",
      " - 0s - loss: 2.9796 - acc: 0.4504 - val_loss: 3.0326 - val_acc: 0.3907\n",
      "Epoch 54/2000\n",
      " - 0s - loss: 2.9682 - acc: 0.4657 - val_loss: 3.0212 - val_acc: 0.4082\n",
      "Epoch 55/2000\n",
      " - 0s - loss: 2.9568 - acc: 0.4752 - val_loss: 3.0113 - val_acc: 0.4198\n",
      "Epoch 56/2000\n",
      " - 0s - loss: 2.9459 - acc: 0.4730 - val_loss: 3.0008 - val_acc: 0.4257\n",
      "Epoch 57/2000\n",
      " - 0s - loss: 2.9346 - acc: 0.4847 - val_loss: 2.9904 - val_acc: 0.4227\n",
      "Epoch 58/2000\n",
      " - 0s - loss: 2.9242 - acc: 0.5029 - val_loss: 2.9795 - val_acc: 0.4227\n",
      "Epoch 59/2000\n",
      " - 0s - loss: 2.9129 - acc: 0.4985 - val_loss: 2.9699 - val_acc: 0.4286\n",
      "Epoch 60/2000\n",
      " - 0s - loss: 2.9021 - acc: 0.5109 - val_loss: 2.9602 - val_acc: 0.4344\n",
      "Epoch 61/2000\n",
      " - 0s - loss: 2.8918 - acc: 0.5212 - val_loss: 2.9501 - val_acc: 0.4344\n",
      "Epoch 62/2000\n",
      " - 0s - loss: 2.8808 - acc: 0.5277 - val_loss: 2.9402 - val_acc: 0.4373\n",
      "Epoch 63/2000\n",
      " - 0s - loss: 2.8702 - acc: 0.5372 - val_loss: 2.9290 - val_acc: 0.4548\n",
      "Epoch 64/2000\n",
      " - 0s - loss: 2.8602 - acc: 0.5423 - val_loss: 2.9193 - val_acc: 0.4577\n",
      "Epoch 65/2000\n",
      " - 0s - loss: 2.8498 - acc: 0.5453 - val_loss: 2.9102 - val_acc: 0.4694\n",
      "Epoch 66/2000\n",
      " - 0s - loss: 2.8392 - acc: 0.5474 - val_loss: 2.9002 - val_acc: 0.4577\n",
      "Epoch 67/2000\n",
      " - 0s - loss: 2.8293 - acc: 0.5445 - val_loss: 2.8911 - val_acc: 0.4665\n",
      "Epoch 68/2000\n",
      " - 0s - loss: 2.8189 - acc: 0.5591 - val_loss: 2.8818 - val_acc: 0.4752\n",
      "Epoch 69/2000\n",
      " - 0s - loss: 2.8087 - acc: 0.5613 - val_loss: 2.8709 - val_acc: 0.4752\n",
      "Epoch 70/2000\n",
      " - 0s - loss: 2.7985 - acc: 0.5686 - val_loss: 2.8630 - val_acc: 0.4752\n",
      "Epoch 71/2000\n",
      " - 0s - loss: 2.7888 - acc: 0.5672 - val_loss: 2.8540 - val_acc: 0.4810\n",
      "Epoch 72/2000\n",
      " - 0s - loss: 2.7790 - acc: 0.5686 - val_loss: 2.8453 - val_acc: 0.4810\n",
      "Epoch 73/2000\n",
      " - 0s - loss: 2.7690 - acc: 0.5839 - val_loss: 2.8352 - val_acc: 0.4898\n",
      "Epoch 74/2000\n",
      " - 0s - loss: 2.7595 - acc: 0.5869 - val_loss: 2.8262 - val_acc: 0.4985\n",
      "Epoch 75/2000\n",
      " - 0s - loss: 2.7499 - acc: 0.5898 - val_loss: 2.8165 - val_acc: 0.4927\n",
      "Epoch 76/2000\n",
      " - 0s - loss: 2.7403 - acc: 0.5876 - val_loss: 2.8077 - val_acc: 0.5015\n",
      "Epoch 77/2000\n",
      " - 0s - loss: 2.7307 - acc: 0.5956 - val_loss: 2.7994 - val_acc: 0.5044\n",
      "Epoch 78/2000\n",
      " - 0s - loss: 2.7212 - acc: 0.6066 - val_loss: 2.7902 - val_acc: 0.5073\n",
      "Epoch 79/2000\n",
      " - 0s - loss: 2.7122 - acc: 0.6124 - val_loss: 2.7809 - val_acc: 0.5248\n",
      "Epoch 80/2000\n",
      " - 0s - loss: 2.7023 - acc: 0.6109 - val_loss: 2.7718 - val_acc: 0.5190\n",
      "Epoch 81/2000\n",
      " - 0s - loss: 2.6933 - acc: 0.6146 - val_loss: 2.7638 - val_acc: 0.5306\n",
      "Epoch 82/2000\n",
      " - 0s - loss: 2.6841 - acc: 0.6212 - val_loss: 2.7548 - val_acc: 0.5452\n",
      "Epoch 83/2000\n",
      " - 0s - loss: 2.6749 - acc: 0.6226 - val_loss: 2.7471 - val_acc: 0.5306\n",
      "Epoch 84/2000\n",
      " - 0s - loss: 2.6658 - acc: 0.6277 - val_loss: 2.7386 - val_acc: 0.5306\n",
      "Epoch 85/2000\n",
      " - 0s - loss: 2.6567 - acc: 0.6350 - val_loss: 2.7294 - val_acc: 0.5452\n",
      "Epoch 86/2000\n",
      " - 0s - loss: 2.6479 - acc: 0.6453 - val_loss: 2.7209 - val_acc: 0.5539\n",
      "Epoch 87/2000\n",
      " - 0s - loss: 2.6391 - acc: 0.6453 - val_loss: 2.7126 - val_acc: 0.5539\n",
      "Epoch 88/2000\n",
      " - 0s - loss: 2.6304 - acc: 0.6372 - val_loss: 2.7042 - val_acc: 0.5627\n",
      "Epoch 89/2000\n",
      " - 0s - loss: 2.6214 - acc: 0.6496 - val_loss: 2.6964 - val_acc: 0.5598\n",
      "Epoch 90/2000\n",
      " - 0s - loss: 2.6128 - acc: 0.6526 - val_loss: 2.6889 - val_acc: 0.5743\n",
      "Epoch 91/2000\n",
      " - 0s - loss: 2.6042 - acc: 0.6518 - val_loss: 2.6809 - val_acc: 0.5714\n",
      "Epoch 92/2000\n",
      " - 0s - loss: 2.5955 - acc: 0.6562 - val_loss: 2.6714 - val_acc: 0.5743\n",
      "Epoch 93/2000\n",
      " - 0s - loss: 2.5864 - acc: 0.6642 - val_loss: 2.6636 - val_acc: 0.5918\n",
      "Epoch 94/2000\n",
      " - 0s - loss: 2.5786 - acc: 0.6730 - val_loss: 2.6562 - val_acc: 0.5948\n",
      "Epoch 95/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 2.5701 - acc: 0.6803 - val_loss: 2.6477 - val_acc: 0.5977\n",
      "Epoch 96/2000\n",
      " - 0s - loss: 2.5622 - acc: 0.6752 - val_loss: 2.6401 - val_acc: 0.5948\n",
      "Epoch 97/2000\n",
      " - 0s - loss: 2.5534 - acc: 0.6796 - val_loss: 2.6324 - val_acc: 0.6035\n",
      "Epoch 98/2000\n",
      " - 0s - loss: 2.5447 - acc: 0.6788 - val_loss: 2.6256 - val_acc: 0.6006\n",
      "Epoch 99/2000\n",
      " - 0s - loss: 2.5371 - acc: 0.6825 - val_loss: 2.6167 - val_acc: 0.6152\n",
      "Epoch 100/2000\n",
      " - 0s - loss: 2.5291 - acc: 0.6818 - val_loss: 2.6101 - val_acc: 0.6064\n",
      "Epoch 101/2000\n",
      " - 0s - loss: 2.5206 - acc: 0.6898 - val_loss: 2.6019 - val_acc: 0.6152\n",
      "Epoch 102/2000\n",
      " - 0s - loss: 2.5130 - acc: 0.6971 - val_loss: 2.5949 - val_acc: 0.6122\n",
      "Epoch 103/2000\n",
      " - 0s - loss: 2.5045 - acc: 0.7022 - val_loss: 2.5861 - val_acc: 0.6268\n",
      "Epoch 104/2000\n",
      " - 0s - loss: 2.4965 - acc: 0.7066 - val_loss: 2.5794 - val_acc: 0.6239\n",
      "Epoch 105/2000\n",
      " - 0s - loss: 2.4886 - acc: 0.7095 - val_loss: 2.5715 - val_acc: 0.6268\n",
      "Epoch 106/2000\n",
      " - 0s - loss: 2.4805 - acc: 0.7109 - val_loss: 2.5645 - val_acc: 0.6268\n",
      "Epoch 107/2000\n",
      " - 0s - loss: 2.4732 - acc: 0.7131 - val_loss: 2.5571 - val_acc: 0.6268\n",
      "Epoch 108/2000\n",
      " - 0s - loss: 2.4653 - acc: 0.7131 - val_loss: 2.5500 - val_acc: 0.6297\n",
      "Epoch 109/2000\n",
      " - 0s - loss: 2.4575 - acc: 0.7190 - val_loss: 2.5432 - val_acc: 0.6327\n",
      "Epoch 110/2000\n",
      " - 0s - loss: 2.4498 - acc: 0.7212 - val_loss: 2.5363 - val_acc: 0.6443\n",
      "Epoch 111/2000\n",
      " - 0s - loss: 2.4422 - acc: 0.7285 - val_loss: 2.5298 - val_acc: 0.6356\n",
      "Epoch 112/2000\n",
      " - 0s - loss: 2.4347 - acc: 0.7299 - val_loss: 2.5222 - val_acc: 0.6414\n",
      "Epoch 113/2000\n",
      " - 0s - loss: 2.4269 - acc: 0.7343 - val_loss: 2.5143 - val_acc: 0.6472\n",
      "Epoch 114/2000\n",
      " - 0s - loss: 2.4197 - acc: 0.7350 - val_loss: 2.5078 - val_acc: 0.6414\n",
      "Epoch 115/2000\n",
      " - 0s - loss: 2.4124 - acc: 0.7343 - val_loss: 2.5012 - val_acc: 0.6443\n",
      "Epoch 116/2000\n",
      " - 0s - loss: 2.4049 - acc: 0.7401 - val_loss: 2.4946 - val_acc: 0.6414\n",
      "Epoch 117/2000\n",
      " - 0s - loss: 2.3977 - acc: 0.7409 - val_loss: 2.4871 - val_acc: 0.6356\n",
      "Epoch 118/2000\n",
      " - 0s - loss: 2.3901 - acc: 0.7416 - val_loss: 2.4804 - val_acc: 0.6385\n",
      "Epoch 119/2000\n",
      " - 0s - loss: 2.3826 - acc: 0.7387 - val_loss: 2.4736 - val_acc: 0.6385\n",
      "Epoch 120/2000\n",
      " - 0s - loss: 2.3761 - acc: 0.7423 - val_loss: 2.4668 - val_acc: 0.6414\n",
      "Epoch 121/2000\n",
      " - 0s - loss: 2.3684 - acc: 0.7438 - val_loss: 2.4613 - val_acc: 0.6443\n",
      "Epoch 122/2000\n",
      " - 0s - loss: 2.3612 - acc: 0.7518 - val_loss: 2.4540 - val_acc: 0.6414\n",
      "Epoch 123/2000\n",
      " - 0s - loss: 2.3540 - acc: 0.7562 - val_loss: 2.4475 - val_acc: 0.6501\n",
      "Epoch 124/2000\n",
      " - 0s - loss: 2.3469 - acc: 0.7555 - val_loss: 2.4411 - val_acc: 0.6531\n",
      "Epoch 125/2000\n",
      " - 0s - loss: 2.3400 - acc: 0.7555 - val_loss: 2.4339 - val_acc: 0.6501\n",
      "Epoch 126/2000\n",
      " - 0s - loss: 2.3333 - acc: 0.7650 - val_loss: 2.4280 - val_acc: 0.6589\n",
      "Epoch 127/2000\n",
      " - 0s - loss: 2.3260 - acc: 0.7657 - val_loss: 2.4213 - val_acc: 0.6560\n",
      "Epoch 128/2000\n",
      " - 0s - loss: 2.3192 - acc: 0.7693 - val_loss: 2.4139 - val_acc: 0.6589\n",
      "Epoch 129/2000\n",
      " - 0s - loss: 2.3130 - acc: 0.7701 - val_loss: 2.4082 - val_acc: 0.6560\n",
      "Epoch 130/2000\n",
      " - 0s - loss: 2.3053 - acc: 0.7686 - val_loss: 2.4020 - val_acc: 0.6560\n",
      "Epoch 131/2000\n",
      " - 0s - loss: 2.2990 - acc: 0.7679 - val_loss: 2.3969 - val_acc: 0.6647\n",
      "Epoch 132/2000\n",
      " - 0s - loss: 2.2918 - acc: 0.7803 - val_loss: 2.3895 - val_acc: 0.6706\n",
      "Epoch 133/2000\n",
      " - 0s - loss: 2.2856 - acc: 0.7788 - val_loss: 2.3829 - val_acc: 0.6676\n",
      "Epoch 134/2000\n",
      " - 0s - loss: 2.2787 - acc: 0.7825 - val_loss: 2.3768 - val_acc: 0.6706\n",
      "Epoch 135/2000\n",
      " - 0s - loss: 2.2722 - acc: 0.7861 - val_loss: 2.3703 - val_acc: 0.6706\n",
      "Epoch 136/2000\n",
      " - 0s - loss: 2.2655 - acc: 0.7905 - val_loss: 2.3639 - val_acc: 0.6647\n",
      "Epoch 137/2000\n",
      " - 0s - loss: 2.2589 - acc: 0.7825 - val_loss: 2.3584 - val_acc: 0.6676\n",
      "Epoch 138/2000\n",
      " - 0s - loss: 2.2526 - acc: 0.7825 - val_loss: 2.3527 - val_acc: 0.6706\n",
      "Epoch 139/2000\n",
      " - 0s - loss: 2.2459 - acc: 0.7861 - val_loss: 2.3465 - val_acc: 0.6706\n",
      "Epoch 140/2000\n",
      " - 0s - loss: 2.2393 - acc: 0.7891 - val_loss: 2.3401 - val_acc: 0.6735\n",
      "Epoch 141/2000\n",
      " - 0s - loss: 2.2328 - acc: 0.7891 - val_loss: 2.3338 - val_acc: 0.6676\n",
      "Epoch 142/2000\n",
      " - 0s - loss: 2.2267 - acc: 0.7898 - val_loss: 2.3291 - val_acc: 0.6764\n",
      "Epoch 143/2000\n",
      " - 0s - loss: 2.2199 - acc: 0.7898 - val_loss: 2.3227 - val_acc: 0.6764\n",
      "Epoch 144/2000\n",
      " - 0s - loss: 2.2138 - acc: 0.7912 - val_loss: 2.3172 - val_acc: 0.6764\n",
      "Epoch 145/2000\n",
      " - 0s - loss: 2.2076 - acc: 0.7942 - val_loss: 2.3108 - val_acc: 0.6793\n",
      "Epoch 146/2000\n",
      " - 0s - loss: 2.2014 - acc: 0.7934 - val_loss: 2.3048 - val_acc: 0.6822\n",
      "Epoch 147/2000\n",
      " - 0s - loss: 2.1950 - acc: 0.8007 - val_loss: 2.2997 - val_acc: 0.6822\n",
      "Epoch 148/2000\n",
      " - 0s - loss: 2.1889 - acc: 0.8007 - val_loss: 2.2946 - val_acc: 0.6822\n",
      "Epoch 149/2000\n",
      " - 0s - loss: 2.1827 - acc: 0.8015 - val_loss: 2.2882 - val_acc: 0.6939\n",
      "Epoch 150/2000\n",
      " - 0s - loss: 2.1767 - acc: 0.8029 - val_loss: 2.2823 - val_acc: 0.6880\n",
      "Epoch 151/2000\n",
      " - 0s - loss: 2.1706 - acc: 0.8058 - val_loss: 2.2768 - val_acc: 0.6851\n",
      "Epoch 152/2000\n",
      " - 0s - loss: 2.1645 - acc: 0.8051 - val_loss: 2.2708 - val_acc: 0.6851\n",
      "Epoch 153/2000\n",
      " - 0s - loss: 2.1584 - acc: 0.8044 - val_loss: 2.2663 - val_acc: 0.6880\n",
      "Epoch 154/2000\n",
      " - 0s - loss: 2.1525 - acc: 0.8015 - val_loss: 2.2613 - val_acc: 0.6910\n",
      "Epoch 155/2000\n",
      " - 0s - loss: 2.1464 - acc: 0.8080 - val_loss: 2.2543 - val_acc: 0.6880\n",
      "Epoch 156/2000\n",
      " - 0s - loss: 2.1403 - acc: 0.8095 - val_loss: 2.2487 - val_acc: 0.6968\n",
      "Epoch 157/2000\n",
      " - 0s - loss: 2.1347 - acc: 0.8153 - val_loss: 2.2435 - val_acc: 0.6822\n",
      "Epoch 158/2000\n",
      " - 0s - loss: 2.1288 - acc: 0.8117 - val_loss: 2.2381 - val_acc: 0.6939\n",
      "Epoch 159/2000\n",
      " - 0s - loss: 2.1233 - acc: 0.8153 - val_loss: 2.2319 - val_acc: 0.7026\n",
      "Epoch 160/2000\n",
      " - 0s - loss: 2.1172 - acc: 0.8161 - val_loss: 2.2270 - val_acc: 0.6997\n",
      "Epoch 161/2000\n",
      " - 0s - loss: 2.1115 - acc: 0.8168 - val_loss: 2.2214 - val_acc: 0.6997\n",
      "Epoch 162/2000\n",
      " - 0s - loss: 2.1056 - acc: 0.8175 - val_loss: 2.2168 - val_acc: 0.6997\n",
      "Epoch 163/2000\n",
      " - 0s - loss: 2.0999 - acc: 0.8190 - val_loss: 2.2110 - val_acc: 0.6939\n",
      "Epoch 164/2000\n",
      " - 0s - loss: 2.0945 - acc: 0.8219 - val_loss: 2.2056 - val_acc: 0.7055\n",
      "Epoch 165/2000\n",
      " - 0s - loss: 2.0887 - acc: 0.8204 - val_loss: 2.2009 - val_acc: 0.7055\n",
      "Epoch 166/2000\n",
      " - 0s - loss: 2.0828 - acc: 0.8153 - val_loss: 2.1960 - val_acc: 0.7085\n",
      "Epoch 167/2000\n",
      " - 0s - loss: 2.0775 - acc: 0.8219 - val_loss: 2.1916 - val_acc: 0.7026\n",
      "Epoch 168/2000\n",
      " - 0s - loss: 2.0714 - acc: 0.8270 - val_loss: 2.1857 - val_acc: 0.7026\n",
      "Epoch 169/2000\n",
      " - 0s - loss: 2.0665 - acc: 0.8321 - val_loss: 2.1808 - val_acc: 0.7114\n",
      "Epoch 170/2000\n",
      " - 0s - loss: 2.0611 - acc: 0.8321 - val_loss: 2.1745 - val_acc: 0.7201\n",
      "Epoch 171/2000\n",
      " - 0s - loss: 2.0552 - acc: 0.8321 - val_loss: 2.1707 - val_acc: 0.7085\n",
      "Epoch 172/2000\n",
      " - 0s - loss: 2.0499 - acc: 0.8277 - val_loss: 2.1661 - val_acc: 0.7055\n",
      "Epoch 173/2000\n",
      " - 0s - loss: 2.0446 - acc: 0.8350 - val_loss: 2.1597 - val_acc: 0.7055\n",
      "Epoch 174/2000\n",
      " - 0s - loss: 2.0386 - acc: 0.8328 - val_loss: 2.1547 - val_acc: 0.7114\n",
      "Epoch 175/2000\n",
      " - 0s - loss: 2.0334 - acc: 0.8299 - val_loss: 2.1499 - val_acc: 0.7143\n",
      "Epoch 176/2000\n",
      " - 0s - loss: 2.0281 - acc: 0.8299 - val_loss: 2.1455 - val_acc: 0.7055\n",
      "Epoch 177/2000\n",
      " - 0s - loss: 2.0228 - acc: 0.8292 - val_loss: 2.1402 - val_acc: 0.7055\n",
      "Epoch 178/2000\n",
      " - 0s - loss: 2.0175 - acc: 0.8285 - val_loss: 2.1358 - val_acc: 0.7085\n",
      "Epoch 179/2000\n",
      " - 0s - loss: 2.0119 - acc: 0.8270 - val_loss: 2.1303 - val_acc: 0.7055\n",
      "Epoch 180/2000\n",
      " - 0s - loss: 2.0070 - acc: 0.8314 - val_loss: 2.1260 - val_acc: 0.7055\n",
      "Epoch 181/2000\n",
      " - 0s - loss: 2.0020 - acc: 0.8328 - val_loss: 2.1206 - val_acc: 0.7230\n",
      "Epoch 182/2000\n",
      " - 0s - loss: 1.9963 - acc: 0.8350 - val_loss: 2.1160 - val_acc: 0.7114\n",
      "Epoch 183/2000\n",
      " - 0s - loss: 1.9911 - acc: 0.8358 - val_loss: 2.1113 - val_acc: 0.7201\n",
      "Epoch 184/2000\n",
      " - 0s - loss: 1.9859 - acc: 0.8350 - val_loss: 2.1066 - val_acc: 0.7114\n",
      "Epoch 185/2000\n",
      " - 0s - loss: 1.9810 - acc: 0.8372 - val_loss: 2.1022 - val_acc: 0.7085\n",
      "Epoch 186/2000\n",
      " - 0s - loss: 1.9758 - acc: 0.8343 - val_loss: 2.0972 - val_acc: 0.7114\n",
      "Epoch 187/2000\n",
      " - 0s - loss: 1.9707 - acc: 0.8358 - val_loss: 2.0927 - val_acc: 0.7143\n",
      "Epoch 188/2000\n",
      " - 0s - loss: 1.9658 - acc: 0.8365 - val_loss: 2.0885 - val_acc: 0.7201\n",
      "Epoch 189/2000\n",
      " - 0s - loss: 1.9604 - acc: 0.8358 - val_loss: 2.0833 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/2000\n",
      " - 0s - loss: 1.9556 - acc: 0.8401 - val_loss: 2.0786 - val_acc: 0.7230\n",
      "Epoch 191/2000\n",
      " - 0s - loss: 1.9505 - acc: 0.8423 - val_loss: 2.0733 - val_acc: 0.7230\n",
      "Epoch 192/2000\n",
      " - 0s - loss: 1.9457 - acc: 0.8387 - val_loss: 2.0690 - val_acc: 0.7259\n",
      "Epoch 193/2000\n",
      " - 0s - loss: 1.9406 - acc: 0.8358 - val_loss: 2.0646 - val_acc: 0.7318\n",
      "Epoch 194/2000\n",
      " - 0s - loss: 1.9354 - acc: 0.8380 - val_loss: 2.0596 - val_acc: 0.7289\n",
      "Epoch 195/2000\n",
      " - 0s - loss: 1.9308 - acc: 0.8401 - val_loss: 2.0560 - val_acc: 0.7259\n",
      "Epoch 196/2000\n",
      " - 0s - loss: 1.9263 - acc: 0.8394 - val_loss: 2.0515 - val_acc: 0.7289\n",
      "Epoch 197/2000\n",
      " - 0s - loss: 1.9213 - acc: 0.8372 - val_loss: 2.0469 - val_acc: 0.7259\n",
      "Epoch 198/2000\n",
      " - 0s - loss: 1.9164 - acc: 0.8416 - val_loss: 2.0427 - val_acc: 0.7230\n",
      "Epoch 199/2000\n",
      " - 0s - loss: 1.9117 - acc: 0.8467 - val_loss: 2.0379 - val_acc: 0.7347\n",
      "Epoch 200/2000\n",
      " - 0s - loss: 1.9065 - acc: 0.8431 - val_loss: 2.0338 - val_acc: 0.7347\n",
      "Epoch 201/2000\n",
      " - 0s - loss: 1.9020 - acc: 0.8431 - val_loss: 2.0298 - val_acc: 0.7347\n",
      "Epoch 202/2000\n",
      " - 0s - loss: 1.8973 - acc: 0.8453 - val_loss: 2.0247 - val_acc: 0.7318\n",
      "Epoch 203/2000\n",
      " - 0s - loss: 1.8923 - acc: 0.8453 - val_loss: 2.0199 - val_acc: 0.7289\n",
      "Epoch 204/2000\n",
      " - 0s - loss: 1.8877 - acc: 0.8467 - val_loss: 2.0158 - val_acc: 0.7405\n",
      "Epoch 205/2000\n",
      " - 0s - loss: 1.8831 - acc: 0.8482 - val_loss: 2.0127 - val_acc: 0.7318\n",
      "Epoch 206/2000\n",
      " - 0s - loss: 1.8783 - acc: 0.8467 - val_loss: 2.0065 - val_acc: 0.7405\n",
      "Epoch 207/2000\n",
      " - 0s - loss: 1.8738 - acc: 0.8460 - val_loss: 2.0031 - val_acc: 0.7434\n",
      "Epoch 208/2000\n",
      " - 0s - loss: 1.8690 - acc: 0.8474 - val_loss: 1.9991 - val_acc: 0.7434\n",
      "Epoch 209/2000\n",
      " - 0s - loss: 1.8644 - acc: 0.8474 - val_loss: 1.9948 - val_acc: 0.7376\n",
      "Epoch 210/2000\n",
      " - 0s - loss: 1.8598 - acc: 0.8453 - val_loss: 1.9908 - val_acc: 0.7434\n",
      "Epoch 211/2000\n",
      " - 0s - loss: 1.8554 - acc: 0.8496 - val_loss: 1.9856 - val_acc: 0.7376\n",
      "Epoch 212/2000\n",
      " - 0s - loss: 1.8505 - acc: 0.8482 - val_loss: 1.9825 - val_acc: 0.7493\n",
      "Epoch 213/2000\n",
      " - 0s - loss: 1.8461 - acc: 0.8489 - val_loss: 1.9791 - val_acc: 0.7464\n",
      "Epoch 214/2000\n",
      " - 0s - loss: 1.8419 - acc: 0.8496 - val_loss: 1.9744 - val_acc: 0.7376\n",
      "Epoch 215/2000\n",
      " - 0s - loss: 1.8372 - acc: 0.8547 - val_loss: 1.9696 - val_acc: 0.7405\n",
      "Epoch 216/2000\n",
      " - 0s - loss: 1.8330 - acc: 0.8504 - val_loss: 1.9661 - val_acc: 0.7493\n",
      "Epoch 217/2000\n",
      " - 0s - loss: 1.8282 - acc: 0.8533 - val_loss: 1.9619 - val_acc: 0.7434\n",
      "Epoch 218/2000\n",
      " - 0s - loss: 1.8239 - acc: 0.8540 - val_loss: 1.9579 - val_acc: 0.7464\n",
      "Epoch 219/2000\n",
      " - 0s - loss: 1.8199 - acc: 0.8511 - val_loss: 1.9548 - val_acc: 0.7464\n",
      "Epoch 220/2000\n",
      " - 0s - loss: 1.8150 - acc: 0.8511 - val_loss: 1.9499 - val_acc: 0.7493\n",
      "Epoch 221/2000\n",
      " - 0s - loss: 1.8104 - acc: 0.8547 - val_loss: 1.9454 - val_acc: 0.7464\n",
      "Epoch 222/2000\n",
      " - 0s - loss: 1.8062 - acc: 0.8540 - val_loss: 1.9415 - val_acc: 0.7493\n",
      "Epoch 223/2000\n",
      " - 0s - loss: 1.8017 - acc: 0.8562 - val_loss: 1.9373 - val_acc: 0.7551\n",
      "Epoch 224/2000\n",
      " - 0s - loss: 1.7976 - acc: 0.8540 - val_loss: 1.9331 - val_acc: 0.7493\n",
      "Epoch 225/2000\n",
      " - 0s - loss: 1.7936 - acc: 0.8555 - val_loss: 1.9296 - val_acc: 0.7522\n",
      "Epoch 226/2000\n",
      " - 0s - loss: 1.7891 - acc: 0.8577 - val_loss: 1.9262 - val_acc: 0.7580\n",
      "Epoch 227/2000\n",
      " - 0s - loss: 1.7849 - acc: 0.8562 - val_loss: 1.9234 - val_acc: 0.7580\n",
      "Epoch 228/2000\n",
      " - 0s - loss: 1.7805 - acc: 0.8555 - val_loss: 1.9186 - val_acc: 0.7551\n",
      "Epoch 229/2000\n",
      " - 0s - loss: 1.7766 - acc: 0.8569 - val_loss: 1.9144 - val_acc: 0.7551\n",
      "Epoch 230/2000\n",
      " - 0s - loss: 1.7719 - acc: 0.8591 - val_loss: 1.9104 - val_acc: 0.7580\n",
      "Epoch 231/2000\n",
      " - 0s - loss: 1.7678 - acc: 0.8599 - val_loss: 1.9071 - val_acc: 0.7551\n",
      "Epoch 232/2000\n",
      " - 0s - loss: 1.7639 - acc: 0.8606 - val_loss: 1.9040 - val_acc: 0.7609\n",
      "Epoch 233/2000\n",
      " - 0s - loss: 1.7596 - acc: 0.8599 - val_loss: 1.8999 - val_acc: 0.7551\n",
      "Epoch 234/2000\n",
      " - 0s - loss: 1.7559 - acc: 0.8591 - val_loss: 1.8949 - val_acc: 0.7580\n",
      "Epoch 235/2000\n",
      " - 0s - loss: 1.7518 - acc: 0.8591 - val_loss: 1.8924 - val_acc: 0.7551\n",
      "Epoch 236/2000\n",
      " - 0s - loss: 1.7470 - acc: 0.8591 - val_loss: 1.8883 - val_acc: 0.7551\n",
      "Epoch 237/2000\n",
      " - 0s - loss: 1.7432 - acc: 0.8584 - val_loss: 1.8836 - val_acc: 0.7668\n",
      "Epoch 238/2000\n",
      " - 0s - loss: 1.7391 - acc: 0.8599 - val_loss: 1.8793 - val_acc: 0.7726\n",
      "Epoch 239/2000\n",
      " - 0s - loss: 1.7350 - acc: 0.8599 - val_loss: 1.8763 - val_acc: 0.7668\n",
      "Epoch 240/2000\n",
      " - 0s - loss: 1.7309 - acc: 0.8628 - val_loss: 1.8729 - val_acc: 0.7784\n",
      "Epoch 241/2000\n",
      " - 0s - loss: 1.7275 - acc: 0.8635 - val_loss: 1.8699 - val_acc: 0.7668\n",
      "Epoch 242/2000\n",
      " - 0s - loss: 1.7228 - acc: 0.8642 - val_loss: 1.8655 - val_acc: 0.7726\n",
      "Epoch 243/2000\n",
      " - 0s - loss: 1.7187 - acc: 0.8606 - val_loss: 1.8619 - val_acc: 0.7726\n",
      "Epoch 244/2000\n",
      " - 0s - loss: 1.7149 - acc: 0.8628 - val_loss: 1.8588 - val_acc: 0.7726\n",
      "Epoch 245/2000\n",
      " - 0s - loss: 1.7112 - acc: 0.8599 - val_loss: 1.8550 - val_acc: 0.7726\n",
      "Epoch 246/2000\n",
      " - 0s - loss: 1.7073 - acc: 0.8591 - val_loss: 1.8514 - val_acc: 0.7668\n",
      "Epoch 247/2000\n",
      " - 0s - loss: 1.7032 - acc: 0.8620 - val_loss: 1.8477 - val_acc: 0.7697\n",
      "Epoch 248/2000\n",
      " - 0s - loss: 1.6992 - acc: 0.8606 - val_loss: 1.8443 - val_acc: 0.7668\n",
      "Epoch 249/2000\n",
      " - 0s - loss: 1.6955 - acc: 0.8664 - val_loss: 1.8397 - val_acc: 0.7813\n",
      "Epoch 250/2000\n",
      " - 0s - loss: 1.6916 - acc: 0.8635 - val_loss: 1.8373 - val_acc: 0.7784\n",
      "Epoch 251/2000\n",
      " - 0s - loss: 1.6877 - acc: 0.8635 - val_loss: 1.8339 - val_acc: 0.7697\n",
      "Epoch 252/2000\n",
      " - 0s - loss: 1.6837 - acc: 0.8657 - val_loss: 1.8300 - val_acc: 0.7813\n",
      "Epoch 253/2000\n",
      " - 0s - loss: 1.6803 - acc: 0.8657 - val_loss: 1.8262 - val_acc: 0.7843\n",
      "Epoch 254/2000\n",
      " - 0s - loss: 1.6763 - acc: 0.8620 - val_loss: 1.8234 - val_acc: 0.7726\n",
      "Epoch 255/2000\n",
      " - 0s - loss: 1.6726 - acc: 0.8657 - val_loss: 1.8194 - val_acc: 0.7784\n",
      "Epoch 256/2000\n",
      " - 0s - loss: 1.6686 - acc: 0.8664 - val_loss: 1.8168 - val_acc: 0.7843\n",
      "Epoch 257/2000\n",
      " - 0s - loss: 1.6650 - acc: 0.8664 - val_loss: 1.8129 - val_acc: 0.7843\n",
      "Epoch 258/2000\n",
      " - 0s - loss: 1.6611 - acc: 0.8664 - val_loss: 1.8090 - val_acc: 0.7784\n",
      "Epoch 259/2000\n",
      " - 0s - loss: 1.6570 - acc: 0.8664 - val_loss: 1.8059 - val_acc: 0.7843\n",
      "Epoch 260/2000\n",
      " - 0s - loss: 1.6536 - acc: 0.8650 - val_loss: 1.8030 - val_acc: 0.7784\n",
      "Epoch 261/2000\n",
      " - 0s - loss: 1.6499 - acc: 0.8672 - val_loss: 1.8000 - val_acc: 0.7813\n",
      "Epoch 262/2000\n",
      " - 0s - loss: 1.6462 - acc: 0.8664 - val_loss: 1.7960 - val_acc: 0.7843\n",
      "Epoch 263/2000\n",
      " - 0s - loss: 1.6425 - acc: 0.8664 - val_loss: 1.7929 - val_acc: 0.7784\n",
      "Epoch 264/2000\n",
      " - 0s - loss: 1.6390 - acc: 0.8679 - val_loss: 1.7887 - val_acc: 0.7872\n",
      "Epoch 265/2000\n",
      " - 0s - loss: 1.6353 - acc: 0.8664 - val_loss: 1.7856 - val_acc: 0.7813\n",
      "Epoch 266/2000\n",
      " - 0s - loss: 1.6315 - acc: 0.8679 - val_loss: 1.7833 - val_acc: 0.7843\n",
      "Epoch 267/2000\n",
      " - 0s - loss: 1.6277 - acc: 0.8715 - val_loss: 1.7810 - val_acc: 0.7784\n",
      "Epoch 268/2000\n",
      " - 0s - loss: 1.6242 - acc: 0.8679 - val_loss: 1.7772 - val_acc: 0.7755\n",
      "Epoch 269/2000\n",
      " - 0s - loss: 1.6209 - acc: 0.8679 - val_loss: 1.7725 - val_acc: 0.7813\n",
      "Epoch 270/2000\n",
      " - 0s - loss: 1.6172 - acc: 0.8686 - val_loss: 1.7689 - val_acc: 0.7872\n",
      "Epoch 271/2000\n",
      " - 0s - loss: 1.6135 - acc: 0.8693 - val_loss: 1.7663 - val_acc: 0.7872\n",
      "Epoch 272/2000\n",
      " - 0s - loss: 1.6100 - acc: 0.8693 - val_loss: 1.7632 - val_acc: 0.7843\n",
      "Epoch 273/2000\n",
      " - 0s - loss: 1.6064 - acc: 0.8708 - val_loss: 1.7609 - val_acc: 0.7843\n",
      "Epoch 274/2000\n",
      " - 0s - loss: 1.6030 - acc: 0.8701 - val_loss: 1.7569 - val_acc: 0.7872\n",
      "Epoch 275/2000\n",
      " - 0s - loss: 1.5995 - acc: 0.8708 - val_loss: 1.7540 - val_acc: 0.7843\n",
      "Epoch 276/2000\n",
      " - 0s - loss: 1.5961 - acc: 0.8708 - val_loss: 1.7509 - val_acc: 0.7843\n",
      "Epoch 277/2000\n",
      " - 0s - loss: 1.5921 - acc: 0.8708 - val_loss: 1.7482 - val_acc: 0.7813\n",
      "Epoch 278/2000\n",
      " - 0s - loss: 1.5888 - acc: 0.8715 - val_loss: 1.7447 - val_acc: 0.7784\n",
      "Epoch 279/2000\n",
      " - 0s - loss: 1.5857 - acc: 0.8693 - val_loss: 1.7415 - val_acc: 0.7813\n",
      "Epoch 280/2000\n",
      " - 0s - loss: 1.5826 - acc: 0.8679 - val_loss: 1.7386 - val_acc: 0.7872\n",
      "Epoch 281/2000\n",
      " - 0s - loss: 1.5787 - acc: 0.8715 - val_loss: 1.7346 - val_acc: 0.7813\n",
      "Epoch 282/2000\n",
      " - 0s - loss: 1.5751 - acc: 0.8730 - val_loss: 1.7323 - val_acc: 0.7813\n",
      "Epoch 283/2000\n",
      " - 0s - loss: 1.5718 - acc: 0.8752 - val_loss: 1.7284 - val_acc: 0.7872\n",
      "Epoch 284/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.5684 - acc: 0.8723 - val_loss: 1.7255 - val_acc: 0.7843\n",
      "Epoch 285/2000\n",
      " - 0s - loss: 1.5650 - acc: 0.8730 - val_loss: 1.7229 - val_acc: 0.7813\n",
      "Epoch 286/2000\n",
      " - 0s - loss: 1.5624 - acc: 0.8715 - val_loss: 1.7212 - val_acc: 0.7872\n",
      "Epoch 287/2000\n",
      " - 0s - loss: 1.5599 - acc: 0.8737 - val_loss: 1.7181 - val_acc: 0.7872\n",
      "Epoch 288/2000\n",
      " - 0s - loss: 1.5571 - acc: 0.8759 - val_loss: 1.7158 - val_acc: 0.7813\n",
      "Epoch 289/2000\n",
      " - 0s - loss: 1.5543 - acc: 0.8752 - val_loss: 1.7142 - val_acc: 0.7843\n",
      "Epoch 290/2000\n",
      " - 0s - loss: 1.5517 - acc: 0.8737 - val_loss: 1.7109 - val_acc: 0.7843\n",
      "Epoch 291/2000\n",
      " - 0s - loss: 1.5490 - acc: 0.8752 - val_loss: 1.7090 - val_acc: 0.7843\n",
      "Epoch 292/2000\n",
      " - 0s - loss: 1.5463 - acc: 0.8752 - val_loss: 1.7066 - val_acc: 0.7813\n",
      "Epoch 293/2000\n",
      " - 0s - loss: 1.5442 - acc: 0.8737 - val_loss: 1.7036 - val_acc: 0.7872\n",
      "Epoch 294/2000\n",
      " - 0s - loss: 1.5409 - acc: 0.8730 - val_loss: 1.7020 - val_acc: 0.7872\n",
      "Epoch 295/2000\n",
      " - 0s - loss: 1.5383 - acc: 0.8737 - val_loss: 1.6995 - val_acc: 0.7813\n",
      "Epoch 296/2000\n",
      " - 0s - loss: 1.5356 - acc: 0.8745 - val_loss: 1.6970 - val_acc: 0.7843\n",
      "Epoch 297/2000\n",
      " - 0s - loss: 1.5333 - acc: 0.8759 - val_loss: 1.6944 - val_acc: 0.7843\n",
      "Epoch 298/2000\n",
      " - 0s - loss: 1.5308 - acc: 0.8745 - val_loss: 1.6922 - val_acc: 0.7901\n",
      "Epoch 299/2000\n",
      " - 0s - loss: 1.5281 - acc: 0.8723 - val_loss: 1.6907 - val_acc: 0.7843\n",
      "Epoch 300/2000\n",
      " - 0s - loss: 1.5252 - acc: 0.8737 - val_loss: 1.6882 - val_acc: 0.7901\n",
      "Epoch 301/2000\n",
      " - 0s - loss: 1.5228 - acc: 0.8752 - val_loss: 1.6853 - val_acc: 0.7843\n",
      "Epoch 302/2000\n",
      " - 0s - loss: 1.5202 - acc: 0.8752 - val_loss: 1.6831 - val_acc: 0.7872\n",
      "Epoch 303/2000\n",
      " - 0s - loss: 1.5179 - acc: 0.8766 - val_loss: 1.6808 - val_acc: 0.7930\n",
      "Epoch 304/2000\n",
      " - 0s - loss: 1.5147 - acc: 0.8781 - val_loss: 1.6779 - val_acc: 0.7901\n",
      "Epoch 305/2000\n",
      " - 0s - loss: 1.5124 - acc: 0.8788 - val_loss: 1.6755 - val_acc: 0.7930\n",
      "Epoch 306/2000\n",
      " - 0s - loss: 1.5098 - acc: 0.8774 - val_loss: 1.6732 - val_acc: 0.7930\n",
      "Epoch 307/2000\n",
      " - 0s - loss: 1.5076 - acc: 0.8745 - val_loss: 1.6712 - val_acc: 0.7901\n",
      "Epoch 308/2000\n",
      " - 0s - loss: 1.5049 - acc: 0.8752 - val_loss: 1.6693 - val_acc: 0.7901\n",
      "Epoch 309/2000\n",
      " - 0s - loss: 1.5022 - acc: 0.8745 - val_loss: 1.6672 - val_acc: 0.7901\n",
      "Epoch 310/2000\n",
      " - 0s - loss: 1.4999 - acc: 0.8759 - val_loss: 1.6650 - val_acc: 0.7843\n",
      "Epoch 311/2000\n",
      " - 0s - loss: 1.4971 - acc: 0.8759 - val_loss: 1.6622 - val_acc: 0.7872\n",
      "Epoch 312/2000\n",
      " - 0s - loss: 1.4947 - acc: 0.8788 - val_loss: 1.6603 - val_acc: 0.7901\n",
      "Epoch 313/2000\n",
      " - 0s - loss: 1.4923 - acc: 0.8766 - val_loss: 1.6579 - val_acc: 0.7959\n",
      "Epoch 314/2000\n",
      " - 0s - loss: 1.4900 - acc: 0.8810 - val_loss: 1.6554 - val_acc: 0.7959\n",
      "Epoch 315/2000\n",
      " - 0s - loss: 1.4871 - acc: 0.8788 - val_loss: 1.6537 - val_acc: 0.7901\n",
      "Epoch 316/2000\n",
      " - 0s - loss: 1.4848 - acc: 0.8781 - val_loss: 1.6515 - val_acc: 0.7930\n",
      "Epoch 317/2000\n",
      " - 0s - loss: 1.4823 - acc: 0.8752 - val_loss: 1.6495 - val_acc: 0.7901\n",
      "Epoch 318/2000\n",
      " - 0s - loss: 1.4800 - acc: 0.8752 - val_loss: 1.6470 - val_acc: 0.7901\n",
      "Epoch 319/2000\n",
      " - 0s - loss: 1.4771 - acc: 0.8810 - val_loss: 1.6447 - val_acc: 0.7901\n",
      "Epoch 320/2000\n",
      " - 0s - loss: 1.4748 - acc: 0.8810 - val_loss: 1.6425 - val_acc: 0.7901\n",
      "Epoch 321/2000\n",
      " - 0s - loss: 1.4725 - acc: 0.8818 - val_loss: 1.6403 - val_acc: 0.7930\n",
      "Epoch 322/2000\n",
      " - 0s - loss: 1.4699 - acc: 0.8818 - val_loss: 1.6379 - val_acc: 0.7930\n",
      "Epoch 323/2000\n",
      " - 0s - loss: 1.4674 - acc: 0.8818 - val_loss: 1.6356 - val_acc: 0.7930\n",
      "Epoch 324/2000\n",
      " - 0s - loss: 1.4652 - acc: 0.8825 - val_loss: 1.6333 - val_acc: 0.7901\n",
      "Epoch 325/2000\n",
      " - 0s - loss: 1.4624 - acc: 0.8818 - val_loss: 1.6314 - val_acc: 0.7901\n",
      "Epoch 326/2000\n",
      " - 0s - loss: 1.4602 - acc: 0.8803 - val_loss: 1.6296 - val_acc: 0.7901\n",
      "Epoch 327/2000\n",
      " - 0s - loss: 1.4579 - acc: 0.8788 - val_loss: 1.6279 - val_acc: 0.7901\n",
      "Epoch 328/2000\n",
      " - 0s - loss: 1.4556 - acc: 0.8818 - val_loss: 1.6249 - val_acc: 0.7901\n",
      "Epoch 329/2000\n",
      " - 0s - loss: 1.4532 - acc: 0.8839 - val_loss: 1.6232 - val_acc: 0.7930\n",
      "Epoch 330/2000\n",
      " - 0s - loss: 1.4506 - acc: 0.8818 - val_loss: 1.6213 - val_acc: 0.7901\n",
      "Epoch 331/2000\n",
      " - 0s - loss: 1.4483 - acc: 0.8796 - val_loss: 1.6199 - val_acc: 0.7901\n",
      "Epoch 332/2000\n",
      " - 0s - loss: 1.4459 - acc: 0.8832 - val_loss: 1.6167 - val_acc: 0.7959\n",
      "Epoch 333/2000\n",
      " - 0s - loss: 1.4434 - acc: 0.8839 - val_loss: 1.6143 - val_acc: 0.7901\n",
      "Epoch 334/2000\n",
      " - 0s - loss: 1.4413 - acc: 0.8832 - val_loss: 1.6131 - val_acc: 0.7930\n",
      "Epoch 335/2000\n",
      " - 0s - loss: 1.4391 - acc: 0.8839 - val_loss: 1.6107 - val_acc: 0.7930\n",
      "Epoch 336/2000\n",
      " - 0s - loss: 1.4374 - acc: 0.8839 - val_loss: 1.6086 - val_acc: 0.7930\n",
      "Epoch 337/2000\n",
      " - 0s - loss: 1.4354 - acc: 0.8847 - val_loss: 1.6072 - val_acc: 0.7930\n",
      "Epoch 338/2000\n",
      " - 0s - loss: 1.4336 - acc: 0.8825 - val_loss: 1.6056 - val_acc: 0.7872\n",
      "Epoch 339/2000\n",
      " - 0s - loss: 1.4317 - acc: 0.8847 - val_loss: 1.6037 - val_acc: 0.7930\n",
      "Epoch 340/2000\n",
      " - 0s - loss: 1.4299 - acc: 0.8825 - val_loss: 1.6018 - val_acc: 0.7930\n",
      "Epoch 341/2000\n",
      " - 0s - loss: 1.4280 - acc: 0.8832 - val_loss: 1.6003 - val_acc: 0.7930\n",
      "Epoch 342/2000\n",
      " - 0s - loss: 1.4262 - acc: 0.8839 - val_loss: 1.5990 - val_acc: 0.7872\n",
      "Epoch 343/2000\n",
      " - 0s - loss: 1.4241 - acc: 0.8854 - val_loss: 1.5973 - val_acc: 0.7901\n",
      "Epoch 344/2000\n",
      " - 0s - loss: 1.4225 - acc: 0.8847 - val_loss: 1.5954 - val_acc: 0.7872\n",
      "Epoch 345/2000\n",
      " - 0s - loss: 1.4206 - acc: 0.8832 - val_loss: 1.5937 - val_acc: 0.7901\n",
      "Epoch 346/2000\n",
      " - 0s - loss: 1.4186 - acc: 0.8861 - val_loss: 1.5927 - val_acc: 0.7901\n",
      "Epoch 347/2000\n",
      " - 0s - loss: 1.4168 - acc: 0.8847 - val_loss: 1.5911 - val_acc: 0.7901\n",
      "Epoch 348/2000\n",
      " - 0s - loss: 1.4150 - acc: 0.8847 - val_loss: 1.5889 - val_acc: 0.7901\n",
      "Epoch 349/2000\n",
      " - 0s - loss: 1.4132 - acc: 0.8847 - val_loss: 1.5875 - val_acc: 0.7901\n",
      "Epoch 350/2000\n",
      " - 0s - loss: 1.4113 - acc: 0.8847 - val_loss: 1.5861 - val_acc: 0.7930\n",
      "Epoch 351/2000\n",
      " - 0s - loss: 1.4092 - acc: 0.8847 - val_loss: 1.5844 - val_acc: 0.7930\n",
      "Epoch 352/2000\n",
      " - 0s - loss: 1.4078 - acc: 0.8847 - val_loss: 1.5834 - val_acc: 0.7872\n",
      "Epoch 353/2000\n",
      " - 0s - loss: 1.4060 - acc: 0.8847 - val_loss: 1.5814 - val_acc: 0.7901\n",
      "Epoch 354/2000\n",
      " - 0s - loss: 1.4041 - acc: 0.8854 - val_loss: 1.5801 - val_acc: 0.7901\n",
      "Epoch 355/2000\n",
      " - 0s - loss: 1.4027 - acc: 0.8861 - val_loss: 1.5788 - val_acc: 0.7901\n",
      "Epoch 356/2000\n",
      " - 0s - loss: 1.4010 - acc: 0.8876 - val_loss: 1.5770 - val_acc: 0.7930\n",
      "Epoch 357/2000\n",
      " - 0s - loss: 1.3998 - acc: 0.8854 - val_loss: 1.5757 - val_acc: 0.7930\n",
      "Epoch 358/2000\n",
      " - 0s - loss: 1.3982 - acc: 0.8854 - val_loss: 1.5747 - val_acc: 0.7930\n",
      "Epoch 359/2000\n",
      " - 0s - loss: 1.3968 - acc: 0.8854 - val_loss: 1.5737 - val_acc: 0.7901\n",
      "Epoch 360/2000\n",
      " - 0s - loss: 1.3954 - acc: 0.8854 - val_loss: 1.5716 - val_acc: 0.7930\n",
      "Epoch 361/2000\n",
      " - 0s - loss: 1.3938 - acc: 0.8869 - val_loss: 1.5702 - val_acc: 0.7930\n",
      "Epoch 362/2000\n",
      " - 0s - loss: 1.3925 - acc: 0.8861 - val_loss: 1.5687 - val_acc: 0.7959\n",
      "Epoch 363/2000\n",
      " - 0s - loss: 1.3909 - acc: 0.8869 - val_loss: 1.5679 - val_acc: 0.7901\n",
      "Epoch 364/2000\n",
      " - 0s - loss: 1.3895 - acc: 0.8861 - val_loss: 1.5669 - val_acc: 0.7901\n",
      "Epoch 365/2000\n",
      " - 0s - loss: 1.3882 - acc: 0.8861 - val_loss: 1.5654 - val_acc: 0.7959\n",
      "Epoch 366/2000\n",
      " - 0s - loss: 1.3867 - acc: 0.8869 - val_loss: 1.5641 - val_acc: 0.7930\n",
      "Epoch 367/2000\n",
      " - 0s - loss: 1.3854 - acc: 0.8861 - val_loss: 1.5629 - val_acc: 0.7901\n",
      "Epoch 368/2000\n",
      " - 0s - loss: 1.3838 - acc: 0.8861 - val_loss: 1.5612 - val_acc: 0.7901\n",
      "Epoch 369/2000\n",
      " - 0s - loss: 1.3825 - acc: 0.8861 - val_loss: 1.5600 - val_acc: 0.7930\n",
      "Epoch 370/2000\n",
      " - 0s - loss: 1.3811 - acc: 0.8861 - val_loss: 1.5595 - val_acc: 0.7930\n",
      "Epoch 371/2000\n",
      " - 0s - loss: 1.3795 - acc: 0.8869 - val_loss: 1.5582 - val_acc: 0.7901\n",
      "Epoch 372/2000\n",
      " - 0s - loss: 1.3781 - acc: 0.8861 - val_loss: 1.5563 - val_acc: 0.7930\n",
      "Epoch 373/2000\n",
      " - 0s - loss: 1.3768 - acc: 0.8861 - val_loss: 1.5552 - val_acc: 0.7930\n",
      "Epoch 374/2000\n",
      " - 0s - loss: 1.3754 - acc: 0.8854 - val_loss: 1.5544 - val_acc: 0.7901\n",
      "Epoch 375/2000\n",
      " - 0s - loss: 1.3742 - acc: 0.8854 - val_loss: 1.5533 - val_acc: 0.7930\n",
      "Epoch 376/2000\n",
      " - 0s - loss: 1.3731 - acc: 0.8869 - val_loss: 1.5520 - val_acc: 0.7901\n",
      "Epoch 377/2000\n",
      " - 0s - loss: 1.3720 - acc: 0.8891 - val_loss: 1.5513 - val_acc: 0.7901\n",
      "Epoch 378/2000\n",
      " - 0s - loss: 1.3708 - acc: 0.8876 - val_loss: 1.5499 - val_acc: 0.7959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/2000\n",
      " - 0s - loss: 1.3697 - acc: 0.8861 - val_loss: 1.5492 - val_acc: 0.7959\n",
      "Epoch 380/2000\n",
      " - 0s - loss: 1.3686 - acc: 0.8876 - val_loss: 1.5477 - val_acc: 0.7930\n",
      "Epoch 381/2000\n",
      " - 0s - loss: 1.3676 - acc: 0.8869 - val_loss: 1.5468 - val_acc: 0.7930\n",
      "Epoch 382/2000\n",
      " - 0s - loss: 1.3662 - acc: 0.8869 - val_loss: 1.5461 - val_acc: 0.7988\n",
      "Epoch 383/2000\n",
      " - 0s - loss: 1.3654 - acc: 0.8883 - val_loss: 1.5453 - val_acc: 0.7959\n",
      "Epoch 384/2000\n",
      " - 0s - loss: 1.3641 - acc: 0.8883 - val_loss: 1.5443 - val_acc: 0.7959\n",
      "Epoch 385/2000\n",
      " - 0s - loss: 1.3630 - acc: 0.8898 - val_loss: 1.5432 - val_acc: 0.7988\n",
      "Epoch 386/2000\n",
      " - 0s - loss: 1.3618 - acc: 0.8898 - val_loss: 1.5422 - val_acc: 0.7988\n",
      "Epoch 387/2000\n",
      " - 0s - loss: 1.3607 - acc: 0.8891 - val_loss: 1.5412 - val_acc: 0.7959\n",
      "Epoch 388/2000\n",
      " - 0s - loss: 1.3595 - acc: 0.8898 - val_loss: 1.5401 - val_acc: 0.7959\n",
      "Epoch 389/2000\n",
      " - 0s - loss: 1.3585 - acc: 0.8898 - val_loss: 1.5392 - val_acc: 0.7959\n",
      "Epoch 390/2000\n",
      " - 0s - loss: 1.3574 - acc: 0.8891 - val_loss: 1.5376 - val_acc: 0.7959\n",
      "Epoch 391/2000\n",
      " - 0s - loss: 1.3562 - acc: 0.8891 - val_loss: 1.5369 - val_acc: 0.7959\n",
      "Epoch 392/2000\n",
      " - 0s - loss: 1.3552 - acc: 0.8898 - val_loss: 1.5360 - val_acc: 0.7988\n",
      "Epoch 393/2000\n",
      " - 0s - loss: 1.3539 - acc: 0.8898 - val_loss: 1.5350 - val_acc: 0.7988\n",
      "Epoch 394/2000\n",
      " - 0s - loss: 1.3530 - acc: 0.8905 - val_loss: 1.5342 - val_acc: 0.7988\n",
      "Epoch 395/2000\n",
      " - 0s - loss: 1.3519 - acc: 0.8898 - val_loss: 1.5331 - val_acc: 0.7988\n",
      "Epoch 396/2000\n",
      " - 0s - loss: 1.3507 - acc: 0.8898 - val_loss: 1.5322 - val_acc: 0.7988\n",
      "Epoch 397/2000\n",
      " - 0s - loss: 1.3495 - acc: 0.8898 - val_loss: 1.5314 - val_acc: 0.7988\n",
      "Epoch 398/2000\n",
      " - 0s - loss: 1.3485 - acc: 0.8898 - val_loss: 1.5302 - val_acc: 0.8017\n",
      "Epoch 399/2000\n",
      " - 0s - loss: 1.3475 - acc: 0.8920 - val_loss: 1.5293 - val_acc: 0.8017\n",
      "Epoch 400/2000\n",
      " - 0s - loss: 1.3465 - acc: 0.8912 - val_loss: 1.5284 - val_acc: 0.7988\n",
      "Epoch 401/2000\n",
      " - 0s - loss: 1.3452 - acc: 0.8912 - val_loss: 1.5269 - val_acc: 0.7988\n",
      "Epoch 402/2000\n",
      " - 0s - loss: 1.3441 - acc: 0.8898 - val_loss: 1.5261 - val_acc: 0.7959\n",
      "Epoch 403/2000\n",
      " - 0s - loss: 1.3430 - acc: 0.8905 - val_loss: 1.5255 - val_acc: 0.7988\n",
      "Epoch 404/2000\n",
      " - 0s - loss: 1.3419 - acc: 0.8905 - val_loss: 1.5246 - val_acc: 0.7988\n",
      "Epoch 405/2000\n",
      " - 0s - loss: 1.3408 - acc: 0.8905 - val_loss: 1.5235 - val_acc: 0.7988\n",
      "Epoch 406/2000\n",
      " - 0s - loss: 1.3397 - acc: 0.8912 - val_loss: 1.5224 - val_acc: 0.7988\n",
      "Epoch 407/2000\n",
      " - 0s - loss: 1.3385 - acc: 0.8905 - val_loss: 1.5215 - val_acc: 0.7988\n",
      "Epoch 408/2000\n",
      " - 0s - loss: 1.3376 - acc: 0.8905 - val_loss: 1.5203 - val_acc: 0.7988\n",
      "Epoch 409/2000\n",
      " - 0s - loss: 1.3365 - acc: 0.8898 - val_loss: 1.5191 - val_acc: 0.7988\n",
      "Epoch 410/2000\n",
      " - 0s - loss: 1.3355 - acc: 0.8905 - val_loss: 1.5183 - val_acc: 0.7988\n",
      "Epoch 411/2000\n",
      " - 0s - loss: 1.3343 - acc: 0.8891 - val_loss: 1.5177 - val_acc: 0.7988\n",
      "Epoch 412/2000\n",
      " - 0s - loss: 1.3331 - acc: 0.8898 - val_loss: 1.5164 - val_acc: 0.7988\n",
      "Epoch 413/2000\n",
      " - 0s - loss: 1.3321 - acc: 0.8898 - val_loss: 1.5154 - val_acc: 0.7988\n",
      "Epoch 414/2000\n",
      " - 0s - loss: 1.3308 - acc: 0.8905 - val_loss: 1.5145 - val_acc: 0.7988\n",
      "Epoch 415/2000\n",
      " - 0s - loss: 1.3298 - acc: 0.8898 - val_loss: 1.5135 - val_acc: 0.7988\n",
      "Epoch 416/2000\n",
      " - 0s - loss: 1.3288 - acc: 0.8905 - val_loss: 1.5127 - val_acc: 0.7988\n",
      "Epoch 417/2000\n",
      " - 0s - loss: 1.3277 - acc: 0.8905 - val_loss: 1.5115 - val_acc: 0.7988\n",
      "Epoch 418/2000\n",
      " - 0s - loss: 1.3267 - acc: 0.8905 - val_loss: 1.5106 - val_acc: 0.7988\n",
      "Epoch 419/2000\n",
      " - 0s - loss: 1.3255 - acc: 0.8905 - val_loss: 1.5099 - val_acc: 0.7988\n",
      "Epoch 420/2000\n",
      " - 0s - loss: 1.3247 - acc: 0.8905 - val_loss: 1.5093 - val_acc: 0.7988\n",
      "Epoch 421/2000\n",
      " - 0s - loss: 1.3238 - acc: 0.8898 - val_loss: 1.5086 - val_acc: 0.7988\n",
      "Epoch 422/2000\n",
      " - 0s - loss: 1.3230 - acc: 0.8905 - val_loss: 1.5078 - val_acc: 0.7988\n",
      "Epoch 423/2000\n",
      " - 0s - loss: 1.3221 - acc: 0.8905 - val_loss: 1.5068 - val_acc: 0.7988\n",
      "Epoch 424/2000\n",
      " - 0s - loss: 1.3213 - acc: 0.8905 - val_loss: 1.5063 - val_acc: 0.8017\n",
      "Epoch 425/2000\n",
      " - 0s - loss: 1.3204 - acc: 0.8905 - val_loss: 1.5056 - val_acc: 0.8017\n",
      "Epoch 426/2000\n",
      " - 0s - loss: 1.3196 - acc: 0.8905 - val_loss: 1.5049 - val_acc: 0.7988\n",
      "Epoch 427/2000\n",
      " - 0s - loss: 1.3186 - acc: 0.8905 - val_loss: 1.5040 - val_acc: 0.7988\n",
      "Epoch 428/2000\n",
      " - 0s - loss: 1.3178 - acc: 0.8905 - val_loss: 1.5035 - val_acc: 0.7988\n",
      "Epoch 429/2000\n",
      " - 0s - loss: 1.3171 - acc: 0.8912 - val_loss: 1.5027 - val_acc: 0.7988\n",
      "Epoch 430/2000\n",
      " - 0s - loss: 1.3162 - acc: 0.8905 - val_loss: 1.5017 - val_acc: 0.7988\n",
      "Epoch 431/2000\n",
      " - 0s - loss: 1.3152 - acc: 0.8912 - val_loss: 1.5012 - val_acc: 0.7959\n",
      "Epoch 432/2000\n",
      " - 0s - loss: 1.3144 - acc: 0.8905 - val_loss: 1.5001 - val_acc: 0.8017\n",
      "Epoch 433/2000\n",
      " - 0s - loss: 1.3135 - acc: 0.8927 - val_loss: 1.4995 - val_acc: 0.8017\n",
      "Epoch 434/2000\n",
      " - 0s - loss: 1.3127 - acc: 0.8927 - val_loss: 1.4989 - val_acc: 0.8017\n",
      "Epoch 435/2000\n",
      " - 0s - loss: 1.3119 - acc: 0.8927 - val_loss: 1.4980 - val_acc: 0.8017\n",
      "Epoch 436/2000\n",
      " - 0s - loss: 1.3110 - acc: 0.8927 - val_loss: 1.4972 - val_acc: 0.7988\n",
      "Epoch 437/2000\n",
      " - 0s - loss: 1.3102 - acc: 0.8920 - val_loss: 1.4965 - val_acc: 0.7988\n",
      "Epoch 438/2000\n",
      " - 0s - loss: 1.3092 - acc: 0.8920 - val_loss: 1.4956 - val_acc: 0.7988\n",
      "Epoch 439/2000\n",
      " - 0s - loss: 1.3084 - acc: 0.8912 - val_loss: 1.4951 - val_acc: 0.7988\n",
      "Epoch 440/2000\n",
      " - 0s - loss: 1.3079 - acc: 0.8927 - val_loss: 1.4946 - val_acc: 0.7988\n",
      "Epoch 441/2000\n",
      " - 0s - loss: 1.3070 - acc: 0.8927 - val_loss: 1.4939 - val_acc: 0.8017\n",
      "Epoch 442/2000\n",
      " - 0s - loss: 1.3064 - acc: 0.8920 - val_loss: 1.4932 - val_acc: 0.7988\n",
      "Epoch 443/2000\n",
      " - 0s - loss: 1.3057 - acc: 0.8927 - val_loss: 1.4925 - val_acc: 0.8017\n",
      "Epoch 444/2000\n",
      " - 0s - loss: 1.3050 - acc: 0.8934 - val_loss: 1.4920 - val_acc: 0.8017\n",
      "Epoch 445/2000\n",
      " - 0s - loss: 1.3043 - acc: 0.8934 - val_loss: 1.4916 - val_acc: 0.8017\n",
      "Epoch 446/2000\n",
      " - 0s - loss: 1.3038 - acc: 0.8927 - val_loss: 1.4910 - val_acc: 0.7988\n",
      "Epoch 447/2000\n",
      " - 0s - loss: 1.3031 - acc: 0.8927 - val_loss: 1.4903 - val_acc: 0.8017\n",
      "Epoch 448/2000\n",
      " - 0s - loss: 1.3023 - acc: 0.8927 - val_loss: 1.4897 - val_acc: 0.8017\n",
      "Epoch 449/2000\n",
      " - 0s - loss: 1.3016 - acc: 0.8927 - val_loss: 1.4893 - val_acc: 0.7988\n",
      "Epoch 450/2000\n",
      " - 0s - loss: 1.3010 - acc: 0.8934 - val_loss: 1.4884 - val_acc: 0.8017\n",
      "Epoch 451/2000\n",
      " - 0s - loss: 1.3003 - acc: 0.8927 - val_loss: 1.4878 - val_acc: 0.8017\n",
      "Epoch 452/2000\n",
      " - 0s - loss: 1.2996 - acc: 0.8927 - val_loss: 1.4872 - val_acc: 0.8017\n",
      "Epoch 453/2000\n",
      " - 0s - loss: 1.2989 - acc: 0.8927 - val_loss: 1.4867 - val_acc: 0.8017\n",
      "Epoch 454/2000\n",
      " - 0s - loss: 1.2983 - acc: 0.8927 - val_loss: 1.4861 - val_acc: 0.8017\n",
      "Epoch 455/2000\n",
      " - 0s - loss: 1.2977 - acc: 0.8934 - val_loss: 1.4856 - val_acc: 0.8017\n",
      "Epoch 456/2000\n",
      " - 0s - loss: 1.2969 - acc: 0.8934 - val_loss: 1.4848 - val_acc: 0.7988\n",
      "Epoch 457/2000\n",
      " - 0s - loss: 1.2963 - acc: 0.8934 - val_loss: 1.4844 - val_acc: 0.7988\n",
      "Epoch 458/2000\n",
      " - 0s - loss: 1.2955 - acc: 0.8934 - val_loss: 1.4837 - val_acc: 0.8017\n",
      "Epoch 459/2000\n",
      " - 0s - loss: 1.2949 - acc: 0.8934 - val_loss: 1.4832 - val_acc: 0.8017\n",
      "Epoch 460/2000\n",
      " - 0s - loss: 1.2944 - acc: 0.8934 - val_loss: 1.4829 - val_acc: 0.8017\n",
      "Epoch 461/2000\n",
      " - 0s - loss: 1.2938 - acc: 0.8934 - val_loss: 1.4824 - val_acc: 0.8017\n",
      "Epoch 462/2000\n",
      " - 0s - loss: 1.2933 - acc: 0.8942 - val_loss: 1.4818 - val_acc: 0.8017\n",
      "Epoch 463/2000\n",
      " - 0s - loss: 1.2928 - acc: 0.8942 - val_loss: 1.4813 - val_acc: 0.8047\n",
      "Epoch 464/2000\n",
      " - 0s - loss: 1.2922 - acc: 0.8927 - val_loss: 1.4808 - val_acc: 0.7988\n",
      "Epoch 465/2000\n",
      " - 0s - loss: 1.2917 - acc: 0.8934 - val_loss: 1.4804 - val_acc: 0.7988\n",
      "Epoch 466/2000\n",
      " - 0s - loss: 1.2911 - acc: 0.8934 - val_loss: 1.4800 - val_acc: 0.8047\n",
      "Epoch 467/2000\n",
      " - 0s - loss: 1.2906 - acc: 0.8942 - val_loss: 1.4796 - val_acc: 0.8047\n",
      "Epoch 468/2000\n",
      " - 0s - loss: 1.2901 - acc: 0.8934 - val_loss: 1.4791 - val_acc: 0.8017\n",
      "Epoch 469/2000\n",
      " - 0s - loss: 1.2896 - acc: 0.8927 - val_loss: 1.4786 - val_acc: 0.8017\n",
      "Epoch 470/2000\n",
      " - 0s - loss: 1.2890 - acc: 0.8927 - val_loss: 1.4783 - val_acc: 0.8047\n",
      "Epoch 471/2000\n",
      " - 0s - loss: 1.2885 - acc: 0.8934 - val_loss: 1.4777 - val_acc: 0.8047\n",
      "Epoch 472/2000\n",
      " - 0s - loss: 1.2879 - acc: 0.8942 - val_loss: 1.4773 - val_acc: 0.8017\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2873 - acc: 0.8942 - val_loss: 1.4768 - val_acc: 0.8047\n",
      "Epoch 474/2000\n",
      " - 0s - loss: 1.2869 - acc: 0.8942 - val_loss: 1.4759 - val_acc: 0.8076\n",
      "Epoch 475/2000\n",
      " - 0s - loss: 1.2863 - acc: 0.8942 - val_loss: 1.4755 - val_acc: 0.8076\n",
      "Epoch 476/2000\n",
      " - 0s - loss: 1.2858 - acc: 0.8934 - val_loss: 1.4752 - val_acc: 0.8076\n",
      "Epoch 477/2000\n",
      " - 0s - loss: 1.2853 - acc: 0.8942 - val_loss: 1.4747 - val_acc: 0.8017\n",
      "Epoch 478/2000\n",
      " - 0s - loss: 1.2847 - acc: 0.8942 - val_loss: 1.4744 - val_acc: 0.8047\n",
      "Epoch 479/2000\n",
      " - 0s - loss: 1.2842 - acc: 0.8942 - val_loss: 1.4736 - val_acc: 0.8047\n",
      "Epoch 480/2000\n",
      " - 0s - loss: 1.2837 - acc: 0.8934 - val_loss: 1.4731 - val_acc: 0.8017\n",
      "Epoch 481/2000\n",
      " - 0s - loss: 1.2831 - acc: 0.8934 - val_loss: 1.4728 - val_acc: 0.8017\n",
      "Epoch 482/2000\n",
      " - 0s - loss: 1.2826 - acc: 0.8942 - val_loss: 1.4721 - val_acc: 0.8017\n",
      "Epoch 483/2000\n",
      " - 0s - loss: 1.2820 - acc: 0.8934 - val_loss: 1.4719 - val_acc: 0.8017\n",
      "Epoch 484/2000\n",
      " - 0s - loss: 1.2815 - acc: 0.8927 - val_loss: 1.4713 - val_acc: 0.8017\n",
      "Epoch 485/2000\n",
      " - 0s - loss: 1.2810 - acc: 0.8934 - val_loss: 1.4710 - val_acc: 0.8017\n",
      "Epoch 486/2000\n",
      " - 0s - loss: 1.2804 - acc: 0.8934 - val_loss: 1.4703 - val_acc: 0.8047\n",
      "Epoch 487/2000\n",
      " - 0s - loss: 1.2799 - acc: 0.8927 - val_loss: 1.4700 - val_acc: 0.8047\n",
      "Epoch 488/2000\n",
      " - 0s - loss: 1.2794 - acc: 0.8927 - val_loss: 1.4695 - val_acc: 0.7988\n",
      "Epoch 489/2000\n",
      " - 0s - loss: 1.2789 - acc: 0.8927 - val_loss: 1.4692 - val_acc: 0.8017\n",
      "Epoch 490/2000\n",
      " - 0s - loss: 1.2783 - acc: 0.8934 - val_loss: 1.4688 - val_acc: 0.8047\n",
      "Epoch 491/2000\n",
      " - 0s - loss: 1.2778 - acc: 0.8934 - val_loss: 1.4682 - val_acc: 0.8047\n",
      "Epoch 492/2000\n",
      " - 0s - loss: 1.2773 - acc: 0.8942 - val_loss: 1.4679 - val_acc: 0.8047\n",
      "Epoch 493/2000\n",
      " - 0s - loss: 1.2768 - acc: 0.8942 - val_loss: 1.4672 - val_acc: 0.8047\n",
      "Epoch 494/2000\n",
      " - 0s - loss: 1.2762 - acc: 0.8942 - val_loss: 1.4666 - val_acc: 0.8047\n",
      "Epoch 495/2000\n",
      " - 0s - loss: 1.2757 - acc: 0.8942 - val_loss: 1.4663 - val_acc: 0.8047\n",
      "Epoch 496/2000\n",
      " - 0s - loss: 1.2753 - acc: 0.8942 - val_loss: 1.4659 - val_acc: 0.8047\n",
      "Epoch 497/2000\n",
      " - 0s - loss: 1.2748 - acc: 0.8934 - val_loss: 1.4655 - val_acc: 0.8047\n",
      "Epoch 498/2000\n",
      " - 0s - loss: 1.2744 - acc: 0.8942 - val_loss: 1.4653 - val_acc: 0.8047\n",
      "Epoch 499/2000\n",
      " - 0s - loss: 1.2740 - acc: 0.8942 - val_loss: 1.4648 - val_acc: 0.8047\n",
      "Epoch 500/2000\n",
      " - 0s - loss: 1.2735 - acc: 0.8934 - val_loss: 1.4644 - val_acc: 0.8047\n",
      "Epoch 501/2000\n",
      " - 0s - loss: 1.2732 - acc: 0.8942 - val_loss: 1.4640 - val_acc: 0.8076\n",
      "Epoch 502/2000\n",
      " - 0s - loss: 1.2727 - acc: 0.8942 - val_loss: 1.4636 - val_acc: 0.8076\n",
      "Epoch 503/2000\n",
      " - 0s - loss: 1.2724 - acc: 0.8934 - val_loss: 1.4631 - val_acc: 0.8047\n",
      "Epoch 504/2000\n",
      " - 0s - loss: 1.2719 - acc: 0.8942 - val_loss: 1.4628 - val_acc: 0.8047\n",
      "Epoch 505/2000\n",
      " - 0s - loss: 1.2714 - acc: 0.8942 - val_loss: 1.4624 - val_acc: 0.8047\n",
      "Epoch 506/2000\n",
      " - 0s - loss: 1.2711 - acc: 0.8942 - val_loss: 1.4620 - val_acc: 0.8047\n",
      "Epoch 507/2000\n",
      " - 0s - loss: 1.2706 - acc: 0.8942 - val_loss: 1.4618 - val_acc: 0.8047\n",
      "Epoch 508/2000\n",
      " - 0s - loss: 1.2702 - acc: 0.8942 - val_loss: 1.4614 - val_acc: 0.8076\n",
      "Epoch 509/2000\n",
      " - 0s - loss: 1.2698 - acc: 0.8942 - val_loss: 1.4611 - val_acc: 0.8076\n",
      "Epoch 510/2000\n",
      " - 0s - loss: 1.2693 - acc: 0.8942 - val_loss: 1.4607 - val_acc: 0.8076\n",
      "Epoch 511/2000\n",
      " - 0s - loss: 1.2689 - acc: 0.8942 - val_loss: 1.4602 - val_acc: 0.8076\n",
      "Epoch 512/2000\n",
      " - 0s - loss: 1.2685 - acc: 0.8942 - val_loss: 1.4597 - val_acc: 0.8076\n",
      "Epoch 513/2000\n",
      " - 0s - loss: 1.2681 - acc: 0.8942 - val_loss: 1.4593 - val_acc: 0.8076\n",
      "Epoch 514/2000\n",
      " - 0s - loss: 1.2677 - acc: 0.8942 - val_loss: 1.4592 - val_acc: 0.8076\n",
      "Epoch 515/2000\n",
      " - 0s - loss: 1.2672 - acc: 0.8942 - val_loss: 1.4588 - val_acc: 0.8076\n",
      "Epoch 516/2000\n",
      " - 0s - loss: 1.2669 - acc: 0.8942 - val_loss: 1.4586 - val_acc: 0.8076\n",
      "Epoch 517/2000\n",
      " - 0s - loss: 1.2666 - acc: 0.8942 - val_loss: 1.4583 - val_acc: 0.8076\n",
      "Epoch 518/2000\n",
      " - 0s - loss: 1.2662 - acc: 0.8942 - val_loss: 1.4580 - val_acc: 0.8076\n",
      "Epoch 519/2000\n",
      " - 0s - loss: 1.2659 - acc: 0.8942 - val_loss: 1.4577 - val_acc: 0.8076\n",
      "Epoch 520/2000\n",
      " - 0s - loss: 1.2656 - acc: 0.8942 - val_loss: 1.4573 - val_acc: 0.8076\n",
      "Epoch 521/2000\n",
      " - 0s - loss: 1.2652 - acc: 0.8942 - val_loss: 1.4569 - val_acc: 0.8076\n",
      "Epoch 522/2000\n",
      " - 0s - loss: 1.2649 - acc: 0.8942 - val_loss: 1.4566 - val_acc: 0.8076\n",
      "Epoch 523/2000\n",
      " - 0s - loss: 1.2646 - acc: 0.8942 - val_loss: 1.4565 - val_acc: 0.8076\n",
      "Epoch 524/2000\n",
      " - 0s - loss: 1.2643 - acc: 0.8942 - val_loss: 1.4562 - val_acc: 0.8076\n",
      "Epoch 525/2000\n",
      " - 0s - loss: 1.2639 - acc: 0.8942 - val_loss: 1.4559 - val_acc: 0.8076\n",
      "Epoch 526/2000\n",
      " - 0s - loss: 1.2635 - acc: 0.8942 - val_loss: 1.4556 - val_acc: 0.8105\n",
      "Epoch 527/2000\n",
      " - 0s - loss: 1.2632 - acc: 0.8942 - val_loss: 1.4553 - val_acc: 0.8076\n",
      "Epoch 528/2000\n",
      " - 0s - loss: 1.2629 - acc: 0.8942 - val_loss: 1.4550 - val_acc: 0.8076\n",
      "Epoch 529/2000\n",
      " - 0s - loss: 1.2625 - acc: 0.8942 - val_loss: 1.4548 - val_acc: 0.8076\n",
      "Epoch 530/2000\n",
      " - 0s - loss: 1.2622 - acc: 0.8942 - val_loss: 1.4544 - val_acc: 0.8105\n",
      "Epoch 531/2000\n",
      " - 0s - loss: 1.2619 - acc: 0.8942 - val_loss: 1.4541 - val_acc: 0.8076\n",
      "Epoch 532/2000\n",
      " - 0s - loss: 1.2615 - acc: 0.8942 - val_loss: 1.4538 - val_acc: 0.8076\n",
      "Epoch 533/2000\n",
      " - 0s - loss: 1.2612 - acc: 0.8942 - val_loss: 1.4536 - val_acc: 0.8076\n",
      "Epoch 534/2000\n",
      " - 0s - loss: 1.2609 - acc: 0.8942 - val_loss: 1.4532 - val_acc: 0.8105\n",
      "Epoch 535/2000\n",
      " - 0s - loss: 1.2606 - acc: 0.8942 - val_loss: 1.4529 - val_acc: 0.8076\n",
      "Epoch 536/2000\n",
      " - 0s - loss: 1.2602 - acc: 0.8942 - val_loss: 1.4526 - val_acc: 0.8076\n",
      "Epoch 537/2000\n",
      " - 0s - loss: 1.2599 - acc: 0.8942 - val_loss: 1.4522 - val_acc: 0.8105\n",
      "Epoch 538/2000\n",
      " - 0s - loss: 1.2595 - acc: 0.8942 - val_loss: 1.4519 - val_acc: 0.8076\n",
      "Epoch 539/2000\n",
      " - 0s - loss: 1.2592 - acc: 0.8942 - val_loss: 1.4516 - val_acc: 0.8105\n",
      "Epoch 540/2000\n",
      " - 0s - loss: 1.2589 - acc: 0.8942 - val_loss: 1.4513 - val_acc: 0.8105\n",
      "Epoch 541/2000\n",
      " - 0s - loss: 1.2585 - acc: 0.8942 - val_loss: 1.4510 - val_acc: 0.8105\n",
      "Epoch 542/2000\n",
      " - 0s - loss: 1.2582 - acc: 0.8942 - val_loss: 1.4508 - val_acc: 0.8105\n",
      "Epoch 543/2000\n",
      " - 0s - loss: 1.2578 - acc: 0.8942 - val_loss: 1.4505 - val_acc: 0.8105\n",
      "Epoch 544/2000\n",
      " - 0s - loss: 1.2575 - acc: 0.8942 - val_loss: 1.4502 - val_acc: 0.8105\n",
      "Epoch 545/2000\n",
      " - 0s - loss: 1.2572 - acc: 0.8942 - val_loss: 1.4500 - val_acc: 0.8105\n",
      "Epoch 546/2000\n",
      " - 0s - loss: 1.2568 - acc: 0.8942 - val_loss: 1.4496 - val_acc: 0.8076\n",
      "Epoch 547/2000\n",
      " - 0s - loss: 1.2565 - acc: 0.8949 - val_loss: 1.4494 - val_acc: 0.8105\n",
      "Epoch 548/2000\n",
      " - 0s - loss: 1.2563 - acc: 0.8942 - val_loss: 1.4492 - val_acc: 0.8076\n",
      "Epoch 549/2000\n",
      " - 0s - loss: 1.2560 - acc: 0.8949 - val_loss: 1.4490 - val_acc: 0.8105\n",
      "Epoch 550/2000\n",
      " - 0s - loss: 1.2557 - acc: 0.8942 - val_loss: 1.4487 - val_acc: 0.8105\n",
      "Epoch 551/2000\n",
      " - 0s - loss: 1.2554 - acc: 0.8942 - val_loss: 1.4485 - val_acc: 0.8105\n",
      "Epoch 552/2000\n",
      " - 0s - loss: 1.2552 - acc: 0.8949 - val_loss: 1.4483 - val_acc: 0.8105\n",
      "Epoch 553/2000\n",
      " - 0s - loss: 1.2549 - acc: 0.8942 - val_loss: 1.4481 - val_acc: 0.8105\n",
      "Epoch 554/2000\n",
      " - 0s - loss: 1.2546 - acc: 0.8942 - val_loss: 1.4479 - val_acc: 0.8076\n",
      "Epoch 555/2000\n",
      " - 0s - loss: 1.2544 - acc: 0.8949 - val_loss: 1.4475 - val_acc: 0.8105\n",
      "Epoch 556/2000\n",
      " - 0s - loss: 1.2541 - acc: 0.8949 - val_loss: 1.4472 - val_acc: 0.8105\n",
      "Epoch 557/2000\n",
      " - 0s - loss: 1.2538 - acc: 0.8942 - val_loss: 1.4471 - val_acc: 0.8105\n",
      "Epoch 558/2000\n",
      " - 0s - loss: 1.2536 - acc: 0.8942 - val_loss: 1.4468 - val_acc: 0.8105\n",
      "Epoch 559/2000\n",
      " - 0s - loss: 1.2533 - acc: 0.8949 - val_loss: 1.4465 - val_acc: 0.8105\n",
      "Epoch 560/2000\n",
      " - 0s - loss: 1.2530 - acc: 0.8949 - val_loss: 1.4462 - val_acc: 0.8134\n",
      "Epoch 561/2000\n",
      " - 0s - loss: 1.2528 - acc: 0.8949 - val_loss: 1.4461 - val_acc: 0.8105\n",
      "Epoch 562/2000\n",
      " - 0s - loss: 1.2525 - acc: 0.8942 - val_loss: 1.4458 - val_acc: 0.8134\n",
      "Epoch 563/2000\n",
      " - 0s - loss: 1.2523 - acc: 0.8942 - val_loss: 1.4455 - val_acc: 0.8163\n",
      "Epoch 564/2000\n",
      " - 0s - loss: 1.2520 - acc: 0.8942 - val_loss: 1.4453 - val_acc: 0.8105\n",
      "Epoch 565/2000\n",
      " - 0s - loss: 1.2517 - acc: 0.8942 - val_loss: 1.4452 - val_acc: 0.8105\n",
      "Epoch 566/2000\n",
      " - 0s - loss: 1.2514 - acc: 0.8949 - val_loss: 1.4448 - val_acc: 0.8105\n",
      "Epoch 567/2000\n",
      " - 0s - loss: 1.2512 - acc: 0.8949 - val_loss: 1.4447 - val_acc: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/2000\n",
      " - 0s - loss: 1.2509 - acc: 0.8949 - val_loss: 1.4445 - val_acc: 0.8105\n",
      "Epoch 569/2000\n",
      " - 0s - loss: 1.2506 - acc: 0.8949 - val_loss: 1.4442 - val_acc: 0.8134\n",
      "Epoch 570/2000\n",
      " - 0s - loss: 1.2504 - acc: 0.8949 - val_loss: 1.4439 - val_acc: 0.8105\n",
      "Epoch 571/2000\n",
      " - 0s - loss: 1.2501 - acc: 0.8949 - val_loss: 1.4436 - val_acc: 0.8134\n",
      "Epoch 572/2000\n",
      " - 0s - loss: 1.2499 - acc: 0.8949 - val_loss: 1.4435 - val_acc: 0.8134\n",
      "Epoch 573/2000\n",
      " - 0s - loss: 1.2496 - acc: 0.8942 - val_loss: 1.4432 - val_acc: 0.8134\n",
      "Epoch 574/2000\n",
      " - 0s - loss: 1.2493 - acc: 0.8942 - val_loss: 1.4429 - val_acc: 0.8134\n",
      "Epoch 575/2000\n",
      " - 0s - loss: 1.2490 - acc: 0.8949 - val_loss: 1.4428 - val_acc: 0.8163\n",
      "Epoch 576/2000\n",
      " - 0s - loss: 1.2488 - acc: 0.8949 - val_loss: 1.4426 - val_acc: 0.8105\n",
      "Epoch 577/2000\n",
      " - 0s - loss: 1.2485 - acc: 0.8949 - val_loss: 1.4423 - val_acc: 0.8163\n",
      "Epoch 578/2000\n",
      " - 0s - loss: 1.2482 - acc: 0.8942 - val_loss: 1.4421 - val_acc: 0.8134\n",
      "Epoch 579/2000\n",
      " - 0s - loss: 1.2480 - acc: 0.8949 - val_loss: 1.4419 - val_acc: 0.8163\n",
      "Epoch 580/2000\n",
      " - 0s - loss: 1.2477 - acc: 0.8949 - val_loss: 1.4416 - val_acc: 0.8105\n",
      "Epoch 581/2000\n",
      " - 0s - loss: 1.2475 - acc: 0.8942 - val_loss: 1.4413 - val_acc: 0.8134\n",
      "Epoch 582/2000\n",
      " - 0s - loss: 1.2472 - acc: 0.8942 - val_loss: 1.4412 - val_acc: 0.8134\n",
      "Epoch 583/2000\n",
      " - 0s - loss: 1.2469 - acc: 0.8942 - val_loss: 1.4410 - val_acc: 0.8134\n",
      "Epoch 584/2000\n",
      " - 0s - loss: 1.2467 - acc: 0.8949 - val_loss: 1.4408 - val_acc: 0.8192\n",
      "Epoch 585/2000\n",
      " - 0s - loss: 1.2465 - acc: 0.8949 - val_loss: 1.4406 - val_acc: 0.8134\n",
      "Epoch 586/2000\n",
      " - 0s - loss: 1.2462 - acc: 0.8949 - val_loss: 1.4404 - val_acc: 0.8134\n",
      "Epoch 587/2000\n",
      " - 0s - loss: 1.2460 - acc: 0.8949 - val_loss: 1.4402 - val_acc: 0.8105\n",
      "Epoch 588/2000\n",
      " - 0s - loss: 1.2458 - acc: 0.8949 - val_loss: 1.4400 - val_acc: 0.8163\n",
      "Epoch 589/2000\n",
      " - 0s - loss: 1.2456 - acc: 0.8949 - val_loss: 1.4399 - val_acc: 0.8134\n",
      "Epoch 590/2000\n",
      " - 0s - loss: 1.2454 - acc: 0.8949 - val_loss: 1.4396 - val_acc: 0.8163\n",
      "Epoch 591/2000\n",
      " - 0s - loss: 1.2452 - acc: 0.8949 - val_loss: 1.4394 - val_acc: 0.8163\n",
      "Epoch 592/2000\n",
      " - 0s - loss: 1.2450 - acc: 0.8949 - val_loss: 1.4393 - val_acc: 0.8134\n",
      "Epoch 593/2000\n",
      " - 0s - loss: 1.2448 - acc: 0.8949 - val_loss: 1.4390 - val_acc: 0.8192\n",
      "Epoch 594/2000\n",
      " - 0s - loss: 1.2446 - acc: 0.8949 - val_loss: 1.4389 - val_acc: 0.8163\n",
      "Epoch 595/2000\n",
      " - 0s - loss: 1.2443 - acc: 0.8949 - val_loss: 1.4387 - val_acc: 0.8192\n",
      "Epoch 596/2000\n",
      " - 0s - loss: 1.2441 - acc: 0.8949 - val_loss: 1.4385 - val_acc: 0.8105\n",
      "Epoch 597/2000\n",
      " - 0s - loss: 1.2439 - acc: 0.8949 - val_loss: 1.4383 - val_acc: 0.8192\n",
      "Epoch 598/2000\n",
      " - 0s - loss: 1.2437 - acc: 0.8949 - val_loss: 1.4382 - val_acc: 0.8192\n",
      "Epoch 599/2000\n",
      " - 0s - loss: 1.2435 - acc: 0.8949 - val_loss: 1.4379 - val_acc: 0.8163\n",
      "Epoch 600/2000\n",
      " - 0s - loss: 1.2433 - acc: 0.8949 - val_loss: 1.4378 - val_acc: 0.8134\n",
      "Epoch 601/2000\n",
      " - 0s - loss: 1.2431 - acc: 0.8949 - val_loss: 1.4376 - val_acc: 0.8105\n",
      "Epoch 602/2000\n",
      " - 0s - loss: 1.2429 - acc: 0.8949 - val_loss: 1.4374 - val_acc: 0.8134\n",
      "Epoch 603/2000\n",
      " - 0s - loss: 1.2427 - acc: 0.8949 - val_loss: 1.4371 - val_acc: 0.8134\n",
      "Epoch 604/2000\n",
      " - 0s - loss: 1.2424 - acc: 0.8949 - val_loss: 1.4370 - val_acc: 0.8134\n",
      "Epoch 605/2000\n",
      " - 0s - loss: 1.2422 - acc: 0.8949 - val_loss: 1.4368 - val_acc: 0.8134\n",
      "Epoch 606/2000\n",
      " - 0s - loss: 1.2421 - acc: 0.8949 - val_loss: 1.4367 - val_acc: 0.8105\n",
      "Epoch 607/2000\n",
      " - 0s - loss: 1.2419 - acc: 0.8949 - val_loss: 1.4367 - val_acc: 0.8105\n",
      "Epoch 608/2000\n",
      " - 0s - loss: 1.2417 - acc: 0.8949 - val_loss: 1.4364 - val_acc: 0.8163\n",
      "Epoch 609/2000\n",
      " - 0s - loss: 1.2416 - acc: 0.8949 - val_loss: 1.4363 - val_acc: 0.8134\n",
      "Epoch 610/2000\n",
      " - 0s - loss: 1.2414 - acc: 0.8949 - val_loss: 1.4361 - val_acc: 0.8134\n",
      "Epoch 611/2000\n",
      " - 0s - loss: 1.2412 - acc: 0.8949 - val_loss: 1.4360 - val_acc: 0.8163\n",
      "Epoch 612/2000\n",
      " - 0s - loss: 1.2411 - acc: 0.8949 - val_loss: 1.4359 - val_acc: 0.8163\n",
      "Epoch 613/2000\n",
      " - 0s - loss: 1.2409 - acc: 0.8949 - val_loss: 1.4357 - val_acc: 0.8163\n",
      "Epoch 614/2000\n",
      " - 0s - loss: 1.2407 - acc: 0.8949 - val_loss: 1.4356 - val_acc: 0.8105\n",
      "Epoch 615/2000\n",
      " - 0s - loss: 1.2405 - acc: 0.8949 - val_loss: 1.4354 - val_acc: 0.8163\n",
      "Epoch 616/2000\n",
      " - 0s - loss: 1.2404 - acc: 0.8949 - val_loss: 1.4352 - val_acc: 0.8163\n",
      "Epoch 617/2000\n",
      " - 0s - loss: 1.2402 - acc: 0.8949 - val_loss: 1.4351 - val_acc: 0.8163\n",
      "Epoch 618/2000\n",
      " - 0s - loss: 1.2400 - acc: 0.8949 - val_loss: 1.4350 - val_acc: 0.8163\n",
      "Epoch 619/2000\n",
      " - 0s - loss: 1.2399 - acc: 0.8949 - val_loss: 1.4348 - val_acc: 0.8134\n",
      "Epoch 620/2000\n",
      " - 0s - loss: 1.2397 - acc: 0.8949 - val_loss: 1.4346 - val_acc: 0.8163\n",
      "Epoch 621/2000\n",
      " - 0s - loss: 1.2396 - acc: 0.8949 - val_loss: 1.4346 - val_acc: 0.8134\n",
      "Epoch 622/2000\n",
      " - 0s - loss: 1.2394 - acc: 0.8949 - val_loss: 1.4344 - val_acc: 0.8163\n",
      "Epoch 623/2000\n",
      " - 0s - loss: 1.2392 - acc: 0.8949 - val_loss: 1.4342 - val_acc: 0.8163\n",
      "Epoch 624/2000\n",
      " - 0s - loss: 1.2390 - acc: 0.8949 - val_loss: 1.4341 - val_acc: 0.8163\n",
      "Epoch 625/2000\n",
      " - 0s - loss: 1.2389 - acc: 0.8949 - val_loss: 1.4340 - val_acc: 0.8163\n",
      "Epoch 626/2000\n",
      " - 0s - loss: 1.2387 - acc: 0.8949 - val_loss: 1.4338 - val_acc: 0.8192\n",
      "Epoch 627/2000\n",
      " - 0s - loss: 1.2386 - acc: 0.8949 - val_loss: 1.4337 - val_acc: 0.8222\n",
      "Epoch 628/2000\n",
      " - 0s - loss: 1.2385 - acc: 0.8949 - val_loss: 1.4336 - val_acc: 0.8192\n",
      "Epoch 629/2000\n",
      " - 0s - loss: 1.2383 - acc: 0.8949 - val_loss: 1.4335 - val_acc: 0.8163\n",
      "Epoch 630/2000\n",
      " - 0s - loss: 1.2382 - acc: 0.8949 - val_loss: 1.4333 - val_acc: 0.8192\n",
      "Epoch 631/2000\n",
      " - 0s - loss: 1.2381 - acc: 0.8949 - val_loss: 1.4332 - val_acc: 0.8192\n",
      "Epoch 632/2000\n",
      " - 0s - loss: 1.2379 - acc: 0.8949 - val_loss: 1.4331 - val_acc: 0.8163\n",
      "Epoch 633/2000\n",
      " - 0s - loss: 1.2378 - acc: 0.8949 - val_loss: 1.4330 - val_acc: 0.8134\n",
      "Epoch 634/2000\n",
      " - 0s - loss: 1.2377 - acc: 0.8949 - val_loss: 1.4329 - val_acc: 0.8163\n",
      "Epoch 635/2000\n",
      " - 0s - loss: 1.2375 - acc: 0.8949 - val_loss: 1.4328 - val_acc: 0.8163\n",
      "Epoch 636/2000\n",
      " - 0s - loss: 1.2374 - acc: 0.8949 - val_loss: 1.4326 - val_acc: 0.8163\n",
      "Epoch 637/2000\n",
      " - 0s - loss: 1.2372 - acc: 0.8949 - val_loss: 1.4325 - val_acc: 0.8163\n",
      "Epoch 638/2000\n",
      " - 0s - loss: 1.2371 - acc: 0.8949 - val_loss: 1.4324 - val_acc: 0.8163\n",
      "Epoch 639/2000\n",
      " - 0s - loss: 1.2370 - acc: 0.8949 - val_loss: 1.4323 - val_acc: 0.8192\n",
      "Epoch 640/2000\n",
      " - 0s - loss: 1.2368 - acc: 0.8949 - val_loss: 1.4322 - val_acc: 0.8163\n",
      "Epoch 641/2000\n",
      " - 0s - loss: 1.2367 - acc: 0.8949 - val_loss: 1.4321 - val_acc: 0.8163\n",
      "Epoch 642/2000\n",
      " - 0s - loss: 1.2366 - acc: 0.8949 - val_loss: 1.4320 - val_acc: 0.8163\n",
      "Epoch 643/2000\n",
      " - 0s - loss: 1.2365 - acc: 0.8949 - val_loss: 1.4318 - val_acc: 0.8163\n",
      "Epoch 644/2000\n",
      " - 0s - loss: 1.2363 - acc: 0.8949 - val_loss: 1.4317 - val_acc: 0.8163\n",
      "Epoch 645/2000\n",
      " - 0s - loss: 1.2362 - acc: 0.8949 - val_loss: 1.4316 - val_acc: 0.8192\n",
      "Epoch 646/2000\n",
      " - 0s - loss: 1.2360 - acc: 0.8949 - val_loss: 1.4315 - val_acc: 0.8192\n",
      "Epoch 647/2000\n",
      " - 0s - loss: 1.2359 - acc: 0.8949 - val_loss: 1.4314 - val_acc: 0.8163\n",
      "Epoch 648/2000\n",
      " - 0s - loss: 1.2358 - acc: 0.8949 - val_loss: 1.4313 - val_acc: 0.8222\n",
      "Epoch 649/2000\n",
      " - 0s - loss: 1.2357 - acc: 0.8949 - val_loss: 1.4312 - val_acc: 0.8192\n",
      "Epoch 650/2000\n",
      " - 0s - loss: 1.2356 - acc: 0.8949 - val_loss: 1.4311 - val_acc: 0.8192\n",
      "Epoch 651/2000\n",
      " - 0s - loss: 1.2354 - acc: 0.8949 - val_loss: 1.4310 - val_acc: 0.8192\n",
      "Epoch 652/2000\n",
      " - 0s - loss: 1.2353 - acc: 0.8949 - val_loss: 1.4309 - val_acc: 0.8192\n",
      "Epoch 653/2000\n",
      " - 0s - loss: 1.2352 - acc: 0.8949 - val_loss: 1.4308 - val_acc: 0.8192\n",
      "Epoch 654/2000\n",
      " - 0s - loss: 1.2351 - acc: 0.8949 - val_loss: 1.4308 - val_acc: 0.8192\n",
      "Epoch 655/2000\n",
      " - 0s - loss: 1.2350 - acc: 0.8949 - val_loss: 1.4306 - val_acc: 0.8192\n",
      "Epoch 656/2000\n",
      " - 0s - loss: 1.2349 - acc: 0.8949 - val_loss: 1.4305 - val_acc: 0.8163\n",
      "Epoch 657/2000\n",
      " - 0s - loss: 1.2348 - acc: 0.8949 - val_loss: 1.4304 - val_acc: 0.8192\n",
      "Epoch 658/2000\n",
      " - 0s - loss: 1.2347 - acc: 0.8949 - val_loss: 1.4303 - val_acc: 0.8192\n",
      "Epoch 659/2000\n",
      " - 0s - loss: 1.2346 - acc: 0.8949 - val_loss: 1.4302 - val_acc: 0.8192\n",
      "Epoch 660/2000\n",
      " - 0s - loss: 1.2345 - acc: 0.8949 - val_loss: 1.4301 - val_acc: 0.8192\n",
      "Epoch 661/2000\n",
      " - 0s - loss: 1.2344 - acc: 0.8949 - val_loss: 1.4300 - val_acc: 0.8222\n",
      "Epoch 662/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2343 - acc: 0.8949 - val_loss: 1.4299 - val_acc: 0.8222\n",
      "Epoch 663/2000\n",
      " - 0s - loss: 1.2342 - acc: 0.8949 - val_loss: 1.4298 - val_acc: 0.8192\n",
      "Epoch 664/2000\n",
      " - 0s - loss: 1.2341 - acc: 0.8949 - val_loss: 1.4298 - val_acc: 0.8192\n",
      "Epoch 665/2000\n",
      " - 0s - loss: 1.2339 - acc: 0.8949 - val_loss: 1.4296 - val_acc: 0.8192\n",
      "Epoch 666/2000\n",
      " - 0s - loss: 1.2338 - acc: 0.8949 - val_loss: 1.4296 - val_acc: 0.8192\n",
      "Epoch 667/2000\n",
      " - 0s - loss: 1.2337 - acc: 0.8949 - val_loss: 1.4295 - val_acc: 0.8192\n",
      "Epoch 668/2000\n",
      " - 0s - loss: 1.2336 - acc: 0.8949 - val_loss: 1.4294 - val_acc: 0.8192\n",
      "Epoch 669/2000\n",
      " - 0s - loss: 1.2335 - acc: 0.8949 - val_loss: 1.4293 - val_acc: 0.8222\n",
      "Epoch 670/2000\n",
      " - 0s - loss: 1.2335 - acc: 0.8949 - val_loss: 1.4292 - val_acc: 0.8192\n",
      "Epoch 671/2000\n",
      " - 0s - loss: 1.2334 - acc: 0.8949 - val_loss: 1.4291 - val_acc: 0.8192\n",
      "Epoch 672/2000\n",
      " - 0s - loss: 1.2333 - acc: 0.8956 - val_loss: 1.4291 - val_acc: 0.8192\n",
      "Epoch 673/2000\n",
      " - 0s - loss: 1.2332 - acc: 0.8956 - val_loss: 1.4290 - val_acc: 0.8222\n",
      "Epoch 674/2000\n",
      " - 0s - loss: 1.2331 - acc: 0.8949 - val_loss: 1.4289 - val_acc: 0.8192\n",
      "Epoch 675/2000\n",
      " - 0s - loss: 1.2330 - acc: 0.8956 - val_loss: 1.4288 - val_acc: 0.8222\n",
      "Epoch 676/2000\n",
      " - 0s - loss: 1.2329 - acc: 0.8956 - val_loss: 1.4288 - val_acc: 0.8222\n",
      "Epoch 677/2000\n",
      " - 0s - loss: 1.2328 - acc: 0.8956 - val_loss: 1.4287 - val_acc: 0.8222\n",
      "Epoch 678/2000\n",
      " - 0s - loss: 1.2328 - acc: 0.8949 - val_loss: 1.4286 - val_acc: 0.8192\n",
      "Epoch 679/2000\n",
      " - 0s - loss: 1.2327 - acc: 0.8956 - val_loss: 1.4285 - val_acc: 0.8222\n",
      "Epoch 680/2000\n",
      " - 0s - loss: 1.2326 - acc: 0.8956 - val_loss: 1.4285 - val_acc: 0.8222\n",
      "Epoch 681/2000\n",
      " - 0s - loss: 1.2325 - acc: 0.8956 - val_loss: 1.4284 - val_acc: 0.8222\n",
      "Epoch 682/2000\n",
      " - 0s - loss: 1.2324 - acc: 0.8956 - val_loss: 1.4283 - val_acc: 0.8222\n",
      "Epoch 683/2000\n",
      " - 0s - loss: 1.2323 - acc: 0.8949 - val_loss: 1.4283 - val_acc: 0.8222\n",
      "Epoch 684/2000\n",
      " - 0s - loss: 1.2322 - acc: 0.8949 - val_loss: 1.4282 - val_acc: 0.8192\n",
      "Epoch 685/2000\n",
      " - 0s - loss: 1.2322 - acc: 0.8949 - val_loss: 1.4281 - val_acc: 0.8222\n",
      "Epoch 686/2000\n",
      " - 0s - loss: 1.2321 - acc: 0.8949 - val_loss: 1.4280 - val_acc: 0.8222\n",
      "Epoch 687/2000\n",
      " - 0s - loss: 1.2320 - acc: 0.8949 - val_loss: 1.4280 - val_acc: 0.8222\n",
      "Epoch 688/2000\n",
      " - 0s - loss: 1.2319 - acc: 0.8949 - val_loss: 1.4279 - val_acc: 0.8222\n",
      "Epoch 689/2000\n",
      " - 0s - loss: 1.2318 - acc: 0.8949 - val_loss: 1.4278 - val_acc: 0.8222\n",
      "Epoch 690/2000\n",
      " - 0s - loss: 1.2318 - acc: 0.8949 - val_loss: 1.4278 - val_acc: 0.8222\n",
      "Epoch 691/2000\n",
      " - 0s - loss: 1.2317 - acc: 0.8949 - val_loss: 1.4277 - val_acc: 0.8222\n",
      "Epoch 692/2000\n",
      " - 0s - loss: 1.2316 - acc: 0.8949 - val_loss: 1.4277 - val_acc: 0.8222\n",
      "Epoch 693/2000\n",
      " - 0s - loss: 1.2316 - acc: 0.8949 - val_loss: 1.4276 - val_acc: 0.8222\n",
      "Epoch 694/2000\n",
      " - 0s - loss: 1.2315 - acc: 0.8949 - val_loss: 1.4276 - val_acc: 0.8222\n",
      "Epoch 695/2000\n",
      " - 0s - loss: 1.2314 - acc: 0.8949 - val_loss: 1.4275 - val_acc: 0.8222\n",
      "Epoch 696/2000\n",
      " - 0s - loss: 1.2314 - acc: 0.8949 - val_loss: 1.4275 - val_acc: 0.8222\n",
      "Epoch 697/2000\n",
      " - 0s - loss: 1.2313 - acc: 0.8956 - val_loss: 1.4274 - val_acc: 0.8222\n",
      "Epoch 698/2000\n",
      " - 0s - loss: 1.2312 - acc: 0.8956 - val_loss: 1.4273 - val_acc: 0.8192\n",
      "Epoch 699/2000\n",
      " - 0s - loss: 1.2312 - acc: 0.8949 - val_loss: 1.4272 - val_acc: 0.8222\n",
      "Epoch 700/2000\n",
      " - 0s - loss: 1.2311 - acc: 0.8949 - val_loss: 1.4272 - val_acc: 0.8222\n",
      "Epoch 701/2000\n",
      " - 0s - loss: 1.2310 - acc: 0.8949 - val_loss: 1.4271 - val_acc: 0.8222\n",
      "Epoch 702/2000\n",
      " - 0s - loss: 1.2309 - acc: 0.8956 - val_loss: 1.4271 - val_acc: 0.8222\n",
      "Epoch 703/2000\n",
      " - 0s - loss: 1.2309 - acc: 0.8956 - val_loss: 1.4270 - val_acc: 0.8222\n",
      "Epoch 704/2000\n",
      " - 0s - loss: 1.2308 - acc: 0.8949 - val_loss: 1.4269 - val_acc: 0.8192\n",
      "Epoch 705/2000\n",
      " - 0s - loss: 1.2307 - acc: 0.8949 - val_loss: 1.4269 - val_acc: 0.8192\n",
      "Epoch 706/2000\n",
      " - 0s - loss: 1.2307 - acc: 0.8956 - val_loss: 1.4268 - val_acc: 0.8222\n",
      "Epoch 707/2000\n",
      " - 0s - loss: 1.2306 - acc: 0.8956 - val_loss: 1.4267 - val_acc: 0.8222\n",
      "Epoch 708/2000\n",
      " - 0s - loss: 1.2305 - acc: 0.8956 - val_loss: 1.4267 - val_acc: 0.8222\n",
      "Epoch 709/2000\n",
      " - 0s - loss: 1.2305 - acc: 0.8956 - val_loss: 1.4267 - val_acc: 0.8222\n",
      "Epoch 710/2000\n",
      " - 0s - loss: 1.2304 - acc: 0.8949 - val_loss: 1.4266 - val_acc: 0.8222\n",
      "Epoch 711/2000\n",
      " - 0s - loss: 1.2304 - acc: 0.8949 - val_loss: 1.4266 - val_acc: 0.8222\n",
      "Epoch 712/2000\n",
      " - 0s - loss: 1.2303 - acc: 0.8956 - val_loss: 1.4265 - val_acc: 0.8222\n",
      "Epoch 713/2000\n",
      " - 0s - loss: 1.2303 - acc: 0.8956 - val_loss: 1.4265 - val_acc: 0.8222\n",
      "Epoch 714/2000\n",
      " - 0s - loss: 1.2302 - acc: 0.8956 - val_loss: 1.4264 - val_acc: 0.8222\n",
      "Epoch 715/2000\n",
      " - 0s - loss: 1.2301 - acc: 0.8956 - val_loss: 1.4264 - val_acc: 0.8222\n",
      "Epoch 716/2000\n",
      " - 0s - loss: 1.2301 - acc: 0.8956 - val_loss: 1.4263 - val_acc: 0.8222\n",
      "Epoch 717/2000\n",
      " - 0s - loss: 1.2300 - acc: 0.8956 - val_loss: 1.4263 - val_acc: 0.8222\n",
      "Epoch 718/2000\n",
      " - 0s - loss: 1.2300 - acc: 0.8956 - val_loss: 1.4262 - val_acc: 0.8222\n",
      "Epoch 719/2000\n",
      " - 0s - loss: 1.2299 - acc: 0.8956 - val_loss: 1.4262 - val_acc: 0.8222\n",
      "Epoch 720/2000\n",
      " - 0s - loss: 1.2299 - acc: 0.8956 - val_loss: 1.4262 - val_acc: 0.8222\n",
      "Epoch 721/2000\n",
      " - 0s - loss: 1.2298 - acc: 0.8956 - val_loss: 1.4261 - val_acc: 0.8222\n",
      "Epoch 722/2000\n",
      " - 0s - loss: 1.2298 - acc: 0.8949 - val_loss: 1.4261 - val_acc: 0.8222\n",
      "Epoch 723/2000\n",
      " - 0s - loss: 1.2297 - acc: 0.8956 - val_loss: 1.4260 - val_acc: 0.8222\n",
      "Epoch 724/2000\n",
      " - 0s - loss: 1.2296 - acc: 0.8956 - val_loss: 1.4260 - val_acc: 0.8222\n",
      "Epoch 725/2000\n",
      " - 0s - loss: 1.2296 - acc: 0.8956 - val_loss: 1.4259 - val_acc: 0.8222\n",
      "Epoch 726/2000\n",
      " - 0s - loss: 1.2295 - acc: 0.8956 - val_loss: 1.4259 - val_acc: 0.8222\n",
      "Epoch 727/2000\n",
      " - 0s - loss: 1.2295 - acc: 0.8949 - val_loss: 1.4258 - val_acc: 0.8222\n",
      "Epoch 728/2000\n",
      " - 0s - loss: 1.2294 - acc: 0.8956 - val_loss: 1.4258 - val_acc: 0.8222\n",
      "Epoch 729/2000\n",
      " - 0s - loss: 1.2294 - acc: 0.8956 - val_loss: 1.4258 - val_acc: 0.8222\n",
      "Epoch 730/2000\n",
      " - 0s - loss: 1.2293 - acc: 0.8956 - val_loss: 1.4257 - val_acc: 0.8222\n",
      "Epoch 731/2000\n",
      " - 0s - loss: 1.2293 - acc: 0.8956 - val_loss: 1.4257 - val_acc: 0.8222\n",
      "Epoch 732/2000\n",
      " - 0s - loss: 1.2293 - acc: 0.8956 - val_loss: 1.4256 - val_acc: 0.8222\n",
      "Epoch 733/2000\n",
      " - 0s - loss: 1.2292 - acc: 0.8956 - val_loss: 1.4256 - val_acc: 0.8222\n",
      "Epoch 734/2000\n",
      " - 0s - loss: 1.2292 - acc: 0.8956 - val_loss: 1.4255 - val_acc: 0.8222\n",
      "Epoch 735/2000\n",
      " - 0s - loss: 1.2291 - acc: 0.8956 - val_loss: 1.4255 - val_acc: 0.8222\n",
      "Epoch 736/2000\n",
      " - 0s - loss: 1.2291 - acc: 0.8956 - val_loss: 1.4255 - val_acc: 0.8222\n",
      "Epoch 737/2000\n",
      " - 0s - loss: 1.2290 - acc: 0.8956 - val_loss: 1.4254 - val_acc: 0.8222\n",
      "Epoch 738/2000\n",
      " - 0s - loss: 1.2290 - acc: 0.8956 - val_loss: 1.4254 - val_acc: 0.8222\n",
      "Epoch 739/2000\n",
      " - 0s - loss: 1.2290 - acc: 0.8956 - val_loss: 1.4254 - val_acc: 0.8222\n",
      "Epoch 740/2000\n",
      " - 0s - loss: 1.2289 - acc: 0.8956 - val_loss: 1.4253 - val_acc: 0.8222\n",
      "Epoch 741/2000\n",
      " - 0s - loss: 1.2289 - acc: 0.8956 - val_loss: 1.4253 - val_acc: 0.8222\n",
      "Epoch 742/2000\n",
      " - 0s - loss: 1.2288 - acc: 0.8956 - val_loss: 1.4252 - val_acc: 0.8222\n",
      "Epoch 743/2000\n",
      " - 0s - loss: 1.2288 - acc: 0.8956 - val_loss: 1.4252 - val_acc: 0.8222\n",
      "Epoch 744/2000\n",
      " - 0s - loss: 1.2287 - acc: 0.8956 - val_loss: 1.4251 - val_acc: 0.8222\n",
      "Epoch 745/2000\n",
      " - 0s - loss: 1.2287 - acc: 0.8956 - val_loss: 1.4251 - val_acc: 0.8222\n",
      "Epoch 746/2000\n",
      " - 0s - loss: 1.2286 - acc: 0.8956 - val_loss: 1.4251 - val_acc: 0.8222\n",
      "Epoch 747/2000\n",
      " - 0s - loss: 1.2286 - acc: 0.8956 - val_loss: 1.4250 - val_acc: 0.8222\n",
      "Epoch 748/2000\n",
      " - 0s - loss: 1.2286 - acc: 0.8956 - val_loss: 1.4250 - val_acc: 0.8222\n",
      "Epoch 749/2000\n",
      " - 0s - loss: 1.2285 - acc: 0.8956 - val_loss: 1.4249 - val_acc: 0.8222\n",
      "Epoch 750/2000\n",
      " - 0s - loss: 1.2285 - acc: 0.8956 - val_loss: 1.4249 - val_acc: 0.8222\n",
      "Epoch 751/2000\n",
      " - 0s - loss: 1.2284 - acc: 0.8956 - val_loss: 1.4249 - val_acc: 0.8222\n",
      "Epoch 752/2000\n",
      " - 0s - loss: 1.2284 - acc: 0.8956 - val_loss: 1.4249 - val_acc: 0.8222\n",
      "Epoch 753/2000\n",
      " - 0s - loss: 1.2284 - acc: 0.8956 - val_loss: 1.4248 - val_acc: 0.8222\n",
      "Epoch 754/2000\n",
      " - 0s - loss: 1.2283 - acc: 0.8956 - val_loss: 1.4248 - val_acc: 0.8222\n",
      "Epoch 755/2000\n",
      " - 0s - loss: 1.2283 - acc: 0.8956 - val_loss: 1.4247 - val_acc: 0.8222\n",
      "Epoch 756/2000\n",
      " - 0s - loss: 1.2283 - acc: 0.8956 - val_loss: 1.4247 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/2000\n",
      " - 0s - loss: 1.2282 - acc: 0.8956 - val_loss: 1.4247 - val_acc: 0.8222\n",
      "Epoch 758/2000\n",
      " - 0s - loss: 1.2282 - acc: 0.8956 - val_loss: 1.4247 - val_acc: 0.8222\n",
      "Epoch 759/2000\n",
      " - 0s - loss: 1.2282 - acc: 0.8956 - val_loss: 1.4246 - val_acc: 0.8222\n",
      "Epoch 760/2000\n",
      " - 0s - loss: 1.2281 - acc: 0.8956 - val_loss: 1.4246 - val_acc: 0.8222\n",
      "Epoch 761/2000\n",
      " - 0s - loss: 1.2281 - acc: 0.8956 - val_loss: 1.4246 - val_acc: 0.8222\n",
      "Epoch 762/2000\n",
      " - 0s - loss: 1.2281 - acc: 0.8956 - val_loss: 1.4245 - val_acc: 0.8222\n",
      "Epoch 763/2000\n",
      " - 0s - loss: 1.2280 - acc: 0.8956 - val_loss: 1.4245 - val_acc: 0.8222\n",
      "Epoch 764/2000\n",
      " - 0s - loss: 1.2280 - acc: 0.8956 - val_loss: 1.4245 - val_acc: 0.8222\n",
      "Epoch 765/2000\n",
      " - 0s - loss: 1.2280 - acc: 0.8956 - val_loss: 1.4245 - val_acc: 0.8222\n",
      "Epoch 766/2000\n",
      " - 0s - loss: 1.2279 - acc: 0.8956 - val_loss: 1.4244 - val_acc: 0.8222\n",
      "Epoch 767/2000\n",
      " - 0s - loss: 1.2279 - acc: 0.8956 - val_loss: 1.4244 - val_acc: 0.8222\n",
      "Epoch 768/2000\n",
      " - 0s - loss: 1.2279 - acc: 0.8956 - val_loss: 1.4244 - val_acc: 0.8222\n",
      "Epoch 769/2000\n",
      " - 0s - loss: 1.2278 - acc: 0.8956 - val_loss: 1.4244 - val_acc: 0.8222\n",
      "Epoch 770/2000\n",
      " - 0s - loss: 1.2278 - acc: 0.8956 - val_loss: 1.4243 - val_acc: 0.8222\n",
      "Epoch 771/2000\n",
      " - 0s - loss: 1.2278 - acc: 0.8956 - val_loss: 1.4243 - val_acc: 0.8222\n",
      "Epoch 772/2000\n",
      " - 0s - loss: 1.2277 - acc: 0.8956 - val_loss: 1.4243 - val_acc: 0.8222\n",
      "Epoch 773/2000\n",
      " - 0s - loss: 1.2277 - acc: 0.8956 - val_loss: 1.4242 - val_acc: 0.8222\n",
      "Epoch 774/2000\n",
      " - 0s - loss: 1.2277 - acc: 0.8956 - val_loss: 1.4242 - val_acc: 0.8222\n",
      "Epoch 775/2000\n",
      " - 0s - loss: 1.2277 - acc: 0.8956 - val_loss: 1.4242 - val_acc: 0.8222\n",
      "Epoch 776/2000\n",
      " - 0s - loss: 1.2276 - acc: 0.8956 - val_loss: 1.4242 - val_acc: 0.8222\n",
      "Epoch 777/2000\n",
      " - 0s - loss: 1.2276 - acc: 0.8956 - val_loss: 1.4242 - val_acc: 0.8222\n",
      "Epoch 778/2000\n",
      " - 0s - loss: 1.2276 - acc: 0.8956 - val_loss: 1.4241 - val_acc: 0.8222\n",
      "Epoch 779/2000\n",
      " - 0s - loss: 1.2275 - acc: 0.8956 - val_loss: 1.4241 - val_acc: 0.8222\n",
      "Epoch 780/2000\n",
      " - 0s - loss: 1.2275 - acc: 0.8956 - val_loss: 1.4241 - val_acc: 0.8222\n",
      "Epoch 781/2000\n",
      " - 0s - loss: 1.2275 - acc: 0.8956 - val_loss: 1.4240 - val_acc: 0.8222\n",
      "Epoch 782/2000\n",
      " - 0s - loss: 1.2275 - acc: 0.8956 - val_loss: 1.4240 - val_acc: 0.8222\n",
      "Epoch 783/2000\n",
      " - 0s - loss: 1.2274 - acc: 0.8956 - val_loss: 1.4240 - val_acc: 0.8222\n",
      "Epoch 784/2000\n",
      " - 0s - loss: 1.2274 - acc: 0.8956 - val_loss: 1.4240 - val_acc: 0.8222\n",
      "Epoch 785/2000\n",
      " - 0s - loss: 1.2274 - acc: 0.8956 - val_loss: 1.4240 - val_acc: 0.8222\n",
      "Epoch 786/2000\n",
      " - 0s - loss: 1.2273 - acc: 0.8956 - val_loss: 1.4239 - val_acc: 0.8222\n",
      "Epoch 787/2000\n",
      " - 0s - loss: 1.2273 - acc: 0.8956 - val_loss: 1.4239 - val_acc: 0.8222\n",
      "Epoch 788/2000\n",
      " - 0s - loss: 1.2273 - acc: 0.8956 - val_loss: 1.4239 - val_acc: 0.8222\n",
      "Epoch 789/2000\n",
      " - 0s - loss: 1.2273 - acc: 0.8956 - val_loss: 1.4239 - val_acc: 0.8222\n",
      "Epoch 790/2000\n",
      " - 0s - loss: 1.2272 - acc: 0.8956 - val_loss: 1.4238 - val_acc: 0.8222\n",
      "Epoch 791/2000\n",
      " - 0s - loss: 1.2272 - acc: 0.8956 - val_loss: 1.4238 - val_acc: 0.8222\n",
      "Epoch 792/2000\n",
      " - 0s - loss: 1.2272 - acc: 0.8956 - val_loss: 1.4238 - val_acc: 0.8222\n",
      "Epoch 793/2000\n",
      " - 0s - loss: 1.2272 - acc: 0.8956 - val_loss: 1.4238 - val_acc: 0.8222\n",
      "Epoch 794/2000\n",
      " - 0s - loss: 1.2272 - acc: 0.8956 - val_loss: 1.4238 - val_acc: 0.8222\n",
      "Epoch 795/2000\n",
      " - 0s - loss: 1.2271 - acc: 0.8956 - val_loss: 1.4237 - val_acc: 0.8222\n",
      "Epoch 796/2000\n",
      " - 0s - loss: 1.2271 - acc: 0.8956 - val_loss: 1.4237 - val_acc: 0.8222\n",
      "Epoch 797/2000\n",
      " - 0s - loss: 1.2271 - acc: 0.8956 - val_loss: 1.4237 - val_acc: 0.8222\n",
      "Epoch 798/2000\n",
      " - 0s - loss: 1.2271 - acc: 0.8956 - val_loss: 1.4237 - val_acc: 0.8222\n",
      "Epoch 799/2000\n",
      " - 0s - loss: 1.2270 - acc: 0.8956 - val_loss: 1.4237 - val_acc: 0.8222\n",
      "Epoch 800/2000\n",
      " - 0s - loss: 1.2270 - acc: 0.8956 - val_loss: 1.4236 - val_acc: 0.8222\n",
      "Epoch 801/2000\n",
      " - 0s - loss: 1.2270 - acc: 0.8956 - val_loss: 1.4236 - val_acc: 0.8222\n",
      "Epoch 802/2000\n",
      " - 0s - loss: 1.2270 - acc: 0.8956 - val_loss: 1.4236 - val_acc: 0.8222\n",
      "Epoch 803/2000\n",
      " - 0s - loss: 1.2270 - acc: 0.8956 - val_loss: 1.4236 - val_acc: 0.8222\n",
      "Epoch 804/2000\n",
      " - 0s - loss: 1.2269 - acc: 0.8956 - val_loss: 1.4236 - val_acc: 0.8222\n",
      "Epoch 805/2000\n",
      " - 0s - loss: 1.2269 - acc: 0.8956 - val_loss: 1.4235 - val_acc: 0.8222\n",
      "Epoch 806/2000\n",
      " - 0s - loss: 1.2269 - acc: 0.8956 - val_loss: 1.4235 - val_acc: 0.8222\n",
      "Epoch 807/2000\n",
      " - 0s - loss: 1.2269 - acc: 0.8956 - val_loss: 1.4235 - val_acc: 0.8222\n",
      "Epoch 808/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4235 - val_acc: 0.8222\n",
      "Epoch 809/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4235 - val_acc: 0.8222\n",
      "Epoch 810/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 811/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 812/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 813/2000\n",
      " - 0s - loss: 1.2268 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 814/2000\n",
      " - 0s - loss: 1.2267 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 815/2000\n",
      " - 0s - loss: 1.2267 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 816/2000\n",
      " - 0s - loss: 1.2267 - acc: 0.8956 - val_loss: 1.4234 - val_acc: 0.8222\n",
      "Epoch 817/2000\n",
      " - 0s - loss: 1.2267 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 818/2000\n",
      " - 0s - loss: 1.2267 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 819/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 820/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 821/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 822/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4233 - val_acc: 0.8222\n",
      "Epoch 823/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 824/2000\n",
      " - 0s - loss: 1.2266 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 825/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 826/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 827/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 828/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 829/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4232 - val_acc: 0.8222\n",
      "Epoch 830/2000\n",
      " - 0s - loss: 1.2265 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 831/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 832/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 833/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 834/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 835/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 836/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4231 - val_acc: 0.8222\n",
      "Epoch 837/2000\n",
      " - 0s - loss: 1.2264 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 838/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 839/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 840/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 841/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 842/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 843/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 844/2000\n",
      " - 0s - loss: 1.2263 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 845/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4230 - val_acc: 0.8222\n",
      "Epoch 846/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 847/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 848/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 849/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 850/2000\n",
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 851/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2262 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 852/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 853/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 854/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4229 - val_acc: 0.8222\n",
      "Epoch 855/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 856/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 857/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 858/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 859/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 860/2000\n",
      " - 0s - loss: 1.2261 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 861/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 862/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 863/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4228 - val_acc: 0.8222\n",
      "Epoch 864/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 865/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 866/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 867/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 868/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 869/2000\n",
      " - 0s - loss: 1.2260 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 870/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 871/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 872/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 873/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 874/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4227 - val_acc: 0.8222\n",
      "Epoch 875/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 876/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 877/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 878/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 879/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 880/2000\n",
      " - 0s - loss: 1.2259 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 881/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 882/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 883/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 884/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 885/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 886/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4226 - val_acc: 0.8222\n",
      "Epoch 887/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 888/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 889/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 890/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 891/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 892/2000\n",
      " - 0s - loss: 1.2258 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 893/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 894/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 895/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 896/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 897/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 898/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 899/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 900/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 901/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4225 - val_acc: 0.8222\n",
      "Epoch 902/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 903/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 904/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 905/2000\n",
      " - 0s - loss: 1.2257 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 906/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 907/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 908/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 909/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 910/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 911/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 912/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 913/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 914/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 915/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 916/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 917/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 918/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 919/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4224 - val_acc: 0.8222\n",
      "Epoch 920/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 921/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 922/2000\n",
      " - 0s - loss: 1.2256 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 923/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 924/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 925/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 926/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 927/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 928/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 929/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 930/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 931/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 932/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 933/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 934/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 935/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 936/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 937/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 938/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 939/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 940/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4223 - val_acc: 0.8222\n",
      "Epoch 941/2000\n",
      " - 0s - loss: 1.2255 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 942/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 943/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 944/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 945/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 947/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 948/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 949/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 950/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 951/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 952/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 953/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 954/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 955/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 956/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 957/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 958/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 959/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 960/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 961/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 962/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 963/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 964/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 965/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 966/2000\n",
      " - 0s - loss: 1.2254 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 967/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 968/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 969/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 970/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4222 - val_acc: 0.8222\n",
      "Epoch 971/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 972/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 973/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 974/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 975/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 976/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 977/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 978/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 979/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 980/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 981/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 982/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 983/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 984/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 985/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 986/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 987/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 988/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 989/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 990/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 991/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 992/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 993/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 994/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 995/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 996/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 997/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 998/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 999/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1000/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1001/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1002/2000\n",
      " - 0s - loss: 1.2253 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1003/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1004/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1005/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1006/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1007/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1008/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1009/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1010/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1011/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1012/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1013/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1014/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4221 - val_acc: 0.8222\n",
      "Epoch 1015/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1016/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1017/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1018/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1019/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1020/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1021/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1022/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1023/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1024/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1025/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1026/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1027/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1028/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1029/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1030/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1031/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1032/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1033/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1034/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1035/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1036/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1037/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1038/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1039/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1041/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1042/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1043/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1044/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1045/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1046/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1047/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1048/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1049/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1050/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1051/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1052/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1053/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1054/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1055/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1056/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1057/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1058/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1059/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1060/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1061/2000\n",
      " - 0s - loss: 1.2252 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1062/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1063/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1064/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1065/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1066/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1067/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1068/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1069/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1070/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1071/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1072/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1073/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1074/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1075/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1076/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1077/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1078/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1079/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1080/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1081/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1082/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1083/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1084/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1085/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1086/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1087/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1088/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1089/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1090/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1091/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1092/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1093/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1094/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1095/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1096/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1097/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1098/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1099/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1100/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1101/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1102/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4220 - val_acc: 0.8222\n",
      "Epoch 1103/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1104/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1105/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1106/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1107/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1108/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1109/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1110/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1111/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1112/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1113/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1114/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1115/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1116/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1117/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1118/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1119/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1120/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1121/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1122/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1123/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1124/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1125/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1126/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1127/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1128/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1129/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1130/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1131/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1132/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1133/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1134/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1135/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1136/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1137/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1138/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1139/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1140/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1141/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1142/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1143/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1144/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1145/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1146/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1147/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1148/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1149/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1150/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1151/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1152/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1153/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1154/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1155/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1156/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1157/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1158/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1159/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1160/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1161/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1162/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1163/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1164/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1165/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1166/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1167/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1168/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1169/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1170/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1171/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1172/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1173/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1174/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1175/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1176/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1177/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1178/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1179/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1180/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1181/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1182/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1183/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1184/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1185/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1186/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1187/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1188/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1189/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1190/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1191/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1192/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1193/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1194/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1195/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1196/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1197/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1198/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1199/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1200/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1201/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1202/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1203/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1204/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1205/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1206/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1207/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1208/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1209/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1210/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1211/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1212/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1213/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1214/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1215/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1216/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1217/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1218/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1219/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1220/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1221/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1222/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1223/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1224/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1225/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1226/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1228/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1229/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1230/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1231/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1232/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1233/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1234/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1235/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1236/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1237/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1238/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1239/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1240/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1241/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1242/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1243/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1244/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1245/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1246/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1247/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1248/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1249/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1250/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1251/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1252/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1253/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1254/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1255/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1256/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1257/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1258/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1259/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1260/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1261/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1262/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1263/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1264/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1265/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1266/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1267/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1268/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1269/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1270/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1271/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1272/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1273/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1274/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1275/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1276/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1277/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1278/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1279/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1280/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1281/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1282/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1283/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1284/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1285/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1286/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1287/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1288/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1289/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1290/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1291/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1292/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1293/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1294/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1295/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1296/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1297/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1298/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1299/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1300/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1301/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1302/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1303/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1304/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1305/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1306/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1307/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1308/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1309/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1310/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1311/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1312/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1313/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1314/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1315/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1316/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1317/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1318/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1319/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1320/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1321/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1322/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1323/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1324/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1325/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1326/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1327/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1328/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1329/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1330/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1331/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1332/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1333/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1334/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1335/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1336/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1337/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1338/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1339/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1340/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1341/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1342/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1343/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1344/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1345/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1346/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1347/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1348/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1349/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1350/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1351/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1352/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1353/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1354/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1355/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1356/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1357/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1358/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1359/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1360/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1361/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1362/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1363/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1364/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1365/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1366/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1367/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1368/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1369/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1370/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1371/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1372/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1373/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1374/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1375/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1376/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1377/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1378/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1379/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1380/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1381/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1382/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1383/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1384/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1385/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1386/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1387/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1388/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1389/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1390/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1391/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1392/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1393/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1394/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1395/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1396/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1397/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1398/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1399/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1400/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1401/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1402/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1403/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1404/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1405/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1406/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1407/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1408/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1409/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1410/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1411/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1412/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1413/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1415/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1416/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1417/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1418/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1419/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1420/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1421/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1422/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1423/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1424/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1425/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1426/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1427/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1428/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1429/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1430/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1431/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1432/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1433/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1434/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1435/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1436/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1437/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1438/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1439/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1440/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1441/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1442/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1443/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1444/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1445/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1446/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1447/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1448/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1449/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1450/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1451/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1452/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1453/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1454/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1455/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1456/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1457/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1458/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1459/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1460/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1461/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1462/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1463/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1464/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1465/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1466/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1467/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1468/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1469/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1470/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1471/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1472/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1473/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1474/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1475/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1476/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1477/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1478/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1479/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1480/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1481/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1482/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1483/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1484/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1485/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1486/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1487/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1488/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1489/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1490/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1491/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1492/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1493/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1494/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1495/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1496/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1497/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1498/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1499/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1500/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1501/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1502/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1503/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1504/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1505/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1506/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1507/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1508/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1509/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1510/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1511/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1512/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1513/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1514/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1515/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1516/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1517/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1518/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1519/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1520/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1521/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1522/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1523/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1524/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1525/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1526/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1527/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1528/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1529/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1530/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1531/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1532/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1533/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1534/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1535/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1536/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1537/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1538/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1539/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1540/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1541/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1542/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1543/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1544/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1545/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1546/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1547/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1548/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1549/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1550/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1551/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1552/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1553/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1554/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1555/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1556/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1557/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1558/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1559/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1560/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1561/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1562/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1563/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1564/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1565/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1566/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1567/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1568/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1569/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1570/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1571/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1572/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1573/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1574/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1575/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1576/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1577/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1578/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1579/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1580/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1581/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1582/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1583/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1584/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1585/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1586/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1587/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1588/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1589/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1590/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1591/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1592/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1593/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1594/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1595/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1596/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1597/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1598/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1599/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1600/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1602/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1603/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1604/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1605/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1606/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1607/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1608/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1609/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1610/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1611/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1612/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1613/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1614/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1615/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1616/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1617/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1618/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1619/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1620/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1621/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1622/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1623/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1624/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1625/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1626/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1627/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1628/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1629/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1630/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1631/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1632/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1633/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1634/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1635/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1636/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1637/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1638/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1639/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1640/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1641/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1642/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1643/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1644/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1645/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1646/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1647/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1648/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1649/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1650/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1651/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1652/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1653/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1654/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1655/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1656/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1657/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1658/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1659/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1660/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1661/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1662/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1663/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1664/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1665/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1666/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1667/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1668/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1669/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1670/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1671/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1672/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1673/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1674/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1675/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1676/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1677/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1678/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1679/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1680/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1681/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1682/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1683/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1684/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1685/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1686/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1687/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1688/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1689/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1690/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1691/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1692/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1693/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1694/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1695/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1696/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1697/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1698/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1699/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1700/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1701/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1702/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1703/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1704/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1705/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1706/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1707/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1708/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1709/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1710/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1711/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1712/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1713/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1714/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1715/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1716/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1717/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1718/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1719/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1720/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1721/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1722/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1723/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1724/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1725/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1726/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1727/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1728/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1729/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1730/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1731/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1732/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1733/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1734/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1735/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1736/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1737/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1738/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1739/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1740/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1741/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1742/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1743/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1744/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1745/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1746/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1747/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1748/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1749/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1750/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1751/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1752/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1753/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1754/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1755/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1756/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1757/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1758/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1759/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1760/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1761/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1762/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1763/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1764/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1765/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1766/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1767/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1768/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1769/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1770/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1771/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1772/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1773/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1774/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1775/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1776/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1777/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1778/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1779/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1780/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1781/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1782/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1783/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1784/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1785/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1786/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1787/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1788/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1789/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1790/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1791/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1792/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1793/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1794/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1795/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1796/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1797/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1798/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1799/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1800/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1801/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1802/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1803/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1804/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1805/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1806/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1807/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1808/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1809/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1810/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1811/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1812/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1813/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1814/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1815/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1816/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1817/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1818/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1819/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1820/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1821/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1822/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1823/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1824/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1825/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1826/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1827/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1828/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1829/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1830/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1831/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1832/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1833/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1834/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1835/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1836/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1837/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1838/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1839/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1840/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1841/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1842/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1843/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1844/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1845/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1846/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1847/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1848/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1849/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1850/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1851/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1852/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1853/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1854/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1855/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1856/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1857/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1858/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1859/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1860/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1861/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1862/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1863/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1864/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1865/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1866/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1867/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1868/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1869/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1870/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1871/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1872/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1873/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1874/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1875/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1876/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1877/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1878/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1879/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1880/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1881/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1882/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1883/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1884/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1885/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1886/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1887/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1888/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1889/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1890/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1891/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1892/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1893/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1894/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1895/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1896/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1897/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1898/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1899/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1900/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1901/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1902/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1903/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1904/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1905/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1906/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1907/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1908/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1909/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1910/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1911/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1912/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1913/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1914/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1915/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1916/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1917/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1918/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1919/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1920/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1921/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1922/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1923/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1924/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1925/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1926/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1927/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1928/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1929/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1930/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1931/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1932/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1933/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1934/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1935/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1936/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1937/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1938/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1939/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1940/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1941/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1942/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1943/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1944/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1945/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1946/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1947/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1948/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1949/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1950/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1951/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1952/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1953/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1954/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1955/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1956/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1957/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1958/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1959/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1960/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1961/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1962/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1963/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1964/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1965/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1966/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1967/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1968/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1969/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1970/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1971/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1972/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1973/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1974/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1975/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1976/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1977/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1978/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1979/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1980/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1981/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1982/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1983/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1984/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1985/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1986/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1987/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1988/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1989/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1990/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1991/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1992/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1993/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1994/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1995/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1996/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1997/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1998/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 1999/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n",
      "Epoch 2000/2000\n",
      " - 0s - loss: 1.2251 - acc: 0.8956 - val_loss: 1.4219 - val_acc: 0.8222\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_history = model.fit(X_train, Y_train, \n",
    "                          batch_size = 100, \n",
    "                          epochs = 2000, \n",
    "                          verbose = 2,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [rd]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XXWd//HXJ/vSdEtaupO2lKXF0kLtFFlERCwoIE6Voo7CwHRkEVxwxAfzY5ABR0dF7QgKKG6DAlZZZqaIioWCQCFlqV2olNIlXdO0TdPsN/n8/jgn6U2apEmbc0+a+34+Hnncc77n3HPf9yS5n/s9q7k7IiIiABlxBxARkf5DRUFERNqoKIiISBsVBRERaaOiICIibVQURESkjYqCpD0zyzSz/WY2IaLlTzKz/VEsW6SvqSjIUSf8AG/9aTGzuqTxT/Z2ee7e7O6D3H3TYWQ5zswOOtnHzP7bzG4Ll7/e3Qf1YFlXm9kzvc0g0pey4g4g0lvJH7BmtgG42t3/1NX8Zpbl7olUZItTurxPiZZ6CjLgmNkdZvawmf3azKqBT5nZ6Wb2kpntNbNtZrbQzLLD+bPMzM2sNBz/73D6k2ZWbWYvmtnEI8jTrjdhZleZ2YZw2evNbL6ZvQv4AXBW2OPZFc47NMxTET7nq2Zm4bSrzWxpmHU3cEf4/k5Keq3RZlZrZsWHm1/Si4qCDFSXAr8ChgAPAwngRqAEOAOYC/xzN8//BPD/gOHAJuDf+yKUmQ0G7gI+4O5FYZYV7v5X4HrguXBTVkn4lHuAAmAScC5wFfDppEW+B1gDjAC+BjwCfKrD+3jK3Sv7Ir8MfCoKMlA97+7/4+4t7l7n7q+4+zJ3T7j7euA+4L3dPH+Ru5e5exPwIDCjuxcLv6G3/QAf72Z2B042szx33+buq7tYZna4nJvdvTrM/V3gH5Jm2+TuPwz3i9QBPwc+0dqbCOf9ZXfZRZKpKMhAtTl5xMxONLP/M7PtZrYPuJ2g19CV7UnDtUC3O4rdfWjyD8E39s7m2wdcDlwHbDez/zWz47tY7EggE9iY1LYRGJs03u59uvtfCHpFZ5rZycAE4P+6yy6STEVBBqqORwTdC6wEjnP3wcCtgB30rBRw9yfd/TxgNLAuzAYHZ94JNAPHJrVNALYkL66Tl/gFwSakfwAecfeGvsgt6UFFQdJFEVAF1IQ7YrvbnxCZcMfvRWZWADQCNQQf/AA7gHGtO8DDTVeLgK+b2aBwZ/cXgP8+xMv8EphHsD/hFxG8DRnAVBQkXXwJ+AxQTfDN/OGYcmQCXwa2AZUEO4qvD6f9EXgL2GFmrZuvriUoHu8AzxLsM+j2g97dNwB/BRrd/YU+zi8DnOkmOyIDj5n9Aljv7rfFnUWOLjp5TWSAMbNJwCXAu+LOIkcfbT4SGUDM7D+AN4CvH85lO0S0+UhERNqopyAiIm2Oun0KJSUlXlpaGncMEZGjyvLly3e5+4hDzXfUFYXS0lLKysrijiEiclQxs42Hnkubj0REJImKgoiItFFREBGRNioKIiLSRkVBRETaqCiIiEgbFQUREWlz1J2nINFpveRJ650caxoSbKuq551dNTS3tLB+Vw2FOVkMK8yhMdHClj11TBxReMjlVtU1sXVvHa9u3MNpxw6jvqmFt3ZWMyQ/m6wMY8Lwgkjfl8hA8f6TjuGU8UMjfQ0VhQGmIdHMs2srePS1LTS3OIW5WSz9WwWVNY1kZxrHFheSnZlBUV4Wg/OyeLuihoamZjIyjJ3VDbg7Iwbl0tjs7Nrf9zfsWvbO7oPaLJb7n4kcfUYOzlNRkK7VNTazs7qe5hbnm79/k6dW7eh2/qyMDDbtrqUx0UJxYQ4jB+eRaGlh8shBDC3IYUX5XiaVFDIoLxsDhhVkk5WZQUOimfOnjqKuqZlEs3PCqCI27a6hcn8jMycMO2ROMygtLmTr3jrGDs2nsqaRffVN5GVnMjQ/m8Jc/RmK9Bf6bzzKJJpbWLK2ghffruSBv7zT5XzXnDOZ90wuJisjg+njhvT5B+9xI7u9j32nxoebiUYU5TKiKLdP84hI31BROEo0JJr5+I9e5I3yqi7nWfTZ0xlemENpcSEZGdomIyK9p6LQT7k71//6NRqamvnTmp0HTb9s1niqG5r43LlTOGn04BgSishApKLQj+yrb+LDC5/ng9OO4dVNe1m+cU+n87301fczakheitOJSDpQUYhZfVMzl97zAmu27Wtru/+59vsKPjR9NNeeM5lpY4akOp6IpBkVhRj9x+I13Lt0/UHtJ44q4p/OmsQHTx7FIB2ZIyIppE+cGLy2aQ+X3vNCu7bzThrJgrMnM3vi8JhSiYioKKTcZfe+2O4ErocWzOGk0YMZkp8dYyoRkYCKQgo9vWZHu4Iwblg+cyYVx5hIRKQ9FYUU2V3TyFU/D+4t/dFTx/KF845nzND8mFOJiLSnohAxd+fepev5xpNvtrXd+uGpDC3IiTGViEjnVBQidtsTq/j5ixvbxr8/f4YKgoj0WyoKEXrh7V3tCsJbd15AdqZuYSEi/Zc+oSKydns1n7h/GQAzxg9l/dcvVEEQkX5PPYUItLQ4H/ze0rbxx647I8Y0IiI9p6+uEbjmweVtw7+79j0xJhER6R31FPrYTb95o+1mN2/++1zysjNjTiQi0nOR9hTMbK6ZrTWzdWZ2cyfTJ5jZEjN7zcxWmNmFUeaJ2o+fW8+i5eUAjCzKVUEQkaNOZEXBzDKBu4ELgKnA5WY2tcNs/wo84u4zgfnAPVHliVpdYzN3/N8aAC6fPZ4/33ROvIFERA5DlJuPZgPr3H09gJk9BFwCrE6ax4HWO8QMAbZGmCdSH7s3uMDdDecexxfPPyHmNCIihyfKzUdjgc1J4+VhW7LbgE+ZWTmwGPhcZwsyswVmVmZmZRUVFVFkPSKbKmtZuSW4H8Kn31MabxgRkSMQZU+hs5sEe4fxy4Gfuft3zOx04JdmdrK7t7R7kvt9wH0As2bN6riMWD308iZu/t1fgeDQ05JBEd6QvrE2eMwpgKpyyMiCnELIzA2GG6ogf1jfvmb9Pmiqg6ZaMIPmRPA6mbnQ3BA8FgyHlgQ01UNGJgybCBnh942meqjZCdmFwfNzi2D7CsjSneNEeq1odPD/FqEoi0I5MD5pfBwHbx66CpgL4O4vmlkeUAIcfFPifmhvbWNbQRiSn82M8UP7ZsG718Nj18K0j8Lk98GG54IP38evDaaPmh58sHbmtCtg0DEwciqsehTWPgkzPxV8CGcfxgfxc9/p/XOKj4Opl3T+/JxB0Li/98sUEfjQXfDuqyJ9iSiLwivAFDObCGwh2JH8iQ7zbALeD/zMzE4C8oD+t32oC59+4OUDw6cfe+QLrNkVfGAunBmMb3qx8/m6KggAy392cFvZT4JHywh++kJ2AbjDoBGwd1P7aZXr4C/f7/x5rQXhtCuDgiciPTdqeuQvEVlRcPeEmV0PPAVkAg+4+yozux0oc/cngC8B95vZFwg2LV3h7v1q81BX6puaWVFeBcCn5kzgC+cdf3gLcocX/gtevg+qNh96/pP/PvjWXzQanvt21/NNnw+JOtjyavCtffAYOP26w8soImkj0pPX3H0xwQ7k5LZbk4ZXA0flNSCWb9wDwLknjuSOj7zr8Bby68th7eKup59/BzzzTWishlMuh/f+CwyfdGD6uf8KFW/CyJMO7/VFRDrQGc2H6X/eCHaPfPEDvewhVL4NG/8C65/tvCCUngUT5sBx5wWP7+n0gKyAmQqCiPQpFYXDsG7nfh56JdjUM7a3d0/7r1O7nnbGjfCB248gmYjIkVFROAzX/+rVtuFhhb24Yc7ud7qedlvVESQSEekbKgqHoSgvWG0PLZjT8yf9/qvwUoereBz3ARg0EnIHd/4cEZEUU1E4DIkWZ86k4cyZVNyzJ7S0HFwQINhxPH5234YTETkCup9CL23YVcNrm/Zy4qhefLvfuar9+OhT4Oo/qyCISL+jnkIvffLHwS02z5pS0vMn1ew6MHztMhh5Yh+nEhHpG+op9NKWvXUAnH38iJ49IdEAv006LV0FQUT6MfUUemliSSHDCrLJzuxBPX32W7DkjgPj17wQXTARkT6gnkIv1DU2s6GyhrOmHKKX4A4v/bB9QQA4Zlp04URE+oB6Cr3wvaf/hjucOKqo8xncoW4PvLMUft/h7qNnfzn6gCIiR0hFoRfe3FYNwJld7WR+/rvw9NcObteJaSJylFBR6IVESwszJwylKC+7/YSVv4VF/9j5k67+c/TBRET6iIpCD23YVcNf1lWS09kO5s4KwlV/gvHvjj6YiEgfUlHooWXvVALQ2NzS/YzDSuGzf4HcQdGHEhHpYyoKPbRrfyPQyUlrL99/YDhvCNz4RgpTiYj0LR2S2kM/fm49AD/5TNImoWX3weKbDoxfuyzFqURE+paKQg+0tDh7apsAyMkKV1lzEzzZ4TDTwaNTnExEpG+pKPTAzuoGAD522rgDjcvujSmNiEh0tE+hBzZU1gBw8YwxBxpfWHhg+KKFwa0zRUSOcioKPfC7V8sBmDQiPKLIHfbvCIZzB8Npn4kpmYhI39Lmox7YvLuOwXlZB+7HvOjKAxNVEERkAFFR6IGquibeXTo8GNmzEVY9GgwPnwzn3R5fMBGRPqai0AP76psYnB9e2uKdpQcmXP4QZGgVisjAoU+0Q1i1tYryPXUU5YW7X7aUHZg4fFI8oUREIqKicAgX/dfzALS4Bw3LfxY8/ss7kKn99CIysKgoHEJLWAsmlXS4llHB8NSHERGJmIpCD00aURjcb1lEZABTUeihc04YCQ37444hIhIpFYXeqKmIO4GISKRUFLrR1PHeCff8XfD48V+mPoyISAqoKHSj9UJ4t18yrf0E3UBHRAYoFYVufH3xGgAaEx16DLlDYkgjIhI9FYVubNtbB8AHph4DVeUHJmTnxZRIRCRaOvuqG1mZGcwuHc6xxYVwW9Jls0dOjS+UiEiEIu0pmNlcM1trZuvM7OYu5vm4ma02s1Vm9qso8/RGTUOCl9/ZTUlRzsETzVIfSEQkBSLrKZhZJnA38AGgHHjFzJ5w99VJ80wBvgqc4e57zGxkVHl66+4l6wB44e3K9hOOOy+GNCIiqRFlT2E2sM7d17t7I/AQcEmHef4JuNvd9wC4+84I8/TKjn3BkUenjBvafsJlD8aQRkQkNaIsCmOBzUnj5WFbsuOB483sL2b2kpnNjTBPr4woygXgB5+Y2X6CdjKLyAAW5Y7mzja8eyevPwU4BxgHPGdmJ7v73nYLMlsALACYMGFC3yftxM599Ywdmk9RXjb85spDP0FEZACIsqdQDoxPGh8HbO1knsfdvcnd3wHWEhSJdtz9Pnef5e6zRowYEVngZNv31XPM4KC3wKrfpeQ1RUTiFmVReAWYYmYTzSwHmA880WGex4D3AZhZCcHmpPURZuqxHfvqGTWkw6ai998aTxgRkRSJrCi4ewK4HngKWAM84u6rzOx2M7s4nO0poNLMVgNLgC+7e2XnS0ytHfsaGFnUoSjoTmsiMsBFevKauy8GFndouzVp2IEvhj/9xv6GBPsbEgd6CkMnQPFxMO3SeIOJiERMl7noxOqt+wAO7FNorIVhpfEFEhFJERWFTnz83hcBKMrNhj0boHYX5BTGG0pEJAV07aNuTBxRCN8/PhjRlVFFJA2oKHRiUkkhxwzOY/KIpPsmzPxUfIFERFJEm486aEy0sHF3LacdOyxoyC6AMTNh8Oh4g4mIpICKQgebdtfQ3OJMHpm0D6H0zPgCiYikkIpCByvKqwA4cdRgcIem2qC3ICKSBlQUOti+rx6AiSWFUL09aMzKjTGRiEjqqCh08Oc1OzGDvOxMePzaoHHbinhDiYikiIpCB7nZGeRmhatl11vBY5Yuly0i6UFFoYPGRAszx4dHHlWFt4M4+8vxBRIRSSEVhQ4aEy3kZHVYLSXHxRNGRCTFVBQ6aOisKIiIpAl9+nXQ2BwWhYq/BQ2j3hVvIBGRFFJRSNKYaGF9RQ376xPwzNeDxqz8eEOJiKSQikKSVzbsBuDZv1VA3Z6gMSMzxkQiIqmlopAkOzNYHXd85GTIGxo0XnJ3jIlERFJLRSFJbWMCgJNGD4bVjwWNxZNjTCQikloqCkmq6poAKMpuiTmJiEg8VBSSbKysBeDYQc0xJxERiYeKQpK9tU0U5mSS21wXdxQRkVj0qCiY2aVmNiRpfKiZfSS6WPGoqmtiSH42NNYEDR/7ebyBRERSrKc9hX9z96rWEXffC/xbNJHiUdOQ4LevlrO1qv5AUcgZ1P2TREQGmJ4Whc7mG1D3d66objgw8ug/B485hZ3PLCIyQPW0KJSZ2V1mNtnMJpnZd4HlUQZLtYZEcMTR3GmjYPfbQaOKgoikmZ4Whc8BjcDDwCNAHXBdVKHisL8hOEfh8tNGHmgcOiGmNCIi8ejRJiB3rwFujjhLrFpPXBuW2HmgMX9oTGlEROLR06OP/mhmQ5PGh5nZU9HFSr2ahuDchIIMnaMgIumrp5uPSsIjjgBw9z3AyG7mP+rUhJuPCjOaYk4iIhKfnhaFFjNr28BuZqWARxEoLtuqghPWhmapKIhI+urpYaW3AM+b2bPh+NnAgmgixePtihrGDMkjv2FX0PChu+INJCISg57uaP69mc0iKASvA48THIE0YOza38DIwXmweVnQMP2yeAOJiMSgR0XBzK4GbgTGERSFOcCLwLnRRUutmoYEg3KzoGJt0JCrs5lFJP30dJ/CjcC7gY3u/j5gJlARWaoY1DY2U5CTCS0JGHta3HFERGLR06JQ7+71AGaW6+5vAidEFyv1quvDnkKi/sBd10RE0kxPdzSXh+cpPAb80cz2AFuji5Vaf9tRzZa9dbxevhfy66EoP+5IIiKx6FFPwd0vdfe97n4b8P+AnwCHvHS2mc01s7Vmts7Mujwj2szmmZmHO7NT7rVNewBYX1ET9BSy8uKIISISu17fZMfdn3X3J9y9sbv5zCwTuBu4AJgKXG5mUzuZrwi4AVjW2yx9JT8n6DB98bwpwcXwMgbUBWBFRHosyjuvzQbWufv6sIA8BFzSyXz/DvwnUB9hlm41hldIvWzEpqBhxUNxRRERiVWURWEssDlpvDxsa2NmM4Hx7v6/3S3IzBaYWZmZlVVU9P1BT03NQVHIyghP0tbNdUQkTUVZFKyTtrZLY5hZBvBd4EuHWpC73+fus9x91ogRI/owYqC1p5CVGUae99M+fw0RkaNBlEWhHBifND6O9kcsFQEnA8+Y2QaCE+KeiGNnc2tRyG4Jt2AVFqc6gohIvxBlUXgFmGJmE80sB5gPPNE60d2r3L3E3UvdvRR4CbjY3csizNSp6oYEZpDn4S05swtSHUFEpF+IrCi4ewK4HngKWAM84u6rzOx2M7s4qtc9HLtrGhiSn01G4/6gQfsURCRNRXrspbsvBhZ3aLu1i3nPiTJLd8r31DFmSD60FgVd90hE0lSUm4+OGlv31jFuWD40tPYUiuINJCISExUFYGd1AyMH58KG54KzmTN18pqIpKe0//RrSDSzt7aJv2tcFhQFEZE0lvY9hT+s2gHAGHbFnEREJH5pXxQqqoPDUEeNGRdzEhGR+KV9UahPNAMworgk5iQiIvFL+6Kwvz5BVoYdOJtZRCSNpf2O5v0NCQblZWG/uTxo+Ozz8QYSEYlR2vcUqusTFOUl1caM7PjCiIjELO2Lwr66JopykwpBRmZ8YUREYpb2RWF3bSPTcnYcaEg0xBdGRCRmab9PYU9NIxdlPXGgIacwvjAiIjFTT6GmkUR+eDjqPz4FwyfGG0hEJEZpXRQSzS3sq09w+q5FQcOEOfEGEhGJWVoXhZ3h2cz5iaqYk4iI9A9pXRTe3L7vwMjIafEFERHpJ9K6KOypaQLAM7Lg+A/GnEZEJH5pXRQq9jeQQQvWkgjuoyAikubSuihsrKxlVIEFI1k58YYREekH0rooNCSaOS5rZzCiy1uIiKR3UWhMtPCtpjuDkb2b4g0jItIPpH1RqMoYGoxMOT/eMCIi/UB6F4XmFnZmjobBY2HKeXHHERGJXVoXhfqmZoZQDUN0K04REUjzolDb2Mxw3wMFxXFHERHpF9K6KOyva2Js00YoOT7uKCIi/ULaFoVd+xs4oSq89ebu9fGGERHpJ9K2KLy+aS/vpSwY2bEq3jAiIv1E2haF3bWNzM96Jhi56PuxZhER6S/StijUNTYfGNGNdUREgDQuCrXJRSG7IL4gIiL9SBoXhQRLW96FZxdAwfC444iI9AtpXBSayTHHRp8SdxQRkX4jrYtCQUYjZOfHHUVEpN9I46KQoMAatT9BRCRJ2haF/fUJCmhQT0FEJEmkRcHM5prZWjNbZ2Y3dzL9i2a22sxWmNnTZnZslHmS7atvIl9FQUSknciKgpllAncDFwBTgcvNbGqH2V4DZrn7dGAR8J9R5eloc2Utw1p2Q76OPBIRaRVlT2E2sM7d17t7I/AQcEnyDO6+xN1rw9GXgJRdw/qY2jeDAe1TEBFpE2VRGAtsThovD9u6chXwZGcTzGyBmZWZWVlFRcURB2tqbmG8bw9GTrzwiJcnIjJQRFkUrJM273RGs08Bs4BvdTbd3e9z91nuPmvEiBFHHKy+qZnjMrYEIyUnHPHyREQGiqwIl10OjE8aHwds7TiTmZ0H3AK8190bIszTZse+BvJpIJGZR1ZWTipeUkTkqBBlT+EVYIqZTTSzHGA+8ETyDGY2E7gXuNjdd0aYpZ3P/fo1iqglQXaqXlJE5KgQWU/B3RNmdj3wFJAJPODuq8zsdqDM3Z8g2Fw0CPiNmQFscveLo8rUyoBPZC2B5kPOKiKSVqLcfIS7LwYWd2i7NWn4vChfvysfmj4ano3jlUVE+re0PKO5IdFCwjPws26KO4qISL8SaU+hv2pqaiLLWiBTO5lFRJKlZU8h0dQYDGRqR7OISLK0LApNjfXBgHoKIiLtpGVRyNy/LRxQURARSZaWReGftvxrMFC1Kd4gIiL9TFoWhZJEeN0j9RRERNpJy6KQ1XrWWmZuvEFERPqZtDwktY11ds0+EUmlpqYmysvLqa+vjzvKgJCXl8e4cePIzj68oyvTrig0JlrQRiOR/qO8vJyioiJKS0sxfVE7Iu5OZWUl5eXlTJw48bCWkXabj2obE3FHEJEk9fX1FBcXqyD0ATOjuLj4iHpdaVgUkq+Cpz9Ckf5ABaHvHOm6TLuiUNfUTIOHW80mnhVvGBGRfib9ikJjM2v8WCpHng4T5sQdR0RitnfvXu65555eP+/CCy9k7969ESSKV9oVhfqaamZkvE1L3rC4o4hIP9BVUWhu7v6GK4sXL2bo0KFRxYpN2h19ZLvXAdBSODLmJCLS0df+ZxWrt+7r02VOHTOYf7toWpfTb775Zt5++21mzJhBdnY2gwYNYvTo0bz++uusXr2aj3zkI2zevJn6+npuvPFGFixYAEBpaSllZWXs37+fCy64gDPPPJMXXniBsWPH8vjjj5Ofn9+n7yNV0q6n0NRQC0BD6bkxJxGR/uAb3/gGkydP5vXXX+db3/oWL7/8MnfeeSerV68G4IEHHmD58uWUlZWxcOFCKisrD1rGW2+9xXXXXceqVasYOnQov/3tb1P9NvpM2vUUGhvqAMjJLYg5iYh01N03+lSZPXt2u2P8Fy5cyKOPPgrA5s2beeuttyguLm73nIkTJzJjxgwATjvtNDZs2JCyvH0t7YpCc2NYFPKOzq6diESrsLCwbfiZZ57hT3/6Ey+++CIFBQWcc845nZ4DkJt74JI5mZmZ1NXVpSRrFNJu81GiIfiF5uarpyAiUFRURHV1dafTqqqqGDZsGAUFBbz55pu89NJLKU6XemnXU0iEPYXcPBUFEYHi4mLOOOMMTj75ZPLz8znmmGPaps2dO5cf/ehHTJ8+nRNOOIE5cwb+YexpVxQa6oMdzVk52nwkIoFf/epXnbbn5uby5JNPdjqtdb9BSUkJK1eubGu/6aab+jxfKqXd5qPKvWE3MSsv3iAiIv1Q2hWFurqgp0CW7qUgItJR2hWFaY1vBAPqKYiIHCStikJzi1PTHO5GyVZREBHpKK2Kwr66JvJoYFfRiXFHERHpl9KqKOza30A+jVi2DkcVEelMWhWF8b+YwxmZq8jUJS5E5DANGjQIgK1btzJv3rxO5znnnHMoKyvrdjnf+973qK2tbRvvL5fiTpui0NLi5NWUByMjT4o3jIgc9caMGcOiRYsO+/kdi0J/uRR32py8tnZHNa2lIOekubFmEZEuPHkzbP9r3y5z1Lvggm90OfkrX/kKxx57LNdeey0At912G2bG0qVL2bNnD01NTdxxxx1ccskl7Z63YcMGPvzhD7Ny5Urq6uq48sorWb16NSeddFK7ax9dc801vPLKK9TV1TFv3jy+9rWvsXDhQrZu3cr73vc+SkpKWLJkSduluEtKSrjrrrt44IEHALj66qv5/Oc/z4YNG1Jyie606SlU1yfahvMnnxljEhHpT+bPn8/DDz/cNv7II49w5ZVX8uijj/Lqq6+yZMkSvvSlL+HuXS7jhz/8IQUFBaxYsYJbbrmF5cuXt0278847KSsrY8WKFTz77LOsWLGCG264gTFjxrBkyRKWLFnSblnLly/npz/9KcuWLeOll17i/vvv57XXXgNSc4nutOkp7K1tbBs2HY4q0j91840+KjNnzmTnzp1s3bqViooKhg0bxujRo/nCF77A0qVLycjIYMuWLezYsYNRo0Z1uoylS5dyww03ADB9+nSmT5/eNu2RRx7hvvvuI5FIsG3bNlavXt1uekfPP/88l156advVWj/60Y/y3HPPcfHFF6fkEt1pUxS27Q7u5tRw3Fx0LrOIJJs3bx6LFi1i+/btzJ8/nwcffJCKigqWL19OdnY2paWlnV4yO5mZHdT2zjvv8O1vf5tXXnmFYcOGccUVVxxyOd31SFJxie602Xw0pznozuWccH7MSUSkv5k/fz4PPfQQixYtYt68eVRVVTFy5Eiys7NZsmQJGzdu7Pb5Z599Ng8++CAAK1euZMWKFQDs27ePwsJChgwZwo4dO9pdXK+rS3afffbZPPaz2Zf5AAAI60lEQVTYY9TW1lJTU8Ojjz7KWWed1Yfvtntp01M4ofZVAJ2jICIHmTZtGtXV1YwdO5bRo0fzyU9+kosuuohZs2YxY8YMTjyx+xNer7nmGq688kqmT5/OjBkzmD17NgCnnHIKM2fOZNq0aUyaNIkzzjij7TkLFizgggsuYPTo0e32K5x66qlcccUVbcu4+uqrmTlzZsru5mbddVWOeOFmc4HvA5nAj939Gx2m5wK/AE4DKoHL3H1Dd8ucNWuWH+r4307VVMJz34Fz/xVyVBhE+os1a9Zw0kk6TLwvdbZOzWy5u8861HMj23xkZpnA3cAFwFTgcjOb2mG2q4A97n4c8F3gm1HlobAY5n5dBUFEpBtR7lOYDaxz9/Xu3gg8BFzSYZ5LgJ+Hw4uA91tne2tERCQloiwKY4HNSePlYVun87h7AqgCijsuyMwWmFmZmZVVVFREFFdE4hLlZux0c6TrMsqi0Nk3/o5pezIP7n6fu89y91kjRozok3Ai0j/k5eVRWVmpwtAH3J3Kykry8g7/XKwojz4qB8YnjY8DtnYxT7mZZQFDgN0RZhKRfmbcuHGUl5ejrQB9Iy8vj3Hjxh3286MsCq8AU8xsIrAFmA98osM8TwCfAV4E5gF/dn1dEEkr2dnZTJw4Me4YEoqsKLh7wsyuB54iOCT1AXdfZWa3A2Xu/gTwE+CXZraOoIcwP6o8IiJyaJGevObui4HFHdpuTRquBz4WZQYREem5tLnMhYiIHFqkZzRHwcwqgO4vRNK1EmBXH8bpK8rVO/01F/TfbMrVOwMx17HufsjDN4+6onAkzKysJ6d5p5py9U5/zQX9N5ty9U4659LmIxERaaOiICIibdKtKNwXd4AuKFfv9Ndc0H+zKVfvpG2utNqnICIi3Uu3noKIiHRDRUFERNqkTVEws7lmttbM1pnZzSl+7fFmtsTM1pjZKjO7MWy/zcy2mNnr4c+FSc/5aph1rZl9MMJsG8zsr+Hrl4Vtw83sj2b2Vvg4LGw3M1sY5lphZqdGlOmEpHXyupntM7PPx7G+zOwBM9tpZiuT2nq9fszsM+H8b5nZZyLK9S0zezN87UfNbGjYXmpmdUnr7UdJzzkt/P2vC7Mf0f1MusjV699bX/+/dpHr4aRMG8zs9bA9leurq8+G+P7G3H3A/xBce+ltYBKQA7wBTE3h648GTg2Hi4C/EdyN7jbgpk7mnxpmzAUmhtkzI8q2ASjp0PafwM3h8M3AN8PhC4EnCS55PgdYlqLf3Xbg2DjWF3A2cCqw8nDXDzAcWB8+DguHh0WQ63wgKxz+ZlKu0uT5OiznZeD0MPOTwAUR5OrV7y2K/9fOcnWY/h3g1hjWV1efDbH9jaVLT6End4GLjLtvc/dXw+FqYA0H33Ao2SXAQ+7e4O7vAOsI3kOqJN8R7+fAR5Laf+GBl4ChZjY64izvB9529+7OYo9sfbn7Ug6+nHtv188HgT+6+2533wP8EZjb17nc/Q8e3KwK4CWCy9V3Kcw22N1f9OCT5RdJ76XPcnWjq99bn/+/dpcr/Lb/ceDX3S0jovXV1WdDbH9j6VIUenIXuJQws1JgJrAsbLo+7AY+0NpFJLV5HfiDmS03swVh2zHuvg2CP1pgZAy5Ws2n/T9r3OsLer9+4lhv/0jwjbLVRDN7zcyeNbOzwraxYZZU5OrN7y3V6+ssYIe7v5XUlvL11eGzIba/sXQpCj26w1vkIcwGAb8FPu/u+4AfApOBGcA2gi4spDbvGe5+KnABcJ2Znd3NvCldj2aWA1wM/CZs6g/rqztd5Uj1ersFSAAPhk3bgAnuPhP4IvArMxucwly9/b2l+vd5Oe2/eKR8fXXy2dDlrF1k6LNs6VIUenIXuEiZWTbBL/1Bd/8dgLvvcPdmd28B7ufAJo+U5XX3reHjTuDRMMOO1s1C4ePOVOcKXQC86u47woyxr69Qb9dPyvKFOxg/DHwy3MRBuHmmMhxeTrC9/vgwV/ImpkhyHcbvLZXrKwv4KPBwUt6Urq/OPhuI8W8sXYpC213gwm+f8wnu+pYS4TbLnwBr3P2upPbk7fGXAq1HRjwBzDezXAvuXDeFYAdXX+cqNLOi1mGCHZUrOXBHPMLHx5NyfTo8AmIOUNXaxY1Iu29wca+vJL1dP08B55vZsHDTyflhW58ys7nAV4CL3b02qX2EmWWGw5MI1s/6MFu1mc0J/0Y/nfRe+jJXb39vqfx/PQ94093bNgulcn119dlAnH9jR7Ln/Gj6Idhr/zeCqn9Lil/7TIKu3Arg9fDnQuCXwF/D9ieA0UnPuSXMupYjPMKhm1yTCI7seANY1bpegGLgaeCt8HF42G7A3WGuvwKzIlxnBUAlMCSpLeXri6AobQOaCL6NXXU464dgG/+68OfKiHKtI9iu3Po39qNw3r8Pf79vAK8CFyUtZxbBh/TbwA8Ir3LQx7l6/Xvr6//XznKF7T8DPtth3lSur64+G2L7G9NlLkREpE26bD4SEZEeUFEQEZE2KgoiItJGRUFERNqoKIiISBsVBZEOzKzZ2l+ltc+uqmvBFThXHnpOkXhkxR1ApB+qc/cZcYcQiYN6CiI9ZME1979pZi+HP8eF7cea2dPhBd+eNrMJYfsxFtzX4I3w5z3hojLN7H4Lrp//BzPLj+1NiXSgoiBysPwOm48uS5q2z91nE5zN+r2w7QcElzOeTnARuoVh+0LgWXc/heBa/qvC9inA3e4+DdhLcAatSL+gM5pFOjCz/e4+qJP2DcC57r4+vIjZdncvNrNdBJduaArbt7l7iZlVAOPcvSFpGaUE172fEo5/Bch29zuif2cih6aegkjveBfDXc3TmYak4Wa0b0/6ERUFkd65LOnxxXD4BYIreQJ8Eng+HH4auAbAzDLDa/KL9Gv6hiJysHwLb+Ie+r27tx6Wmmtmywi+UF0ett0APGBmXwYqgCvD9huB+8zsKoIewTUEV+oU6be0T0Gkh8J9CrPcfVfcWUSios1HIiLSRj0FERFpo56CiIi0UVEQEZE2KgoiItJGRUFERNqoKIiISJv/D8HswzQKyCxFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history, 'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.75757581315118"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before saving: are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_logistic.h5\")\n",
    "#for this\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST-SEE: \n",
    "* https://www.kaggle.com/randyrose2017/for-beginners-using-keras-to-build-models\n",
    "* https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d\n",
    "* https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n",
    "## Just liked:\n",
    "* https://missinglink.ai/guides/neural-network-concepts/classification-neural-networks-neural-network-right-choice/\n",
    "## Full-house:\n",
    "https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why rerunning with same configuration gives different output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = Sequential()\n",
    "model_load.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))\n",
    "#model_load.add(Dense(units = 10, \n",
    "                #activation = 'tanh'))\n",
    "model_load.add(Dense(units = 20, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_weights('/home/amanzhol/Documents/Capstone/MAIN Work/models/model_10_10_20_tanh_100_1000_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to compile before evaluating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_load.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.35198137976907"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Ms. Asma Salem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='AsmaSalemResults.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "predictions = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing confustion matrix from source:\n",
    "https://stackoverflow.com/questions/50920908/get-confusion-matrix-from-a-keras-multiclass-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 9, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 7, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 7, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 7]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FAR, FRR and EER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stats.stackexchange.com/questions/272962/are-far-and-frr-the-same-as-fpr-and-fnr-respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ConfusionMatrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='PerformanceMetrics.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edit:\n",
    "this is the format for confusion_matrix():\n",
    "[[TP,FN]\n",
    "[FP,TN]]\n",
    "And classification report gives all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-86b2e0ad5146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-c62d2e9dae18>\u001b[0m in \u001b[0;36mperf_measure\u001b[0;34m(y_actual, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m            \u001b[0mTP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "perf_measure(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus\n",
    "TP = 6\n",
    "FP = 1\n",
    "TN = 11\n",
    "FN = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAR(FP, TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FRR(FN, TP):\n",
    "    return FN/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333332"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAR(FP, TN) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.78082191780823"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRR(FN, TP) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (Performance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ms. Asma Results\n",
    "* FAR = 0.3%\n",
    "* FRR = 1.5%\n",
    "* EER = 0.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* How to have several FAR, FRR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read for Confusion Matrix - Get Items FP/FN/TP/TN - Python\n",
    "* https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python\n",
    "* https://classeval.wordpress.com/introduction/basic-evaluation-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
