{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "The dataset is taken from http://www.vmonaco.com/keystroke-datasets.\n",
    "Specifically from https://ms.sapientia.ro/~manyi/keystroke.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read:\n",
    "* https://appliedmachinelearning.blog/2017/07/26/user-verification-based-on-keystroke-dynamics-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('dataset2_norm.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['user_id'].values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.mean(a == b'37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As it can be seen the number of samples per user are 51. Since the user are 42 users, there in total 51 * 42 = 2142 samples. Number of features is 71."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the dataset is 2142 * 72."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good source for Pandas: https://chrisalbon.com/python/data_wrangling/pandas_replace_values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_unique = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b'10', b'20',\n",
       "       b'21', b'24', b'25', b'26', b'27', b'28', b'29', b'35', b'36',\n",
       "       b'37', b'38', b'40', b'41', b'50', b'51', b'53', b'54', b'55',\n",
       "       b'65', b'66', b'68', b'69', b'70', b'71', b'73', b'80', b'81',\n",
       "       b'82', b'83', b'84', b'85'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_id[user_id == b'20'] = b'11'\\nuser_id[user_id == b'21'] = b'12'\\nuser_id[user_id == b'24'] = b'13'\\nuser_id[user_id == b'25'] = b'14'\\nuser_id[user_id == b'26'] = b'15'\\nuser_id[user_id == b'27'] = b'16'\\nuser_id[user_id == b'28'] = b'17'\\nuser_id[user_id == b'29'] = b'18'\\nuser_id[user_id == b'35'] = b'19'\\nuser_id[user_id == b'35'] = b'20'\\nuser_id[user_id == b'37'] = b'21'\\nuser_id[user_id == b'38'] = b'22'\\nuser_id[user_id == b'20'] = b'11'\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "user_id[user_id == b'21'] = b'12'\n",
    "user_id[user_id == b'24'] = b'13'\n",
    "user_id[user_id == b'25'] = b'14'\n",
    "user_id[user_id == b'26'] = b'15'\n",
    "user_id[user_id == b'27'] = b'16'\n",
    "user_id[user_id == b'28'] = b'17'\n",
    "user_id[user_id == b'29'] = b'18'\n",
    "user_id[user_id == b'35'] = b'19'\n",
    "user_id[user_id == b'35'] = b'20'\n",
    "user_id[user_id == b'37'] = b'21'\n",
    "user_id[user_id == b'38'] = b'22'\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Creating Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 1 Âµs, total: 3 Âµs\n",
      "Wall time: 5.48 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "label = []\n",
    "for i in range(42):\n",
    "    for j in range(51):\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == 0) * 2142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Input Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 71)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanzhol/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[51].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the dataset into the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 71)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.6000000000001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, train_test_split splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "#model.add(Dense(units = 10, \n",
    "                #activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 10, \n",
    "                activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "model.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 10)                720       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 42)                462       \n",
      "=================================================================\n",
      "Total params: 1,292\n",
      "Trainable params: 1,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.3, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       Congratulations for myself, I have build my first Deep Learning Neural Network model using Keras with understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "#                              #verbose=1, \n",
    "#                              monitor='val_acc',\n",
    "#                              save_best_only=True, \n",
    "#                              mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', \n",
    "                   mode = 'auto', \n",
    "                   patience=50, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 0 ns, total: 4 Âµs\n",
      "Wall time: 8.11 Âµs\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/1500\n",
      " - 0s - loss: 3.7513 - acc: 0.0124 - val_loss: 3.7343 - val_acc: 0.0204\n",
      "Epoch 2/1500\n",
      " - 0s - loss: 3.7332 - acc: 0.0365 - val_loss: 3.7248 - val_acc: 0.0408\n",
      "Epoch 3/1500\n",
      " - 0s - loss: 3.7216 - acc: 0.0489 - val_loss: 3.7169 - val_acc: 0.0437\n",
      "Epoch 4/1500\n",
      " - 0s - loss: 3.7102 - acc: 0.0584 - val_loss: 3.7074 - val_acc: 0.0641\n",
      "Epoch 5/1500\n",
      " - 0s - loss: 3.6980 - acc: 0.0752 - val_loss: 3.6964 - val_acc: 0.0758\n",
      "Epoch 6/1500\n",
      " - 0s - loss: 3.6833 - acc: 0.0759 - val_loss: 3.6812 - val_acc: 0.0787\n",
      "Epoch 7/1500\n",
      " - 0s - loss: 3.6666 - acc: 0.0788 - val_loss: 3.6639 - val_acc: 0.0787\n",
      "Epoch 8/1500\n",
      " - 0s - loss: 3.6459 - acc: 0.0810 - val_loss: 3.6423 - val_acc: 0.0758\n",
      "Epoch 9/1500\n",
      " - 0s - loss: 3.6219 - acc: 0.0832 - val_loss: 3.6186 - val_acc: 0.0700\n",
      "Epoch 10/1500\n",
      " - 0s - loss: 3.5908 - acc: 0.0861 - val_loss: 3.5826 - val_acc: 0.1020\n",
      "Epoch 11/1500\n",
      " - 0s - loss: 3.5564 - acc: 0.1109 - val_loss: 3.5456 - val_acc: 0.1137\n",
      "Epoch 12/1500\n",
      " - 0s - loss: 3.5155 - acc: 0.1109 - val_loss: 3.5039 - val_acc: 0.1137\n",
      "Epoch 13/1500\n",
      " - 0s - loss: 3.4702 - acc: 0.1212 - val_loss: 3.4538 - val_acc: 0.1137\n",
      "Epoch 14/1500\n",
      " - 0s - loss: 3.4200 - acc: 0.1263 - val_loss: 3.4004 - val_acc: 0.1166\n",
      "Epoch 15/1500\n",
      " - 0s - loss: 3.3661 - acc: 0.1409 - val_loss: 3.3453 - val_acc: 0.1166\n",
      "Epoch 16/1500\n",
      " - 0s - loss: 3.3096 - acc: 0.1372 - val_loss: 3.2868 - val_acc: 0.1254\n",
      "Epoch 17/1500\n",
      " - 0s - loss: 3.2518 - acc: 0.1496 - val_loss: 3.2268 - val_acc: 0.1312\n",
      "Epoch 18/1500\n",
      " - 0s - loss: 3.1904 - acc: 0.1657 - val_loss: 3.1650 - val_acc: 0.1545\n",
      "Epoch 19/1500\n",
      " - 0s - loss: 3.1298 - acc: 0.1854 - val_loss: 3.1015 - val_acc: 0.1837\n",
      "Epoch 20/1500\n",
      " - 0s - loss: 3.0682 - acc: 0.2044 - val_loss: 3.0424 - val_acc: 0.1837\n",
      "Epoch 21/1500\n",
      " - 0s - loss: 3.0071 - acc: 0.2102 - val_loss: 2.9783 - val_acc: 0.2012\n",
      "Epoch 22/1500\n",
      " - 0s - loss: 2.9472 - acc: 0.2307 - val_loss: 2.9210 - val_acc: 0.2128\n",
      "Epoch 23/1500\n",
      " - 0s - loss: 2.8878 - acc: 0.2467 - val_loss: 2.8598 - val_acc: 0.2332\n",
      "Epoch 24/1500\n",
      " - 0s - loss: 2.8308 - acc: 0.2628 - val_loss: 2.8033 - val_acc: 0.2536\n",
      "Epoch 25/1500\n",
      " - 0s - loss: 2.7763 - acc: 0.2693 - val_loss: 2.7507 - val_acc: 0.2478\n",
      "Epoch 26/1500\n",
      " - 0s - loss: 2.7241 - acc: 0.2905 - val_loss: 2.6991 - val_acc: 0.2799\n",
      "Epoch 27/1500\n",
      " - 0s - loss: 2.6737 - acc: 0.2920 - val_loss: 2.6512 - val_acc: 0.2828\n",
      "Epoch 28/1500\n",
      " - 0s - loss: 2.6270 - acc: 0.2949 - val_loss: 2.6027 - val_acc: 0.3003\n",
      "Epoch 29/1500\n",
      " - 0s - loss: 2.5832 - acc: 0.3073 - val_loss: 2.5596 - val_acc: 0.3061\n",
      "Epoch 30/1500\n",
      " - 0s - loss: 2.5409 - acc: 0.3044 - val_loss: 2.5202 - val_acc: 0.3120\n",
      "Epoch 31/1500\n",
      " - 0s - loss: 2.5009 - acc: 0.3073 - val_loss: 2.4838 - val_acc: 0.3178\n",
      "Epoch 32/1500\n",
      " - 0s - loss: 2.4632 - acc: 0.3139 - val_loss: 2.4451 - val_acc: 0.3265\n",
      "Epoch 33/1500\n",
      " - 0s - loss: 2.4280 - acc: 0.3190 - val_loss: 2.4133 - val_acc: 0.3294\n",
      "Epoch 34/1500\n",
      " - 0s - loss: 2.3944 - acc: 0.3292 - val_loss: 2.3809 - val_acc: 0.3528\n",
      "Epoch 35/1500\n",
      " - 0s - loss: 2.3625 - acc: 0.3292 - val_loss: 2.3481 - val_acc: 0.3528\n",
      "Epoch 36/1500\n",
      " - 0s - loss: 2.3314 - acc: 0.3372 - val_loss: 2.3193 - val_acc: 0.3615\n",
      "Epoch 37/1500\n",
      " - 0s - loss: 2.3022 - acc: 0.3445 - val_loss: 2.2906 - val_acc: 0.3790\n",
      "Epoch 38/1500\n",
      " - 0s - loss: 2.2739 - acc: 0.3533 - val_loss: 2.2672 - val_acc: 0.3644\n",
      "Epoch 39/1500\n",
      " - 0s - loss: 2.2478 - acc: 0.3642 - val_loss: 2.2395 - val_acc: 0.3615\n",
      "Epoch 40/1500\n",
      " - 0s - loss: 2.2217 - acc: 0.3693 - val_loss: 2.2198 - val_acc: 0.3848\n",
      "Epoch 41/1500\n",
      " - 0s - loss: 2.1970 - acc: 0.3759 - val_loss: 2.1937 - val_acc: 0.4052\n",
      "Epoch 42/1500\n",
      " - 0s - loss: 2.1729 - acc: 0.3832 - val_loss: 2.1727 - val_acc: 0.3907\n",
      "Epoch 43/1500\n",
      " - 0s - loss: 2.1499 - acc: 0.3956 - val_loss: 2.1501 - val_acc: 0.4169\n",
      "Epoch 44/1500\n",
      " - 0s - loss: 2.1276 - acc: 0.3964 - val_loss: 2.1275 - val_acc: 0.4111\n",
      "Epoch 45/1500\n",
      " - 0s - loss: 2.1062 - acc: 0.4022 - val_loss: 2.1105 - val_acc: 0.4140\n",
      "Epoch 46/1500\n",
      " - 0s - loss: 2.0850 - acc: 0.4131 - val_loss: 2.0919 - val_acc: 0.4169\n",
      "Epoch 47/1500\n",
      " - 0s - loss: 2.0647 - acc: 0.4175 - val_loss: 2.0711 - val_acc: 0.4198\n",
      "Epoch 48/1500\n",
      " - 0s - loss: 2.0461 - acc: 0.4190 - val_loss: 2.0562 - val_acc: 0.4140\n",
      "Epoch 49/1500\n",
      " - 0s - loss: 2.0257 - acc: 0.4204 - val_loss: 2.0396 - val_acc: 0.4257\n",
      "Epoch 50/1500\n",
      " - 0s - loss: 2.0066 - acc: 0.4299 - val_loss: 2.0193 - val_acc: 0.4286\n",
      "Epoch 51/1500\n",
      " - 0s - loss: 1.9888 - acc: 0.4343 - val_loss: 2.0044 - val_acc: 0.4111\n",
      "Epoch 52/1500\n",
      " - 0s - loss: 1.9710 - acc: 0.4387 - val_loss: 1.9864 - val_acc: 0.4286\n",
      "Epoch 53/1500\n",
      " - 0s - loss: 1.9535 - acc: 0.4489 - val_loss: 1.9726 - val_acc: 0.4344\n",
      "Epoch 54/1500\n",
      " - 0s - loss: 1.9366 - acc: 0.4540 - val_loss: 1.9599 - val_acc: 0.4490\n",
      "Epoch 55/1500\n",
      " - 0s - loss: 1.9210 - acc: 0.4562 - val_loss: 1.9449 - val_acc: 0.4402\n",
      "Epoch 56/1500\n",
      " - 0s - loss: 1.9037 - acc: 0.4679 - val_loss: 1.9277 - val_acc: 0.4577\n",
      "Epoch 57/1500\n",
      " - 0s - loss: 1.8882 - acc: 0.4715 - val_loss: 1.9143 - val_acc: 0.4694\n",
      "Epoch 58/1500\n",
      " - 0s - loss: 1.8753 - acc: 0.4708 - val_loss: 1.9006 - val_acc: 0.4636\n",
      "Epoch 59/1500\n",
      " - 0s - loss: 1.8579 - acc: 0.4803 - val_loss: 1.8885 - val_acc: 0.4752\n",
      "Epoch 60/1500\n",
      " - 0s - loss: 1.8433 - acc: 0.4876 - val_loss: 1.8755 - val_acc: 0.4752\n",
      "Epoch 61/1500\n",
      " - 0s - loss: 1.8291 - acc: 0.4869 - val_loss: 1.8626 - val_acc: 0.4781\n",
      "Epoch 62/1500\n",
      " - 0s - loss: 1.8164 - acc: 0.4905 - val_loss: 1.8491 - val_acc: 0.4927\n",
      "Epoch 63/1500\n",
      " - 0s - loss: 1.8014 - acc: 0.4993 - val_loss: 1.8379 - val_acc: 0.4927\n",
      "Epoch 64/1500\n",
      " - 0s - loss: 1.7880 - acc: 0.4993 - val_loss: 1.8280 - val_acc: 0.4869\n",
      "Epoch 65/1500\n",
      " - 0s - loss: 1.7738 - acc: 0.5088 - val_loss: 1.8153 - val_acc: 0.5219\n",
      "Epoch 66/1500\n",
      " - 0s - loss: 1.7605 - acc: 0.5102 - val_loss: 1.8050 - val_acc: 0.4810\n",
      "Epoch 67/1500\n",
      " - 0s - loss: 1.7481 - acc: 0.5139 - val_loss: 1.7908 - val_acc: 0.5015\n",
      "Epoch 68/1500\n",
      " - 0s - loss: 1.7356 - acc: 0.5175 - val_loss: 1.7859 - val_acc: 0.4869\n",
      "Epoch 69/1500\n",
      " - 0s - loss: 1.7233 - acc: 0.5109 - val_loss: 1.7705 - val_acc: 0.5015\n",
      "Epoch 70/1500\n",
      " - 0s - loss: 1.7102 - acc: 0.5212 - val_loss: 1.7614 - val_acc: 0.5044\n",
      "Epoch 71/1500\n",
      " - 0s - loss: 1.6984 - acc: 0.5307 - val_loss: 1.7520 - val_acc: 0.4985\n",
      "Epoch 72/1500\n",
      " - 0s - loss: 1.6883 - acc: 0.5336 - val_loss: 1.7417 - val_acc: 0.4869\n",
      "Epoch 73/1500\n",
      " - 0s - loss: 1.6764 - acc: 0.5416 - val_loss: 1.7311 - val_acc: 0.5073\n",
      "Epoch 74/1500\n",
      " - 0s - loss: 1.6647 - acc: 0.5423 - val_loss: 1.7201 - val_acc: 0.5160\n",
      "Epoch 75/1500\n",
      " - 0s - loss: 1.6535 - acc: 0.5489 - val_loss: 1.7096 - val_acc: 0.5306\n",
      "Epoch 76/1500\n",
      " - 0s - loss: 1.6417 - acc: 0.5474 - val_loss: 1.7029 - val_acc: 0.5160\n",
      "Epoch 77/1500\n",
      " - 0s - loss: 1.6340 - acc: 0.5504 - val_loss: 1.6911 - val_acc: 0.5306\n",
      "Epoch 78/1500\n",
      " - 0s - loss: 1.6210 - acc: 0.5584 - val_loss: 1.6817 - val_acc: 0.5335\n",
      "Epoch 79/1500\n",
      " - 0s - loss: 1.6102 - acc: 0.5650 - val_loss: 1.6758 - val_acc: 0.5248\n",
      "Epoch 80/1500\n",
      " - 0s - loss: 1.6018 - acc: 0.5562 - val_loss: 1.6667 - val_acc: 0.5306\n",
      "Epoch 81/1500\n",
      " - 0s - loss: 1.5920 - acc: 0.5635 - val_loss: 1.6578 - val_acc: 0.5423\n",
      "Epoch 82/1500\n",
      " - 0s - loss: 1.5813 - acc: 0.5730 - val_loss: 1.6483 - val_acc: 0.5364\n",
      "Epoch 83/1500\n",
      " - 0s - loss: 1.5719 - acc: 0.5781 - val_loss: 1.6399 - val_acc: 0.5569\n",
      "Epoch 84/1500\n",
      " - 0s - loss: 1.5621 - acc: 0.5818 - val_loss: 1.6348 - val_acc: 0.5423\n",
      "Epoch 85/1500\n",
      " - 0s - loss: 1.5527 - acc: 0.5861 - val_loss: 1.6242 - val_acc: 0.5598\n",
      "Epoch 86/1500\n",
      " - 0s - loss: 1.5438 - acc: 0.5825 - val_loss: 1.6162 - val_acc: 0.5539\n",
      "Epoch 87/1500\n",
      " - 0s - loss: 1.5348 - acc: 0.5854 - val_loss: 1.6108 - val_acc: 0.5510\n",
      "Epoch 88/1500\n",
      " - 0s - loss: 1.5259 - acc: 0.5883 - val_loss: 1.6012 - val_acc: 0.5627\n",
      "Epoch 89/1500\n",
      " - 0s - loss: 1.5168 - acc: 0.5891 - val_loss: 1.5932 - val_acc: 0.5627\n",
      "Epoch 90/1500\n",
      " - 0s - loss: 1.5080 - acc: 0.5971 - val_loss: 1.5887 - val_acc: 0.5481\n",
      "Epoch 91/1500\n",
      " - 0s - loss: 1.5007 - acc: 0.5912 - val_loss: 1.5808 - val_acc: 0.5743\n",
      "Epoch 92/1500\n",
      " - 0s - loss: 1.4923 - acc: 0.5971 - val_loss: 1.5715 - val_acc: 0.5656\n",
      "Epoch 93/1500\n",
      " - 0s - loss: 1.4843 - acc: 0.6015 - val_loss: 1.5666 - val_acc: 0.5627\n",
      "Epoch 94/1500\n",
      " - 0s - loss: 1.4766 - acc: 0.6029 - val_loss: 1.5620 - val_acc: 0.5714\n",
      "Epoch 95/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.4694 - acc: 0.6036 - val_loss: 1.5526 - val_acc: 0.5743\n",
      "Epoch 96/1500\n",
      " - 0s - loss: 1.4633 - acc: 0.6058 - val_loss: 1.5464 - val_acc: 0.5685\n",
      "Epoch 97/1500\n",
      " - 0s - loss: 1.4554 - acc: 0.6029 - val_loss: 1.5410 - val_acc: 0.5714\n",
      "Epoch 98/1500\n",
      " - 0s - loss: 1.4459 - acc: 0.6051 - val_loss: 1.5329 - val_acc: 0.5714\n",
      "Epoch 99/1500\n",
      " - 0s - loss: 1.4402 - acc: 0.6102 - val_loss: 1.5267 - val_acc: 0.5685\n",
      "Epoch 100/1500\n",
      " - 0s - loss: 1.4315 - acc: 0.6080 - val_loss: 1.5195 - val_acc: 0.5773\n",
      "Epoch 101/1500\n",
      " - 0s - loss: 1.4230 - acc: 0.6095 - val_loss: 1.5135 - val_acc: 0.5714\n",
      "Epoch 102/1500\n",
      " - 0s - loss: 1.4162 - acc: 0.6146 - val_loss: 1.5086 - val_acc: 0.5773\n",
      "Epoch 103/1500\n",
      " - 0s - loss: 1.4099 - acc: 0.6168 - val_loss: 1.5033 - val_acc: 0.5743\n",
      "Epoch 104/1500\n",
      " - 0s - loss: 1.4040 - acc: 0.6212 - val_loss: 1.4966 - val_acc: 0.5773\n",
      "Epoch 105/1500\n",
      " - 0s - loss: 1.3976 - acc: 0.6182 - val_loss: 1.4923 - val_acc: 0.5685\n",
      "Epoch 106/1500\n",
      " - 0s - loss: 1.3907 - acc: 0.6219 - val_loss: 1.4858 - val_acc: 0.5714\n",
      "Epoch 107/1500\n",
      " - 0s - loss: 1.3831 - acc: 0.6219 - val_loss: 1.4800 - val_acc: 0.5714\n",
      "Epoch 108/1500\n",
      " - 0s - loss: 1.3785 - acc: 0.6234 - val_loss: 1.4758 - val_acc: 0.5773\n",
      "Epoch 109/1500\n",
      " - 0s - loss: 1.3731 - acc: 0.6270 - val_loss: 1.4712 - val_acc: 0.5773\n",
      "Epoch 110/1500\n",
      " - 0s - loss: 1.3651 - acc: 0.6226 - val_loss: 1.4659 - val_acc: 0.5743\n",
      "Epoch 111/1500\n",
      " - 0s - loss: 1.3582 - acc: 0.6307 - val_loss: 1.4599 - val_acc: 0.5743\n",
      "Epoch 112/1500\n",
      " - 0s - loss: 1.3523 - acc: 0.6350 - val_loss: 1.4559 - val_acc: 0.5773\n",
      "Epoch 113/1500\n",
      " - 0s - loss: 1.3462 - acc: 0.6328 - val_loss: 1.4507 - val_acc: 0.5773\n",
      "Epoch 114/1500\n",
      " - 0s - loss: 1.3411 - acc: 0.6343 - val_loss: 1.4449 - val_acc: 0.5773\n",
      "Epoch 115/1500\n",
      " - 0s - loss: 1.3351 - acc: 0.6292 - val_loss: 1.4402 - val_acc: 0.5802\n",
      "Epoch 116/1500\n",
      " - 0s - loss: 1.3314 - acc: 0.6314 - val_loss: 1.4356 - val_acc: 0.5802\n",
      "Epoch 117/1500\n",
      " - 0s - loss: 1.3249 - acc: 0.6299 - val_loss: 1.4317 - val_acc: 0.5860\n",
      "Epoch 118/1500\n",
      " - 0s - loss: 1.3179 - acc: 0.6365 - val_loss: 1.4262 - val_acc: 0.5860\n",
      "Epoch 119/1500\n",
      " - 0s - loss: 1.3145 - acc: 0.6365 - val_loss: 1.4209 - val_acc: 0.5948\n",
      "Epoch 120/1500\n",
      " - 0s - loss: 1.3087 - acc: 0.6394 - val_loss: 1.4168 - val_acc: 0.5860\n",
      "Epoch 121/1500\n",
      " - 0s - loss: 1.3045 - acc: 0.6372 - val_loss: 1.4137 - val_acc: 0.5889\n",
      "Epoch 122/1500\n",
      " - 0s - loss: 1.2981 - acc: 0.6380 - val_loss: 1.4075 - val_acc: 0.5889\n",
      "Epoch 123/1500\n",
      " - 0s - loss: 1.2909 - acc: 0.6445 - val_loss: 1.4031 - val_acc: 0.5860\n",
      "Epoch 124/1500\n",
      " - 0s - loss: 1.2863 - acc: 0.6482 - val_loss: 1.3991 - val_acc: 0.5977\n",
      "Epoch 125/1500\n",
      " - 0s - loss: 1.2825 - acc: 0.6460 - val_loss: 1.3942 - val_acc: 0.5889\n",
      "Epoch 126/1500\n",
      " - 0s - loss: 1.2787 - acc: 0.6401 - val_loss: 1.3901 - val_acc: 0.6006\n",
      "Epoch 127/1500\n",
      " - 0s - loss: 1.2731 - acc: 0.6394 - val_loss: 1.3879 - val_acc: 0.5977\n",
      "Epoch 128/1500\n",
      " - 0s - loss: 1.2699 - acc: 0.6453 - val_loss: 1.3825 - val_acc: 0.5977\n",
      "Epoch 129/1500\n",
      " - 0s - loss: 1.2641 - acc: 0.6504 - val_loss: 1.3784 - val_acc: 0.6006\n",
      "Epoch 130/1500\n",
      " - 0s - loss: 1.2574 - acc: 0.6474 - val_loss: 1.3743 - val_acc: 0.6006\n",
      "Epoch 131/1500\n",
      " - 0s - loss: 1.2529 - acc: 0.6526 - val_loss: 1.3704 - val_acc: 0.6064\n",
      "Epoch 132/1500\n",
      " - 0s - loss: 1.2488 - acc: 0.6569 - val_loss: 1.3674 - val_acc: 0.6035\n",
      "Epoch 133/1500\n",
      " - 0s - loss: 1.2436 - acc: 0.6547 - val_loss: 1.3628 - val_acc: 0.6093\n",
      "Epoch 134/1500\n",
      " - 0s - loss: 1.2392 - acc: 0.6533 - val_loss: 1.3602 - val_acc: 0.6122\n",
      "Epoch 135/1500\n",
      " - 0s - loss: 1.2354 - acc: 0.6526 - val_loss: 1.3561 - val_acc: 0.6093\n",
      "Epoch 136/1500\n",
      " - 0s - loss: 1.2313 - acc: 0.6620 - val_loss: 1.3516 - val_acc: 0.6093\n",
      "Epoch 137/1500\n",
      " - 0s - loss: 1.2257 - acc: 0.6584 - val_loss: 1.3484 - val_acc: 0.6152\n",
      "Epoch 138/1500\n",
      " - 0s - loss: 1.2242 - acc: 0.6591 - val_loss: 1.3464 - val_acc: 0.5977\n",
      "Epoch 139/1500\n",
      " - 0s - loss: 1.2183 - acc: 0.6635 - val_loss: 1.3409 - val_acc: 0.6122\n",
      "Epoch 140/1500\n",
      " - 0s - loss: 1.2137 - acc: 0.6642 - val_loss: 1.3386 - val_acc: 0.6122\n",
      "Epoch 141/1500\n",
      " - 0s - loss: 1.2103 - acc: 0.6599 - val_loss: 1.3343 - val_acc: 0.6122\n",
      "Epoch 142/1500\n",
      " - 0s - loss: 1.2052 - acc: 0.6657 - val_loss: 1.3308 - val_acc: 0.6239\n",
      "Epoch 143/1500\n",
      " - 0s - loss: 1.2021 - acc: 0.6686 - val_loss: 1.3278 - val_acc: 0.6152\n",
      "Epoch 144/1500\n",
      " - 0s - loss: 1.1974 - acc: 0.6693 - val_loss: 1.3253 - val_acc: 0.6210\n",
      "Epoch 145/1500\n",
      " - 0s - loss: 1.1924 - acc: 0.6715 - val_loss: 1.3210 - val_acc: 0.6181\n",
      "Epoch 146/1500\n",
      " - 0s - loss: 1.1897 - acc: 0.6628 - val_loss: 1.3184 - val_acc: 0.6297\n",
      "Epoch 147/1500\n",
      " - 0s - loss: 1.1851 - acc: 0.6686 - val_loss: 1.3141 - val_acc: 0.6152\n",
      "Epoch 148/1500\n",
      " - 0s - loss: 1.1806 - acc: 0.6730 - val_loss: 1.3127 - val_acc: 0.6210\n",
      "Epoch 149/1500\n",
      " - 0s - loss: 1.1788 - acc: 0.6715 - val_loss: 1.3090 - val_acc: 0.6122\n",
      "Epoch 150/1500\n",
      " - 0s - loss: 1.1734 - acc: 0.6774 - val_loss: 1.3050 - val_acc: 0.6181\n",
      "Epoch 151/1500\n",
      " - 0s - loss: 1.1702 - acc: 0.6766 - val_loss: 1.3028 - val_acc: 0.6210\n",
      "Epoch 152/1500\n",
      " - 0s - loss: 1.1658 - acc: 0.6774 - val_loss: 1.2999 - val_acc: 0.6327\n",
      "Epoch 153/1500\n",
      " - 0s - loss: 1.1623 - acc: 0.6730 - val_loss: 1.2970 - val_acc: 0.6268\n",
      "Epoch 154/1500\n",
      " - 0s - loss: 1.1584 - acc: 0.6745 - val_loss: 1.2935 - val_acc: 0.6181\n",
      "Epoch 155/1500\n",
      " - 0s - loss: 1.1550 - acc: 0.6788 - val_loss: 1.2900 - val_acc: 0.6268\n",
      "Epoch 156/1500\n",
      " - 0s - loss: 1.1532 - acc: 0.6788 - val_loss: 1.2881 - val_acc: 0.6297\n",
      "Epoch 157/1500\n",
      " - 0s - loss: 1.1477 - acc: 0.6803 - val_loss: 1.2856 - val_acc: 0.6297\n",
      "Epoch 158/1500\n",
      " - 0s - loss: 1.1449 - acc: 0.6781 - val_loss: 1.2820 - val_acc: 0.6297\n",
      "Epoch 159/1500\n",
      " - 0s - loss: 1.1411 - acc: 0.6781 - val_loss: 1.2811 - val_acc: 0.6327\n",
      "Epoch 160/1500\n",
      " - 0s - loss: 1.1378 - acc: 0.6876 - val_loss: 1.2776 - val_acc: 0.6327\n",
      "Epoch 161/1500\n",
      " - 0s - loss: 1.1349 - acc: 0.6854 - val_loss: 1.2746 - val_acc: 0.6297\n",
      "Epoch 162/1500\n",
      " - 0s - loss: 1.1304 - acc: 0.6825 - val_loss: 1.2717 - val_acc: 0.6327\n",
      "Epoch 163/1500\n",
      " - 0s - loss: 1.1274 - acc: 0.6912 - val_loss: 1.2685 - val_acc: 0.6297\n",
      "Epoch 164/1500\n",
      " - 0s - loss: 1.1251 - acc: 0.6832 - val_loss: 1.2662 - val_acc: 0.6239\n",
      "Epoch 165/1500\n",
      " - 0s - loss: 1.1225 - acc: 0.6847 - val_loss: 1.2643 - val_acc: 0.6297\n",
      "Epoch 166/1500\n",
      " - 0s - loss: 1.1177 - acc: 0.6847 - val_loss: 1.2646 - val_acc: 0.6327\n",
      "Epoch 167/1500\n",
      " - 0s - loss: 1.1148 - acc: 0.6847 - val_loss: 1.2571 - val_acc: 0.6472\n",
      "Epoch 168/1500\n",
      " - 0s - loss: 1.1119 - acc: 0.6876 - val_loss: 1.2552 - val_acc: 0.6443\n",
      "Epoch 169/1500\n",
      " - 0s - loss: 1.1073 - acc: 0.6905 - val_loss: 1.2534 - val_acc: 0.6268\n",
      "Epoch 170/1500\n",
      " - 0s - loss: 1.1042 - acc: 0.6949 - val_loss: 1.2505 - val_acc: 0.6531\n",
      "Epoch 171/1500\n",
      " - 0s - loss: 1.1005 - acc: 0.6964 - val_loss: 1.2474 - val_acc: 0.6385\n",
      "Epoch 172/1500\n",
      " - 0s - loss: 1.0984 - acc: 0.6934 - val_loss: 1.2456 - val_acc: 0.6472\n",
      "Epoch 173/1500\n",
      " - 0s - loss: 1.0955 - acc: 0.6920 - val_loss: 1.2447 - val_acc: 0.6472\n",
      "Epoch 174/1500\n",
      " - 0s - loss: 1.0914 - acc: 0.6964 - val_loss: 1.2428 - val_acc: 0.6239\n",
      "Epoch 175/1500\n",
      " - 0s - loss: 1.0913 - acc: 0.6956 - val_loss: 1.2397 - val_acc: 0.6531\n",
      "Epoch 176/1500\n",
      " - 0s - loss: 1.0858 - acc: 0.6949 - val_loss: 1.2355 - val_acc: 0.6472\n",
      "Epoch 177/1500\n",
      " - 0s - loss: 1.0838 - acc: 0.7007 - val_loss: 1.2330 - val_acc: 0.6414\n",
      "Epoch 178/1500\n",
      " - 0s - loss: 1.0812 - acc: 0.6956 - val_loss: 1.2327 - val_acc: 0.6385\n",
      "Epoch 179/1500\n",
      " - 0s - loss: 1.0772 - acc: 0.6993 - val_loss: 1.2289 - val_acc: 0.6385\n",
      "Epoch 180/1500\n",
      " - 0s - loss: 1.0739 - acc: 0.7036 - val_loss: 1.2282 - val_acc: 0.6501\n",
      "Epoch 181/1500\n",
      " - 0s - loss: 1.0717 - acc: 0.6993 - val_loss: 1.2243 - val_acc: 0.6414\n",
      "Epoch 182/1500\n",
      " - 0s - loss: 1.0685 - acc: 0.7058 - val_loss: 1.2223 - val_acc: 0.6385\n",
      "Epoch 183/1500\n",
      " - 0s - loss: 1.0650 - acc: 0.7000 - val_loss: 1.2211 - val_acc: 0.6472\n",
      "Epoch 184/1500\n",
      " - 0s - loss: 1.0630 - acc: 0.6964 - val_loss: 1.2187 - val_acc: 0.6443\n",
      "Epoch 185/1500\n",
      " - 0s - loss: 1.0608 - acc: 0.7051 - val_loss: 1.2154 - val_acc: 0.6443\n",
      "Epoch 186/1500\n",
      " - 0s - loss: 1.0570 - acc: 0.7000 - val_loss: 1.2151 - val_acc: 0.6472\n",
      "Epoch 187/1500\n",
      " - 0s - loss: 1.0569 - acc: 0.6985 - val_loss: 1.2138 - val_acc: 0.6327\n",
      "Epoch 188/1500\n",
      " - 0s - loss: 1.0524 - acc: 0.7066 - val_loss: 1.2102 - val_acc: 0.6472\n",
      "Epoch 189/1500\n",
      " - 0s - loss: 1.0478 - acc: 0.7029 - val_loss: 1.2077 - val_acc: 0.6472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1500\n",
      " - 0s - loss: 1.0454 - acc: 0.7051 - val_loss: 1.2068 - val_acc: 0.6501\n",
      "Epoch 191/1500\n",
      " - 0s - loss: 1.0439 - acc: 0.7058 - val_loss: 1.2039 - val_acc: 0.6472\n",
      "Epoch 192/1500\n",
      " - 0s - loss: 1.0435 - acc: 0.7029 - val_loss: 1.2021 - val_acc: 0.6531\n",
      "Epoch 193/1500\n",
      " - 0s - loss: 1.0367 - acc: 0.7029 - val_loss: 1.1997 - val_acc: 0.6414\n",
      "Epoch 194/1500\n",
      " - 0s - loss: 1.0355 - acc: 0.7066 - val_loss: 1.1986 - val_acc: 0.6501\n",
      "Epoch 195/1500\n",
      " - 0s - loss: 1.0316 - acc: 0.7088 - val_loss: 1.1959 - val_acc: 0.6443\n",
      "Epoch 196/1500\n",
      " - 0s - loss: 1.0290 - acc: 0.7131 - val_loss: 1.1937 - val_acc: 0.6501\n",
      "Epoch 197/1500\n",
      " - 0s - loss: 1.0260 - acc: 0.7139 - val_loss: 1.1930 - val_acc: 0.6472\n",
      "Epoch 198/1500\n",
      " - 0s - loss: 1.0249 - acc: 0.7088 - val_loss: 1.1912 - val_acc: 0.6589\n",
      "Epoch 199/1500\n",
      " - 0s - loss: 1.0224 - acc: 0.7109 - val_loss: 1.1871 - val_acc: 0.6560\n",
      "Epoch 200/1500\n",
      " - 0s - loss: 1.0204 - acc: 0.7095 - val_loss: 1.1866 - val_acc: 0.6676\n",
      "Epoch 201/1500\n",
      " - 0s - loss: 1.0215 - acc: 0.7051 - val_loss: 1.1877 - val_acc: 0.6618\n",
      "Epoch 202/1500\n",
      " - 0s - loss: 1.0150 - acc: 0.7131 - val_loss: 1.1842 - val_acc: 0.6443\n",
      "Epoch 203/1500\n",
      " - 0s - loss: 1.0113 - acc: 0.7168 - val_loss: 1.1810 - val_acc: 0.6560\n",
      "Epoch 204/1500\n",
      " - 0s - loss: 1.0087 - acc: 0.7153 - val_loss: 1.1779 - val_acc: 0.6560\n",
      "Epoch 205/1500\n",
      " - 0s - loss: 1.0057 - acc: 0.7168 - val_loss: 1.1763 - val_acc: 0.6589\n",
      "Epoch 206/1500\n",
      " - 0s - loss: 1.0044 - acc: 0.7182 - val_loss: 1.1742 - val_acc: 0.6618\n",
      "Epoch 207/1500\n",
      " - 0s - loss: 1.0011 - acc: 0.7175 - val_loss: 1.1738 - val_acc: 0.6618\n",
      "Epoch 208/1500\n",
      " - 0s - loss: 0.9979 - acc: 0.7190 - val_loss: 1.1714 - val_acc: 0.6589\n",
      "Epoch 209/1500\n",
      " - 0s - loss: 0.9957 - acc: 0.7175 - val_loss: 1.1715 - val_acc: 0.6560\n",
      "Epoch 210/1500\n",
      " - 0s - loss: 0.9924 - acc: 0.7182 - val_loss: 1.1689 - val_acc: 0.6531\n",
      "Epoch 211/1500\n",
      " - 0s - loss: 0.9921 - acc: 0.7175 - val_loss: 1.1690 - val_acc: 0.6676\n",
      "Epoch 212/1500\n",
      " - 0s - loss: 0.9897 - acc: 0.7175 - val_loss: 1.1643 - val_acc: 0.6589\n",
      "Epoch 213/1500\n",
      " - 0s - loss: 0.9870 - acc: 0.7219 - val_loss: 1.1626 - val_acc: 0.6560\n",
      "Epoch 214/1500\n",
      " - 0s - loss: 0.9842 - acc: 0.7182 - val_loss: 1.1629 - val_acc: 0.6618\n",
      "Epoch 215/1500\n",
      " - 0s - loss: 0.9834 - acc: 0.7197 - val_loss: 1.1608 - val_acc: 0.6414\n",
      "Epoch 216/1500\n",
      " - 0s - loss: 0.9792 - acc: 0.7234 - val_loss: 1.1583 - val_acc: 0.6676\n",
      "Epoch 217/1500\n",
      " - 0s - loss: 0.9778 - acc: 0.7219 - val_loss: 1.1569 - val_acc: 0.6560\n",
      "Epoch 218/1500\n",
      " - 0s - loss: 0.9743 - acc: 0.7292 - val_loss: 1.1543 - val_acc: 0.6589\n",
      "Epoch 219/1500\n",
      " - 0s - loss: 0.9727 - acc: 0.7226 - val_loss: 1.1532 - val_acc: 0.6647\n",
      "Epoch 220/1500\n",
      " - 0s - loss: 0.9696 - acc: 0.7204 - val_loss: 1.1521 - val_acc: 0.6501\n",
      "Epoch 221/1500\n",
      " - 0s - loss: 0.9689 - acc: 0.7241 - val_loss: 1.1506 - val_acc: 0.6618\n",
      "Epoch 222/1500\n",
      " - 0s - loss: 0.9650 - acc: 0.7285 - val_loss: 1.1488 - val_acc: 0.6618\n",
      "Epoch 223/1500\n",
      " - 0s - loss: 0.9626 - acc: 0.7255 - val_loss: 1.1461 - val_acc: 0.6676\n",
      "Epoch 224/1500\n",
      " - 0s - loss: 0.9597 - acc: 0.7263 - val_loss: 1.1486 - val_acc: 0.6531\n",
      "Epoch 225/1500\n",
      " - 0s - loss: 0.9581 - acc: 0.7314 - val_loss: 1.1457 - val_acc: 0.6531\n",
      "Epoch 226/1500\n",
      " - 0s - loss: 0.9563 - acc: 0.7314 - val_loss: 1.1430 - val_acc: 0.6618\n",
      "Epoch 227/1500\n",
      " - 0s - loss: 0.9535 - acc: 0.7285 - val_loss: 1.1403 - val_acc: 0.6706\n",
      "Epoch 228/1500\n",
      " - 0s - loss: 0.9521 - acc: 0.7277 - val_loss: 1.1391 - val_acc: 0.6618\n",
      "Epoch 229/1500\n",
      " - 0s - loss: 0.9508 - acc: 0.7314 - val_loss: 1.1392 - val_acc: 0.6618\n",
      "Epoch 230/1500\n",
      " - 0s - loss: 0.9508 - acc: 0.7285 - val_loss: 1.1378 - val_acc: 0.6706\n",
      "Epoch 231/1500\n",
      " - 0s - loss: 0.9454 - acc: 0.7350 - val_loss: 1.1350 - val_acc: 0.6706\n",
      "Epoch 232/1500\n",
      " - 0s - loss: 0.9432 - acc: 0.7321 - val_loss: 1.1340 - val_acc: 0.6589\n",
      "Epoch 233/1500\n",
      " - 0s - loss: 0.9397 - acc: 0.7372 - val_loss: 1.1310 - val_acc: 0.6647\n",
      "Epoch 234/1500\n",
      " - 0s - loss: 0.9376 - acc: 0.7350 - val_loss: 1.1315 - val_acc: 0.6531\n",
      "Epoch 235/1500\n",
      " - 0s - loss: 0.9366 - acc: 0.7365 - val_loss: 1.1298 - val_acc: 0.6706\n",
      "Epoch 236/1500\n",
      " - 0s - loss: 0.9346 - acc: 0.7365 - val_loss: 1.1277 - val_acc: 0.6706\n",
      "Epoch 237/1500\n",
      " - 0s - loss: 0.9315 - acc: 0.7380 - val_loss: 1.1280 - val_acc: 0.6676\n",
      "Epoch 238/1500\n",
      " - 0s - loss: 0.9307 - acc: 0.7372 - val_loss: 1.1246 - val_acc: 0.6706\n",
      "Epoch 239/1500\n",
      " - 0s - loss: 0.9277 - acc: 0.7343 - val_loss: 1.1254 - val_acc: 0.6647\n",
      "Epoch 240/1500\n",
      " - 0s - loss: 0.9270 - acc: 0.7336 - val_loss: 1.1242 - val_acc: 0.6647\n",
      "Epoch 241/1500\n",
      " - 0s - loss: 0.9226 - acc: 0.7394 - val_loss: 1.1205 - val_acc: 0.6676\n",
      "Epoch 242/1500\n",
      " - 0s - loss: 0.9222 - acc: 0.7387 - val_loss: 1.1202 - val_acc: 0.6676\n",
      "Epoch 243/1500\n",
      " - 0s - loss: 0.9185 - acc: 0.7387 - val_loss: 1.1182 - val_acc: 0.6764\n",
      "Epoch 244/1500\n",
      " - 0s - loss: 0.9182 - acc: 0.7409 - val_loss: 1.1185 - val_acc: 0.6647\n",
      "Epoch 245/1500\n",
      " - 0s - loss: 0.9154 - acc: 0.7372 - val_loss: 1.1174 - val_acc: 0.6618\n",
      "Epoch 246/1500\n",
      " - 0s - loss: 0.9145 - acc: 0.7401 - val_loss: 1.1179 - val_acc: 0.6764\n",
      "Epoch 247/1500\n",
      " - 0s - loss: 0.9126 - acc: 0.7365 - val_loss: 1.1168 - val_acc: 0.6647\n",
      "Epoch 248/1500\n",
      " - 0s - loss: 0.9090 - acc: 0.7423 - val_loss: 1.1135 - val_acc: 0.6735\n",
      "Epoch 249/1500\n",
      " - 0s - loss: 0.9102 - acc: 0.7431 - val_loss: 1.1122 - val_acc: 0.6647\n",
      "Epoch 250/1500\n",
      " - 0s - loss: 0.9066 - acc: 0.7365 - val_loss: 1.1106 - val_acc: 0.6647\n",
      "Epoch 251/1500\n",
      " - 0s - loss: 0.9054 - acc: 0.7416 - val_loss: 1.1106 - val_acc: 0.6910\n",
      "Epoch 252/1500\n",
      " - 0s - loss: 0.9034 - acc: 0.7423 - val_loss: 1.1102 - val_acc: 0.6618\n",
      "Epoch 253/1500\n",
      " - 0s - loss: 0.8990 - acc: 0.7460 - val_loss: 1.1056 - val_acc: 0.6764\n",
      "Epoch 254/1500\n",
      " - 0s - loss: 0.8973 - acc: 0.7482 - val_loss: 1.1045 - val_acc: 0.6764\n",
      "Epoch 255/1500\n",
      " - 0s - loss: 0.8949 - acc: 0.7401 - val_loss: 1.1044 - val_acc: 0.6735\n",
      "Epoch 256/1500\n",
      " - 0s - loss: 0.8930 - acc: 0.7489 - val_loss: 1.1020 - val_acc: 0.6793\n",
      "Epoch 257/1500\n",
      " - 0s - loss: 0.8911 - acc: 0.7547 - val_loss: 1.1011 - val_acc: 0.6735\n",
      "Epoch 258/1500\n",
      " - 0s - loss: 0.8903 - acc: 0.7489 - val_loss: 1.1010 - val_acc: 0.6793\n",
      "Epoch 259/1500\n",
      " - 0s - loss: 0.8888 - acc: 0.7489 - val_loss: 1.1003 - val_acc: 0.6793\n",
      "Epoch 260/1500\n",
      " - 0s - loss: 0.8852 - acc: 0.7577 - val_loss: 1.0973 - val_acc: 0.6735\n",
      "Epoch 261/1500\n",
      " - 0s - loss: 0.8843 - acc: 0.7474 - val_loss: 1.0969 - val_acc: 0.6822\n",
      "Epoch 262/1500\n",
      " - 0s - loss: 0.8828 - acc: 0.7540 - val_loss: 1.0946 - val_acc: 0.6851\n",
      "Epoch 263/1500\n",
      " - 0s - loss: 0.8790 - acc: 0.7533 - val_loss: 1.0960 - val_acc: 0.6735\n",
      "Epoch 264/1500\n",
      " - 0s - loss: 0.8776 - acc: 0.7504 - val_loss: 1.0921 - val_acc: 0.6793\n",
      "Epoch 265/1500\n",
      " - 0s - loss: 0.8764 - acc: 0.7504 - val_loss: 1.0945 - val_acc: 0.6706\n",
      "Epoch 266/1500\n",
      " - 0s - loss: 0.8765 - acc: 0.7540 - val_loss: 1.0915 - val_acc: 0.6822\n",
      "Epoch 267/1500\n",
      " - 0s - loss: 0.8718 - acc: 0.7547 - val_loss: 1.0898 - val_acc: 0.6735\n",
      "Epoch 268/1500\n",
      " - 0s - loss: 0.8698 - acc: 0.7540 - val_loss: 1.0896 - val_acc: 0.6822\n",
      "Epoch 269/1500\n",
      " - 0s - loss: 0.8679 - acc: 0.7511 - val_loss: 1.0881 - val_acc: 0.6793\n",
      "Epoch 270/1500\n",
      " - 0s - loss: 0.8674 - acc: 0.7526 - val_loss: 1.0868 - val_acc: 0.6851\n",
      "Epoch 271/1500\n",
      " - 0s - loss: 0.8646 - acc: 0.7540 - val_loss: 1.0871 - val_acc: 0.6822\n",
      "Epoch 272/1500\n",
      " - 0s - loss: 0.8636 - acc: 0.7540 - val_loss: 1.0851 - val_acc: 0.6764\n",
      "Epoch 273/1500\n",
      " - 0s - loss: 0.8629 - acc: 0.7555 - val_loss: 1.0842 - val_acc: 0.6764\n",
      "Epoch 274/1500\n",
      " - 0s - loss: 0.8609 - acc: 0.7562 - val_loss: 1.0822 - val_acc: 0.6880\n",
      "Epoch 275/1500\n",
      " - 0s - loss: 0.8582 - acc: 0.7628 - val_loss: 1.0839 - val_acc: 0.6764\n",
      "Epoch 276/1500\n",
      " - 0s - loss: 0.8569 - acc: 0.7518 - val_loss: 1.0814 - val_acc: 0.6851\n",
      "Epoch 277/1500\n",
      " - 0s - loss: 0.8564 - acc: 0.7620 - val_loss: 1.0806 - val_acc: 0.6735\n",
      "Epoch 278/1500\n",
      " - 0s - loss: 0.8521 - acc: 0.7547 - val_loss: 1.0810 - val_acc: 0.6793\n",
      "Epoch 279/1500\n",
      " - 0s - loss: 0.8497 - acc: 0.7613 - val_loss: 1.0805 - val_acc: 0.6764\n",
      "Epoch 280/1500\n",
      " - 0s - loss: 0.8504 - acc: 0.7620 - val_loss: 1.0772 - val_acc: 0.6880\n",
      "Epoch 281/1500\n",
      " - 0s - loss: 0.8472 - acc: 0.7613 - val_loss: 1.0786 - val_acc: 0.6764\n",
      "Epoch 282/1500\n",
      " - 0s - loss: 0.8448 - acc: 0.7584 - val_loss: 1.0759 - val_acc: 0.6910\n",
      "Epoch 283/1500\n",
      " - 0s - loss: 0.8442 - acc: 0.7577 - val_loss: 1.0758 - val_acc: 0.6822\n",
      "Epoch 284/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.8414 - acc: 0.7613 - val_loss: 1.0740 - val_acc: 0.6822\n",
      "Epoch 285/1500\n",
      " - 0s - loss: 0.8405 - acc: 0.7664 - val_loss: 1.0720 - val_acc: 0.6910\n",
      "Epoch 286/1500\n",
      " - 0s - loss: 0.8392 - acc: 0.7613 - val_loss: 1.0744 - val_acc: 0.6822\n",
      "Epoch 287/1500\n",
      " - 0s - loss: 0.8373 - acc: 0.7613 - val_loss: 1.0723 - val_acc: 0.6822\n",
      "Epoch 288/1500\n",
      " - 0s - loss: 0.8350 - acc: 0.7606 - val_loss: 1.0716 - val_acc: 0.6822\n",
      "Epoch 289/1500\n",
      " - 0s - loss: 0.8356 - acc: 0.7657 - val_loss: 1.0692 - val_acc: 0.6910\n",
      "Epoch 290/1500\n",
      " - 0s - loss: 0.8305 - acc: 0.7650 - val_loss: 1.0687 - val_acc: 0.6851\n",
      "Epoch 291/1500\n",
      " - 0s - loss: 0.8305 - acc: 0.7657 - val_loss: 1.0676 - val_acc: 0.6939\n",
      "Epoch 292/1500\n",
      " - 0s - loss: 0.8288 - acc: 0.7672 - val_loss: 1.0691 - val_acc: 0.6880\n",
      "Epoch 293/1500\n",
      " - 0s - loss: 0.8270 - acc: 0.7650 - val_loss: 1.0659 - val_acc: 0.6939\n",
      "Epoch 294/1500\n",
      " - 0s - loss: 0.8256 - acc: 0.7679 - val_loss: 1.0660 - val_acc: 0.6880\n",
      "Epoch 295/1500\n",
      " - 0s - loss: 0.8241 - acc: 0.7679 - val_loss: 1.0638 - val_acc: 0.6939\n",
      "Epoch 296/1500\n",
      " - 0s - loss: 0.8210 - acc: 0.7650 - val_loss: 1.0662 - val_acc: 0.6822\n",
      "Epoch 297/1500\n",
      " - 0s - loss: 0.8195 - acc: 0.7708 - val_loss: 1.0616 - val_acc: 0.6939\n",
      "Epoch 298/1500\n",
      " - 0s - loss: 0.8183 - acc: 0.7672 - val_loss: 1.0625 - val_acc: 0.6822\n",
      "Epoch 299/1500\n",
      " - 0s - loss: 0.8158 - acc: 0.7672 - val_loss: 1.0609 - val_acc: 0.6997\n",
      "Epoch 300/1500\n",
      " - 0s - loss: 0.8149 - acc: 0.7664 - val_loss: 1.0607 - val_acc: 0.7026\n",
      "Epoch 301/1500\n",
      " - 0s - loss: 0.8131 - acc: 0.7701 - val_loss: 1.0628 - val_acc: 0.6968\n",
      "Epoch 302/1500\n",
      " - 0s - loss: 0.8130 - acc: 0.7708 - val_loss: 1.0578 - val_acc: 0.6939\n",
      "Epoch 303/1500\n",
      " - 0s - loss: 0.8103 - acc: 0.7672 - val_loss: 1.0613 - val_acc: 0.6793\n",
      "Epoch 304/1500\n",
      " - 0s - loss: 0.8090 - acc: 0.7693 - val_loss: 1.0571 - val_acc: 0.7085\n",
      "Epoch 305/1500\n",
      " - 0s - loss: 0.8085 - acc: 0.7708 - val_loss: 1.0595 - val_acc: 0.6910\n",
      "Epoch 306/1500\n",
      " - 0s - loss: 0.8075 - acc: 0.7650 - val_loss: 1.0558 - val_acc: 0.6997\n",
      "Epoch 307/1500\n",
      " - 0s - loss: 0.8040 - acc: 0.7664 - val_loss: 1.0576 - val_acc: 0.6851\n",
      "Epoch 308/1500\n",
      " - 0s - loss: 0.8044 - acc: 0.7693 - val_loss: 1.0559 - val_acc: 0.7026\n",
      "Epoch 309/1500\n",
      " - 0s - loss: 0.8010 - acc: 0.7715 - val_loss: 1.0561 - val_acc: 0.6910\n",
      "Epoch 310/1500\n",
      " - 0s - loss: 0.7997 - acc: 0.7730 - val_loss: 1.0536 - val_acc: 0.6997\n",
      "Epoch 311/1500\n",
      " - 0s - loss: 0.7974 - acc: 0.7781 - val_loss: 1.0559 - val_acc: 0.6939\n",
      "Epoch 312/1500\n",
      " - 0s - loss: 0.7957 - acc: 0.7759 - val_loss: 1.0539 - val_acc: 0.7026\n",
      "Epoch 313/1500\n",
      " - 0s - loss: 0.7949 - acc: 0.7723 - val_loss: 1.0504 - val_acc: 0.6968\n",
      "Epoch 314/1500\n",
      " - 0s - loss: 0.7930 - acc: 0.7752 - val_loss: 1.0500 - val_acc: 0.6997\n",
      "Epoch 315/1500\n",
      " - 0s - loss: 0.7916 - acc: 0.7730 - val_loss: 1.0488 - val_acc: 0.7055\n",
      "Epoch 316/1500\n",
      " - 0s - loss: 0.7903 - acc: 0.7759 - val_loss: 1.0489 - val_acc: 0.6910\n",
      "Epoch 317/1500\n",
      " - 0s - loss: 0.7893 - acc: 0.7752 - val_loss: 1.0488 - val_acc: 0.7055\n",
      "Epoch 318/1500\n",
      " - 0s - loss: 0.7869 - acc: 0.7752 - val_loss: 1.0493 - val_acc: 0.6968\n",
      "Epoch 319/1500\n",
      " - 0s - loss: 0.7854 - acc: 0.7752 - val_loss: 1.0479 - val_acc: 0.6997\n",
      "Epoch 320/1500\n",
      " - 0s - loss: 0.7829 - acc: 0.7723 - val_loss: 1.0441 - val_acc: 0.7026\n",
      "Epoch 321/1500\n",
      " - 0s - loss: 0.7820 - acc: 0.7752 - val_loss: 1.0451 - val_acc: 0.6997\n",
      "Epoch 322/1500\n",
      " - 0s - loss: 0.7818 - acc: 0.7796 - val_loss: 1.0467 - val_acc: 0.7026\n",
      "Epoch 323/1500\n",
      " - 0s - loss: 0.7800 - acc: 0.7788 - val_loss: 1.0454 - val_acc: 0.6997\n",
      "Epoch 324/1500\n",
      " - 0s - loss: 0.7789 - acc: 0.7774 - val_loss: 1.0430 - val_acc: 0.7055\n",
      "Epoch 325/1500\n",
      " - 0s - loss: 0.7778 - acc: 0.7796 - val_loss: 1.0447 - val_acc: 0.7055\n",
      "Epoch 326/1500\n",
      " - 0s - loss: 0.7758 - acc: 0.7818 - val_loss: 1.0411 - val_acc: 0.7026\n",
      "Epoch 327/1500\n",
      " - 0s - loss: 0.7729 - acc: 0.7766 - val_loss: 1.0442 - val_acc: 0.6997\n",
      "Epoch 328/1500\n",
      " - 0s - loss: 0.7709 - acc: 0.7788 - val_loss: 1.0386 - val_acc: 0.6997\n",
      "Epoch 329/1500\n",
      " - 0s - loss: 0.7719 - acc: 0.7752 - val_loss: 1.0426 - val_acc: 0.7114\n",
      "Epoch 330/1500\n",
      " - 0s - loss: 0.7709 - acc: 0.7818 - val_loss: 1.0411 - val_acc: 0.6968\n",
      "Epoch 331/1500\n",
      " - 0s - loss: 0.7666 - acc: 0.7781 - val_loss: 1.0416 - val_acc: 0.7085\n",
      "Epoch 332/1500\n",
      " - 0s - loss: 0.7655 - acc: 0.7810 - val_loss: 1.0395 - val_acc: 0.7055\n",
      "Epoch 333/1500\n",
      " - 0s - loss: 0.7648 - acc: 0.7854 - val_loss: 1.0388 - val_acc: 0.7055\n",
      "Epoch 334/1500\n",
      " - 0s - loss: 0.7643 - acc: 0.7796 - val_loss: 1.0379 - val_acc: 0.7055\n",
      "Epoch 335/1500\n",
      " - 0s - loss: 0.7618 - acc: 0.7847 - val_loss: 1.0397 - val_acc: 0.6968\n",
      "Epoch 336/1500\n",
      " - 0s - loss: 0.7621 - acc: 0.7803 - val_loss: 1.0371 - val_acc: 0.7026\n",
      "Epoch 337/1500\n",
      " - 0s - loss: 0.7603 - acc: 0.7810 - val_loss: 1.0373 - val_acc: 0.7085\n",
      "Epoch 338/1500\n",
      " - 0s - loss: 0.7588 - acc: 0.7854 - val_loss: 1.0387 - val_acc: 0.6939\n",
      "Epoch 339/1500\n",
      " - 0s - loss: 0.7575 - acc: 0.7810 - val_loss: 1.0370 - val_acc: 0.7055\n",
      "Epoch 340/1500\n",
      " - 0s - loss: 0.7563 - acc: 0.7781 - val_loss: 1.0326 - val_acc: 0.7085\n",
      "Epoch 341/1500\n",
      " - 0s - loss: 0.7559 - acc: 0.7839 - val_loss: 1.0370 - val_acc: 0.7055\n",
      "Epoch 342/1500\n",
      " - 0s - loss: 0.7537 - acc: 0.7781 - val_loss: 1.0362 - val_acc: 0.7055\n",
      "Epoch 343/1500\n",
      " - 0s - loss: 0.7526 - acc: 0.7810 - val_loss: 1.0318 - val_acc: 0.7055\n",
      "Epoch 344/1500\n",
      " - 0s - loss: 0.7502 - acc: 0.7883 - val_loss: 1.0353 - val_acc: 0.7055\n",
      "Epoch 345/1500\n",
      " - 0s - loss: 0.7479 - acc: 0.7818 - val_loss: 1.0313 - val_acc: 0.7055\n",
      "Epoch 346/1500\n",
      " - 0s - loss: 0.7475 - acc: 0.7854 - val_loss: 1.0343 - val_acc: 0.6997\n",
      "Epoch 347/1500\n",
      " - 0s - loss: 0.7461 - acc: 0.7883 - val_loss: 1.0299 - val_acc: 0.7085\n",
      "Epoch 348/1500\n",
      " - 0s - loss: 0.7457 - acc: 0.7869 - val_loss: 1.0288 - val_acc: 0.7026\n",
      "Epoch 349/1500\n",
      " - 0s - loss: 0.7452 - acc: 0.7847 - val_loss: 1.0333 - val_acc: 0.7085\n",
      "Epoch 350/1500\n",
      " - 0s - loss: 0.7408 - acc: 0.7847 - val_loss: 1.0306 - val_acc: 0.7026\n",
      "Epoch 351/1500\n",
      " - 0s - loss: 0.7409 - acc: 0.7847 - val_loss: 1.0273 - val_acc: 0.7085\n",
      "Epoch 352/1500\n",
      " - 0s - loss: 0.7377 - acc: 0.7869 - val_loss: 1.0273 - val_acc: 0.7055\n",
      "Epoch 353/1500\n",
      " - 0s - loss: 0.7376 - acc: 0.7869 - val_loss: 1.0302 - val_acc: 0.7026\n",
      "Epoch 354/1500\n",
      " - 0s - loss: 0.7358 - acc: 0.7861 - val_loss: 1.0261 - val_acc: 0.7114\n",
      "Epoch 355/1500\n",
      " - 0s - loss: 0.7342 - acc: 0.7883 - val_loss: 1.0283 - val_acc: 0.7055\n",
      "Epoch 356/1500\n",
      " - 0s - loss: 0.7327 - acc: 0.7883 - val_loss: 1.0264 - val_acc: 0.7085\n",
      "Epoch 357/1500\n",
      " - 0s - loss: 0.7319 - acc: 0.7861 - val_loss: 1.0253 - val_acc: 0.7055\n",
      "Epoch 358/1500\n",
      " - 0s - loss: 0.7318 - acc: 0.7927 - val_loss: 1.0275 - val_acc: 0.7055\n",
      "Epoch 359/1500\n",
      " - 0s - loss: 0.7312 - acc: 0.7898 - val_loss: 1.0241 - val_acc: 0.7055\n",
      "Epoch 360/1500\n",
      " - 0s - loss: 0.7301 - acc: 0.7891 - val_loss: 1.0288 - val_acc: 0.6997\n",
      "Epoch 361/1500\n",
      " - 0s - loss: 0.7314 - acc: 0.7876 - val_loss: 1.0259 - val_acc: 0.7026\n",
      "Epoch 362/1500\n",
      " - 0s - loss: 0.7287 - acc: 0.7898 - val_loss: 1.0243 - val_acc: 0.7055\n",
      "Epoch 363/1500\n",
      " - 0s - loss: 0.7269 - acc: 0.7898 - val_loss: 1.0271 - val_acc: 0.6997\n",
      "Epoch 364/1500\n",
      " - 0s - loss: 0.7234 - acc: 0.7920 - val_loss: 1.0212 - val_acc: 0.7026\n",
      "Epoch 365/1500\n",
      " - 0s - loss: 0.7229 - acc: 0.7898 - val_loss: 1.0222 - val_acc: 0.7085\n",
      "Epoch 366/1500\n",
      " - 0s - loss: 0.7217 - acc: 0.7934 - val_loss: 1.0202 - val_acc: 0.7055\n",
      "Epoch 367/1500\n",
      " - 0s - loss: 0.7231 - acc: 0.7927 - val_loss: 1.0242 - val_acc: 0.7114\n",
      "Epoch 368/1500\n",
      " - 0s - loss: 0.7224 - acc: 0.7964 - val_loss: 1.0242 - val_acc: 0.7026\n",
      "Epoch 369/1500\n",
      " - 0s - loss: 0.7202 - acc: 0.7927 - val_loss: 1.0215 - val_acc: 0.7026\n",
      "Epoch 370/1500\n",
      " - 0s - loss: 0.7159 - acc: 0.7920 - val_loss: 1.0216 - val_acc: 0.7055\n",
      "Epoch 371/1500\n",
      " - 0s - loss: 0.7173 - acc: 0.7891 - val_loss: 1.0236 - val_acc: 0.6997\n",
      "Epoch 372/1500\n",
      " - 0s - loss: 0.7137 - acc: 0.7934 - val_loss: 1.0171 - val_acc: 0.7085\n",
      "Epoch 373/1500\n",
      " - 0s - loss: 0.7169 - acc: 0.7905 - val_loss: 1.0242 - val_acc: 0.7143\n",
      "Epoch 374/1500\n",
      " - 0s - loss: 0.7126 - acc: 0.7949 - val_loss: 1.0183 - val_acc: 0.7055\n",
      "Epoch 375/1500\n",
      " - 0s - loss: 0.7111 - acc: 0.7964 - val_loss: 1.0187 - val_acc: 0.7055\n",
      "Epoch 376/1500\n",
      " - 0s - loss: 0.7134 - acc: 0.7912 - val_loss: 1.0211 - val_acc: 0.7114\n",
      "Epoch 377/1500\n",
      " - 0s - loss: 0.7078 - acc: 0.7927 - val_loss: 1.0164 - val_acc: 0.7026\n",
      "Epoch 378/1500\n",
      " - 0s - loss: 0.7076 - acc: 0.7964 - val_loss: 1.0164 - val_acc: 0.7055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1500\n",
      " - 0s - loss: 0.7066 - acc: 0.7971 - val_loss: 1.0197 - val_acc: 0.7055\n",
      "Epoch 380/1500\n",
      " - 0s - loss: 0.7073 - acc: 0.7978 - val_loss: 1.0179 - val_acc: 0.7085\n",
      "Epoch 381/1500\n",
      " - 0s - loss: 0.7062 - acc: 0.7942 - val_loss: 1.0186 - val_acc: 0.7055\n",
      "Epoch 382/1500\n",
      " - 0s - loss: 0.7019 - acc: 0.7956 - val_loss: 1.0119 - val_acc: 0.7026\n",
      "Epoch 383/1500\n",
      " - 0s - loss: 0.7008 - acc: 0.8000 - val_loss: 1.0148 - val_acc: 0.7055\n",
      "Epoch 384/1500\n",
      " - 0s - loss: 0.7002 - acc: 0.7949 - val_loss: 1.0140 - val_acc: 0.7055\n",
      "Epoch 385/1500\n",
      " - 0s - loss: 0.7000 - acc: 0.7985 - val_loss: 1.0120 - val_acc: 0.7055\n",
      "Epoch 386/1500\n",
      " - 0s - loss: 0.7003 - acc: 0.7956 - val_loss: 1.0202 - val_acc: 0.6968\n",
      "Epoch 387/1500\n",
      " - 0s - loss: 0.6966 - acc: 0.8007 - val_loss: 1.0117 - val_acc: 0.7026\n",
      "Epoch 388/1500\n",
      " - 0s - loss: 0.6970 - acc: 0.7934 - val_loss: 1.0116 - val_acc: 0.7085\n",
      "Epoch 389/1500\n",
      " - 0s - loss: 0.6968 - acc: 0.8000 - val_loss: 1.0140 - val_acc: 0.7026\n",
      "Epoch 390/1500\n",
      " - 0s - loss: 0.6949 - acc: 0.7949 - val_loss: 1.0134 - val_acc: 0.7026\n",
      "Epoch 391/1500\n",
      " - 0s - loss: 0.6927 - acc: 0.8044 - val_loss: 1.0123 - val_acc: 0.6968\n",
      "Epoch 392/1500\n",
      " - 0s - loss: 0.6932 - acc: 0.7934 - val_loss: 1.0159 - val_acc: 0.7085\n",
      "Epoch 393/1500\n",
      " - 0s - loss: 0.6892 - acc: 0.8051 - val_loss: 1.0082 - val_acc: 0.7026\n",
      "Epoch 394/1500\n",
      " - 0s - loss: 0.6889 - acc: 0.8015 - val_loss: 1.0100 - val_acc: 0.7114\n",
      "Epoch 395/1500\n",
      " - 0s - loss: 0.6881 - acc: 0.7993 - val_loss: 1.0120 - val_acc: 0.7085\n",
      "Epoch 396/1500\n",
      " - 0s - loss: 0.6865 - acc: 0.8015 - val_loss: 1.0092 - val_acc: 0.7055\n",
      "Epoch 397/1500\n",
      " - 0s - loss: 0.6876 - acc: 0.8015 - val_loss: 1.0125 - val_acc: 0.7085\n",
      "Epoch 398/1500\n",
      " - 0s - loss: 0.6840 - acc: 0.7964 - val_loss: 1.0075 - val_acc: 0.7026\n",
      "Epoch 399/1500\n",
      " - 0s - loss: 0.6833 - acc: 0.8044 - val_loss: 1.0090 - val_acc: 0.7055\n",
      "Epoch 400/1500\n",
      " - 0s - loss: 0.6844 - acc: 0.8007 - val_loss: 1.0105 - val_acc: 0.7114\n",
      "Epoch 401/1500\n",
      " - 0s - loss: 0.6806 - acc: 0.8000 - val_loss: 1.0067 - val_acc: 0.7026\n",
      "Epoch 402/1500\n",
      " - 0s - loss: 0.6828 - acc: 0.8022 - val_loss: 1.0114 - val_acc: 0.7085\n",
      "Epoch 403/1500\n",
      " - 0s - loss: 0.6819 - acc: 0.8015 - val_loss: 1.0088 - val_acc: 0.7114\n",
      "Epoch 404/1500\n",
      " - 0s - loss: 0.6800 - acc: 0.7978 - val_loss: 1.0103 - val_acc: 0.7026\n",
      "Epoch 405/1500\n",
      " - 0s - loss: 0.6775 - acc: 0.8095 - val_loss: 1.0047 - val_acc: 0.7114\n",
      "Epoch 406/1500\n",
      " - 0s - loss: 0.6766 - acc: 0.8022 - val_loss: 1.0062 - val_acc: 0.7085\n",
      "Epoch 407/1500\n",
      " - 0s - loss: 0.6750 - acc: 0.8029 - val_loss: 1.0091 - val_acc: 0.7055\n",
      "Epoch 408/1500\n",
      " - 0s - loss: 0.6733 - acc: 0.8036 - val_loss: 1.0044 - val_acc: 0.7114\n",
      "Epoch 409/1500\n",
      " - 0s - loss: 0.6740 - acc: 0.8044 - val_loss: 1.0047 - val_acc: 0.6997\n",
      "Epoch 410/1500\n",
      " - 0s - loss: 0.6727 - acc: 0.8073 - val_loss: 1.0057 - val_acc: 0.7055\n",
      "Epoch 411/1500\n",
      " - 0s - loss: 0.6715 - acc: 0.8095 - val_loss: 1.0041 - val_acc: 0.7085\n",
      "Epoch 412/1500\n",
      " - 0s - loss: 0.6694 - acc: 0.8051 - val_loss: 1.0054 - val_acc: 0.7055\n",
      "Epoch 413/1500\n",
      " - 0s - loss: 0.6681 - acc: 0.8051 - val_loss: 1.0034 - val_acc: 0.7085\n",
      "Epoch 414/1500\n",
      " - 0s - loss: 0.6678 - acc: 0.8022 - val_loss: 1.0065 - val_acc: 0.6968\n",
      "Epoch 415/1500\n",
      " - 0s - loss: 0.6669 - acc: 0.8088 - val_loss: 1.0034 - val_acc: 0.7114\n",
      "Epoch 416/1500\n",
      " - 0s - loss: 0.6686 - acc: 0.8066 - val_loss: 1.0037 - val_acc: 0.7114\n",
      "Epoch 417/1500\n",
      " - 0s - loss: 0.6640 - acc: 0.8124 - val_loss: 0.9998 - val_acc: 0.7055\n",
      "Epoch 418/1500\n",
      " - 0s - loss: 0.6634 - acc: 0.8066 - val_loss: 1.0065 - val_acc: 0.7055\n",
      "Epoch 419/1500\n",
      " - 0s - loss: 0.6630 - acc: 0.8088 - val_loss: 1.0039 - val_acc: 0.7085\n",
      "Epoch 420/1500\n",
      " - 0s - loss: 0.6611 - acc: 0.8095 - val_loss: 1.0010 - val_acc: 0.7085\n",
      "Epoch 421/1500\n",
      " - 0s - loss: 0.6617 - acc: 0.8058 - val_loss: 1.0041 - val_acc: 0.7085\n",
      "Epoch 422/1500\n",
      " - 0s - loss: 0.6590 - acc: 0.8124 - val_loss: 0.9998 - val_acc: 0.7055\n",
      "Epoch 423/1500\n",
      " - 0s - loss: 0.6599 - acc: 0.8036 - val_loss: 1.0044 - val_acc: 0.7055\n",
      "Epoch 424/1500\n",
      " - 0s - loss: 0.6567 - acc: 0.8066 - val_loss: 1.0003 - val_acc: 0.7114\n",
      "Epoch 425/1500\n",
      " - 0s - loss: 0.6547 - acc: 0.8088 - val_loss: 1.0038 - val_acc: 0.7055\n",
      "Epoch 426/1500\n",
      " - 0s - loss: 0.6544 - acc: 0.8117 - val_loss: 0.9982 - val_acc: 0.7114\n",
      "Epoch 427/1500\n",
      " - 0s - loss: 0.6540 - acc: 0.8088 - val_loss: 1.0028 - val_acc: 0.7143\n",
      "Epoch 428/1500\n",
      " - 0s - loss: 0.6530 - acc: 0.8124 - val_loss: 0.9979 - val_acc: 0.7085\n",
      "Epoch 429/1500\n",
      " - 0s - loss: 0.6524 - acc: 0.8095 - val_loss: 1.0009 - val_acc: 0.7143\n",
      "Epoch 430/1500\n",
      " - 0s - loss: 0.6513 - acc: 0.8131 - val_loss: 0.9961 - val_acc: 0.7026\n",
      "Epoch 431/1500\n",
      " - 0s - loss: 0.6509 - acc: 0.8095 - val_loss: 0.9970 - val_acc: 0.7143\n",
      "Epoch 432/1500\n",
      " - 0s - loss: 0.6492 - acc: 0.8131 - val_loss: 0.9995 - val_acc: 0.7026\n",
      "Epoch 433/1500\n",
      " - 0s - loss: 0.6484 - acc: 0.8146 - val_loss: 0.9987 - val_acc: 0.7085\n",
      "Epoch 434/1500\n",
      " - 0s - loss: 0.6468 - acc: 0.8139 - val_loss: 0.9963 - val_acc: 0.7201\n",
      "Epoch 435/1500\n",
      " - 0s - loss: 0.6474 - acc: 0.8117 - val_loss: 1.0037 - val_acc: 0.7026\n",
      "Epoch 436/1500\n",
      " - 0s - loss: 0.6455 - acc: 0.8139 - val_loss: 0.9957 - val_acc: 0.7172\n",
      "Epoch 437/1500\n",
      " - 0s - loss: 0.6448 - acc: 0.8088 - val_loss: 0.9978 - val_acc: 0.7114\n",
      "Epoch 438/1500\n",
      " - 0s - loss: 0.6439 - acc: 0.8124 - val_loss: 0.9981 - val_acc: 0.7026\n",
      "Epoch 439/1500\n",
      " - 0s - loss: 0.6433 - acc: 0.8131 - val_loss: 0.9941 - val_acc: 0.7143\n",
      "Epoch 440/1500\n",
      " - 0s - loss: 0.6427 - acc: 0.8168 - val_loss: 0.9982 - val_acc: 0.7143\n",
      "Epoch 441/1500\n",
      " - 0s - loss: 0.6410 - acc: 0.8139 - val_loss: 0.9966 - val_acc: 0.7085\n",
      "Epoch 442/1500\n",
      " - 0s - loss: 0.6419 - acc: 0.8139 - val_loss: 0.9949 - val_acc: 0.7114\n",
      "Epoch 443/1500\n",
      " - 0s - loss: 0.6383 - acc: 0.8182 - val_loss: 0.9945 - val_acc: 0.7085\n",
      "Epoch 444/1500\n",
      " - 0s - loss: 0.6369 - acc: 0.8153 - val_loss: 0.9949 - val_acc: 0.7085\n",
      "Epoch 445/1500\n",
      " - 0s - loss: 0.6368 - acc: 0.8146 - val_loss: 0.9916 - val_acc: 0.7172\n",
      "Epoch 446/1500\n",
      " - 0s - loss: 0.6357 - acc: 0.8190 - val_loss: 0.9936 - val_acc: 0.7085\n",
      "Epoch 447/1500\n",
      " - 0s - loss: 0.6338 - acc: 0.8153 - val_loss: 0.9935 - val_acc: 0.7201\n",
      "Epoch 448/1500\n",
      " - 0s - loss: 0.6329 - acc: 0.8197 - val_loss: 0.9931 - val_acc: 0.7085\n",
      "Epoch 449/1500\n",
      " - 0s - loss: 0.6326 - acc: 0.8131 - val_loss: 0.9927 - val_acc: 0.7114\n",
      "Epoch 450/1500\n",
      " - 0s - loss: 0.6320 - acc: 0.8146 - val_loss: 0.9934 - val_acc: 0.7172\n",
      "Epoch 451/1500\n",
      " - 0s - loss: 0.6330 - acc: 0.8139 - val_loss: 0.9922 - val_acc: 0.7055\n",
      "Epoch 452/1500\n",
      " - 0s - loss: 0.6311 - acc: 0.8190 - val_loss: 0.9965 - val_acc: 0.7085\n",
      "Epoch 453/1500\n",
      " - 0s - loss: 0.6294 - acc: 0.8182 - val_loss: 0.9904 - val_acc: 0.7085\n",
      "Epoch 454/1500\n",
      " - 0s - loss: 0.6290 - acc: 0.8182 - val_loss: 0.9929 - val_acc: 0.7085\n",
      "Epoch 455/1500\n",
      " - 0s - loss: 0.6272 - acc: 0.8212 - val_loss: 0.9905 - val_acc: 0.7172\n",
      "Epoch 456/1500\n",
      " - 0s - loss: 0.6273 - acc: 0.8131 - val_loss: 0.9932 - val_acc: 0.7114\n",
      "Epoch 457/1500\n",
      " - 0s - loss: 0.6262 - acc: 0.8175 - val_loss: 0.9904 - val_acc: 0.7026\n",
      "Epoch 458/1500\n",
      " - 0s - loss: 0.6249 - acc: 0.8161 - val_loss: 0.9926 - val_acc: 0.7085\n",
      "Epoch 459/1500\n",
      " - 0s - loss: 0.6250 - acc: 0.8182 - val_loss: 0.9935 - val_acc: 0.7055\n",
      "Epoch 460/1500\n",
      " - 0s - loss: 0.6237 - acc: 0.8182 - val_loss: 0.9893 - val_acc: 0.7143\n",
      "Epoch 461/1500\n",
      " - 0s - loss: 0.6210 - acc: 0.8204 - val_loss: 0.9917 - val_acc: 0.7085\n",
      "Epoch 462/1500\n",
      " - 0s - loss: 0.6227 - acc: 0.8146 - val_loss: 0.9895 - val_acc: 0.7143\n",
      "Epoch 463/1500\n",
      " - 0s - loss: 0.6224 - acc: 0.8182 - val_loss: 0.9914 - val_acc: 0.7143\n",
      "Epoch 464/1500\n",
      " - 0s - loss: 0.6191 - acc: 0.8175 - val_loss: 0.9896 - val_acc: 0.7114\n",
      "Epoch 465/1500\n",
      " - 0s - loss: 0.6200 - acc: 0.8219 - val_loss: 0.9870 - val_acc: 0.7114\n",
      "Epoch 466/1500\n",
      " - 0s - loss: 0.6195 - acc: 0.8204 - val_loss: 0.9872 - val_acc: 0.7114\n",
      "Epoch 467/1500\n",
      " - 0s - loss: 0.6166 - acc: 0.8204 - val_loss: 0.9887 - val_acc: 0.7143\n",
      "Epoch 468/1500\n",
      " - 0s - loss: 0.6155 - acc: 0.8234 - val_loss: 0.9901 - val_acc: 0.7143\n",
      "Epoch 469/1500\n",
      " - 0s - loss: 0.6157 - acc: 0.8197 - val_loss: 0.9859 - val_acc: 0.7143\n",
      "Epoch 470/1500\n",
      " - 0s - loss: 0.6142 - acc: 0.8175 - val_loss: 0.9903 - val_acc: 0.7172\n",
      "Epoch 471/1500\n",
      " - 0s - loss: 0.6132 - acc: 0.8219 - val_loss: 0.9849 - val_acc: 0.7114\n",
      "Epoch 472/1500\n",
      " - 0s - loss: 0.6134 - acc: 0.8190 - val_loss: 0.9920 - val_acc: 0.7143\n",
      "Epoch 473/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6146 - acc: 0.8212 - val_loss: 0.9858 - val_acc: 0.7172\n",
      "Epoch 474/1500\n",
      " - 0s - loss: 0.6119 - acc: 0.8197 - val_loss: 0.9839 - val_acc: 0.7114\n",
      "Epoch 475/1500\n",
      " - 0s - loss: 0.6107 - acc: 0.8248 - val_loss: 0.9885 - val_acc: 0.7085\n",
      "Epoch 476/1500\n",
      " - 0s - loss: 0.6115 - acc: 0.8168 - val_loss: 0.9830 - val_acc: 0.7026\n",
      "Epoch 477/1500\n",
      " - 0s - loss: 0.6090 - acc: 0.8241 - val_loss: 0.9870 - val_acc: 0.7085\n",
      "Epoch 478/1500\n",
      " - 0s - loss: 0.6078 - acc: 0.8219 - val_loss: 0.9860 - val_acc: 0.7085\n",
      "Epoch 479/1500\n",
      " - 0s - loss: 0.6073 - acc: 0.8255 - val_loss: 0.9842 - val_acc: 0.7172\n",
      "Epoch 480/1500\n",
      " - 0s - loss: 0.6066 - acc: 0.8241 - val_loss: 0.9842 - val_acc: 0.7143\n",
      "Epoch 481/1500\n",
      " - 0s - loss: 0.6070 - acc: 0.8204 - val_loss: 0.9849 - val_acc: 0.7172\n",
      "Epoch 482/1500\n",
      " - 0s - loss: 0.6046 - acc: 0.8248 - val_loss: 0.9846 - val_acc: 0.7085\n",
      "Epoch 483/1500\n",
      " - 0s - loss: 0.6028 - acc: 0.8270 - val_loss: 0.9824 - val_acc: 0.7201\n",
      "Epoch 484/1500\n",
      " - 0s - loss: 0.6021 - acc: 0.8241 - val_loss: 0.9820 - val_acc: 0.7055\n",
      "Epoch 485/1500\n",
      " - 0s - loss: 0.6015 - acc: 0.8212 - val_loss: 0.9817 - val_acc: 0.7172\n",
      "Epoch 486/1500\n",
      " - 0s - loss: 0.5998 - acc: 0.8248 - val_loss: 0.9812 - val_acc: 0.7114\n",
      "Epoch 487/1500\n",
      " - 0s - loss: 0.5996 - acc: 0.8255 - val_loss: 0.9843 - val_acc: 0.7085\n",
      "Epoch 488/1500\n",
      " - 0s - loss: 0.5990 - acc: 0.8248 - val_loss: 0.9818 - val_acc: 0.7114\n",
      "Epoch 489/1500\n",
      " - 0s - loss: 0.5987 - acc: 0.8255 - val_loss: 0.9815 - val_acc: 0.7172\n",
      "Epoch 490/1500\n",
      " - 0s - loss: 0.5995 - acc: 0.8270 - val_loss: 0.9791 - val_acc: 0.7143\n",
      "Epoch 491/1500\n",
      " - 0s - loss: 0.5974 - acc: 0.8277 - val_loss: 0.9822 - val_acc: 0.7172\n",
      "Epoch 492/1500\n",
      " - 0s - loss: 0.5970 - acc: 0.8270 - val_loss: 0.9845 - val_acc: 0.7143\n",
      "Epoch 493/1500\n",
      " - 0s - loss: 0.5964 - acc: 0.8248 - val_loss: 0.9826 - val_acc: 0.7143\n",
      "Epoch 494/1500\n",
      " - 0s - loss: 0.5986 - acc: 0.8234 - val_loss: 0.9853 - val_acc: 0.7114\n",
      "Epoch 495/1500\n",
      " - 0s - loss: 0.5950 - acc: 0.8263 - val_loss: 0.9791 - val_acc: 0.7143\n",
      "Epoch 496/1500\n",
      " - 0s - loss: 0.5940 - acc: 0.8263 - val_loss: 0.9796 - val_acc: 0.7114\n",
      "Epoch 497/1500\n",
      " - 0s - loss: 0.5937 - acc: 0.8263 - val_loss: 0.9788 - val_acc: 0.7172\n",
      "Epoch 498/1500\n",
      " - 0s - loss: 0.5914 - acc: 0.8285 - val_loss: 0.9793 - val_acc: 0.7143\n",
      "Epoch 499/1500\n",
      " - 0s - loss: 0.5904 - acc: 0.8277 - val_loss: 0.9780 - val_acc: 0.7230\n",
      "Epoch 500/1500\n",
      " - 0s - loss: 0.5901 - acc: 0.8263 - val_loss: 0.9801 - val_acc: 0.7172\n",
      "Epoch 501/1500\n",
      " - 0s - loss: 0.5882 - acc: 0.8307 - val_loss: 0.9772 - val_acc: 0.7114\n",
      "Epoch 502/1500\n",
      " - 0s - loss: 0.5881 - acc: 0.8292 - val_loss: 0.9820 - val_acc: 0.7201\n",
      "Epoch 503/1500\n",
      " - 0s - loss: 0.5867 - acc: 0.8307 - val_loss: 0.9789 - val_acc: 0.7114\n",
      "Epoch 504/1500\n",
      " - 0s - loss: 0.5888 - acc: 0.8270 - val_loss: 0.9822 - val_acc: 0.7143\n",
      "Epoch 505/1500\n",
      " - 0s - loss: 0.5888 - acc: 0.8285 - val_loss: 0.9793 - val_acc: 0.7259\n",
      "Epoch 506/1500\n",
      " - 0s - loss: 0.5847 - acc: 0.8307 - val_loss: 0.9778 - val_acc: 0.7230\n",
      "Epoch 507/1500\n",
      " - 0s - loss: 0.5849 - acc: 0.8285 - val_loss: 0.9735 - val_acc: 0.7143\n",
      "Epoch 508/1500\n",
      " - 0s - loss: 0.5832 - acc: 0.8307 - val_loss: 0.9784 - val_acc: 0.7143\n",
      "Epoch 509/1500\n",
      " - 0s - loss: 0.5836 - acc: 0.8314 - val_loss: 0.9775 - val_acc: 0.7201\n",
      "Epoch 510/1500\n",
      " - 0s - loss: 0.5839 - acc: 0.8285 - val_loss: 0.9793 - val_acc: 0.7201\n",
      "Epoch 511/1500\n",
      " - 0s - loss: 0.5822 - acc: 0.8285 - val_loss: 0.9752 - val_acc: 0.7143\n",
      "Epoch 512/1500\n",
      " - 0s - loss: 0.5812 - acc: 0.8292 - val_loss: 0.9765 - val_acc: 0.7172\n",
      "Epoch 513/1500\n",
      " - 0s - loss: 0.5819 - acc: 0.8292 - val_loss: 0.9777 - val_acc: 0.7143\n",
      "Epoch 514/1500\n",
      " - 0s - loss: 0.5786 - acc: 0.8321 - val_loss: 0.9748 - val_acc: 0.7201\n",
      "Epoch 515/1500\n",
      " - 0s - loss: 0.5783 - acc: 0.8255 - val_loss: 0.9768 - val_acc: 0.7201\n",
      "Epoch 516/1500\n",
      " - 0s - loss: 0.5795 - acc: 0.8343 - val_loss: 0.9750 - val_acc: 0.7201\n",
      "Epoch 517/1500\n",
      " - 0s - loss: 0.5772 - acc: 0.8343 - val_loss: 0.9754 - val_acc: 0.7143\n",
      "Epoch 518/1500\n",
      " - 0s - loss: 0.5770 - acc: 0.8321 - val_loss: 0.9747 - val_acc: 0.7143\n",
      "Epoch 519/1500\n",
      " - 0s - loss: 0.5755 - acc: 0.8299 - val_loss: 0.9778 - val_acc: 0.7114\n",
      "Epoch 520/1500\n",
      " - 0s - loss: 0.5755 - acc: 0.8328 - val_loss: 0.9765 - val_acc: 0.7201\n",
      "Epoch 521/1500\n",
      " - 0s - loss: 0.5731 - acc: 0.8321 - val_loss: 0.9731 - val_acc: 0.7172\n",
      "Epoch 522/1500\n",
      " - 0s - loss: 0.5734 - acc: 0.8321 - val_loss: 0.9768 - val_acc: 0.7259\n",
      "Epoch 523/1500\n",
      " - 0s - loss: 0.5728 - acc: 0.8321 - val_loss: 0.9730 - val_acc: 0.7201\n",
      "Epoch 524/1500\n",
      " - 0s - loss: 0.5720 - acc: 0.8321 - val_loss: 0.9726 - val_acc: 0.7143\n",
      "Epoch 525/1500\n",
      " - 0s - loss: 0.5724 - acc: 0.8321 - val_loss: 0.9721 - val_acc: 0.7259\n",
      "Epoch 526/1500\n",
      " - 0s - loss: 0.5704 - acc: 0.8328 - val_loss: 0.9738 - val_acc: 0.7230\n",
      "Epoch 527/1500\n",
      " - 0s - loss: 0.5699 - acc: 0.8321 - val_loss: 0.9736 - val_acc: 0.7201\n",
      "Epoch 528/1500\n",
      " - 0s - loss: 0.5703 - acc: 0.8321 - val_loss: 0.9726 - val_acc: 0.7143\n",
      "Epoch 529/1500\n",
      " - 0s - loss: 0.5690 - acc: 0.8299 - val_loss: 0.9737 - val_acc: 0.7172\n",
      "Epoch 530/1500\n",
      " - 0s - loss: 0.5691 - acc: 0.8292 - val_loss: 0.9703 - val_acc: 0.7172\n",
      "Epoch 531/1500\n",
      " - 0s - loss: 0.5704 - acc: 0.8321 - val_loss: 0.9785 - val_acc: 0.7143\n",
      "Epoch 532/1500\n",
      " - 0s - loss: 0.5658 - acc: 0.8328 - val_loss: 0.9687 - val_acc: 0.7230\n",
      "Epoch 533/1500\n",
      " - 0s - loss: 0.5679 - acc: 0.8343 - val_loss: 0.9741 - val_acc: 0.7259\n",
      "Epoch 534/1500\n",
      " - 0s - loss: 0.5658 - acc: 0.8321 - val_loss: 0.9695 - val_acc: 0.7230\n",
      "Epoch 535/1500\n",
      " - 0s - loss: 0.5651 - acc: 0.8350 - val_loss: 0.9700 - val_acc: 0.7230\n",
      "Epoch 536/1500\n",
      " - 0s - loss: 0.5645 - acc: 0.8336 - val_loss: 0.9747 - val_acc: 0.7172\n",
      "Epoch 537/1500\n",
      " - 0s - loss: 0.5629 - acc: 0.8321 - val_loss: 0.9685 - val_acc: 0.7143\n",
      "Epoch 538/1500\n",
      " - 0s - loss: 0.5631 - acc: 0.8277 - val_loss: 0.9728 - val_acc: 0.7172\n",
      "Epoch 539/1500\n",
      " - 0s - loss: 0.5628 - acc: 0.8321 - val_loss: 0.9729 - val_acc: 0.7230\n",
      "Epoch 540/1500\n",
      " - 0s - loss: 0.5641 - acc: 0.8343 - val_loss: 0.9670 - val_acc: 0.7172\n",
      "Epoch 541/1500\n",
      " - 0s - loss: 0.5606 - acc: 0.8358 - val_loss: 0.9741 - val_acc: 0.7259\n",
      "Epoch 542/1500\n",
      " - 0s - loss: 0.5606 - acc: 0.8387 - val_loss: 0.9706 - val_acc: 0.7143\n",
      "Epoch 543/1500\n",
      " - 0s - loss: 0.5638 - acc: 0.8328 - val_loss: 0.9674 - val_acc: 0.7230\n",
      "Epoch 544/1500\n",
      " - 0s - loss: 0.5584 - acc: 0.8401 - val_loss: 0.9775 - val_acc: 0.7143\n",
      "Epoch 545/1500\n",
      " - 0s - loss: 0.5592 - acc: 0.8350 - val_loss: 0.9668 - val_acc: 0.7230\n",
      "Epoch 546/1500\n",
      " - 0s - loss: 0.5574 - acc: 0.8358 - val_loss: 0.9771 - val_acc: 0.7172\n",
      "Epoch 547/1500\n",
      " - 0s - loss: 0.5568 - acc: 0.8350 - val_loss: 0.9662 - val_acc: 0.7201\n",
      "Epoch 548/1500\n",
      " - 0s - loss: 0.5569 - acc: 0.8336 - val_loss: 0.9682 - val_acc: 0.7201\n",
      "Epoch 549/1500\n",
      " - 0s - loss: 0.5545 - acc: 0.8372 - val_loss: 0.9698 - val_acc: 0.7172\n",
      "Epoch 550/1500\n",
      " - 0s - loss: 0.5547 - acc: 0.8343 - val_loss: 0.9692 - val_acc: 0.7143\n",
      "Epoch 551/1500\n",
      " - 0s - loss: 0.5544 - acc: 0.8314 - val_loss: 0.9706 - val_acc: 0.7230\n",
      "Epoch 552/1500\n",
      " - 0s - loss: 0.5526 - acc: 0.8365 - val_loss: 0.9685 - val_acc: 0.7172\n",
      "Epoch 553/1500\n",
      " - 0s - loss: 0.5530 - acc: 0.8343 - val_loss: 0.9735 - val_acc: 0.7201\n",
      "Epoch 554/1500\n",
      " - 0s - loss: 0.5526 - acc: 0.8387 - val_loss: 0.9682 - val_acc: 0.7172\n",
      "Epoch 555/1500\n",
      " - 0s - loss: 0.5519 - acc: 0.8358 - val_loss: 0.9678 - val_acc: 0.7259\n",
      "Epoch 556/1500\n",
      " - 0s - loss: 0.5514 - acc: 0.8365 - val_loss: 0.9683 - val_acc: 0.7318\n",
      "Epoch 557/1500\n",
      " - 0s - loss: 0.5501 - acc: 0.8372 - val_loss: 0.9681 - val_acc: 0.7230\n",
      "Epoch 558/1500\n",
      " - 0s - loss: 0.5505 - acc: 0.8358 - val_loss: 0.9701 - val_acc: 0.7230\n",
      "Epoch 559/1500\n",
      " - 0s - loss: 0.5489 - acc: 0.8365 - val_loss: 0.9678 - val_acc: 0.7259\n",
      "Epoch 560/1500\n",
      " - 0s - loss: 0.5496 - acc: 0.8380 - val_loss: 0.9681 - val_acc: 0.7172\n",
      "Epoch 561/1500\n",
      " - 0s - loss: 0.5466 - acc: 0.8372 - val_loss: 0.9713 - val_acc: 0.7259\n",
      "Epoch 562/1500\n",
      " - 0s - loss: 0.5486 - acc: 0.8358 - val_loss: 0.9688 - val_acc: 0.7259\n",
      "Epoch 563/1500\n",
      " - 0s - loss: 0.5476 - acc: 0.8387 - val_loss: 0.9713 - val_acc: 0.7114\n",
      "Epoch 564/1500\n",
      " - 0s - loss: 0.5466 - acc: 0.8365 - val_loss: 0.9672 - val_acc: 0.7259\n",
      "Epoch 565/1500\n",
      " - 0s - loss: 0.5444 - acc: 0.8380 - val_loss: 0.9668 - val_acc: 0.7172\n",
      "Epoch 566/1500\n",
      " - 0s - loss: 0.5443 - acc: 0.8380 - val_loss: 0.9689 - val_acc: 0.7347\n",
      "Epoch 567/1500\n",
      " - 0s - loss: 0.5448 - acc: 0.8358 - val_loss: 0.9641 - val_acc: 0.7201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/1500\n",
      " - 0s - loss: 0.5427 - acc: 0.8401 - val_loss: 0.9690 - val_acc: 0.7289\n",
      "Epoch 569/1500\n",
      " - 0s - loss: 0.5423 - acc: 0.8416 - val_loss: 0.9670 - val_acc: 0.7230\n",
      "Epoch 570/1500\n",
      " - 0s - loss: 0.5419 - acc: 0.8380 - val_loss: 0.9631 - val_acc: 0.7230\n",
      "Epoch 571/1500\n",
      " - 0s - loss: 0.5406 - acc: 0.8358 - val_loss: 0.9733 - val_acc: 0.7318\n",
      "Epoch 572/1500\n",
      " - 0s - loss: 0.5418 - acc: 0.8336 - val_loss: 0.9649 - val_acc: 0.7201\n",
      "Epoch 573/1500\n",
      " - 0s - loss: 0.5404 - acc: 0.8387 - val_loss: 0.9649 - val_acc: 0.7230\n",
      "Epoch 574/1500\n",
      " - 0s - loss: 0.5396 - acc: 0.8394 - val_loss: 0.9669 - val_acc: 0.7318\n",
      "Epoch 575/1500\n",
      " - 0s - loss: 0.5397 - acc: 0.8394 - val_loss: 0.9665 - val_acc: 0.7347\n",
      "Epoch 576/1500\n",
      " - 0s - loss: 0.5393 - acc: 0.8394 - val_loss: 0.9638 - val_acc: 0.7201\n",
      "Epoch 577/1500\n",
      " - 0s - loss: 0.5408 - acc: 0.8460 - val_loss: 0.9681 - val_acc: 0.7230\n",
      "Epoch 578/1500\n",
      " - 0s - loss: 0.5372 - acc: 0.8387 - val_loss: 0.9650 - val_acc: 0.7230\n",
      "Epoch 579/1500\n",
      " - 0s - loss: 0.5355 - acc: 0.8431 - val_loss: 0.9701 - val_acc: 0.7230\n",
      "Epoch 580/1500\n",
      " - 0s - loss: 0.5373 - acc: 0.8394 - val_loss: 0.9634 - val_acc: 0.7230\n",
      "Epoch 581/1500\n",
      " - 0s - loss: 0.5367 - acc: 0.8423 - val_loss: 0.9668 - val_acc: 0.7230\n",
      "Epoch 582/1500\n",
      " - 0s - loss: 0.5346 - acc: 0.8401 - val_loss: 0.9676 - val_acc: 0.7201\n",
      "Epoch 583/1500\n",
      " - 0s - loss: 0.5340 - acc: 0.8380 - val_loss: 0.9614 - val_acc: 0.7259\n",
      "Epoch 584/1500\n",
      " - 0s - loss: 0.5335 - acc: 0.8438 - val_loss: 0.9662 - val_acc: 0.7230\n",
      "Epoch 585/1500\n",
      " - 0s - loss: 0.5316 - acc: 0.8401 - val_loss: 0.9638 - val_acc: 0.7259\n",
      "Epoch 586/1500\n",
      " - 0s - loss: 0.5335 - acc: 0.8416 - val_loss: 0.9709 - val_acc: 0.7318\n",
      "Epoch 587/1500\n",
      " - 0s - loss: 0.5315 - acc: 0.8431 - val_loss: 0.9655 - val_acc: 0.7289\n",
      "Epoch 588/1500\n",
      " - 0s - loss: 0.5311 - acc: 0.8460 - val_loss: 0.9632 - val_acc: 0.7230\n",
      "Epoch 589/1500\n",
      " - 0s - loss: 0.5348 - acc: 0.8438 - val_loss: 0.9666 - val_acc: 0.7230\n",
      "Epoch 590/1500\n",
      " - 0s - loss: 0.5315 - acc: 0.8365 - val_loss: 0.9620 - val_acc: 0.7259\n",
      "Epoch 591/1500\n",
      " - 0s - loss: 0.5295 - acc: 0.8467 - val_loss: 0.9664 - val_acc: 0.7259\n",
      "Epoch 592/1500\n",
      " - 0s - loss: 0.5296 - acc: 0.8431 - val_loss: 0.9629 - val_acc: 0.7230\n",
      "Epoch 593/1500\n",
      " - 0s - loss: 0.5291 - acc: 0.8431 - val_loss: 0.9653 - val_acc: 0.7230\n",
      "Epoch 594/1500\n",
      " - 0s - loss: 0.5303 - acc: 0.8438 - val_loss: 0.9625 - val_acc: 0.7259\n",
      "Epoch 595/1500\n",
      " - 0s - loss: 0.5269 - acc: 0.8431 - val_loss: 0.9646 - val_acc: 0.7259\n",
      "Epoch 596/1500\n",
      " - 0s - loss: 0.5266 - acc: 0.8460 - val_loss: 0.9634 - val_acc: 0.7201\n",
      "Epoch 597/1500\n",
      " - 0s - loss: 0.5274 - acc: 0.8453 - val_loss: 0.9668 - val_acc: 0.7201\n",
      "Epoch 598/1500\n",
      " - 0s - loss: 0.5256 - acc: 0.8467 - val_loss: 0.9667 - val_acc: 0.7289\n",
      "Epoch 599/1500\n",
      " - 0s - loss: 0.5251 - acc: 0.8416 - val_loss: 0.9633 - val_acc: 0.7289\n",
      "Epoch 600/1500\n",
      " - 0s - loss: 0.5241 - acc: 0.8445 - val_loss: 0.9640 - val_acc: 0.7259\n",
      "Epoch 601/1500\n",
      " - 0s - loss: 0.5234 - acc: 0.8467 - val_loss: 0.9630 - val_acc: 0.7318\n",
      "Epoch 602/1500\n",
      " - 0s - loss: 0.5228 - acc: 0.8445 - val_loss: 0.9622 - val_acc: 0.7230\n",
      "Epoch 603/1500\n",
      " - 0s - loss: 0.5228 - acc: 0.8489 - val_loss: 0.9635 - val_acc: 0.7289\n",
      "Epoch 604/1500\n",
      " - 0s - loss: 0.5215 - acc: 0.8496 - val_loss: 0.9601 - val_acc: 0.7259\n",
      "Epoch 605/1500\n",
      " - 0s - loss: 0.5221 - acc: 0.8423 - val_loss: 0.9633 - val_acc: 0.7259\n",
      "Epoch 606/1500\n",
      " - 0s - loss: 0.5215 - acc: 0.8489 - val_loss: 0.9668 - val_acc: 0.7289\n",
      "Epoch 607/1500\n",
      " - 0s - loss: 0.5213 - acc: 0.8445 - val_loss: 0.9618 - val_acc: 0.7259\n",
      "Epoch 608/1500\n",
      " - 0s - loss: 0.5202 - acc: 0.8467 - val_loss: 0.9647 - val_acc: 0.7201\n",
      "Epoch 609/1500\n",
      " - 0s - loss: 0.5200 - acc: 0.8474 - val_loss: 0.9598 - val_acc: 0.7259\n",
      "Epoch 610/1500\n",
      " - 0s - loss: 0.5192 - acc: 0.8467 - val_loss: 0.9623 - val_acc: 0.7230\n",
      "Epoch 611/1500\n",
      " - 0s - loss: 0.5176 - acc: 0.8511 - val_loss: 0.9662 - val_acc: 0.7318\n",
      "Epoch 612/1500\n",
      " - 0s - loss: 0.5189 - acc: 0.8460 - val_loss: 0.9613 - val_acc: 0.7289\n",
      "Epoch 613/1500\n",
      " - 0s - loss: 0.5169 - acc: 0.8504 - val_loss: 0.9608 - val_acc: 0.7318\n",
      "Epoch 614/1500\n",
      " - 0s - loss: 0.5177 - acc: 0.8474 - val_loss: 0.9671 - val_acc: 0.7201\n",
      "Epoch 615/1500\n",
      " - 0s - loss: 0.5160 - acc: 0.8467 - val_loss: 0.9606 - val_acc: 0.7201\n",
      "Epoch 616/1500\n",
      " - 0s - loss: 0.5173 - acc: 0.8489 - val_loss: 0.9653 - val_acc: 0.7318\n",
      "Epoch 617/1500\n",
      " - 0s - loss: 0.5146 - acc: 0.8504 - val_loss: 0.9636 - val_acc: 0.7289\n",
      "Epoch 618/1500\n",
      " - 0s - loss: 0.5146 - acc: 0.8496 - val_loss: 0.9630 - val_acc: 0.7259\n",
      "Epoch 619/1500\n",
      " - 0s - loss: 0.5163 - acc: 0.8474 - val_loss: 0.9624 - val_acc: 0.7230\n",
      "Epoch 620/1500\n",
      " - 0s - loss: 0.5142 - acc: 0.8482 - val_loss: 0.9651 - val_acc: 0.7201\n",
      "Epoch 621/1500\n",
      " - 0s - loss: 0.5122 - acc: 0.8496 - val_loss: 0.9585 - val_acc: 0.7259\n",
      "Epoch 622/1500\n",
      " - 0s - loss: 0.5131 - acc: 0.8504 - val_loss: 0.9630 - val_acc: 0.7318\n",
      "Epoch 623/1500\n",
      " - 0s - loss: 0.5124 - acc: 0.8467 - val_loss: 0.9639 - val_acc: 0.7230\n",
      "Epoch 624/1500\n",
      " - 0s - loss: 0.5135 - acc: 0.8474 - val_loss: 0.9637 - val_acc: 0.7201\n",
      "Epoch 625/1500\n",
      " - 0s - loss: 0.5116 - acc: 0.8474 - val_loss: 0.9636 - val_acc: 0.7259\n",
      "Epoch 626/1500\n",
      " - 0s - loss: 0.5123 - acc: 0.8416 - val_loss: 0.9610 - val_acc: 0.7347\n",
      "Epoch 627/1500\n",
      " - 0s - loss: 0.5111 - acc: 0.8504 - val_loss: 0.9635 - val_acc: 0.7230\n",
      "Epoch 628/1500\n",
      " - 0s - loss: 0.5090 - acc: 0.8489 - val_loss: 0.9645 - val_acc: 0.7318\n",
      "Epoch 629/1500\n",
      " - 0s - loss: 0.5091 - acc: 0.8474 - val_loss: 0.9580 - val_acc: 0.7318\n",
      "Epoch 630/1500\n",
      " - 0s - loss: 0.5141 - acc: 0.8526 - val_loss: 0.9699 - val_acc: 0.7143\n",
      "Epoch 631/1500\n",
      " - 0s - loss: 0.5127 - acc: 0.8453 - val_loss: 0.9602 - val_acc: 0.7259\n",
      "Epoch 632/1500\n",
      " - 0s - loss: 0.5093 - acc: 0.8518 - val_loss: 0.9628 - val_acc: 0.7259\n",
      "Epoch 633/1500\n",
      " - 0s - loss: 0.5106 - acc: 0.8474 - val_loss: 0.9612 - val_acc: 0.7230\n",
      "Epoch 634/1500\n",
      " - 0s - loss: 0.5094 - acc: 0.8445 - val_loss: 0.9614 - val_acc: 0.7318\n",
      "Epoch 635/1500\n",
      " - 0s - loss: 0.5054 - acc: 0.8496 - val_loss: 0.9636 - val_acc: 0.7172\n",
      "Epoch 636/1500\n",
      " - 0s - loss: 0.5050 - acc: 0.8496 - val_loss: 0.9598 - val_acc: 0.7230\n",
      "Epoch 637/1500\n",
      " - 0s - loss: 0.5041 - acc: 0.8504 - val_loss: 0.9650 - val_acc: 0.7201\n",
      "Epoch 638/1500\n",
      " - 0s - loss: 0.5035 - acc: 0.8496 - val_loss: 0.9597 - val_acc: 0.7230\n",
      "Epoch 639/1500\n",
      " - 0s - loss: 0.5044 - acc: 0.8547 - val_loss: 0.9661 - val_acc: 0.7201\n",
      "Epoch 640/1500\n",
      " - 0s - loss: 0.5042 - acc: 0.8511 - val_loss: 0.9618 - val_acc: 0.7259\n",
      "Epoch 641/1500\n",
      " - 0s - loss: 0.5027 - acc: 0.8496 - val_loss: 0.9621 - val_acc: 0.7230\n",
      "Epoch 642/1500\n",
      " - 0s - loss: 0.5030 - acc: 0.8526 - val_loss: 0.9593 - val_acc: 0.7318\n",
      "Epoch 643/1500\n",
      " - 0s - loss: 0.5011 - acc: 0.8533 - val_loss: 0.9624 - val_acc: 0.7259\n",
      "Epoch 644/1500\n",
      " - 0s - loss: 0.4995 - acc: 0.8547 - val_loss: 0.9584 - val_acc: 0.7201\n",
      "Epoch 645/1500\n",
      " - 0s - loss: 0.5001 - acc: 0.8511 - val_loss: 0.9614 - val_acc: 0.7201\n",
      "Epoch 646/1500\n",
      " - 0s - loss: 0.5033 - acc: 0.8577 - val_loss: 0.9587 - val_acc: 0.7376\n",
      "Epoch 647/1500\n",
      " - 0s - loss: 0.5018 - acc: 0.8518 - val_loss: 0.9628 - val_acc: 0.7230\n",
      "Epoch 648/1500\n",
      " - 0s - loss: 0.5005 - acc: 0.8511 - val_loss: 0.9628 - val_acc: 0.7289\n",
      "Epoch 649/1500\n",
      " - 0s - loss: 0.4978 - acc: 0.8504 - val_loss: 0.9589 - val_acc: 0.7201\n",
      "Epoch 650/1500\n",
      " - 0s - loss: 0.5007 - acc: 0.8504 - val_loss: 0.9604 - val_acc: 0.7259\n",
      "Epoch 651/1500\n",
      " - 0s - loss: 0.4985 - acc: 0.8526 - val_loss: 0.9675 - val_acc: 0.7143\n",
      "Epoch 652/1500\n",
      " - 0s - loss: 0.4963 - acc: 0.8547 - val_loss: 0.9577 - val_acc: 0.7230\n",
      "Epoch 653/1500\n",
      " - 0s - loss: 0.4970 - acc: 0.8504 - val_loss: 0.9630 - val_acc: 0.7230\n",
      "Epoch 654/1500\n",
      " - 0s - loss: 0.4965 - acc: 0.8518 - val_loss: 0.9590 - val_acc: 0.7230\n",
      "Epoch 655/1500\n",
      " - 0s - loss: 0.4992 - acc: 0.8547 - val_loss: 0.9617 - val_acc: 0.7201\n",
      "Epoch 656/1500\n",
      " - 0s - loss: 0.4959 - acc: 0.8562 - val_loss: 0.9598 - val_acc: 0.7289\n",
      "Epoch 657/1500\n",
      " - 0s - loss: 0.4982 - acc: 0.8518 - val_loss: 0.9658 - val_acc: 0.7143\n",
      "Epoch 658/1500\n",
      " - 0s - loss: 0.4949 - acc: 0.8547 - val_loss: 0.9627 - val_acc: 0.7143\n",
      "Epoch 659/1500\n",
      " - 0s - loss: 0.4956 - acc: 0.8504 - val_loss: 0.9571 - val_acc: 0.7347\n",
      "Epoch 660/1500\n",
      " - 0s - loss: 0.4931 - acc: 0.8518 - val_loss: 0.9682 - val_acc: 0.7143\n",
      "Epoch 661/1500\n",
      " - 0s - loss: 0.4957 - acc: 0.8562 - val_loss: 0.9633 - val_acc: 0.7259\n",
      "Epoch 662/1500\n",
      " - 0s - loss: 0.4944 - acc: 0.8540 - val_loss: 0.9568 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1500\n",
      " - 0s - loss: 0.4936 - acc: 0.8504 - val_loss: 0.9593 - val_acc: 0.7318\n",
      "Epoch 664/1500\n",
      " - 0s - loss: 0.4922 - acc: 0.8533 - val_loss: 0.9684 - val_acc: 0.7143\n",
      "Epoch 665/1500\n",
      " - 0s - loss: 0.4926 - acc: 0.8526 - val_loss: 0.9576 - val_acc: 0.7259\n",
      "Epoch 666/1500\n",
      " - 0s - loss: 0.4919 - acc: 0.8569 - val_loss: 0.9656 - val_acc: 0.7289\n",
      "Epoch 667/1500\n",
      " - 0s - loss: 0.4912 - acc: 0.8533 - val_loss: 0.9579 - val_acc: 0.7201\n",
      "Epoch 668/1500\n",
      " - 0s - loss: 0.4897 - acc: 0.8540 - val_loss: 0.9582 - val_acc: 0.7201\n",
      "Epoch 669/1500\n",
      " - 0s - loss: 0.4897 - acc: 0.8540 - val_loss: 0.9603 - val_acc: 0.7289\n",
      "Epoch 670/1500\n",
      " - 0s - loss: 0.4899 - acc: 0.8526 - val_loss: 0.9622 - val_acc: 0.7172\n",
      "Epoch 671/1500\n",
      " - 0s - loss: 0.4879 - acc: 0.8562 - val_loss: 0.9579 - val_acc: 0.7259\n",
      "Epoch 672/1500\n",
      " - 0s - loss: 0.4874 - acc: 0.8511 - val_loss: 0.9639 - val_acc: 0.7143\n",
      "Epoch 673/1500\n",
      " - 0s - loss: 0.4876 - acc: 0.8504 - val_loss: 0.9597 - val_acc: 0.7230\n",
      "Epoch 674/1500\n",
      " - 0s - loss: 0.4879 - acc: 0.8555 - val_loss: 0.9580 - val_acc: 0.7259\n",
      "Epoch 675/1500\n",
      " - 0s - loss: 0.4859 - acc: 0.8591 - val_loss: 0.9590 - val_acc: 0.7230\n",
      "Epoch 676/1500\n",
      " - 0s - loss: 0.4854 - acc: 0.8569 - val_loss: 0.9632 - val_acc: 0.7172\n",
      "Epoch 677/1500\n",
      " - 0s - loss: 0.4853 - acc: 0.8547 - val_loss: 0.9602 - val_acc: 0.7259\n",
      "Epoch 678/1500\n",
      " - 0s - loss: 0.4845 - acc: 0.8562 - val_loss: 0.9551 - val_acc: 0.7318\n",
      "Epoch 679/1500\n",
      " - 0s - loss: 0.4857 - acc: 0.8540 - val_loss: 0.9609 - val_acc: 0.7201\n",
      "Epoch 680/1500\n",
      " - 0s - loss: 0.4852 - acc: 0.8547 - val_loss: 0.9648 - val_acc: 0.7201\n",
      "Epoch 681/1500\n",
      " - 0s - loss: 0.4841 - acc: 0.8584 - val_loss: 0.9552 - val_acc: 0.7289\n",
      "Epoch 682/1500\n",
      " - 0s - loss: 0.4856 - acc: 0.8569 - val_loss: 0.9579 - val_acc: 0.7289\n",
      "Epoch 683/1500\n",
      " - 0s - loss: 0.4820 - acc: 0.8555 - val_loss: 0.9632 - val_acc: 0.7114\n",
      "Epoch 684/1500\n",
      " - 0s - loss: 0.4823 - acc: 0.8533 - val_loss: 0.9572 - val_acc: 0.7230\n",
      "Epoch 685/1500\n",
      " - 0s - loss: 0.4815 - acc: 0.8599 - val_loss: 0.9645 - val_acc: 0.7143\n",
      "Epoch 686/1500\n",
      " - 0s - loss: 0.4835 - acc: 0.8599 - val_loss: 0.9576 - val_acc: 0.7259\n",
      "Epoch 687/1500\n",
      " - 0s - loss: 0.4826 - acc: 0.8599 - val_loss: 0.9583 - val_acc: 0.7230\n",
      "Epoch 688/1500\n",
      " - 0s - loss: 0.4816 - acc: 0.8591 - val_loss: 0.9563 - val_acc: 0.7289\n",
      "Epoch 689/1500\n",
      " - 0s - loss: 0.4799 - acc: 0.8547 - val_loss: 0.9641 - val_acc: 0.7143\n",
      "Epoch 690/1500\n",
      " - 0s - loss: 0.4798 - acc: 0.8577 - val_loss: 0.9578 - val_acc: 0.7259\n",
      "Epoch 691/1500\n",
      " - 0s - loss: 0.4786 - acc: 0.8591 - val_loss: 0.9603 - val_acc: 0.7172\n",
      "Epoch 692/1500\n",
      " - 0s - loss: 0.4787 - acc: 0.8569 - val_loss: 0.9606 - val_acc: 0.7230\n",
      "Epoch 693/1500\n",
      " - 0s - loss: 0.4789 - acc: 0.8613 - val_loss: 0.9584 - val_acc: 0.7201\n",
      "Epoch 694/1500\n",
      " - 0s - loss: 0.4773 - acc: 0.8569 - val_loss: 0.9593 - val_acc: 0.7230\n",
      "Epoch 695/1500\n",
      " - 0s - loss: 0.4775 - acc: 0.8599 - val_loss: 0.9563 - val_acc: 0.7347\n",
      "Epoch 696/1500\n",
      " - 0s - loss: 0.4785 - acc: 0.8569 - val_loss: 0.9560 - val_acc: 0.7318\n",
      "Epoch 697/1500\n",
      " - 0s - loss: 0.4765 - acc: 0.8547 - val_loss: 0.9576 - val_acc: 0.7259\n",
      "Epoch 698/1500\n",
      " - 0s - loss: 0.4765 - acc: 0.8591 - val_loss: 0.9592 - val_acc: 0.7318\n",
      "Epoch 699/1500\n",
      " - 0s - loss: 0.4761 - acc: 0.8591 - val_loss: 0.9565 - val_acc: 0.7259\n",
      "Epoch 700/1500\n",
      " - 0s - loss: 0.4747 - acc: 0.8650 - val_loss: 0.9586 - val_acc: 0.7201\n",
      "Epoch 701/1500\n",
      " - 0s - loss: 0.4747 - acc: 0.8577 - val_loss: 0.9580 - val_acc: 0.7230\n",
      "Epoch 702/1500\n",
      " - 0s - loss: 0.4744 - acc: 0.8599 - val_loss: 0.9618 - val_acc: 0.7230\n",
      "Epoch 703/1500\n",
      " - 0s - loss: 0.4730 - acc: 0.8569 - val_loss: 0.9584 - val_acc: 0.7230\n",
      "Epoch 704/1500\n",
      " - 0s - loss: 0.4718 - acc: 0.8591 - val_loss: 0.9572 - val_acc: 0.7259\n",
      "Epoch 705/1500\n",
      " - 0s - loss: 0.4720 - acc: 0.8613 - val_loss: 0.9588 - val_acc: 0.7259\n",
      "Epoch 706/1500\n",
      " - 0s - loss: 0.4728 - acc: 0.8635 - val_loss: 0.9539 - val_acc: 0.7318\n",
      "Epoch 707/1500\n",
      " - 0s - loss: 0.4734 - acc: 0.8620 - val_loss: 0.9749 - val_acc: 0.7055\n",
      "Epoch 708/1500\n",
      " - 0s - loss: 0.4732 - acc: 0.8606 - val_loss: 0.9534 - val_acc: 0.7259\n",
      "Epoch 709/1500\n",
      " - 0s - loss: 0.4751 - acc: 0.8555 - val_loss: 0.9663 - val_acc: 0.7143\n",
      "Epoch 710/1500\n",
      " - 0s - loss: 0.4747 - acc: 0.8591 - val_loss: 0.9619 - val_acc: 0.7172\n",
      "Epoch 711/1500\n",
      " - 0s - loss: 0.4704 - acc: 0.8620 - val_loss: 0.9585 - val_acc: 0.7259\n",
      "Epoch 712/1500\n",
      " - 0s - loss: 0.4706 - acc: 0.8577 - val_loss: 0.9690 - val_acc: 0.7114\n",
      "Epoch 713/1500\n",
      " - 0s - loss: 0.4745 - acc: 0.8613 - val_loss: 0.9546 - val_acc: 0.7289\n",
      "Epoch 714/1500\n",
      " - 0s - loss: 0.4701 - acc: 0.8584 - val_loss: 0.9660 - val_acc: 0.7143\n",
      "Epoch 715/1500\n",
      " - 0s - loss: 0.4673 - acc: 0.8606 - val_loss: 0.9554 - val_acc: 0.7289\n",
      "Epoch 716/1500\n",
      " - 0s - loss: 0.4694 - acc: 0.8599 - val_loss: 0.9615 - val_acc: 0.7201\n",
      "Epoch 717/1500\n",
      " - 0s - loss: 0.4676 - acc: 0.8584 - val_loss: 0.9559 - val_acc: 0.7259\n",
      "Epoch 718/1500\n",
      " - 0s - loss: 0.4692 - acc: 0.8613 - val_loss: 0.9585 - val_acc: 0.7201\n",
      "Epoch 719/1500\n",
      " - 0s - loss: 0.4670 - acc: 0.8584 - val_loss: 0.9608 - val_acc: 0.7172\n",
      "Epoch 720/1500\n",
      " - 0s - loss: 0.4657 - acc: 0.8628 - val_loss: 0.9603 - val_acc: 0.7201\n",
      "Epoch 721/1500\n",
      " - 0s - loss: 0.4669 - acc: 0.8613 - val_loss: 0.9641 - val_acc: 0.7114\n",
      "Epoch 722/1500\n",
      " - 0s - loss: 0.4682 - acc: 0.8584 - val_loss: 0.9544 - val_acc: 0.7318\n",
      "Epoch 723/1500\n",
      " - 0s - loss: 0.4662 - acc: 0.8613 - val_loss: 0.9641 - val_acc: 0.7143\n",
      "Epoch 724/1500\n",
      " - 0s - loss: 0.4659 - acc: 0.8628 - val_loss: 0.9594 - val_acc: 0.7289\n",
      "Epoch 725/1500\n",
      " - 0s - loss: 0.4642 - acc: 0.8628 - val_loss: 0.9587 - val_acc: 0.7259\n",
      "Epoch 726/1500\n",
      " - 0s - loss: 0.4637 - acc: 0.8591 - val_loss: 0.9592 - val_acc: 0.7230\n",
      "Epoch 727/1500\n",
      " - 0s - loss: 0.4637 - acc: 0.8591 - val_loss: 0.9608 - val_acc: 0.7114\n",
      "Epoch 728/1500\n",
      " - 0s - loss: 0.4634 - acc: 0.8606 - val_loss: 0.9562 - val_acc: 0.7259\n",
      "Epoch 729/1500\n",
      " - 0s - loss: 0.4607 - acc: 0.8686 - val_loss: 0.9631 - val_acc: 0.7172\n",
      "Epoch 730/1500\n",
      " - 0s - loss: 0.4625 - acc: 0.8664 - val_loss: 0.9561 - val_acc: 0.7201\n",
      "Epoch 731/1500\n",
      " - 0s - loss: 0.4633 - acc: 0.8613 - val_loss: 0.9599 - val_acc: 0.7201\n",
      "Epoch 732/1500\n",
      " - 0s - loss: 0.4631 - acc: 0.8635 - val_loss: 0.9594 - val_acc: 0.7201\n",
      "Epoch 733/1500\n",
      " - 0s - loss: 0.4618 - acc: 0.8635 - val_loss: 0.9604 - val_acc: 0.7230\n",
      "Epoch 734/1500\n",
      " - 0s - loss: 0.4615 - acc: 0.8620 - val_loss: 0.9611 - val_acc: 0.7201\n",
      "Epoch 735/1500\n",
      " - 0s - loss: 0.4598 - acc: 0.8642 - val_loss: 0.9568 - val_acc: 0.7230\n",
      "Epoch 736/1500\n",
      " - 0s - loss: 0.4594 - acc: 0.8613 - val_loss: 0.9609 - val_acc: 0.7259\n",
      "Epoch 737/1500\n",
      " - 0s - loss: 0.4612 - acc: 0.8628 - val_loss: 0.9643 - val_acc: 0.7143\n",
      "Epoch 738/1500\n",
      " - 0s - loss: 0.4615 - acc: 0.8628 - val_loss: 0.9602 - val_acc: 0.7230\n",
      "Epoch 739/1500\n",
      " - 0s - loss: 0.4589 - acc: 0.8620 - val_loss: 0.9582 - val_acc: 0.7201\n",
      "Epoch 740/1500\n",
      " - 0s - loss: 0.4583 - acc: 0.8628 - val_loss: 0.9561 - val_acc: 0.7230\n",
      "Epoch 741/1500\n",
      " - 0s - loss: 0.4590 - acc: 0.8599 - val_loss: 0.9636 - val_acc: 0.7201\n",
      "Epoch 742/1500\n",
      " - 0s - loss: 0.4575 - acc: 0.8591 - val_loss: 0.9569 - val_acc: 0.7172\n",
      "Epoch 743/1500\n",
      " - 0s - loss: 0.4583 - acc: 0.8672 - val_loss: 0.9632 - val_acc: 0.7143\n",
      "Epoch 744/1500\n",
      " - 0s - loss: 0.4581 - acc: 0.8657 - val_loss: 0.9577 - val_acc: 0.7201\n",
      "Epoch 745/1500\n",
      " - 0s - loss: 0.4568 - acc: 0.8650 - val_loss: 0.9620 - val_acc: 0.7143\n",
      "Epoch 746/1500\n",
      " - 0s - loss: 0.4553 - acc: 0.8679 - val_loss: 0.9618 - val_acc: 0.7114\n",
      "Epoch 747/1500\n",
      " - 0s - loss: 0.4550 - acc: 0.8642 - val_loss: 0.9562 - val_acc: 0.7230\n",
      "Epoch 748/1500\n",
      " - 0s - loss: 0.4555 - acc: 0.8672 - val_loss: 0.9678 - val_acc: 0.7114\n",
      "Epoch 749/1500\n",
      " - 0s - loss: 0.4542 - acc: 0.8657 - val_loss: 0.9566 - val_acc: 0.7230\n",
      "Epoch 750/1500\n",
      " - 0s - loss: 0.4544 - acc: 0.8679 - val_loss: 0.9662 - val_acc: 0.7172\n",
      "Epoch 751/1500\n",
      " - 0s - loss: 0.4559 - acc: 0.8650 - val_loss: 0.9542 - val_acc: 0.7259\n",
      "Epoch 752/1500\n",
      " - 0s - loss: 0.4537 - acc: 0.8635 - val_loss: 0.9689 - val_acc: 0.7114\n",
      "Epoch 753/1500\n",
      " - 0s - loss: 0.4545 - acc: 0.8642 - val_loss: 0.9584 - val_acc: 0.7230\n",
      "Epoch 754/1500\n",
      " - 0s - loss: 0.4537 - acc: 0.8635 - val_loss: 0.9598 - val_acc: 0.7114\n",
      "Epoch 755/1500\n",
      " - 0s - loss: 0.4525 - acc: 0.8620 - val_loss: 0.9556 - val_acc: 0.7201\n",
      "Epoch 756/1500\n",
      " - 0s - loss: 0.4520 - acc: 0.8693 - val_loss: 0.9658 - val_acc: 0.7114\n",
      "Epoch 757/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4523 - acc: 0.8628 - val_loss: 0.9604 - val_acc: 0.7259\n",
      "Epoch 758/1500\n",
      " - 0s - loss: 0.4510 - acc: 0.8628 - val_loss: 0.9597 - val_acc: 0.7143\n",
      "Epoch 759/1500\n",
      " - 0s - loss: 0.4518 - acc: 0.8650 - val_loss: 0.9669 - val_acc: 0.7114\n",
      "Epoch 760/1500\n",
      " - 0s - loss: 0.4547 - acc: 0.8591 - val_loss: 0.9604 - val_acc: 0.7201\n",
      "Epoch 761/1500\n",
      " - 0s - loss: 0.4534 - acc: 0.8686 - val_loss: 0.9670 - val_acc: 0.7114\n",
      "Epoch 762/1500\n",
      " - 0s - loss: 0.4519 - acc: 0.8657 - val_loss: 0.9568 - val_acc: 0.7259\n",
      "Epoch 763/1500\n",
      " - 0s - loss: 0.4498 - acc: 0.8679 - val_loss: 0.9624 - val_acc: 0.7143\n",
      "Epoch 764/1500\n",
      " - 0s - loss: 0.4499 - acc: 0.8613 - val_loss: 0.9635 - val_acc: 0.7143\n",
      "Epoch 765/1500\n",
      " - 0s - loss: 0.4524 - acc: 0.8657 - val_loss: 0.9623 - val_acc: 0.7172\n",
      "Epoch 766/1500\n",
      " - 0s - loss: 0.4465 - acc: 0.8686 - val_loss: 0.9598 - val_acc: 0.7172\n",
      "Epoch 767/1500\n",
      " - 0s - loss: 0.4485 - acc: 0.8650 - val_loss: 0.9603 - val_acc: 0.7114\n",
      "Epoch 768/1500\n",
      " - 0s - loss: 0.4475 - acc: 0.8664 - val_loss: 0.9612 - val_acc: 0.7172\n",
      "Epoch 769/1500\n",
      " - 0s - loss: 0.4481 - acc: 0.8664 - val_loss: 0.9612 - val_acc: 0.7172\n",
      "Epoch 770/1500\n",
      " - 0s - loss: 0.4463 - acc: 0.8642 - val_loss: 0.9609 - val_acc: 0.7259\n",
      "Epoch 771/1500\n",
      " - 0s - loss: 0.4472 - acc: 0.8672 - val_loss: 0.9676 - val_acc: 0.7143\n",
      "Epoch 772/1500\n",
      " - 0s - loss: 0.4461 - acc: 0.8650 - val_loss: 0.9604 - val_acc: 0.7172\n",
      "Epoch 773/1500\n",
      " - 0s - loss: 0.4479 - acc: 0.8642 - val_loss: 0.9627 - val_acc: 0.7143\n",
      "Epoch 774/1500\n",
      " - 0s - loss: 0.4459 - acc: 0.8650 - val_loss: 0.9597 - val_acc: 0.7143\n",
      "Epoch 775/1500\n",
      " - 0s - loss: 0.4459 - acc: 0.8693 - val_loss: 0.9667 - val_acc: 0.7085\n",
      "Epoch 776/1500\n",
      " - 0s - loss: 0.4460 - acc: 0.8672 - val_loss: 0.9652 - val_acc: 0.7143\n",
      "Epoch 777/1500\n",
      " - 0s - loss: 0.4451 - acc: 0.8635 - val_loss: 0.9585 - val_acc: 0.7201\n",
      "Epoch 778/1500\n",
      " - 0s - loss: 0.4456 - acc: 0.8650 - val_loss: 0.9614 - val_acc: 0.7114\n",
      "Epoch 779/1500\n",
      " - 0s - loss: 0.4422 - acc: 0.8686 - val_loss: 0.9647 - val_acc: 0.7143\n",
      "Epoch 780/1500\n",
      " - 0s - loss: 0.4441 - acc: 0.8657 - val_loss: 0.9605 - val_acc: 0.7172\n",
      "Epoch 781/1500\n",
      " - 0s - loss: 0.4429 - acc: 0.8679 - val_loss: 0.9627 - val_acc: 0.7201\n",
      "Epoch 782/1500\n",
      " - 0s - loss: 0.4436 - acc: 0.8650 - val_loss: 0.9634 - val_acc: 0.7114\n",
      "Epoch 783/1500\n",
      " - 0s - loss: 0.4466 - acc: 0.8650 - val_loss: 0.9608 - val_acc: 0.7172\n",
      "Epoch 784/1500\n",
      " - 0s - loss: 0.4424 - acc: 0.8679 - val_loss: 0.9622 - val_acc: 0.7172\n",
      "Epoch 785/1500\n",
      " - 0s - loss: 0.4422 - acc: 0.8672 - val_loss: 0.9653 - val_acc: 0.7114\n",
      "Epoch 786/1500\n",
      " - 0s - loss: 0.4425 - acc: 0.8686 - val_loss: 0.9584 - val_acc: 0.7114\n",
      "Epoch 787/1500\n",
      " - 0s - loss: 0.4416 - acc: 0.8635 - val_loss: 0.9681 - val_acc: 0.7085\n",
      "Epoch 788/1500\n",
      " - 0s - loss: 0.4414 - acc: 0.8679 - val_loss: 0.9586 - val_acc: 0.7085\n",
      "Epoch 789/1500\n",
      " - 0s - loss: 0.4412 - acc: 0.8657 - val_loss: 0.9675 - val_acc: 0.7114\n",
      "Epoch 790/1500\n",
      " - 0s - loss: 0.4385 - acc: 0.8672 - val_loss: 0.9607 - val_acc: 0.7143\n",
      "Epoch 791/1500\n",
      " - 0s - loss: 0.4391 - acc: 0.8686 - val_loss: 0.9660 - val_acc: 0.7085\n",
      "Epoch 792/1500\n",
      " - 0s - loss: 0.4371 - acc: 0.8679 - val_loss: 0.9603 - val_acc: 0.7201\n",
      "Epoch 793/1500\n",
      " - 0s - loss: 0.4369 - acc: 0.8693 - val_loss: 0.9604 - val_acc: 0.7143\n",
      "Epoch 794/1500\n",
      " - 0s - loss: 0.4382 - acc: 0.8723 - val_loss: 0.9702 - val_acc: 0.7055\n",
      "Epoch 795/1500\n",
      " - 0s - loss: 0.4383 - acc: 0.8672 - val_loss: 0.9592 - val_acc: 0.7085\n",
      "Epoch 796/1500\n",
      " - 0s - loss: 0.4392 - acc: 0.8642 - val_loss: 0.9629 - val_acc: 0.7201\n",
      "Epoch 797/1500\n",
      " - 0s - loss: 0.4369 - acc: 0.8686 - val_loss: 0.9631 - val_acc: 0.7143\n",
      "Epoch 798/1500\n",
      " - 0s - loss: 0.4363 - acc: 0.8650 - val_loss: 0.9600 - val_acc: 0.7085\n",
      "Epoch 799/1500\n",
      " - 0s - loss: 0.4369 - acc: 0.8693 - val_loss: 0.9588 - val_acc: 0.7172\n",
      "Epoch 800/1500\n",
      " - 0s - loss: 0.4357 - acc: 0.8664 - val_loss: 0.9663 - val_acc: 0.7085\n",
      "Epoch 801/1500\n",
      " - 0s - loss: 0.4348 - acc: 0.8679 - val_loss: 0.9592 - val_acc: 0.7172\n",
      "Epoch 802/1500\n",
      " - 0s - loss: 0.4338 - acc: 0.8672 - val_loss: 0.9702 - val_acc: 0.7055\n",
      "Epoch 803/1500\n",
      " - 0s - loss: 0.4360 - acc: 0.8708 - val_loss: 0.9580 - val_acc: 0.7201\n",
      "Epoch 804/1500\n",
      " - 0s - loss: 0.4339 - acc: 0.8686 - val_loss: 0.9687 - val_acc: 0.7085\n",
      "Epoch 805/1500\n",
      " - 0s - loss: 0.4357 - acc: 0.8715 - val_loss: 0.9689 - val_acc: 0.7055\n",
      "Epoch 806/1500\n",
      " - 0s - loss: 0.4341 - acc: 0.8679 - val_loss: 0.9587 - val_acc: 0.7201\n",
      "Epoch 807/1500\n",
      " - 0s - loss: 0.4334 - acc: 0.8693 - val_loss: 0.9691 - val_acc: 0.7085\n",
      "Epoch 808/1500\n",
      " - 0s - loss: 0.4329 - acc: 0.8693 - val_loss: 0.9641 - val_acc: 0.7085\n",
      "Epoch 809/1500\n",
      " - 0s - loss: 0.4326 - acc: 0.8679 - val_loss: 0.9653 - val_acc: 0.7114\n",
      "Epoch 810/1500\n",
      " - 0s - loss: 0.4324 - acc: 0.8723 - val_loss: 0.9608 - val_acc: 0.7201\n",
      "Epoch 811/1500\n",
      " - 0s - loss: 0.4315 - acc: 0.8708 - val_loss: 0.9654 - val_acc: 0.7114\n",
      "Epoch 812/1500\n",
      " - 0s - loss: 0.4317 - acc: 0.8715 - val_loss: 0.9629 - val_acc: 0.7114\n",
      "Epoch 813/1500\n",
      " - 0s - loss: 0.4326 - acc: 0.8745 - val_loss: 0.9605 - val_acc: 0.7114\n",
      "Epoch 814/1500\n",
      " - 0s - loss: 0.4344 - acc: 0.8693 - val_loss: 0.9607 - val_acc: 0.7201\n",
      "Epoch 815/1500\n",
      " - 0s - loss: 0.4329 - acc: 0.8723 - val_loss: 0.9701 - val_acc: 0.6997\n",
      "Epoch 816/1500\n",
      " - 0s - loss: 0.4322 - acc: 0.8701 - val_loss: 0.9624 - val_acc: 0.7172\n",
      "Epoch 817/1500\n",
      " - 0s - loss: 0.4291 - acc: 0.8723 - val_loss: 0.9644 - val_acc: 0.7114\n",
      "Epoch 818/1500\n",
      " - 0s - loss: 0.4306 - acc: 0.8708 - val_loss: 0.9679 - val_acc: 0.7085\n",
      "Epoch 819/1500\n",
      " - 0s - loss: 0.4280 - acc: 0.8745 - val_loss: 0.9638 - val_acc: 0.7201\n",
      "Epoch 820/1500\n",
      " - 0s - loss: 0.4301 - acc: 0.8701 - val_loss: 0.9699 - val_acc: 0.7026\n",
      "Epoch 821/1500\n",
      " - 0s - loss: 0.4288 - acc: 0.8730 - val_loss: 0.9652 - val_acc: 0.7143\n",
      "Epoch 822/1500\n",
      " - 0s - loss: 0.4293 - acc: 0.8664 - val_loss: 0.9663 - val_acc: 0.7114\n",
      "Epoch 823/1500\n",
      " - 0s - loss: 0.4271 - acc: 0.8708 - val_loss: 0.9635 - val_acc: 0.7201\n",
      "Epoch 824/1500\n",
      " - 0s - loss: 0.4281 - acc: 0.8745 - val_loss: 0.9718 - val_acc: 0.6997\n",
      "Epoch 825/1500\n",
      " - 0s - loss: 0.4279 - acc: 0.8701 - val_loss: 0.9602 - val_acc: 0.7143\n",
      "Epoch 826/1500\n",
      " - 0s - loss: 0.4283 - acc: 0.8715 - val_loss: 0.9666 - val_acc: 0.7143\n",
      "Epoch 827/1500\n",
      " - 0s - loss: 0.4283 - acc: 0.8766 - val_loss: 0.9699 - val_acc: 0.7085\n",
      "Epoch 828/1500\n",
      " - 0s - loss: 0.4265 - acc: 0.8679 - val_loss: 0.9663 - val_acc: 0.7026\n",
      "Epoch 829/1500\n",
      " - 0s - loss: 0.4260 - acc: 0.8715 - val_loss: 0.9593 - val_acc: 0.7114\n",
      "Epoch 830/1500\n",
      " - 0s - loss: 0.4253 - acc: 0.8766 - val_loss: 0.9698 - val_acc: 0.7026\n",
      "Epoch 831/1500\n",
      " - 0s - loss: 0.4259 - acc: 0.8730 - val_loss: 0.9710 - val_acc: 0.7085\n",
      "Epoch 832/1500\n",
      " - 0s - loss: 0.4253 - acc: 0.8715 - val_loss: 0.9627 - val_acc: 0.7143\n",
      "Epoch 833/1500\n",
      " - 0s - loss: 0.4241 - acc: 0.8708 - val_loss: 0.9631 - val_acc: 0.7172\n",
      "Epoch 834/1500\n",
      " - 0s - loss: 0.4243 - acc: 0.8730 - val_loss: 0.9652 - val_acc: 0.7085\n",
      "Epoch 835/1500\n",
      " - 0s - loss: 0.4228 - acc: 0.8715 - val_loss: 0.9658 - val_acc: 0.7026\n",
      "Epoch 836/1500\n",
      " - 0s - loss: 0.4244 - acc: 0.8715 - val_loss: 0.9673 - val_acc: 0.7055\n",
      "Epoch 837/1500\n",
      " - 0s - loss: 0.4240 - acc: 0.8723 - val_loss: 0.9673 - val_acc: 0.7143\n",
      "Epoch 838/1500\n",
      " - 0s - loss: 0.4254 - acc: 0.8679 - val_loss: 0.9654 - val_acc: 0.7026\n",
      "Epoch 839/1500\n",
      " - 0s - loss: 0.4215 - acc: 0.8759 - val_loss: 0.9729 - val_acc: 0.7026\n",
      "Epoch 840/1500\n",
      " - 0s - loss: 0.4225 - acc: 0.8723 - val_loss: 0.9639 - val_acc: 0.7026\n",
      "Epoch 841/1500\n",
      " - 0s - loss: 0.4216 - acc: 0.8701 - val_loss: 0.9701 - val_acc: 0.6997\n",
      "Epoch 842/1500\n",
      " - 0s - loss: 0.4220 - acc: 0.8723 - val_loss: 0.9655 - val_acc: 0.7085\n",
      "Epoch 843/1500\n",
      " - 0s - loss: 0.4234 - acc: 0.8737 - val_loss: 0.9631 - val_acc: 0.7114\n",
      "Epoch 844/1500\n",
      " - 0s - loss: 0.4213 - acc: 0.8715 - val_loss: 0.9656 - val_acc: 0.7114\n",
      "Epoch 845/1500\n",
      " - 0s - loss: 0.4198 - acc: 0.8708 - val_loss: 0.9668 - val_acc: 0.7055\n",
      "Epoch 846/1500\n",
      " - 0s - loss: 0.4202 - acc: 0.8723 - val_loss: 0.9700 - val_acc: 0.7055\n",
      "Epoch 847/1500\n",
      " - 0s - loss: 0.4218 - acc: 0.8752 - val_loss: 0.9629 - val_acc: 0.7114\n",
      "Epoch 848/1500\n",
      " - 0s - loss: 0.4193 - acc: 0.8730 - val_loss: 0.9726 - val_acc: 0.7055\n",
      "Epoch 849/1500\n",
      " - 0s - loss: 0.4205 - acc: 0.8693 - val_loss: 0.9657 - val_acc: 0.7055\n",
      "Epoch 850/1500\n",
      " - 0s - loss: 0.4184 - acc: 0.8752 - val_loss: 0.9676 - val_acc: 0.7085\n",
      "Epoch 851/1500\n",
      " - 0s - loss: 0.4205 - acc: 0.8774 - val_loss: 0.9666 - val_acc: 0.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 852/1500\n",
      " - 0s - loss: 0.4206 - acc: 0.8723 - val_loss: 0.9641 - val_acc: 0.7055\n",
      "Epoch 853/1500\n",
      " - 0s - loss: 0.4189 - acc: 0.8774 - val_loss: 0.9751 - val_acc: 0.6968\n",
      "Epoch 854/1500\n",
      " - 0s - loss: 0.4167 - acc: 0.8730 - val_loss: 0.9689 - val_acc: 0.6968\n",
      "Epoch 855/1500\n",
      " - 0s - loss: 0.4163 - acc: 0.8723 - val_loss: 0.9686 - val_acc: 0.7055\n",
      "Epoch 856/1500\n",
      " - 0s - loss: 0.4173 - acc: 0.8737 - val_loss: 0.9682 - val_acc: 0.7085\n",
      "Epoch 857/1500\n",
      " - 0s - loss: 0.4163 - acc: 0.8737 - val_loss: 0.9722 - val_acc: 0.6997\n",
      "Epoch 858/1500\n",
      " - 0s - loss: 0.4163 - acc: 0.8737 - val_loss: 0.9684 - val_acc: 0.6968\n",
      "Epoch 859/1500\n",
      " - 0s - loss: 0.4162 - acc: 0.8737 - val_loss: 0.9726 - val_acc: 0.7026\n",
      "Epoch 860/1500\n",
      " - 0s - loss: 0.4162 - acc: 0.8781 - val_loss: 0.9673 - val_acc: 0.7114\n",
      "Epoch 861/1500\n",
      " - 0s - loss: 0.4170 - acc: 0.8723 - val_loss: 0.9705 - val_acc: 0.7026\n",
      "Epoch 862/1500\n",
      " - 0s - loss: 0.4167 - acc: 0.8701 - val_loss: 0.9656 - val_acc: 0.7172\n",
      "Epoch 863/1500\n",
      " - 0s - loss: 0.4150 - acc: 0.8723 - val_loss: 0.9742 - val_acc: 0.6910\n",
      "Epoch 864/1500\n",
      " - 0s - loss: 0.4161 - acc: 0.8737 - val_loss: 0.9672 - val_acc: 0.7026\n",
      "Epoch 865/1500\n",
      " - 0s - loss: 0.4143 - acc: 0.8737 - val_loss: 0.9664 - val_acc: 0.7026\n",
      "Epoch 866/1500\n",
      " - 0s - loss: 0.4134 - acc: 0.8759 - val_loss: 0.9709 - val_acc: 0.6968\n",
      "Epoch 867/1500\n",
      " - 0s - loss: 0.4121 - acc: 0.8752 - val_loss: 0.9674 - val_acc: 0.7114\n",
      "Epoch 868/1500\n",
      " - 0s - loss: 0.4139 - acc: 0.8723 - val_loss: 0.9674 - val_acc: 0.7085\n",
      "Epoch 869/1500\n",
      " - 0s - loss: 0.4148 - acc: 0.8723 - val_loss: 0.9700 - val_acc: 0.7055\n",
      "Epoch 870/1500\n",
      " - 0s - loss: 0.4129 - acc: 0.8745 - val_loss: 0.9751 - val_acc: 0.7085\n",
      "Epoch 871/1500\n",
      " - 0s - loss: 0.4125 - acc: 0.8730 - val_loss: 0.9661 - val_acc: 0.6997\n",
      "Epoch 872/1500\n",
      " - 0s - loss: 0.4115 - acc: 0.8737 - val_loss: 0.9712 - val_acc: 0.6997\n",
      "Epoch 873/1500\n",
      " - 0s - loss: 0.4118 - acc: 0.8766 - val_loss: 0.9674 - val_acc: 0.7259\n",
      "Epoch 874/1500\n",
      " - 0s - loss: 0.4109 - acc: 0.8774 - val_loss: 0.9754 - val_acc: 0.6997\n",
      "Epoch 875/1500\n",
      " - 0s - loss: 0.4102 - acc: 0.8752 - val_loss: 0.9679 - val_acc: 0.7085\n",
      "Epoch 876/1500\n",
      " - 0s - loss: 0.4103 - acc: 0.8781 - val_loss: 0.9689 - val_acc: 0.7055\n",
      "Epoch 877/1500\n",
      " - 0s - loss: 0.4103 - acc: 0.8737 - val_loss: 0.9720 - val_acc: 0.7055\n",
      "Epoch 878/1500\n",
      " - 0s - loss: 0.4104 - acc: 0.8730 - val_loss: 0.9677 - val_acc: 0.7026\n",
      "Epoch 879/1500\n",
      " - 0s - loss: 0.4085 - acc: 0.8752 - val_loss: 0.9730 - val_acc: 0.7026\n",
      "Epoch 880/1500\n",
      " - 0s - loss: 0.4109 - acc: 0.8752 - val_loss: 0.9735 - val_acc: 0.7026\n",
      "Epoch 881/1500\n",
      " - 0s - loss: 0.4102 - acc: 0.8766 - val_loss: 0.9690 - val_acc: 0.7055\n",
      "Epoch 882/1500\n",
      " - 0s - loss: 0.4079 - acc: 0.8759 - val_loss: 0.9706 - val_acc: 0.7026\n",
      "Epoch 883/1500\n",
      " - 0s - loss: 0.4084 - acc: 0.8759 - val_loss: 0.9705 - val_acc: 0.6997\n",
      "Epoch 884/1500\n",
      " - 0s - loss: 0.4075 - acc: 0.8759 - val_loss: 0.9668 - val_acc: 0.7114\n",
      "Epoch 885/1500\n",
      " - 0s - loss: 0.4082 - acc: 0.8796 - val_loss: 0.9737 - val_acc: 0.6997\n",
      "Epoch 886/1500\n",
      " - 0s - loss: 0.4069 - acc: 0.8818 - val_loss: 0.9696 - val_acc: 0.6997\n",
      "Epoch 887/1500\n",
      " - 0s - loss: 0.4087 - acc: 0.8781 - val_loss: 0.9710 - val_acc: 0.7143\n",
      "Epoch 888/1500\n",
      " - 0s - loss: 0.4073 - acc: 0.8759 - val_loss: 0.9765 - val_acc: 0.7026\n",
      "Epoch 889/1500\n",
      " - 0s - loss: 0.4061 - acc: 0.8766 - val_loss: 0.9676 - val_acc: 0.7026\n",
      "Epoch 890/1500\n",
      " - 0s - loss: 0.4053 - acc: 0.8788 - val_loss: 0.9771 - val_acc: 0.7026\n",
      "Epoch 891/1500\n",
      " - 0s - loss: 0.4054 - acc: 0.8788 - val_loss: 0.9699 - val_acc: 0.7172\n",
      "Epoch 892/1500\n",
      " - 0s - loss: 0.4057 - acc: 0.8796 - val_loss: 0.9697 - val_acc: 0.6968\n",
      "Epoch 893/1500\n",
      " - 0s - loss: 0.4058 - acc: 0.8788 - val_loss: 0.9738 - val_acc: 0.7114\n",
      "Epoch 894/1500\n",
      " - 0s - loss: 0.4072 - acc: 0.8752 - val_loss: 0.9688 - val_acc: 0.6997\n",
      "Epoch 895/1500\n",
      " - 0s - loss: 0.4068 - acc: 0.8810 - val_loss: 0.9799 - val_acc: 0.6968\n",
      "Epoch 896/1500\n",
      " - 0s - loss: 0.4057 - acc: 0.8781 - val_loss: 0.9696 - val_acc: 0.7055\n",
      "Epoch 897/1500\n",
      " - 0s - loss: 0.4047 - acc: 0.8810 - val_loss: 0.9853 - val_acc: 0.6997\n",
      "Epoch 898/1500\n",
      " - 0s - loss: 0.4053 - acc: 0.8759 - val_loss: 0.9693 - val_acc: 0.7055\n",
      "Epoch 899/1500\n",
      " - 0s - loss: 0.4036 - acc: 0.8759 - val_loss: 0.9732 - val_acc: 0.7085\n",
      "Epoch 900/1500\n",
      " - 0s - loss: 0.4037 - acc: 0.8796 - val_loss: 0.9717 - val_acc: 0.7055\n",
      "Epoch 901/1500\n",
      " - 0s - loss: 0.4032 - acc: 0.8818 - val_loss: 0.9812 - val_acc: 0.6968\n",
      "Epoch 902/1500\n",
      " - 0s - loss: 0.4038 - acc: 0.8730 - val_loss: 0.9681 - val_acc: 0.7055\n",
      "Epoch 903/1500\n",
      " - 0s - loss: 0.4033 - acc: 0.8774 - val_loss: 0.9789 - val_acc: 0.6968\n",
      "Epoch 904/1500\n",
      " - 0s - loss: 0.4024 - acc: 0.8788 - val_loss: 0.9726 - val_acc: 0.7026\n",
      "Epoch 905/1500\n",
      " - 0s - loss: 0.4010 - acc: 0.8774 - val_loss: 0.9720 - val_acc: 0.7085\n",
      "Epoch 906/1500\n",
      " - 0s - loss: 0.4009 - acc: 0.8818 - val_loss: 0.9780 - val_acc: 0.7026\n",
      "Epoch 907/1500\n",
      " - 0s - loss: 0.4020 - acc: 0.8737 - val_loss: 0.9703 - val_acc: 0.7085\n",
      "Epoch 908/1500\n",
      " - 0s - loss: 0.4013 - acc: 0.8781 - val_loss: 0.9801 - val_acc: 0.7055\n",
      "Epoch 909/1500\n",
      " - 0s - loss: 0.4009 - acc: 0.8737 - val_loss: 0.9701 - val_acc: 0.7114\n",
      "Epoch 910/1500\n",
      " - 0s - loss: 0.4004 - acc: 0.8774 - val_loss: 0.9745 - val_acc: 0.7055\n",
      "Epoch 911/1500\n",
      " - 0s - loss: 0.4009 - acc: 0.8796 - val_loss: 0.9751 - val_acc: 0.6968\n",
      "Epoch 912/1500\n",
      " - 0s - loss: 0.4007 - acc: 0.8774 - val_loss: 0.9729 - val_acc: 0.7143\n",
      "Epoch 913/1500\n",
      " - 0s - loss: 0.3985 - acc: 0.8847 - val_loss: 0.9775 - val_acc: 0.7026\n",
      "Epoch 914/1500\n",
      " - 0s - loss: 0.3996 - acc: 0.8788 - val_loss: 0.9692 - val_acc: 0.6997\n",
      "Epoch 915/1500\n",
      " - 0s - loss: 0.4000 - acc: 0.8818 - val_loss: 0.9801 - val_acc: 0.7085\n",
      "Epoch 916/1500\n",
      " - 0s - loss: 0.3976 - acc: 0.8810 - val_loss: 0.9754 - val_acc: 0.7026\n",
      "Epoch 917/1500\n",
      " - 0s - loss: 0.3984 - acc: 0.8781 - val_loss: 0.9762 - val_acc: 0.7114\n",
      "Epoch 918/1500\n",
      " - 0s - loss: 0.3988 - acc: 0.8818 - val_loss: 0.9757 - val_acc: 0.7026\n",
      "Epoch 919/1500\n",
      " - 0s - loss: 0.3979 - acc: 0.8774 - val_loss: 0.9732 - val_acc: 0.7055\n",
      "Epoch 920/1500\n",
      " - 0s - loss: 0.3986 - acc: 0.8774 - val_loss: 0.9880 - val_acc: 0.6939\n",
      "Epoch 921/1500\n",
      " - 0s - loss: 0.3986 - acc: 0.8788 - val_loss: 0.9710 - val_acc: 0.6939\n",
      "Epoch 922/1500\n",
      " - 0s - loss: 0.3965 - acc: 0.8788 - val_loss: 0.9820 - val_acc: 0.7143\n",
      "Epoch 923/1500\n",
      " - 0s - loss: 0.3971 - acc: 0.8788 - val_loss: 0.9709 - val_acc: 0.6939\n",
      "Epoch 924/1500\n",
      " - 0s - loss: 0.3962 - acc: 0.8766 - val_loss: 0.9813 - val_acc: 0.7055\n",
      "Epoch 925/1500\n",
      " - 0s - loss: 0.3965 - acc: 0.8788 - val_loss: 0.9759 - val_acc: 0.7026\n",
      "Epoch 926/1500\n",
      " - 0s - loss: 0.3967 - acc: 0.8766 - val_loss: 0.9772 - val_acc: 0.7114\n",
      "Epoch 927/1500\n",
      " - 0s - loss: 0.3944 - acc: 0.8839 - val_loss: 0.9798 - val_acc: 0.7085\n",
      "Epoch 928/1500\n",
      " - 0s - loss: 0.3954 - acc: 0.8796 - val_loss: 0.9769 - val_acc: 0.7172\n",
      "Epoch 929/1500\n",
      " - 0s - loss: 0.3975 - acc: 0.8796 - val_loss: 0.9820 - val_acc: 0.7026\n",
      "Epoch 930/1500\n",
      " - 0s - loss: 0.3951 - acc: 0.8781 - val_loss: 0.9745 - val_acc: 0.6997\n",
      "Epoch 931/1500\n",
      " - 0s - loss: 0.3947 - acc: 0.8832 - val_loss: 0.9864 - val_acc: 0.7026\n",
      "Epoch 932/1500\n",
      " - 0s - loss: 0.3942 - acc: 0.8839 - val_loss: 0.9744 - val_acc: 0.7085\n",
      "Epoch 933/1500\n",
      " - 0s - loss: 0.3939 - acc: 0.8839 - val_loss: 0.9864 - val_acc: 0.7026\n",
      "Epoch 934/1500\n",
      " - 0s - loss: 0.3932 - acc: 0.8752 - val_loss: 0.9717 - val_acc: 0.7026\n",
      "Epoch 935/1500\n",
      " - 0s - loss: 0.3946 - acc: 0.8818 - val_loss: 0.9767 - val_acc: 0.7026\n",
      "Epoch 936/1500\n",
      " - 0s - loss: 0.3935 - acc: 0.8759 - val_loss: 0.9819 - val_acc: 0.7055\n",
      "Epoch 937/1500\n",
      " - 0s - loss: 0.3918 - acc: 0.8854 - val_loss: 0.9789 - val_acc: 0.7026\n",
      "Epoch 938/1500\n",
      " - 0s - loss: 0.3917 - acc: 0.8810 - val_loss: 0.9762 - val_acc: 0.7026\n",
      "Epoch 939/1500\n",
      " - 0s - loss: 0.3936 - acc: 0.8810 - val_loss: 0.9838 - val_acc: 0.6968\n",
      "Epoch 940/1500\n",
      " - 0s - loss: 0.3920 - acc: 0.8796 - val_loss: 0.9748 - val_acc: 0.6939\n",
      "Epoch 941/1500\n",
      " - 0s - loss: 0.3919 - acc: 0.8766 - val_loss: 0.9763 - val_acc: 0.7026\n",
      "Epoch 942/1500\n",
      " - 0s - loss: 0.3901 - acc: 0.8818 - val_loss: 0.9774 - val_acc: 0.7026\n",
      "Epoch 943/1500\n",
      " - 0s - loss: 0.3903 - acc: 0.8803 - val_loss: 0.9832 - val_acc: 0.7085\n",
      "Epoch 944/1500\n",
      " - 0s - loss: 0.3916 - acc: 0.8818 - val_loss: 0.9790 - val_acc: 0.7055\n",
      "Epoch 945/1500\n",
      " - 0s - loss: 0.3905 - acc: 0.8810 - val_loss: 0.9805 - val_acc: 0.7143\n",
      "Epoch 946/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3898 - acc: 0.8839 - val_loss: 0.9805 - val_acc: 0.7085\n",
      "Epoch 947/1500\n",
      " - 0s - loss: 0.3904 - acc: 0.8832 - val_loss: 0.9771 - val_acc: 0.7055\n",
      "Epoch 948/1500\n",
      " - 0s - loss: 0.3917 - acc: 0.8832 - val_loss: 0.9723 - val_acc: 0.7055\n",
      "Epoch 949/1500\n",
      " - 0s - loss: 0.3898 - acc: 0.8825 - val_loss: 0.9941 - val_acc: 0.7055\n",
      "Epoch 950/1500\n",
      " - 0s - loss: 0.3895 - acc: 0.8781 - val_loss: 0.9742 - val_acc: 0.6939\n",
      "Epoch 951/1500\n",
      " - 0s - loss: 0.3887 - acc: 0.8869 - val_loss: 0.9836 - val_acc: 0.7055\n",
      "Epoch 952/1500\n",
      " - 0s - loss: 0.3880 - acc: 0.8825 - val_loss: 0.9743 - val_acc: 0.6997\n",
      "Epoch 953/1500\n",
      " - 0s - loss: 0.3879 - acc: 0.8839 - val_loss: 0.9853 - val_acc: 0.7055\n",
      "Epoch 954/1500\n",
      " - 0s - loss: 0.3889 - acc: 0.8839 - val_loss: 0.9815 - val_acc: 0.7055\n",
      "Epoch 955/1500\n",
      " - 0s - loss: 0.3882 - acc: 0.8810 - val_loss: 0.9803 - val_acc: 0.7114\n",
      "Epoch 956/1500\n",
      " - 0s - loss: 0.3883 - acc: 0.8818 - val_loss: 0.9799 - val_acc: 0.6968\n",
      "Epoch 957/1500\n",
      " - 0s - loss: 0.3872 - acc: 0.8818 - val_loss: 0.9796 - val_acc: 0.7085\n",
      "Epoch 958/1500\n",
      " - 0s - loss: 0.3881 - acc: 0.8818 - val_loss: 0.9897 - val_acc: 0.7114\n",
      "Epoch 959/1500\n",
      " - 0s - loss: 0.3880 - acc: 0.8818 - val_loss: 0.9779 - val_acc: 0.7085\n",
      "Epoch 960/1500\n",
      " - 0s - loss: 0.3868 - acc: 0.8839 - val_loss: 0.9911 - val_acc: 0.7085\n",
      "Epoch 961/1500\n",
      " - 0s - loss: 0.3861 - acc: 0.8825 - val_loss: 0.9813 - val_acc: 0.7143\n",
      "Epoch 962/1500\n",
      " - 0s - loss: 0.3845 - acc: 0.8861 - val_loss: 0.9822 - val_acc: 0.7114\n",
      "Epoch 963/1500\n",
      " - 0s - loss: 0.3863 - acc: 0.8832 - val_loss: 0.9812 - val_acc: 0.6997\n",
      "Epoch 964/1500\n",
      " - 0s - loss: 0.3865 - acc: 0.8891 - val_loss: 0.9812 - val_acc: 0.7114\n",
      "Epoch 965/1500\n",
      " - 0s - loss: 0.3863 - acc: 0.8832 - val_loss: 0.9786 - val_acc: 0.7026\n",
      "Epoch 966/1500\n",
      " - 0s - loss: 0.3849 - acc: 0.8869 - val_loss: 0.9880 - val_acc: 0.7055\n",
      "Epoch 967/1500\n",
      " - 0s - loss: 0.3867 - acc: 0.8861 - val_loss: 0.9779 - val_acc: 0.7114\n",
      "Epoch 968/1500\n",
      " - 0s - loss: 0.3857 - acc: 0.8847 - val_loss: 0.9847 - val_acc: 0.6997\n",
      "Epoch 969/1500\n",
      " - 0s - loss: 0.3838 - acc: 0.8854 - val_loss: 0.9842 - val_acc: 0.7143\n",
      "Epoch 970/1500\n",
      " - 0s - loss: 0.3825 - acc: 0.8839 - val_loss: 0.9798 - val_acc: 0.7055\n",
      "Epoch 971/1500\n",
      " - 0s - loss: 0.3837 - acc: 0.8825 - val_loss: 0.9771 - val_acc: 0.6968\n",
      "Epoch 972/1500\n",
      " - 0s - loss: 0.3837 - acc: 0.8876 - val_loss: 0.9828 - val_acc: 0.7085\n",
      "Epoch 973/1500\n",
      " - 0s - loss: 0.3826 - acc: 0.8832 - val_loss: 0.9845 - val_acc: 0.7114\n",
      "Epoch 974/1500\n",
      " - 0s - loss: 0.3832 - acc: 0.8861 - val_loss: 0.9841 - val_acc: 0.7026\n",
      "Epoch 975/1500\n",
      " - 0s - loss: 0.3820 - acc: 0.8825 - val_loss: 0.9825 - val_acc: 0.7055\n",
      "Epoch 976/1500\n",
      " - 0s - loss: 0.3822 - acc: 0.8839 - val_loss: 0.9860 - val_acc: 0.7143\n",
      "Epoch 977/1500\n",
      " - 0s - loss: 0.3832 - acc: 0.8818 - val_loss: 0.9800 - val_acc: 0.7055\n",
      "Epoch 978/1500\n",
      " - 0s - loss: 0.3809 - acc: 0.8832 - val_loss: 0.9943 - val_acc: 0.7172\n",
      "Epoch 979/1500\n",
      " - 0s - loss: 0.3829 - acc: 0.8861 - val_loss: 0.9809 - val_acc: 0.6997\n",
      "Epoch 980/1500\n",
      " - 0s - loss: 0.3807 - acc: 0.8861 - val_loss: 0.9814 - val_acc: 0.7055\n",
      "Epoch 981/1500\n",
      " - 0s - loss: 0.3818 - acc: 0.8847 - val_loss: 0.9836 - val_acc: 0.7114\n",
      "Epoch 982/1500\n",
      " - 0s - loss: 0.3815 - acc: 0.8854 - val_loss: 0.9875 - val_acc: 0.7085\n",
      "Epoch 983/1500\n",
      " - 0s - loss: 0.3807 - acc: 0.8839 - val_loss: 0.9804 - val_acc: 0.7055\n",
      "Epoch 984/1500\n",
      " - 0s - loss: 0.3822 - acc: 0.8883 - val_loss: 0.9856 - val_acc: 0.7114\n",
      "Epoch 985/1500\n",
      " - 0s - loss: 0.3808 - acc: 0.8832 - val_loss: 0.9864 - val_acc: 0.7114\n",
      "Epoch 986/1500\n",
      " - 0s - loss: 0.3810 - acc: 0.8810 - val_loss: 0.9806 - val_acc: 0.7085\n",
      "Epoch 987/1500\n",
      " - 0s - loss: 0.3815 - acc: 0.8869 - val_loss: 0.9886 - val_acc: 0.7114\n",
      "Epoch 988/1500\n",
      " - 0s - loss: 0.3825 - acc: 0.8934 - val_loss: 0.9846 - val_acc: 0.6997\n",
      "Epoch 989/1500\n",
      " - 0s - loss: 0.3779 - acc: 0.8883 - val_loss: 0.9898 - val_acc: 0.7114\n",
      "Epoch 990/1500\n",
      " - 0s - loss: 0.3767 - acc: 0.8876 - val_loss: 0.9864 - val_acc: 0.7055\n",
      "Epoch 991/1500\n",
      " - 0s - loss: 0.3789 - acc: 0.8832 - val_loss: 0.9854 - val_acc: 0.7143\n",
      "Epoch 992/1500\n",
      " - 0s - loss: 0.3789 - acc: 0.8883 - val_loss: 0.9903 - val_acc: 0.7172\n",
      "Epoch 993/1500\n",
      " - 0s - loss: 0.3774 - acc: 0.8839 - val_loss: 0.9822 - val_acc: 0.6997\n",
      "Epoch 994/1500\n",
      " - 0s - loss: 0.3771 - acc: 0.8861 - val_loss: 0.9915 - val_acc: 0.7026\n",
      "Epoch 995/1500\n",
      " - 0s - loss: 0.3781 - acc: 0.8883 - val_loss: 0.9832 - val_acc: 0.7114\n",
      "Epoch 996/1500\n",
      " - 0s - loss: 0.3772 - acc: 0.8861 - val_loss: 0.9946 - val_acc: 0.7114\n",
      "Epoch 997/1500\n",
      " - 0s - loss: 0.3772 - acc: 0.8876 - val_loss: 0.9854 - val_acc: 0.7055\n",
      "Epoch 998/1500\n",
      " - 0s - loss: 0.3780 - acc: 0.8861 - val_loss: 0.9856 - val_acc: 0.7085\n",
      "Epoch 999/1500\n",
      " - 0s - loss: 0.3794 - acc: 0.8905 - val_loss: 0.9951 - val_acc: 0.7055\n",
      "Epoch 1000/1500\n",
      " - 0s - loss: 0.3756 - acc: 0.8825 - val_loss: 0.9807 - val_acc: 0.7026\n",
      "Epoch 1001/1500\n",
      " - 0s - loss: 0.3759 - acc: 0.8876 - val_loss: 0.9857 - val_acc: 0.7055\n",
      "Epoch 1002/1500\n",
      " - 0s - loss: 0.3758 - acc: 0.8861 - val_loss: 0.9856 - val_acc: 0.7114\n",
      "Epoch 1003/1500\n",
      " - 0s - loss: 0.3748 - acc: 0.8869 - val_loss: 0.9889 - val_acc: 0.7085\n",
      "Epoch 1004/1500\n",
      " - 0s - loss: 0.3753 - acc: 0.8891 - val_loss: 0.9848 - val_acc: 0.7055\n",
      "Epoch 1005/1500\n",
      " - 0s - loss: 0.3745 - acc: 0.8891 - val_loss: 0.9849 - val_acc: 0.7055\n",
      "Epoch 1006/1500\n",
      " - 0s - loss: 0.3744 - acc: 0.8869 - val_loss: 0.9912 - val_acc: 0.7201\n",
      "Epoch 1007/1500\n",
      " - 0s - loss: 0.3748 - acc: 0.8912 - val_loss: 0.9887 - val_acc: 0.7055\n",
      "Epoch 1008/1500\n",
      " - 0s - loss: 0.3755 - acc: 0.8883 - val_loss: 0.9884 - val_acc: 0.7055\n",
      "Epoch 1009/1500\n",
      " - 0s - loss: 0.3750 - acc: 0.8912 - val_loss: 0.9907 - val_acc: 0.7085\n",
      "Epoch 1010/1500\n",
      " - 0s - loss: 0.3733 - acc: 0.8810 - val_loss: 0.9899 - val_acc: 0.7114\n",
      "Epoch 1011/1500\n",
      " - 0s - loss: 0.3727 - acc: 0.8883 - val_loss: 0.9855 - val_acc: 0.7055\n",
      "Epoch 1012/1500\n",
      " - 0s - loss: 0.3719 - acc: 0.8905 - val_loss: 0.9897 - val_acc: 0.7114\n",
      "Epoch 1013/1500\n",
      " - 0s - loss: 0.3724 - acc: 0.8883 - val_loss: 0.9877 - val_acc: 0.7114\n",
      "Epoch 1014/1500\n",
      " - 0s - loss: 0.3731 - acc: 0.8920 - val_loss: 0.9975 - val_acc: 0.7085\n",
      "Epoch 1015/1500\n",
      " - 0s - loss: 0.3738 - acc: 0.8876 - val_loss: 0.9900 - val_acc: 0.7172\n",
      "Epoch 1016/1500\n",
      " - 0s - loss: 0.3716 - acc: 0.8891 - val_loss: 0.9908 - val_acc: 0.7114\n",
      "Epoch 1017/1500\n",
      " - 0s - loss: 0.3695 - acc: 0.8891 - val_loss: 0.9920 - val_acc: 0.7172\n",
      "Epoch 1018/1500\n",
      " - 0s - loss: 0.3705 - acc: 0.8912 - val_loss: 0.9857 - val_acc: 0.6997\n",
      "Epoch 1019/1500\n",
      " - 0s - loss: 0.3702 - acc: 0.8869 - val_loss: 0.9876 - val_acc: 0.7114\n",
      "Epoch 1020/1500\n",
      " - 0s - loss: 0.3712 - acc: 0.8912 - val_loss: 0.9930 - val_acc: 0.7085\n",
      "Epoch 1021/1500\n",
      " - 0s - loss: 0.3770 - acc: 0.8854 - val_loss: 0.9863 - val_acc: 0.7055\n",
      "Epoch 1022/1500\n",
      " - 0s - loss: 0.3715 - acc: 0.8876 - val_loss: 0.9915 - val_acc: 0.7143\n",
      "Epoch 1023/1500\n",
      " - 0s - loss: 0.3716 - acc: 0.8942 - val_loss: 0.9904 - val_acc: 0.7085\n",
      "Epoch 1024/1500\n",
      " - 0s - loss: 0.3702 - acc: 0.8891 - val_loss: 0.9870 - val_acc: 0.7085\n",
      "Epoch 1025/1500\n",
      " - 0s - loss: 0.3695 - acc: 0.8869 - val_loss: 1.0017 - val_acc: 0.7172\n",
      "Epoch 1026/1500\n",
      " - 0s - loss: 0.3735 - acc: 0.8854 - val_loss: 0.9866 - val_acc: 0.6997\n",
      "Epoch 1027/1500\n",
      " - 0s - loss: 0.3707 - acc: 0.8934 - val_loss: 0.9937 - val_acc: 0.7201\n",
      "Epoch 1028/1500\n",
      " - 0s - loss: 0.3685 - acc: 0.8905 - val_loss: 0.9907 - val_acc: 0.7114\n",
      "Epoch 1029/1500\n",
      " - 0s - loss: 0.3673 - acc: 0.8920 - val_loss: 0.9915 - val_acc: 0.7085\n",
      "Epoch 1030/1500\n",
      " - 0s - loss: 0.3675 - acc: 0.8898 - val_loss: 0.9931 - val_acc: 0.7085\n",
      "Epoch 1031/1500\n",
      " - 0s - loss: 0.3669 - acc: 0.8927 - val_loss: 0.9899 - val_acc: 0.7026\n",
      "Epoch 1032/1500\n",
      " - 0s - loss: 0.3692 - acc: 0.8912 - val_loss: 0.9890 - val_acc: 0.7055\n",
      "Epoch 1033/1500\n",
      " - 0s - loss: 0.3708 - acc: 0.8905 - val_loss: 0.9855 - val_acc: 0.7026\n",
      "Epoch 1034/1500\n",
      " - 0s - loss: 0.3696 - acc: 0.8920 - val_loss: 0.9939 - val_acc: 0.7201\n",
      "Epoch 1035/1500\n",
      " - 0s - loss: 0.3670 - acc: 0.8934 - val_loss: 0.9915 - val_acc: 0.7085\n",
      "Epoch 1036/1500\n",
      " - 0s - loss: 0.3677 - acc: 0.8956 - val_loss: 0.9889 - val_acc: 0.7026\n",
      "Epoch 1037/1500\n",
      " - 0s - loss: 0.3660 - acc: 0.8891 - val_loss: 0.9917 - val_acc: 0.7055\n",
      "Epoch 1038/1500\n",
      " - 0s - loss: 0.3671 - acc: 0.8905 - val_loss: 0.9893 - val_acc: 0.7026\n",
      "Epoch 1039/1500\n",
      " - 0s - loss: 0.3677 - acc: 0.8905 - val_loss: 0.9981 - val_acc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/1500\n",
      " - 0s - loss: 0.3685 - acc: 0.8927 - val_loss: 0.9900 - val_acc: 0.7055\n",
      "Epoch 1041/1500\n",
      " - 0s - loss: 0.3645 - acc: 0.8927 - val_loss: 0.9936 - val_acc: 0.7085\n",
      "Epoch 1042/1500\n",
      " - 0s - loss: 0.3641 - acc: 0.8920 - val_loss: 0.9957 - val_acc: 0.7172\n",
      "Epoch 1043/1500\n",
      " - 0s - loss: 0.3653 - acc: 0.8920 - val_loss: 0.9921 - val_acc: 0.7085\n",
      "Epoch 1044/1500\n",
      " - 0s - loss: 0.3645 - acc: 0.8927 - val_loss: 0.9903 - val_acc: 0.6968\n",
      "Epoch 1045/1500\n",
      " - 0s - loss: 0.3654 - acc: 0.8920 - val_loss: 0.9968 - val_acc: 0.7114\n",
      "Epoch 1046/1500\n",
      " - 0s - loss: 0.3653 - acc: 0.8920 - val_loss: 0.9940 - val_acc: 0.7114\n",
      "Epoch 1047/1500\n",
      " - 0s - loss: 0.3631 - acc: 0.8942 - val_loss: 0.9955 - val_acc: 0.7143\n",
      "Epoch 1048/1500\n",
      " - 0s - loss: 0.3637 - acc: 0.8927 - val_loss: 0.9952 - val_acc: 0.7026\n",
      "Epoch 1049/1500\n",
      " - 0s - loss: 0.3622 - acc: 0.8905 - val_loss: 0.9945 - val_acc: 0.7172\n",
      "Epoch 1050/1500\n",
      " - 0s - loss: 0.3628 - acc: 0.8956 - val_loss: 0.9966 - val_acc: 0.7143\n",
      "Epoch 1051/1500\n",
      " - 0s - loss: 0.3632 - acc: 0.8927 - val_loss: 0.9879 - val_acc: 0.7085\n",
      "Epoch 1052/1500\n",
      " - 0s - loss: 0.3676 - acc: 0.8861 - val_loss: 0.9972 - val_acc: 0.7026\n",
      "Epoch 1053/1500\n",
      " - 0s - loss: 0.3628 - acc: 0.8912 - val_loss: 0.9918 - val_acc: 0.7114\n",
      "Epoch 1054/1500\n",
      " - 0s - loss: 0.3662 - acc: 0.8956 - val_loss: 0.9880 - val_acc: 0.7026\n",
      "Epoch 1055/1500\n",
      " - 0s - loss: 0.3636 - acc: 0.8927 - val_loss: 0.9960 - val_acc: 0.7172\n",
      "Epoch 1056/1500\n",
      " - 0s - loss: 0.3613 - acc: 0.8905 - val_loss: 0.9908 - val_acc: 0.7114\n",
      "Epoch 1057/1500\n",
      " - 0s - loss: 0.3613 - acc: 0.8905 - val_loss: 1.0000 - val_acc: 0.7085\n",
      "Epoch 1058/1500\n",
      " - 0s - loss: 0.3610 - acc: 0.8942 - val_loss: 0.9920 - val_acc: 0.7085\n",
      "Epoch 1059/1500\n",
      " - 0s - loss: 0.3633 - acc: 0.8898 - val_loss: 0.9953 - val_acc: 0.7085\n",
      "Epoch 1060/1500\n",
      " - 0s - loss: 0.3625 - acc: 0.8956 - val_loss: 0.9951 - val_acc: 0.7114\n",
      "Epoch 1061/1500\n",
      " - 0s - loss: 0.3603 - acc: 0.8964 - val_loss: 0.9955 - val_acc: 0.7172\n",
      "Epoch 1062/1500\n",
      " - 0s - loss: 0.3609 - acc: 0.8942 - val_loss: 0.9951 - val_acc: 0.7114\n",
      "Epoch 1063/1500\n",
      " - 0s - loss: 0.3604 - acc: 0.8956 - val_loss: 0.9916 - val_acc: 0.7114\n",
      "Epoch 1064/1500\n",
      " - 0s - loss: 0.3593 - acc: 0.8920 - val_loss: 1.0026 - val_acc: 0.7114\n",
      "Epoch 1065/1500\n",
      " - 0s - loss: 0.3587 - acc: 0.8942 - val_loss: 0.9894 - val_acc: 0.7055\n",
      "Epoch 1066/1500\n",
      " - 0s - loss: 0.3591 - acc: 0.8956 - val_loss: 1.0032 - val_acc: 0.7172\n",
      "Epoch 1067/1500\n",
      " - 0s - loss: 0.3598 - acc: 0.8927 - val_loss: 0.9931 - val_acc: 0.7143\n",
      "Epoch 1068/1500\n",
      " - 0s - loss: 0.3589 - acc: 0.8949 - val_loss: 0.9945 - val_acc: 0.7085\n",
      "Epoch 1069/1500\n",
      " - 0s - loss: 0.3589 - acc: 0.8942 - val_loss: 1.0012 - val_acc: 0.7201\n",
      "Epoch 1070/1500\n",
      " - 0s - loss: 0.3599 - acc: 0.8949 - val_loss: 1.0008 - val_acc: 0.7172\n",
      "Epoch 1071/1500\n",
      " - 0s - loss: 0.3613 - acc: 0.8949 - val_loss: 0.9921 - val_acc: 0.7172\n",
      "Epoch 1072/1500\n",
      " - 0s - loss: 0.3594 - acc: 0.8949 - val_loss: 0.9957 - val_acc: 0.7055\n",
      "Epoch 1073/1500\n",
      " - 0s - loss: 0.3577 - acc: 0.8927 - val_loss: 0.9989 - val_acc: 0.7143\n",
      "Epoch 1074/1500\n",
      " - 0s - loss: 0.3589 - acc: 0.8905 - val_loss: 0.9948 - val_acc: 0.6997\n",
      "Epoch 1075/1500\n",
      " - 0s - loss: 0.3567 - acc: 0.8956 - val_loss: 0.9962 - val_acc: 0.7085\n",
      "Epoch 1076/1500\n",
      " - 0s - loss: 0.3579 - acc: 0.8934 - val_loss: 0.9935 - val_acc: 0.7055\n",
      "Epoch 1077/1500\n",
      " - 0s - loss: 0.3569 - acc: 0.8927 - val_loss: 1.0018 - val_acc: 0.7114\n",
      "Epoch 1078/1500\n",
      " - 0s - loss: 0.3580 - acc: 0.8934 - val_loss: 1.0011 - val_acc: 0.7114\n",
      "Epoch 1079/1500\n",
      " - 0s - loss: 0.3579 - acc: 0.8912 - val_loss: 0.9993 - val_acc: 0.7026\n",
      "Epoch 1080/1500\n",
      " - 0s - loss: 0.3561 - acc: 0.8949 - val_loss: 1.0053 - val_acc: 0.7201\n",
      "Epoch 1081/1500\n",
      " - 0s - loss: 0.3573 - acc: 0.8920 - val_loss: 0.9940 - val_acc: 0.7143\n",
      "Epoch 1082/1500\n",
      " - 0s - loss: 0.3549 - acc: 0.8920 - val_loss: 0.9997 - val_acc: 0.7201\n",
      "Epoch 1083/1500\n",
      " - 0s - loss: 0.3560 - acc: 0.8927 - val_loss: 0.9971 - val_acc: 0.6968\n",
      "Epoch 1084/1500\n",
      " - 0s - loss: 0.3548 - acc: 0.8978 - val_loss: 1.0000 - val_acc: 0.7085\n",
      "Epoch 1085/1500\n",
      " - 0s - loss: 0.3569 - acc: 0.8927 - val_loss: 0.9946 - val_acc: 0.7085\n",
      "Epoch 1086/1500\n",
      " - 0s - loss: 0.3552 - acc: 0.8934 - val_loss: 1.0021 - val_acc: 0.7143\n",
      "Epoch 1087/1500\n",
      " - 0s - loss: 0.3549 - acc: 0.8942 - val_loss: 1.0040 - val_acc: 0.7172\n",
      "Epoch 1088/1500\n",
      " - 0s - loss: 0.3554 - acc: 0.8942 - val_loss: 0.9922 - val_acc: 0.7026\n",
      "Epoch 1089/1500\n",
      " - 0s - loss: 0.3557 - acc: 0.8956 - val_loss: 1.0014 - val_acc: 0.7143\n",
      "Epoch 1090/1500\n",
      " - 0s - loss: 0.3539 - acc: 0.8927 - val_loss: 1.0020 - val_acc: 0.7172\n",
      "Epoch 1091/1500\n",
      " - 0s - loss: 0.3545 - acc: 0.8920 - val_loss: 1.0018 - val_acc: 0.7114\n",
      "Epoch 1092/1500\n",
      " - 0s - loss: 0.3527 - acc: 0.8956 - val_loss: 0.9977 - val_acc: 0.7085\n",
      "Epoch 1093/1500\n",
      " - 0s - loss: 0.3516 - acc: 0.8942 - val_loss: 0.9983 - val_acc: 0.7143\n",
      "Epoch 1094/1500\n",
      " - 0s - loss: 0.3519 - acc: 0.8978 - val_loss: 1.0045 - val_acc: 0.7143\n",
      "Epoch 1095/1500\n",
      " - 0s - loss: 0.3537 - acc: 0.8949 - val_loss: 0.9968 - val_acc: 0.7055\n",
      "Epoch 1096/1500\n",
      " - 0s - loss: 0.3534 - acc: 0.8978 - val_loss: 0.9983 - val_acc: 0.7055\n",
      "Epoch 1097/1500\n",
      " - 0s - loss: 0.3529 - acc: 0.8912 - val_loss: 1.0091 - val_acc: 0.7201\n",
      "Epoch 1098/1500\n",
      " - 0s - loss: 0.3537 - acc: 0.8978 - val_loss: 1.0035 - val_acc: 0.7055\n",
      "Epoch 1099/1500\n",
      " - 0s - loss: 0.3538 - acc: 0.8920 - val_loss: 0.9993 - val_acc: 0.7055\n",
      "Epoch 1100/1500\n",
      " - 0s - loss: 0.3510 - acc: 0.8942 - val_loss: 1.0031 - val_acc: 0.7085\n",
      "Epoch 1101/1500\n",
      " - 0s - loss: 0.3522 - acc: 0.8949 - val_loss: 1.0007 - val_acc: 0.7143\n",
      "Epoch 1102/1500\n",
      " - 0s - loss: 0.3501 - acc: 0.8956 - val_loss: 0.9959 - val_acc: 0.7026\n",
      "Epoch 1103/1500\n",
      " - 0s - loss: 0.3505 - acc: 0.8971 - val_loss: 1.0038 - val_acc: 0.7143\n",
      "Epoch 1104/1500\n",
      " - 0s - loss: 0.3504 - acc: 0.8942 - val_loss: 1.0010 - val_acc: 0.7085\n",
      "Epoch 1105/1500\n",
      " - 0s - loss: 0.3503 - acc: 0.8971 - val_loss: 0.9977 - val_acc: 0.7085\n",
      "Epoch 1106/1500\n",
      " - 0s - loss: 0.3502 - acc: 0.8942 - val_loss: 1.0052 - val_acc: 0.7114\n",
      "Epoch 1107/1500\n",
      " - 0s - loss: 0.3506 - acc: 0.8993 - val_loss: 0.9973 - val_acc: 0.7026\n",
      "Epoch 1108/1500\n",
      " - 0s - loss: 0.3490 - acc: 0.8978 - val_loss: 1.0053 - val_acc: 0.7172\n",
      "Epoch 1109/1500\n",
      " - 0s - loss: 0.3490 - acc: 0.8978 - val_loss: 0.9986 - val_acc: 0.7114\n",
      "Epoch 1110/1500\n",
      " - 0s - loss: 0.3489 - acc: 0.8949 - val_loss: 0.9995 - val_acc: 0.7085\n",
      "Epoch 1111/1500\n",
      " - 0s - loss: 0.3491 - acc: 0.8956 - val_loss: 1.0070 - val_acc: 0.7143\n",
      "Epoch 1112/1500\n",
      " - 0s - loss: 0.3486 - acc: 0.8985 - val_loss: 1.0060 - val_acc: 0.7085\n",
      "Epoch 1113/1500\n",
      " - 0s - loss: 0.3489 - acc: 0.8956 - val_loss: 1.0001 - val_acc: 0.7114\n",
      "Epoch 1114/1500\n",
      " - 0s - loss: 0.3489 - acc: 0.8993 - val_loss: 1.0032 - val_acc: 0.7085\n",
      "Epoch 1115/1500\n",
      " - 0s - loss: 0.3470 - acc: 0.8956 - val_loss: 1.0001 - val_acc: 0.7085\n",
      "Epoch 1116/1500\n",
      " - 0s - loss: 0.3469 - acc: 0.8934 - val_loss: 1.0031 - val_acc: 0.7085\n",
      "Epoch 1117/1500\n",
      " - 0s - loss: 0.3487 - acc: 0.8985 - val_loss: 1.0065 - val_acc: 0.7143\n",
      "Epoch 1118/1500\n",
      " - 0s - loss: 0.3491 - acc: 0.8956 - val_loss: 0.9993 - val_acc: 0.7085\n",
      "Epoch 1119/1500\n",
      " - 0s - loss: 0.3461 - acc: 0.8971 - val_loss: 1.0029 - val_acc: 0.7172\n",
      "Epoch 1120/1500\n",
      " - 0s - loss: 0.3483 - acc: 0.8956 - val_loss: 1.0061 - val_acc: 0.7085\n",
      "Epoch 1121/1500\n",
      " - 0s - loss: 0.3455 - acc: 0.8971 - val_loss: 0.9978 - val_acc: 0.7085\n",
      "Epoch 1122/1500\n",
      " - 0s - loss: 0.3460 - acc: 0.8978 - val_loss: 1.0030 - val_acc: 0.7143\n",
      "Epoch 1123/1500\n",
      " - 0s - loss: 0.3464 - acc: 0.8985 - val_loss: 1.0066 - val_acc: 0.7143\n",
      "Epoch 1124/1500\n",
      " - 0s - loss: 0.3470 - acc: 0.8971 - val_loss: 0.9979 - val_acc: 0.7085\n",
      "Epoch 1125/1500\n",
      " - 0s - loss: 0.3456 - acc: 0.8978 - val_loss: 1.0019 - val_acc: 0.7085\n",
      "Epoch 1126/1500\n",
      " - 0s - loss: 0.3456 - acc: 0.8964 - val_loss: 1.0022 - val_acc: 0.7114\n",
      "Epoch 1127/1500\n",
      " - 0s - loss: 0.3464 - acc: 0.8956 - val_loss: 1.0029 - val_acc: 0.7055\n",
      "Epoch 1128/1500\n",
      " - 0s - loss: 0.3448 - acc: 0.8964 - val_loss: 1.0028 - val_acc: 0.7114\n",
      "Epoch 1129/1500\n",
      " - 0s - loss: 0.3451 - acc: 0.8949 - val_loss: 1.0076 - val_acc: 0.7143\n",
      "Epoch 1130/1500\n",
      " - 0s - loss: 0.3440 - acc: 0.9007 - val_loss: 0.9993 - val_acc: 0.6997\n",
      "Epoch 1131/1500\n",
      " - 0s - loss: 0.3444 - acc: 0.8964 - val_loss: 1.0201 - val_acc: 0.7259\n",
      "Epoch 1132/1500\n",
      " - 0s - loss: 0.3460 - acc: 0.8942 - val_loss: 1.0001 - val_acc: 0.7055\n",
      "Epoch 1133/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3446 - acc: 0.8971 - val_loss: 1.0074 - val_acc: 0.7085\n",
      "Epoch 1134/1500\n",
      " - 0s - loss: 0.3453 - acc: 0.8949 - val_loss: 1.0048 - val_acc: 0.7085\n",
      "Epoch 1135/1500\n",
      " - 0s - loss: 0.3430 - acc: 0.8978 - val_loss: 1.0038 - val_acc: 0.7055\n",
      "Epoch 1136/1500\n",
      " - 0s - loss: 0.3451 - acc: 0.8993 - val_loss: 1.0050 - val_acc: 0.7085\n",
      "Epoch 1137/1500\n",
      " - 0s - loss: 0.3437 - acc: 0.8971 - val_loss: 1.0007 - val_acc: 0.7085\n",
      "Epoch 1138/1500\n",
      " - 0s - loss: 0.3427 - acc: 0.9000 - val_loss: 1.0055 - val_acc: 0.7114\n",
      "Epoch 1139/1500\n",
      " - 0s - loss: 0.3445 - acc: 0.8971 - val_loss: 1.0080 - val_acc: 0.7201\n",
      "Epoch 1140/1500\n",
      " - 0s - loss: 0.3442 - acc: 0.9000 - val_loss: 1.0065 - val_acc: 0.7085\n",
      "Epoch 1141/1500\n",
      " - 0s - loss: 0.3427 - acc: 0.9000 - val_loss: 1.0098 - val_acc: 0.7114\n",
      "Epoch 1142/1500\n",
      " - 0s - loss: 0.3416 - acc: 0.8949 - val_loss: 1.0059 - val_acc: 0.7114\n",
      "Epoch 1143/1500\n",
      " - 0s - loss: 0.3401 - acc: 0.9022 - val_loss: 1.0074 - val_acc: 0.7085\n",
      "Epoch 1144/1500\n",
      " - 0s - loss: 0.3406 - acc: 0.8985 - val_loss: 1.0007 - val_acc: 0.7085\n",
      "Epoch 1145/1500\n",
      " - 0s - loss: 0.3401 - acc: 0.8971 - val_loss: 1.0077 - val_acc: 0.7143\n",
      "Epoch 1146/1500\n",
      " - 0s - loss: 0.3406 - acc: 0.9000 - val_loss: 1.0037 - val_acc: 0.7143\n",
      "Epoch 1147/1500\n",
      " - 0s - loss: 0.3397 - acc: 0.9007 - val_loss: 1.0128 - val_acc: 0.7143\n",
      "Epoch 1148/1500\n",
      " - 0s - loss: 0.3404 - acc: 0.8964 - val_loss: 1.0020 - val_acc: 0.7114\n",
      "Epoch 1149/1500\n",
      " - 0s - loss: 0.3401 - acc: 0.9007 - val_loss: 1.0105 - val_acc: 0.7143\n",
      "Epoch 1150/1500\n",
      " - 0s - loss: 0.3392 - acc: 0.8993 - val_loss: 1.0058 - val_acc: 0.7085\n",
      "Epoch 1151/1500\n",
      " - 0s - loss: 0.3395 - acc: 0.8993 - val_loss: 1.0068 - val_acc: 0.7085\n",
      "Epoch 1152/1500\n",
      " - 0s - loss: 0.3397 - acc: 0.9007 - val_loss: 1.0046 - val_acc: 0.7085\n",
      "Epoch 1153/1500\n",
      " - 0s - loss: 0.3411 - acc: 0.9000 - val_loss: 1.0033 - val_acc: 0.7055\n",
      "Epoch 1154/1500\n",
      " - 0s - loss: 0.3400 - acc: 0.9029 - val_loss: 1.0133 - val_acc: 0.7114\n",
      "Epoch 1155/1500\n",
      " - 0s - loss: 0.3397 - acc: 0.9000 - val_loss: 1.0013 - val_acc: 0.7114\n",
      "Epoch 1156/1500\n",
      " - 0s - loss: 0.3408 - acc: 0.9000 - val_loss: 1.0087 - val_acc: 0.7085\n",
      "Epoch 1157/1500\n",
      " - 0s - loss: 0.3391 - acc: 0.9015 - val_loss: 1.0109 - val_acc: 0.7230\n",
      "Epoch 1158/1500\n",
      " - 0s - loss: 0.3379 - acc: 0.8985 - val_loss: 1.0086 - val_acc: 0.7085\n",
      "Epoch 1159/1500\n",
      " - 0s - loss: 0.3392 - acc: 0.9007 - val_loss: 1.0143 - val_acc: 0.7201\n",
      "Epoch 1160/1500\n",
      " - 0s - loss: 0.3396 - acc: 0.9007 - val_loss: 1.0067 - val_acc: 0.7114\n",
      "Epoch 1161/1500\n",
      " - 0s - loss: 0.3392 - acc: 0.9029 - val_loss: 1.0054 - val_acc: 0.7055\n",
      "Epoch 1162/1500\n",
      " - 0s - loss: 0.3384 - acc: 0.9015 - val_loss: 1.0096 - val_acc: 0.7114\n",
      "Epoch 1163/1500\n",
      " - 0s - loss: 0.3355 - acc: 0.9029 - val_loss: 1.0093 - val_acc: 0.7085\n",
      "Epoch 1164/1500\n",
      " - 0s - loss: 0.3361 - acc: 0.9029 - val_loss: 1.0079 - val_acc: 0.7055\n",
      "Epoch 1165/1500\n",
      " - 0s - loss: 0.3355 - acc: 0.9015 - val_loss: 1.0080 - val_acc: 0.7055\n",
      "Epoch 1166/1500\n",
      " - 0s - loss: 0.3377 - acc: 0.8971 - val_loss: 1.0096 - val_acc: 0.7172\n",
      "Epoch 1167/1500\n",
      " - 0s - loss: 0.3371 - acc: 0.9029 - val_loss: 1.0111 - val_acc: 0.7114\n",
      "Epoch 1168/1500\n",
      " - 0s - loss: 0.3374 - acc: 0.8993 - val_loss: 1.0035 - val_acc: 0.7026\n",
      "Epoch 1169/1500\n",
      " - 0s - loss: 0.3374 - acc: 0.9036 - val_loss: 1.0079 - val_acc: 0.6997\n",
      "Epoch 1170/1500\n",
      " - 0s - loss: 0.3360 - acc: 0.8993 - val_loss: 1.0146 - val_acc: 0.7085\n",
      "Epoch 1171/1500\n",
      " - 0s - loss: 0.3352 - acc: 0.8993 - val_loss: 1.0059 - val_acc: 0.6997\n",
      "Epoch 1172/1500\n",
      " - 0s - loss: 0.3365 - acc: 0.9000 - val_loss: 1.0168 - val_acc: 0.7114\n",
      "Epoch 1173/1500\n",
      " - 0s - loss: 0.3360 - acc: 0.9000 - val_loss: 1.0068 - val_acc: 0.7055\n",
      "Epoch 1174/1500\n",
      " - 0s - loss: 0.3346 - acc: 0.9036 - val_loss: 1.0085 - val_acc: 0.7114\n",
      "Epoch 1175/1500\n",
      " - 0s - loss: 0.3349 - acc: 0.9029 - val_loss: 1.0113 - val_acc: 0.7114\n",
      "Epoch 1176/1500\n",
      " - 0s - loss: 0.3351 - acc: 0.8993 - val_loss: 1.0094 - val_acc: 0.7143\n",
      "Epoch 1177/1500\n",
      " - 0s - loss: 0.3330 - acc: 0.9015 - val_loss: 1.0167 - val_acc: 0.7055\n",
      "Epoch 1178/1500\n",
      " - 0s - loss: 0.3362 - acc: 0.8985 - val_loss: 1.0089 - val_acc: 0.7085\n",
      "Epoch 1179/1500\n",
      " - 0s - loss: 0.3334 - acc: 0.9029 - val_loss: 1.0065 - val_acc: 0.7055\n",
      "Epoch 1180/1500\n",
      " - 0s - loss: 0.3338 - acc: 0.9044 - val_loss: 1.0142 - val_acc: 0.7143\n",
      "Epoch 1181/1500\n",
      " - 0s - loss: 0.3342 - acc: 0.9015 - val_loss: 1.0055 - val_acc: 0.7114\n",
      "Epoch 1182/1500\n",
      " - 0s - loss: 0.3352 - acc: 0.9044 - val_loss: 1.0103 - val_acc: 0.7026\n",
      "Epoch 1183/1500\n",
      " - 0s - loss: 0.3341 - acc: 0.9036 - val_loss: 1.0057 - val_acc: 0.7085\n",
      "Epoch 1184/1500\n",
      " - 0s - loss: 0.3322 - acc: 0.9015 - val_loss: 1.0123 - val_acc: 0.7143\n",
      "Epoch 1185/1500\n",
      " - 0s - loss: 0.3326 - acc: 0.9022 - val_loss: 1.0142 - val_acc: 0.7172\n",
      "Epoch 1186/1500\n",
      " - 0s - loss: 0.3328 - acc: 0.9036 - val_loss: 1.0062 - val_acc: 0.6997\n",
      "Epoch 1187/1500\n",
      " - 0s - loss: 0.3331 - acc: 0.8971 - val_loss: 1.0147 - val_acc: 0.7114\n",
      "Epoch 1188/1500\n",
      " - 0s - loss: 0.3308 - acc: 0.9058 - val_loss: 1.0105 - val_acc: 0.7055\n",
      "Epoch 1189/1500\n",
      " - 0s - loss: 0.3315 - acc: 0.9051 - val_loss: 1.0131 - val_acc: 0.7085\n",
      "Epoch 1190/1500\n",
      " - 0s - loss: 0.3314 - acc: 0.9000 - val_loss: 1.0142 - val_acc: 0.7143\n",
      "Epoch 1191/1500\n",
      " - 0s - loss: 0.3317 - acc: 0.9051 - val_loss: 1.0143 - val_acc: 0.7085\n",
      "Epoch 1192/1500\n",
      " - 0s - loss: 0.3323 - acc: 0.9058 - val_loss: 1.0073 - val_acc: 0.7055\n",
      "Epoch 1193/1500\n",
      " - 0s - loss: 0.3324 - acc: 0.9000 - val_loss: 1.0102 - val_acc: 0.7085\n",
      "Epoch 1194/1500\n",
      " - 0s - loss: 0.3299 - acc: 0.9066 - val_loss: 1.0129 - val_acc: 0.7026\n",
      "Epoch 1195/1500\n",
      " - 0s - loss: 0.3311 - acc: 0.8993 - val_loss: 1.0209 - val_acc: 0.7114\n",
      "Epoch 1196/1500\n",
      " - 0s - loss: 0.3306 - acc: 0.9029 - val_loss: 1.0103 - val_acc: 0.7026\n",
      "Epoch 1197/1500\n",
      " - 0s - loss: 0.3298 - acc: 0.9051 - val_loss: 1.0100 - val_acc: 0.7055\n",
      "Epoch 1198/1500\n",
      " - 0s - loss: 0.3314 - acc: 0.9015 - val_loss: 1.0192 - val_acc: 0.7114\n",
      "Epoch 1199/1500\n",
      " - 0s - loss: 0.3309 - acc: 0.9029 - val_loss: 1.0126 - val_acc: 0.7026\n",
      "Epoch 1200/1500\n",
      " - 0s - loss: 0.3301 - acc: 0.9088 - val_loss: 1.0085 - val_acc: 0.7055\n",
      "Epoch 1201/1500\n",
      " - 0s - loss: 0.3301 - acc: 0.9051 - val_loss: 1.0128 - val_acc: 0.7085\n",
      "Epoch 1202/1500\n",
      " - 0s - loss: 0.3289 - acc: 0.9073 - val_loss: 1.0148 - val_acc: 0.7085\n",
      "Epoch 1203/1500\n",
      " - 0s - loss: 0.3284 - acc: 0.9051 - val_loss: 1.0124 - val_acc: 0.7055\n",
      "Epoch 1204/1500\n",
      " - 0s - loss: 0.3273 - acc: 0.9073 - val_loss: 1.0146 - val_acc: 0.7055\n",
      "Epoch 1205/1500\n",
      " - 0s - loss: 0.3283 - acc: 0.9044 - val_loss: 1.0184 - val_acc: 0.7085\n",
      "Epoch 1206/1500\n",
      " - 0s - loss: 0.3271 - acc: 0.9073 - val_loss: 1.0122 - val_acc: 0.6997\n",
      "Epoch 1207/1500\n",
      " - 0s - loss: 0.3285 - acc: 0.9029 - val_loss: 1.0164 - val_acc: 0.7143\n",
      "Epoch 1208/1500\n",
      " - 0s - loss: 0.3289 - acc: 0.9073 - val_loss: 1.0180 - val_acc: 0.7085\n",
      "Epoch 1209/1500\n",
      " - 0s - loss: 0.3271 - acc: 0.9088 - val_loss: 1.0098 - val_acc: 0.7026\n",
      "Epoch 1210/1500\n",
      " - 0s - loss: 0.3276 - acc: 0.9044 - val_loss: 1.0203 - val_acc: 0.7055\n",
      "Epoch 1211/1500\n",
      " - 0s - loss: 0.3291 - acc: 0.9007 - val_loss: 1.0191 - val_acc: 0.7114\n",
      "Epoch 1212/1500\n",
      " - 0s - loss: 0.3285 - acc: 0.9051 - val_loss: 1.0113 - val_acc: 0.7026\n",
      "Epoch 1213/1500\n",
      " - 0s - loss: 0.3271 - acc: 0.9022 - val_loss: 1.0140 - val_acc: 0.7055\n",
      "Epoch 1214/1500\n",
      " - 0s - loss: 0.3268 - acc: 0.9051 - val_loss: 1.0181 - val_acc: 0.7114\n",
      "Epoch 1215/1500\n",
      " - 0s - loss: 0.3259 - acc: 0.9044 - val_loss: 1.0231 - val_acc: 0.7055\n",
      "Epoch 1216/1500\n",
      " - 0s - loss: 0.3252 - acc: 0.9036 - val_loss: 1.0124 - val_acc: 0.7055\n",
      "Epoch 1217/1500\n",
      " - 0s - loss: 0.3255 - acc: 0.9073 - val_loss: 1.0184 - val_acc: 0.7085\n",
      "Epoch 1218/1500\n",
      " - 0s - loss: 0.3264 - acc: 0.9051 - val_loss: 1.0187 - val_acc: 0.7055\n",
      "Epoch 1219/1500\n",
      " - 0s - loss: 0.3260 - acc: 0.9058 - val_loss: 1.0141 - val_acc: 0.7026\n",
      "Epoch 1220/1500\n",
      " - 0s - loss: 0.3249 - acc: 0.9080 - val_loss: 1.0185 - val_acc: 0.7114\n",
      "Epoch 1221/1500\n",
      " - 0s - loss: 0.3244 - acc: 0.9088 - val_loss: 1.0231 - val_acc: 0.7055\n",
      "Epoch 1222/1500\n",
      " - 0s - loss: 0.3296 - acc: 0.9095 - val_loss: 1.0176 - val_acc: 0.7085\n",
      "Epoch 1223/1500\n",
      " - 0s - loss: 0.3260 - acc: 0.9080 - val_loss: 1.0211 - val_acc: 0.7055\n",
      "Epoch 1224/1500\n",
      " - 0s - loss: 0.3252 - acc: 0.9080 - val_loss: 1.0187 - val_acc: 0.7055\n",
      "Epoch 1225/1500\n",
      " - 0s - loss: 0.3250 - acc: 0.9058 - val_loss: 1.0159 - val_acc: 0.7085\n",
      "Epoch 1226/1500\n",
      " - 0s - loss: 0.3245 - acc: 0.9051 - val_loss: 1.0246 - val_acc: 0.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1227/1500\n",
      " - 0s - loss: 0.3226 - acc: 0.9095 - val_loss: 1.0148 - val_acc: 0.7026\n",
      "Epoch 1228/1500\n",
      " - 0s - loss: 0.3243 - acc: 0.9036 - val_loss: 1.0204 - val_acc: 0.7055\n",
      "Epoch 1229/1500\n",
      " - 0s - loss: 0.3262 - acc: 0.9029 - val_loss: 1.0229 - val_acc: 0.7114\n",
      "Epoch 1230/1500\n",
      " - 0s - loss: 0.3265 - acc: 0.9022 - val_loss: 1.0288 - val_acc: 0.7085\n",
      "Epoch 1231/1500\n",
      " - 0s - loss: 0.3250 - acc: 0.9051 - val_loss: 1.0167 - val_acc: 0.7026\n",
      "Epoch 1232/1500\n",
      " - 0s - loss: 0.3242 - acc: 0.9036 - val_loss: 1.0190 - val_acc: 0.6997\n",
      "Epoch 1233/1500\n",
      " - 0s - loss: 0.3249 - acc: 0.9058 - val_loss: 1.0230 - val_acc: 0.7114\n",
      "Epoch 1234/1500\n",
      " - 0s - loss: 0.3212 - acc: 0.9088 - val_loss: 1.0164 - val_acc: 0.6968\n",
      "Epoch 1235/1500\n",
      " - 0s - loss: 0.3217 - acc: 0.9058 - val_loss: 1.0203 - val_acc: 0.7055\n",
      "Epoch 1236/1500\n",
      " - 0s - loss: 0.3230 - acc: 0.9073 - val_loss: 1.0202 - val_acc: 0.7055\n",
      "Epoch 1237/1500\n",
      " - 0s - loss: 0.3217 - acc: 0.9044 - val_loss: 1.0184 - val_acc: 0.7085\n",
      "Epoch 1238/1500\n",
      " - 0s - loss: 0.3209 - acc: 0.9051 - val_loss: 1.0206 - val_acc: 0.6997\n",
      "Epoch 1239/1500\n",
      " - 0s - loss: 0.3230 - acc: 0.9066 - val_loss: 1.0231 - val_acc: 0.7055\n",
      "Epoch 1240/1500\n",
      " - 0s - loss: 0.3249 - acc: 0.9080 - val_loss: 1.0157 - val_acc: 0.6968\n",
      "Epoch 1241/1500\n",
      " - 0s - loss: 0.3225 - acc: 0.9073 - val_loss: 1.0175 - val_acc: 0.6997\n",
      "Epoch 1242/1500\n",
      " - 0s - loss: 0.3233 - acc: 0.9051 - val_loss: 1.0259 - val_acc: 0.6997\n",
      "Epoch 1243/1500\n",
      " - 0s - loss: 0.3203 - acc: 0.9058 - val_loss: 1.0194 - val_acc: 0.6968\n",
      "Epoch 1244/1500\n",
      " - 0s - loss: 0.3194 - acc: 0.9095 - val_loss: 1.0196 - val_acc: 0.7026\n",
      "Epoch 1245/1500\n",
      " - 0s - loss: 0.3195 - acc: 0.9095 - val_loss: 1.0325 - val_acc: 0.6997\n",
      "Epoch 1246/1500\n",
      " - 0s - loss: 0.3224 - acc: 0.9073 - val_loss: 1.0229 - val_acc: 0.6968\n",
      "Epoch 1247/1500\n",
      " - 0s - loss: 0.3206 - acc: 0.9080 - val_loss: 1.0184 - val_acc: 0.6997\n",
      "Epoch 1248/1500\n",
      " - 0s - loss: 0.3235 - acc: 0.9051 - val_loss: 1.0285 - val_acc: 0.7026\n",
      "Epoch 1249/1500\n",
      " - 0s - loss: 0.3220 - acc: 0.9073 - val_loss: 1.0242 - val_acc: 0.7026\n",
      "Epoch 1250/1500\n",
      " - 0s - loss: 0.3228 - acc: 0.9051 - val_loss: 1.0206 - val_acc: 0.7026\n",
      "Epoch 1251/1500\n",
      " - 0s - loss: 0.3212 - acc: 0.9088 - val_loss: 1.0238 - val_acc: 0.7085\n",
      "Epoch 1252/1500\n",
      " - 0s - loss: 0.3184 - acc: 0.9117 - val_loss: 1.0282 - val_acc: 0.7055\n",
      "Epoch 1253/1500\n",
      " - 0s - loss: 0.3196 - acc: 0.9109 - val_loss: 1.0228 - val_acc: 0.6997\n",
      "Epoch 1254/1500\n",
      " - 0s - loss: 0.3172 - acc: 0.9124 - val_loss: 1.0238 - val_acc: 0.6997\n",
      "Epoch 1255/1500\n",
      " - 0s - loss: 0.3191 - acc: 0.9080 - val_loss: 1.0243 - val_acc: 0.7055\n",
      "Epoch 1256/1500\n",
      " - 0s - loss: 0.3202 - acc: 0.9066 - val_loss: 1.0292 - val_acc: 0.7055\n",
      "Epoch 1257/1500\n",
      " - 0s - loss: 0.3190 - acc: 0.9102 - val_loss: 1.0229 - val_acc: 0.7026\n",
      "Epoch 1258/1500\n",
      " - 0s - loss: 0.3178 - acc: 0.9095 - val_loss: 1.0207 - val_acc: 0.7055\n",
      "Epoch 1259/1500\n",
      " - 0s - loss: 0.3170 - acc: 0.9117 - val_loss: 1.0250 - val_acc: 0.6997\n",
      "Epoch 1260/1500\n",
      " - 0s - loss: 0.3168 - acc: 0.9088 - val_loss: 1.0268 - val_acc: 0.7026\n",
      "Epoch 1261/1500\n",
      " - 0s - loss: 0.3173 - acc: 0.9131 - val_loss: 1.0267 - val_acc: 0.7085\n",
      "Epoch 1262/1500\n",
      " - 0s - loss: 0.3229 - acc: 0.9139 - val_loss: 1.0229 - val_acc: 0.7026\n",
      "Epoch 1263/1500\n",
      " - 0s - loss: 0.3214 - acc: 0.9146 - val_loss: 1.0227 - val_acc: 0.7026\n",
      "Epoch 1264/1500\n",
      " - 0s - loss: 0.3199 - acc: 0.9088 - val_loss: 1.0277 - val_acc: 0.7026\n",
      "Epoch 1265/1500\n",
      " - 0s - loss: 0.3175 - acc: 0.9088 - val_loss: 1.0222 - val_acc: 0.6968\n",
      "Epoch 1266/1500\n",
      " - 0s - loss: 0.3158 - acc: 0.9088 - val_loss: 1.0310 - val_acc: 0.7055\n",
      "Epoch 1267/1500\n",
      " - 0s - loss: 0.3168 - acc: 0.9109 - val_loss: 1.0290 - val_acc: 0.7085\n",
      "Epoch 1268/1500\n",
      " - 0s - loss: 0.3153 - acc: 0.9131 - val_loss: 1.0224 - val_acc: 0.6968\n",
      "Epoch 1269/1500\n",
      " - 0s - loss: 0.3156 - acc: 0.9102 - val_loss: 1.0250 - val_acc: 0.6997\n",
      "Epoch 1270/1500\n",
      " - 0s - loss: 0.3137 - acc: 0.9139 - val_loss: 1.0336 - val_acc: 0.7085\n",
      "Epoch 1271/1500\n",
      " - 0s - loss: 0.3162 - acc: 0.9102 - val_loss: 1.0244 - val_acc: 0.7085\n",
      "Epoch 1272/1500\n",
      " - 0s - loss: 0.3172 - acc: 0.9080 - val_loss: 1.0344 - val_acc: 0.7085\n",
      "Epoch 1273/1500\n",
      " - 0s - loss: 0.3141 - acc: 0.9139 - val_loss: 1.0223 - val_acc: 0.6997\n",
      "Epoch 1274/1500\n",
      " - 0s - loss: 0.3140 - acc: 0.9102 - val_loss: 1.0285 - val_acc: 0.7055\n",
      "Epoch 1275/1500\n",
      " - 0s - loss: 0.3144 - acc: 0.9109 - val_loss: 1.0222 - val_acc: 0.7055\n",
      "Epoch 1276/1500\n",
      " - 0s - loss: 0.3177 - acc: 0.9073 - val_loss: 1.0381 - val_acc: 0.7055\n",
      "Epoch 1277/1500\n",
      " - 0s - loss: 0.3135 - acc: 0.9124 - val_loss: 1.0261 - val_acc: 0.6997\n",
      "Epoch 1278/1500\n",
      " - 0s - loss: 0.3149 - acc: 0.9109 - val_loss: 1.0295 - val_acc: 0.7026\n",
      "Epoch 1279/1500\n",
      " - 0s - loss: 0.3137 - acc: 0.9109 - val_loss: 1.0319 - val_acc: 0.7085\n",
      "Epoch 1280/1500\n",
      " - 0s - loss: 0.3137 - acc: 0.9102 - val_loss: 1.0241 - val_acc: 0.6997\n",
      "Epoch 1281/1500\n",
      " - 0s - loss: 0.3129 - acc: 0.9117 - val_loss: 1.0258 - val_acc: 0.7026\n",
      "Epoch 1282/1500\n",
      " - 0s - loss: 0.3139 - acc: 0.9161 - val_loss: 1.0304 - val_acc: 0.6997\n",
      "Epoch 1283/1500\n",
      " - 0s - loss: 0.3137 - acc: 0.9117 - val_loss: 1.0206 - val_acc: 0.6997\n",
      "Epoch 1284/1500\n",
      " - 0s - loss: 0.3139 - acc: 0.9117 - val_loss: 1.0257 - val_acc: 0.6997\n",
      "Epoch 1285/1500\n",
      " - 0s - loss: 0.3132 - acc: 0.9080 - val_loss: 1.0410 - val_acc: 0.7085\n",
      "Epoch 1286/1500\n",
      " - 0s - loss: 0.3149 - acc: 0.9102 - val_loss: 1.0285 - val_acc: 0.7026\n",
      "Epoch 1287/1500\n",
      " - 0s - loss: 0.3113 - acc: 0.9124 - val_loss: 1.0277 - val_acc: 0.7026\n",
      "Epoch 1288/1500\n",
      " - 0s - loss: 0.3117 - acc: 0.9139 - val_loss: 1.0353 - val_acc: 0.7055\n",
      "Epoch 1289/1500\n",
      " - 0s - loss: 0.3130 - acc: 0.9095 - val_loss: 1.0251 - val_acc: 0.6939\n",
      "Epoch 1290/1500\n",
      " - 0s - loss: 0.3103 - acc: 0.9117 - val_loss: 1.0344 - val_acc: 0.7026\n",
      "Epoch 1291/1500\n",
      " - 0s - loss: 0.3111 - acc: 0.9117 - val_loss: 1.0306 - val_acc: 0.7026\n",
      "Epoch 1292/1500\n",
      " - 0s - loss: 0.3107 - acc: 0.9139 - val_loss: 1.0261 - val_acc: 0.6939\n",
      "Epoch 1293/1500\n",
      " - 0s - loss: 0.3109 - acc: 0.9139 - val_loss: 1.0300 - val_acc: 0.6997\n",
      "Epoch 1294/1500\n",
      " - 0s - loss: 0.3104 - acc: 0.9131 - val_loss: 1.0343 - val_acc: 0.7026\n",
      "Epoch 1295/1500\n",
      " - 0s - loss: 0.3110 - acc: 0.9117 - val_loss: 1.0278 - val_acc: 0.6939\n",
      "Epoch 1296/1500\n",
      " - 0s - loss: 0.3091 - acc: 0.9117 - val_loss: 1.0321 - val_acc: 0.6968\n",
      "Epoch 1297/1500\n",
      " - 0s - loss: 0.3106 - acc: 0.9146 - val_loss: 1.0292 - val_acc: 0.6939\n",
      "Epoch 1298/1500\n",
      " - 0s - loss: 0.3101 - acc: 0.9131 - val_loss: 1.0367 - val_acc: 0.7026\n",
      "Epoch 1299/1500\n",
      " - 0s - loss: 0.3094 - acc: 0.9146 - val_loss: 1.0366 - val_acc: 0.7026\n",
      "Epoch 1300/1500\n",
      " - 0s - loss: 0.3095 - acc: 0.9124 - val_loss: 1.0356 - val_acc: 0.7026\n",
      "Epoch 1301/1500\n",
      " - 0s - loss: 0.3095 - acc: 0.9102 - val_loss: 1.0346 - val_acc: 0.6997\n",
      "Epoch 1302/1500\n",
      " - 0s - loss: 0.3098 - acc: 0.9117 - val_loss: 1.0350 - val_acc: 0.7055\n",
      "Epoch 1303/1500\n",
      " - 0s - loss: 0.3101 - acc: 0.9161 - val_loss: 1.0378 - val_acc: 0.6997\n",
      "Epoch 1304/1500\n",
      " - 0s - loss: 0.3088 - acc: 0.9146 - val_loss: 1.0322 - val_acc: 0.6968\n",
      "Epoch 1305/1500\n",
      " - 0s - loss: 0.3100 - acc: 0.9095 - val_loss: 1.0317 - val_acc: 0.7026\n",
      "Epoch 1306/1500\n",
      " - 0s - loss: 0.3104 - acc: 0.9168 - val_loss: 1.0328 - val_acc: 0.7055\n",
      "Epoch 1307/1500\n",
      " - 0s - loss: 0.3116 - acc: 0.9117 - val_loss: 1.0452 - val_acc: 0.6968\n",
      "Epoch 1308/1500\n",
      " - 0s - loss: 0.3097 - acc: 0.9109 - val_loss: 1.0325 - val_acc: 0.7026\n",
      "Epoch 1309/1500\n",
      " - 0s - loss: 0.3085 - acc: 0.9117 - val_loss: 1.0353 - val_acc: 0.6968\n",
      "Epoch 1310/1500\n",
      " - 0s - loss: 0.3080 - acc: 0.9131 - val_loss: 1.0363 - val_acc: 0.7026\n",
      "Epoch 1311/1500\n",
      " - 0s - loss: 0.3073 - acc: 0.9153 - val_loss: 1.0362 - val_acc: 0.6997\n",
      "Epoch 1312/1500\n",
      " - 0s - loss: 0.3071 - acc: 0.9095 - val_loss: 1.0333 - val_acc: 0.7026\n",
      "Epoch 1313/1500\n",
      " - 0s - loss: 0.3071 - acc: 0.9168 - val_loss: 1.0427 - val_acc: 0.7055\n",
      "Epoch 1314/1500\n",
      " - 0s - loss: 0.3067 - acc: 0.9161 - val_loss: 1.0341 - val_acc: 0.6997\n",
      "Epoch 1315/1500\n",
      " - 0s - loss: 0.3059 - acc: 0.9139 - val_loss: 1.0374 - val_acc: 0.6939\n",
      "Epoch 1316/1500\n",
      " - 0s - loss: 0.3070 - acc: 0.9109 - val_loss: 1.0342 - val_acc: 0.6968\n",
      "Epoch 1317/1500\n",
      " - 0s - loss: 0.3090 - acc: 0.9131 - val_loss: 1.0442 - val_acc: 0.6997\n",
      "Epoch 1318/1500\n",
      " - 0s - loss: 0.3082 - acc: 0.9153 - val_loss: 1.0335 - val_acc: 0.7085\n",
      "Epoch 1319/1500\n",
      " - 0s - loss: 0.3062 - acc: 0.9131 - val_loss: 1.0366 - val_acc: 0.7026\n",
      "Epoch 1320/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3053 - acc: 0.9139 - val_loss: 1.0381 - val_acc: 0.6997\n",
      "Epoch 1321/1500\n",
      " - 0s - loss: 0.3057 - acc: 0.9161 - val_loss: 1.0419 - val_acc: 0.6968\n",
      "Epoch 1322/1500\n",
      " - 0s - loss: 0.3063 - acc: 0.9124 - val_loss: 1.0348 - val_acc: 0.6939\n",
      "Epoch 1323/1500\n",
      " - 0s - loss: 0.3047 - acc: 0.9124 - val_loss: 1.0398 - val_acc: 0.6997\n",
      "Epoch 1324/1500\n",
      " - 0s - loss: 0.3058 - acc: 0.9153 - val_loss: 1.0373 - val_acc: 0.6968\n",
      "Epoch 1325/1500\n",
      " - 0s - loss: 0.3056 - acc: 0.9168 - val_loss: 1.0363 - val_acc: 0.6968\n",
      "Epoch 1326/1500\n",
      " - 0s - loss: 0.3056 - acc: 0.9131 - val_loss: 1.0446 - val_acc: 0.7055\n",
      "Epoch 1327/1500\n",
      " - 0s - loss: 0.3054 - acc: 0.9146 - val_loss: 1.0357 - val_acc: 0.7026\n",
      "Epoch 1328/1500\n",
      " - 0s - loss: 0.3042 - acc: 0.9161 - val_loss: 1.0442 - val_acc: 0.6997\n",
      "Epoch 1329/1500\n",
      " - 0s - loss: 0.3054 - acc: 0.9146 - val_loss: 1.0401 - val_acc: 0.6968\n",
      "Epoch 1330/1500\n",
      " - 0s - loss: 0.3042 - acc: 0.9182 - val_loss: 1.0420 - val_acc: 0.7026\n",
      "Epoch 1331/1500\n",
      " - 0s - loss: 0.3037 - acc: 0.9131 - val_loss: 1.0478 - val_acc: 0.6968\n",
      "Epoch 1332/1500\n",
      " - 0s - loss: 0.3062 - acc: 0.9131 - val_loss: 1.0365 - val_acc: 0.7026\n",
      "Epoch 1333/1500\n",
      " - 0s - loss: 0.3044 - acc: 0.9168 - val_loss: 1.0419 - val_acc: 0.6968\n",
      "Epoch 1334/1500\n",
      " - 0s - loss: 0.3035 - acc: 0.9146 - val_loss: 1.0462 - val_acc: 0.6997\n",
      "Epoch 1335/1500\n",
      " - 0s - loss: 0.3029 - acc: 0.9161 - val_loss: 1.0359 - val_acc: 0.7026\n",
      "Epoch 1336/1500\n",
      " - 0s - loss: 0.3070 - acc: 0.9088 - val_loss: 1.0445 - val_acc: 0.7026\n",
      "Epoch 1337/1500\n",
      " - 0s - loss: 0.3029 - acc: 0.9146 - val_loss: 1.0406 - val_acc: 0.6939\n",
      "Epoch 1338/1500\n",
      " - 0s - loss: 0.3051 - acc: 0.9139 - val_loss: 1.0405 - val_acc: 0.7055\n",
      "Epoch 1339/1500\n",
      " - 0s - loss: 0.3053 - acc: 0.9146 - val_loss: 1.0463 - val_acc: 0.6968\n",
      "Epoch 1340/1500\n",
      " - 0s - loss: 0.3034 - acc: 0.9153 - val_loss: 1.0412 - val_acc: 0.6939\n",
      "Epoch 1341/1500\n",
      " - 0s - loss: 0.3048 - acc: 0.9146 - val_loss: 1.0411 - val_acc: 0.6939\n",
      "Epoch 1342/1500\n",
      " - 0s - loss: 0.3045 - acc: 0.9124 - val_loss: 1.0493 - val_acc: 0.6997\n",
      "Epoch 1343/1500\n",
      " - 0s - loss: 0.3058 - acc: 0.9146 - val_loss: 1.0414 - val_acc: 0.7055\n",
      "Epoch 1344/1500\n",
      " - 0s - loss: 0.3034 - acc: 0.9168 - val_loss: 1.0488 - val_acc: 0.6939\n",
      "Epoch 1345/1500\n",
      " - 0s - loss: 0.3038 - acc: 0.9139 - val_loss: 1.0411 - val_acc: 0.6939\n",
      "Epoch 1346/1500\n",
      " - 0s - loss: 0.3032 - acc: 0.9168 - val_loss: 1.0512 - val_acc: 0.7085\n",
      "Epoch 1347/1500\n",
      " - 0s - loss: 0.3018 - acc: 0.9212 - val_loss: 1.0400 - val_acc: 0.6968\n",
      "Epoch 1348/1500\n",
      " - 0s - loss: 0.3007 - acc: 0.9124 - val_loss: 1.0506 - val_acc: 0.6968\n",
      "Epoch 1349/1500\n",
      " - 0s - loss: 0.3020 - acc: 0.9204 - val_loss: 1.0442 - val_acc: 0.7055\n",
      "Epoch 1350/1500\n",
      " - 0s - loss: 0.3006 - acc: 0.9131 - val_loss: 1.0436 - val_acc: 0.6968\n",
      "Epoch 1351/1500\n",
      " - 0s - loss: 0.2997 - acc: 0.9190 - val_loss: 1.0477 - val_acc: 0.6968\n",
      "Epoch 1352/1500\n",
      " - 0s - loss: 0.3027 - acc: 0.9168 - val_loss: 1.0445 - val_acc: 0.7055\n",
      "Epoch 1353/1500\n",
      " - 0s - loss: 0.3011 - acc: 0.9168 - val_loss: 1.0535 - val_acc: 0.6997\n",
      "Epoch 1354/1500\n",
      " - 0s - loss: 0.2992 - acc: 0.9175 - val_loss: 1.0404 - val_acc: 0.6968\n",
      "Epoch 1355/1500\n",
      " - 0s - loss: 0.3006 - acc: 0.9168 - val_loss: 1.0402 - val_acc: 0.6910\n",
      "Epoch 1356/1500\n",
      " - 0s - loss: 0.2997 - acc: 0.9131 - val_loss: 1.0471 - val_acc: 0.6997\n",
      "Epoch 1357/1500\n",
      " - 0s - loss: 0.3001 - acc: 0.9146 - val_loss: 1.0480 - val_acc: 0.6939\n",
      "Epoch 1358/1500\n",
      " - 0s - loss: 0.3006 - acc: 0.9182 - val_loss: 1.0463 - val_acc: 0.6968\n",
      "Epoch 1359/1500\n",
      " - 0s - loss: 0.2998 - acc: 0.9168 - val_loss: 1.0495 - val_acc: 0.6968\n",
      "Epoch 1360/1500\n",
      " - 0s - loss: 0.3002 - acc: 0.9182 - val_loss: 1.0443 - val_acc: 0.6997\n",
      "Epoch 1361/1500\n",
      " - 0s - loss: 0.2998 - acc: 0.9168 - val_loss: 1.0549 - val_acc: 0.6939\n",
      "Epoch 1362/1500\n",
      " - 0s - loss: 0.3025 - acc: 0.9124 - val_loss: 1.0446 - val_acc: 0.7055\n",
      "Epoch 1363/1500\n",
      " - 0s - loss: 0.2983 - acc: 0.9212 - val_loss: 1.0512 - val_acc: 0.7026\n",
      "Epoch 1364/1500\n",
      " - 0s - loss: 0.3000 - acc: 0.9190 - val_loss: 1.0540 - val_acc: 0.7026\n",
      "Epoch 1365/1500\n",
      " - 0s - loss: 0.2973 - acc: 0.9182 - val_loss: 1.0417 - val_acc: 0.6968\n",
      "Epoch 1366/1500\n",
      " - 0s - loss: 0.2988 - acc: 0.9168 - val_loss: 1.0558 - val_acc: 0.6968\n",
      "Epoch 1367/1500\n",
      " - 0s - loss: 0.3004 - acc: 0.9175 - val_loss: 1.0502 - val_acc: 0.7026\n",
      "Epoch 1368/1500\n",
      " - 0s - loss: 0.2972 - acc: 0.9153 - val_loss: 1.0478 - val_acc: 0.6997\n",
      "Epoch 1369/1500\n",
      " - 0s - loss: 0.3020 - acc: 0.9161 - val_loss: 1.0749 - val_acc: 0.7055\n",
      "Epoch 1370/1500\n",
      " - 0s - loss: 0.2995 - acc: 0.9109 - val_loss: 1.0445 - val_acc: 0.6910\n",
      "Epoch 1371/1500\n",
      " - 0s - loss: 0.2987 - acc: 0.9197 - val_loss: 1.0480 - val_acc: 0.7055\n",
      "Epoch 1372/1500\n",
      " - 0s - loss: 0.2968 - acc: 0.9175 - val_loss: 1.0512 - val_acc: 0.6939\n",
      "Epoch 1373/1500\n",
      " - 0s - loss: 0.2972 - acc: 0.9190 - val_loss: 1.0472 - val_acc: 0.6968\n",
      "Epoch 1374/1500\n",
      " - 0s - loss: 0.2980 - acc: 0.9153 - val_loss: 1.0508 - val_acc: 0.6997\n",
      "Epoch 1375/1500\n",
      " - 0s - loss: 0.2962 - acc: 0.9182 - val_loss: 1.0459 - val_acc: 0.7026\n",
      "Epoch 1376/1500\n",
      " - 0s - loss: 0.2981 - acc: 0.9175 - val_loss: 1.0609 - val_acc: 0.6997\n",
      "Epoch 1377/1500\n",
      " - 0s - loss: 0.2963 - acc: 0.9153 - val_loss: 1.0495 - val_acc: 0.6968\n",
      "Epoch 1378/1500\n",
      " - 0s - loss: 0.2967 - acc: 0.9168 - val_loss: 1.0490 - val_acc: 0.7026\n",
      "Epoch 1379/1500\n",
      " - 0s - loss: 0.2954 - acc: 0.9197 - val_loss: 1.0466 - val_acc: 0.6910\n",
      "Epoch 1380/1500\n",
      " - 0s - loss: 0.2961 - acc: 0.9197 - val_loss: 1.0542 - val_acc: 0.6997\n",
      "Epoch 1381/1500\n",
      " - 0s - loss: 0.2970 - acc: 0.9168 - val_loss: 1.0584 - val_acc: 0.6968\n",
      "Epoch 1382/1500\n",
      " - 0s - loss: 0.2971 - acc: 0.9146 - val_loss: 1.0471 - val_acc: 0.6997\n",
      "Epoch 1383/1500\n",
      " - 0s - loss: 0.2964 - acc: 0.9212 - val_loss: 1.0556 - val_acc: 0.7026\n",
      "Epoch 1384/1500\n",
      " - 0s - loss: 0.2968 - acc: 0.9190 - val_loss: 1.0528 - val_acc: 0.6968\n",
      "Epoch 1385/1500\n",
      " - 0s - loss: 0.2952 - acc: 0.9190 - val_loss: 1.0528 - val_acc: 0.6997\n",
      "Epoch 1386/1500\n",
      " - 0s - loss: 0.2939 - acc: 0.9197 - val_loss: 1.0539 - val_acc: 0.6910\n",
      "Epoch 1387/1500\n",
      " - 0s - loss: 0.2936 - acc: 0.9212 - val_loss: 1.0549 - val_acc: 0.7026\n",
      "Epoch 1388/1500\n",
      " - 0s - loss: 0.2936 - acc: 0.9190 - val_loss: 1.0512 - val_acc: 0.6968\n",
      "Epoch 1389/1500\n",
      " - 0s - loss: 0.2944 - acc: 0.9175 - val_loss: 1.0632 - val_acc: 0.6997\n",
      "Epoch 1390/1500\n",
      " - 0s - loss: 0.2932 - acc: 0.9197 - val_loss: 1.0532 - val_acc: 0.6968\n",
      "Epoch 1391/1500\n",
      " - 0s - loss: 0.2928 - acc: 0.9234 - val_loss: 1.0559 - val_acc: 0.7026\n",
      "Epoch 1392/1500\n",
      " - 0s - loss: 0.2925 - acc: 0.9197 - val_loss: 1.0531 - val_acc: 0.6997\n",
      "Epoch 1393/1500\n",
      " - 0s - loss: 0.2937 - acc: 0.9212 - val_loss: 1.0538 - val_acc: 0.7026\n",
      "Epoch 1394/1500\n",
      " - 0s - loss: 0.2925 - acc: 0.9182 - val_loss: 1.0539 - val_acc: 0.7026\n",
      "Epoch 1395/1500\n",
      " - 0s - loss: 0.2936 - acc: 0.9219 - val_loss: 1.0617 - val_acc: 0.7026\n",
      "Epoch 1396/1500\n",
      " - 0s - loss: 0.2934 - acc: 0.9219 - val_loss: 1.0555 - val_acc: 0.7085\n",
      "Epoch 1397/1500\n",
      " - 0s - loss: 0.2956 - acc: 0.9168 - val_loss: 1.0620 - val_acc: 0.6997\n",
      "Epoch 1398/1500\n",
      " - 0s - loss: 0.2934 - acc: 0.9190 - val_loss: 1.0528 - val_acc: 0.6997\n",
      "Epoch 1399/1500\n",
      " - 0s - loss: 0.2935 - acc: 0.9190 - val_loss: 1.0662 - val_acc: 0.6968\n",
      "Epoch 1400/1500\n",
      " - 0s - loss: 0.2921 - acc: 0.9197 - val_loss: 1.0597 - val_acc: 0.6939\n",
      "Epoch 1401/1500\n",
      " - 0s - loss: 0.2912 - acc: 0.9212 - val_loss: 1.0560 - val_acc: 0.7026\n",
      "Epoch 1402/1500\n",
      " - 0s - loss: 0.2943 - acc: 0.9161 - val_loss: 1.0559 - val_acc: 0.6939\n",
      "Epoch 1403/1500\n",
      " - 0s - loss: 0.2916 - acc: 0.9168 - val_loss: 1.0629 - val_acc: 0.7026\n",
      "Epoch 1404/1500\n",
      " - 0s - loss: 0.2926 - acc: 0.9182 - val_loss: 1.0598 - val_acc: 0.6939\n",
      "Epoch 1405/1500\n",
      " - 0s - loss: 0.2910 - acc: 0.9212 - val_loss: 1.0587 - val_acc: 0.6910\n",
      "Epoch 1406/1500\n",
      " - 0s - loss: 0.2904 - acc: 0.9190 - val_loss: 1.0619 - val_acc: 0.6997\n",
      "Epoch 1407/1500\n",
      " - 0s - loss: 0.2914 - acc: 0.9226 - val_loss: 1.0551 - val_acc: 0.7085\n",
      "Epoch 1408/1500\n",
      " - 0s - loss: 0.2903 - acc: 0.9168 - val_loss: 1.0652 - val_acc: 0.6939\n",
      "Epoch 1409/1500\n",
      " - 0s - loss: 0.2894 - acc: 0.9212 - val_loss: 1.0578 - val_acc: 0.7055\n",
      "Epoch 1410/1500\n",
      " - 0s - loss: 0.2924 - acc: 0.9168 - val_loss: 1.0734 - val_acc: 0.7085\n",
      "Epoch 1411/1500\n",
      " - 0s - loss: 0.2909 - acc: 0.9241 - val_loss: 1.0554 - val_acc: 0.7026\n",
      "Epoch 1412/1500\n",
      " - 0s - loss: 0.2940 - acc: 0.9175 - val_loss: 1.0625 - val_acc: 0.7026\n",
      "Epoch 1413/1500\n",
      " - 0s - loss: 0.2920 - acc: 0.9204 - val_loss: 1.0660 - val_acc: 0.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1414/1500\n",
      " - 0s - loss: 0.2889 - acc: 0.9226 - val_loss: 1.0622 - val_acc: 0.6939\n",
      "Epoch 1415/1500\n",
      " - 0s - loss: 0.2897 - acc: 0.9212 - val_loss: 1.0605 - val_acc: 0.7026\n",
      "Epoch 1416/1500\n",
      " - 0s - loss: 0.2900 - acc: 0.9241 - val_loss: 1.0622 - val_acc: 0.6997\n",
      "Epoch 1417/1500\n",
      " - 0s - loss: 0.2892 - acc: 0.9168 - val_loss: 1.0694 - val_acc: 0.7026\n",
      "Epoch 1418/1500\n",
      " - 0s - loss: 0.2902 - acc: 0.9234 - val_loss: 1.0540 - val_acc: 0.6997\n",
      "Epoch 1419/1500\n",
      " - 0s - loss: 0.2908 - acc: 0.9219 - val_loss: 1.0583 - val_acc: 0.7026\n",
      "Epoch 1420/1500\n",
      " - 0s - loss: 0.2905 - acc: 0.9139 - val_loss: 1.0682 - val_acc: 0.6997\n",
      "Epoch 1421/1500\n",
      " - 0s - loss: 0.2879 - acc: 0.9241 - val_loss: 1.0597 - val_acc: 0.7026\n",
      "Epoch 1422/1500\n",
      " - 0s - loss: 0.2870 - acc: 0.9212 - val_loss: 1.0729 - val_acc: 0.7026\n",
      "Epoch 1423/1500\n",
      " - 0s - loss: 0.2887 - acc: 0.9248 - val_loss: 1.0562 - val_acc: 0.7085\n",
      "Epoch 1424/1500\n",
      " - 0s - loss: 0.2913 - acc: 0.9197 - val_loss: 1.0626 - val_acc: 0.6968\n",
      "Epoch 1425/1500\n",
      " - 0s - loss: 0.2893 - acc: 0.9197 - val_loss: 1.0755 - val_acc: 0.7055\n",
      "Epoch 1426/1500\n",
      " - 0s - loss: 0.2904 - acc: 0.9182 - val_loss: 1.0619 - val_acc: 0.7055\n",
      "Epoch 1427/1500\n",
      " - 0s - loss: 0.2907 - acc: 0.9212 - val_loss: 1.0671 - val_acc: 0.7026\n",
      "Epoch 1428/1500\n",
      " - 0s - loss: 0.2904 - acc: 0.9175 - val_loss: 1.0765 - val_acc: 0.7026\n",
      "Epoch 1429/1500\n",
      " - 0s - loss: 0.2899 - acc: 0.9226 - val_loss: 1.0645 - val_acc: 0.7026\n",
      "Epoch 1430/1500\n",
      " - 0s - loss: 0.2885 - acc: 0.9204 - val_loss: 1.0622 - val_acc: 0.7026\n",
      "Epoch 1431/1500\n",
      " - 0s - loss: 0.2881 - acc: 0.9204 - val_loss: 1.0717 - val_acc: 0.7026\n",
      "Epoch 1432/1500\n",
      " - 0s - loss: 0.2875 - acc: 0.9219 - val_loss: 1.0682 - val_acc: 0.6997\n",
      "Epoch 1433/1500\n",
      " - 0s - loss: 0.2867 - acc: 0.9226 - val_loss: 1.0661 - val_acc: 0.7026\n",
      "Epoch 1434/1500\n",
      " - 0s - loss: 0.2862 - acc: 0.9241 - val_loss: 1.0670 - val_acc: 0.7026\n",
      "Epoch 1435/1500\n",
      " - 0s - loss: 0.2876 - acc: 0.9241 - val_loss: 1.0698 - val_acc: 0.7026\n",
      "Epoch 1436/1500\n",
      " - 0s - loss: 0.2866 - acc: 0.9219 - val_loss: 1.0686 - val_acc: 0.6997\n",
      "Epoch 1437/1500\n",
      " - 0s - loss: 0.2854 - acc: 0.9234 - val_loss: 1.0634 - val_acc: 0.7085\n",
      "Epoch 1438/1500\n",
      " - 0s - loss: 0.2868 - acc: 0.9255 - val_loss: 1.0654 - val_acc: 0.7055\n",
      "Epoch 1439/1500\n",
      " - 0s - loss: 0.2873 - acc: 0.9219 - val_loss: 1.0656 - val_acc: 0.6968\n",
      "Epoch 1440/1500\n",
      " - 0s - loss: 0.2859 - acc: 0.9219 - val_loss: 1.0701 - val_acc: 0.6968\n",
      "Epoch 1441/1500\n",
      " - 0s - loss: 0.2855 - acc: 0.9197 - val_loss: 1.0779 - val_acc: 0.7026\n",
      "Epoch 1442/1500\n",
      " - 0s - loss: 0.2848 - acc: 0.9263 - val_loss: 1.0681 - val_acc: 0.7026\n",
      "Epoch 1443/1500\n",
      " - 0s - loss: 0.2848 - acc: 0.9190 - val_loss: 1.0693 - val_acc: 0.6968\n",
      "Epoch 1444/1500\n",
      " - 0s - loss: 0.2848 - acc: 0.9241 - val_loss: 1.0665 - val_acc: 0.7055\n",
      "Epoch 1445/1500\n",
      " - 0s - loss: 0.2849 - acc: 0.9190 - val_loss: 1.0752 - val_acc: 0.7026\n",
      "Epoch 1446/1500\n",
      " - 0s - loss: 0.2878 - acc: 0.9248 - val_loss: 1.0680 - val_acc: 0.7055\n",
      "Epoch 1447/1500\n",
      " - 0s - loss: 0.2833 - acc: 0.9190 - val_loss: 1.0742 - val_acc: 0.6939\n",
      "Epoch 1448/1500\n",
      " - 0s - loss: 0.2843 - acc: 0.9241 - val_loss: 1.0709 - val_acc: 0.7026\n",
      "Epoch 1449/1500\n",
      " - 0s - loss: 0.2834 - acc: 0.9241 - val_loss: 1.0703 - val_acc: 0.7055\n",
      "Epoch 1450/1500\n",
      " - 0s - loss: 0.2828 - acc: 0.9197 - val_loss: 1.0846 - val_acc: 0.7026\n",
      "Epoch 1451/1500\n",
      " - 0s - loss: 0.2838 - acc: 0.9255 - val_loss: 1.0674 - val_acc: 0.7055\n",
      "Epoch 1452/1500\n",
      " - 0s - loss: 0.2841 - acc: 0.9241 - val_loss: 1.0797 - val_acc: 0.7026\n",
      "Epoch 1453/1500\n",
      " - 0s - loss: 0.2838 - acc: 0.9204 - val_loss: 1.0684 - val_acc: 0.6968\n",
      "Epoch 1454/1500\n",
      " - 0s - loss: 0.2829 - acc: 0.9270 - val_loss: 1.0783 - val_acc: 0.7085\n",
      "Epoch 1455/1500\n",
      " - 0s - loss: 0.2824 - acc: 0.9248 - val_loss: 1.0681 - val_acc: 0.7026\n",
      "Epoch 1456/1500\n",
      " - 0s - loss: 0.2832 - acc: 0.9248 - val_loss: 1.0743 - val_acc: 0.6997\n",
      "Epoch 1457/1500\n",
      " - 0s - loss: 0.2813 - acc: 0.9226 - val_loss: 1.0678 - val_acc: 0.6997\n",
      "Epoch 1458/1500\n",
      " - 0s - loss: 0.2824 - acc: 0.9204 - val_loss: 1.0705 - val_acc: 0.6968\n",
      "Epoch 1459/1500\n",
      " - 0s - loss: 0.2828 - acc: 0.9263 - val_loss: 1.0816 - val_acc: 0.7085\n",
      "Epoch 1460/1500\n",
      " - 0s - loss: 0.2829 - acc: 0.9255 - val_loss: 1.0699 - val_acc: 0.7114\n",
      "Epoch 1461/1500\n",
      " - 0s - loss: 0.2865 - acc: 0.9241 - val_loss: 1.0768 - val_acc: 0.6997\n",
      "Epoch 1462/1500\n",
      " - 0s - loss: 0.2826 - acc: 0.9212 - val_loss: 1.0784 - val_acc: 0.7026\n",
      "Epoch 1463/1500\n",
      " - 0s - loss: 0.2816 - acc: 0.9255 - val_loss: 1.0749 - val_acc: 0.6997\n",
      "Epoch 1464/1500\n",
      " - 0s - loss: 0.2847 - acc: 0.9212 - val_loss: 1.0773 - val_acc: 0.6997\n",
      "Epoch 1465/1500\n",
      " - 0s - loss: 0.2812 - acc: 0.9263 - val_loss: 1.0739 - val_acc: 0.6997\n",
      "Epoch 1466/1500\n",
      " - 0s - loss: 0.2810 - acc: 0.9219 - val_loss: 1.0768 - val_acc: 0.7055\n",
      "Epoch 1467/1500\n",
      " - 0s - loss: 0.2825 - acc: 0.9241 - val_loss: 1.0796 - val_acc: 0.6968\n",
      "Epoch 1468/1500\n",
      " - 0s - loss: 0.2821 - acc: 0.9226 - val_loss: 1.0777 - val_acc: 0.7055\n",
      "Epoch 1469/1500\n",
      " - 0s - loss: 0.2823 - acc: 0.9234 - val_loss: 1.0723 - val_acc: 0.6997\n",
      "Epoch 1470/1500\n",
      " - 0s - loss: 0.2818 - acc: 0.9212 - val_loss: 1.0763 - val_acc: 0.7055\n",
      "Epoch 1471/1500\n",
      " - 0s - loss: 0.2812 - acc: 0.9241 - val_loss: 1.0940 - val_acc: 0.7114\n",
      "Epoch 1472/1500\n",
      " - 0s - loss: 0.2824 - acc: 0.9248 - val_loss: 1.0716 - val_acc: 0.6997\n",
      "Epoch 1473/1500\n",
      " - 0s - loss: 0.2816 - acc: 0.9226 - val_loss: 1.0820 - val_acc: 0.6997\n",
      "Epoch 1474/1500\n",
      " - 0s - loss: 0.2838 - acc: 0.9190 - val_loss: 1.0828 - val_acc: 0.7026\n",
      "Epoch 1475/1500\n",
      " - 0s - loss: 0.2801 - acc: 0.9270 - val_loss: 1.0778 - val_acc: 0.7114\n",
      "Epoch 1476/1500\n",
      " - 0s - loss: 0.2808 - acc: 0.9226 - val_loss: 1.0888 - val_acc: 0.7026\n",
      "Epoch 1477/1500\n",
      " - 0s - loss: 0.2809 - acc: 0.9226 - val_loss: 1.0793 - val_acc: 0.7085\n",
      "Epoch 1478/1500\n",
      " - 0s - loss: 0.2805 - acc: 0.9263 - val_loss: 1.0780 - val_acc: 0.6968\n",
      "Epoch 1479/1500\n",
      " - 0s - loss: 0.2788 - acc: 0.9248 - val_loss: 1.0753 - val_acc: 0.6968\n",
      "Epoch 1480/1500\n",
      " - 0s - loss: 0.2794 - acc: 0.9234 - val_loss: 1.0800 - val_acc: 0.7026\n",
      "Epoch 1481/1500\n",
      " - 0s - loss: 0.2789 - acc: 0.9248 - val_loss: 1.0783 - val_acc: 0.7026\n",
      "Epoch 1482/1500\n",
      " - 0s - loss: 0.2811 - acc: 0.9219 - val_loss: 1.0842 - val_acc: 0.6997\n",
      "Epoch 1483/1500\n",
      " - 0s - loss: 0.2797 - acc: 0.9292 - val_loss: 1.0822 - val_acc: 0.6968\n",
      "Epoch 1484/1500\n",
      " - 0s - loss: 0.2786 - acc: 0.9226 - val_loss: 1.0765 - val_acc: 0.6997\n",
      "Epoch 1485/1500\n",
      " - 0s - loss: 0.2787 - acc: 0.9263 - val_loss: 1.0778 - val_acc: 0.6968\n",
      "Epoch 1486/1500\n",
      " - 0s - loss: 0.2778 - acc: 0.9219 - val_loss: 1.0871 - val_acc: 0.7026\n",
      "Epoch 1487/1500\n",
      " - 0s - loss: 0.2789 - acc: 0.9270 - val_loss: 1.0766 - val_acc: 0.7026\n",
      "Epoch 1488/1500\n",
      " - 0s - loss: 0.2781 - acc: 0.9234 - val_loss: 1.0779 - val_acc: 0.6968\n",
      "Epoch 1489/1500\n",
      " - 0s - loss: 0.2782 - acc: 0.9248 - val_loss: 1.0798 - val_acc: 0.6968\n",
      "Epoch 1490/1500\n",
      " - 0s - loss: 0.2771 - acc: 0.9219 - val_loss: 1.0864 - val_acc: 0.7026\n",
      "Epoch 1491/1500\n",
      " - 0s - loss: 0.2779 - acc: 0.9263 - val_loss: 1.0803 - val_acc: 0.6997\n",
      "Epoch 1492/1500\n",
      " - 0s - loss: 0.2778 - acc: 0.9226 - val_loss: 1.0872 - val_acc: 0.7055\n",
      "Epoch 1493/1500\n",
      " - 0s - loss: 0.2790 - acc: 0.9255 - val_loss: 1.0887 - val_acc: 0.7085\n",
      "Epoch 1494/1500\n",
      " - 0s - loss: 0.2774 - acc: 0.9277 - val_loss: 1.0863 - val_acc: 0.6997\n",
      "Epoch 1495/1500\n",
      " - 0s - loss: 0.2768 - acc: 0.9285 - val_loss: 1.0812 - val_acc: 0.7026\n",
      "Epoch 1496/1500\n",
      " - 0s - loss: 0.2761 - acc: 0.9241 - val_loss: 1.0879 - val_acc: 0.7055\n",
      "Epoch 1497/1500\n",
      " - 0s - loss: 0.2772 - acc: 0.9255 - val_loss: 1.0832 - val_acc: 0.7026\n",
      "Epoch 1498/1500\n",
      " - 0s - loss: 0.2757 - acc: 0.9277 - val_loss: 1.0884 - val_acc: 0.7026\n",
      "Epoch 1499/1500\n",
      " - 0s - loss: 0.2769 - acc: 0.9277 - val_loss: 1.0817 - val_acc: 0.6997\n",
      "Epoch 1500/1500\n",
      " - 0s - loss: 0.2758 - acc: 0.9277 - val_loss: 1.0872 - val_acc: 0.7055\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_history = model.fit(X_train, Y_train, \n",
    "                          batch_size = 100, \n",
    "                          epochs = 1500, \n",
    "                          verbose = 2,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [checkpoint]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history, 'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.32867139814061"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before saving: are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_71_10_20_42_tanh_100_1000.h5\")\n",
    "#for this\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST-SEE: \n",
    "* https://www.kaggle.com/randyrose2017/for-beginners-using-keras-to-build-models\n",
    "* https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d\n",
    "* https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n",
    "## Just liked:\n",
    "* https://missinglink.ai/guides/neural-network-concepts/classification-neural-networks-neural-network-right-choice/\n",
    "## Full-house:\n",
    "https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why rerunning with same configuration gives different output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = Sequential()\n",
    "model_load.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))\n",
    "#model_load.add(Dense(units = 10, \n",
    "                #activation = 'tanh'))\n",
    "model_load.add(Dense(units = 20, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_weights('/home/amanzhol/Documents/Capstone/MAIN Work/models/model_10_10_20_tanh_100_1000_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to compile before evaluating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_load.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.35198137976907"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Ms. Asma Salem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='AsmaSalemResults.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "predictions = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing confustion matrix from source:\n",
    "https://stackoverflow.com/questions/50920908/get-confusion-matrix-from-a-keras-multiclass-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 9, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 7, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 7, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 7]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FAR, FRR and EER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stats.stackexchange.com/questions/272962/are-far-and-frr-the-same-as-fpr-and-fnr-respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ConfusionMatrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='PerformanceMetrics.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edit:\n",
    "this is the format for confusion_matrix():\n",
    "[[TP,FN]\n",
    "[FP,TN]]\n",
    "And classification report gives all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 42)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-86b2e0ad5146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-c62d2e9dae18>\u001b[0m in \u001b[0;36mperf_measure\u001b[0;34m(y_actual, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m            \u001b[0mTP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "perf_measure(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus\n",
    "TP = 6\n",
    "FP = 1\n",
    "TN = 11\n",
    "FN = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAR(FP, TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FRR(FN, TP):\n",
    "    return FN/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333332"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAR(FP, TN) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.78082191780823"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRR(FN, TP) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (Performance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ms. Asma Results\n",
    "* FAR = 0.3%\n",
    "* FRR = 1.5%\n",
    "* EER = 0.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* How to have several FAR, FRR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read for Confusion Matrix - Get Items FP/FN/TP/TN - Python\n",
    "* https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python\n",
    "* https://classeval.wordpress.com/introduction/basic-evaluation-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
