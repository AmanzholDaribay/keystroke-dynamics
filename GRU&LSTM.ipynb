{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "The dataset is taken from http://www.vmonaco.com/keystroke-datasets.\n",
    "Specifically from https://ms.sapientia.ro/~manyi/keystroke.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of subjects: 42 (24 male, 18 female)\n",
    "* Password: .tie5Roanl\n",
    "* Keys: . t i e [123?] 5 [abc] [Shift] R [Shift] o a n l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read:\n",
    "* https://appliedmachinelearning.blog/2017/07/26/user-verification-based-on-keystroke-dynamics-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('dataset2_norm.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Creating Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 0 ns, total: 3 Âµs\n",
      "Wall time: 5.96 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "label = []\n",
    "for i in range(42):\n",
    "    for j in range(51):\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == 0) * 2142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Input Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 71)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_ = df[['holdtime1', 'downdown1', 'updown1', 'pressure1', 'fingerarea1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_.insert(1, 'downdown0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_.insert(3, 'updown0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_ = dot_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = df[['holdtime2', 'downdown1', 'downdown2', 'updown1', 'updown2','pressure2','fingerarea2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ = df[['holdtime3', 'downdown2', 'downdown3', 'updown2', 'updown3','pressure3','fingerarea3']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ = df[['holdtime4', 'downdown3', 'downdown4', 'updown3', 'updown4','pressure4','fingerarea4']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ = df[['holdtime5', 'downdown4', 'downdown5', 'updown4', 'updown5','pressure5','fingerarea5']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_ = df[['holdtime6', 'downdown5', 'downdown6', 'updown5', 'updown6','pressure6','fingerarea6']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_ = df[['holdtime7', 'downdown6', 'downdown7', 'updown6', 'updown7','pressure7','fingerarea7']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift1_ = df[['holdtime8', 'downdown7', 'downdown8', 'updown7', 'updown8','pressure8','fingerarea8']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ = df[['holdtime9', 'downdown8', 'downdown9', 'updown8', 'updown9','pressure9','fingerarea9']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2_ = df[['holdtime10', 'downdown9', 'downdown10', 'updown9', 'updown10','pressure10','fingerarea10']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_ = df[['holdtime11', 'downdown10', 'downdown11', 'updown10', 'updown11','pressure11','fingerarea11']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = df[['holdtime12', 'downdown11', 'downdown12', 'updown11', 'updown12','pressure12','fingerarea12']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ = df[['holdtime13', 'downdown12', 'downdown13', 'updown12', 'updown13','pressure13','fingerarea13']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = df[['holdtime14', 'downdown13', 'updown13','pressure14','fingerarea14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_.insert(2, 'downdown14', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_.insert(4, 'updown14', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = l_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.538793, 0.      , 0.027918, 0.      , 0.02735 , 0.274194,\n",
       "       0.299065])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = []\n",
    "for i in range(2142):\n",
    "    inter_ = []\n",
    "    inter_.append(dot_[i].tolist())\n",
    "    inter_.append(t_[i].tolist())\n",
    "    inter_.append(i_[i].tolist())\n",
    "    inter_.append(e_[i].tolist())\n",
    "    inter_.append(num_[i].tolist())\n",
    "    inter_.append(five_[i].tolist())\n",
    "    inter_.append(lang_[i].tolist())\n",
    "    inter_.append(shift1_[i].tolist())\n",
    "    inter_.append(R_[i].tolist())\n",
    "    inter_.append(shift2_[i].tolist())\n",
    "    inter_.append(o_[i].tolist())\n",
    "    inter_.append(a_[i].tolist())\n",
    "    inter_.append(n_[i].tolist())\n",
    "    inter_.append(l_[i].tolist())\n",
    "    main.append(inter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_np = np.array(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 14, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[51].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the dataset into the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(main_np, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 14, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.6000000000001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, train_test_split splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers import GRU\n",
    "from keras.layers import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(GRU(12,  input_shape = (14, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 12)                720       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 42)                546       \n",
      "=================================================================\n",
      "Total params: 1,266\n",
      "Trainable params: 1,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = optimizers.SGD(lr = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "                             #verbose=1, \n",
    "                             monitor='val_acc',\n",
    "                             save_best_only=True, \n",
    "                             mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', \n",
    "                   mode = 'auto', \n",
    "                   patience=100, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1e+03 ns, total: 5 Âµs\n",
      "Wall time: 11 Âµs\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/2000\n",
      " - 2s - loss: 3.6980 - acc: 0.0314 - val_loss: 3.4966 - val_acc: 0.0204\n",
      "Epoch 2/2000\n",
      " - 1s - loss: 3.3727 - acc: 0.0562 - val_loss: 3.2792 - val_acc: 0.0816\n",
      "Epoch 3/2000\n",
      " - 1s - loss: 3.1686 - acc: 0.0766 - val_loss: 3.0283 - val_acc: 0.0787\n",
      "Epoch 4/2000\n",
      " - 1s - loss: 3.0137 - acc: 0.1241 - val_loss: 2.8176 - val_acc: 0.1399\n",
      "Epoch 5/2000\n",
      " - 1s - loss: 2.7953 - acc: 0.1387 - val_loss: 2.7010 - val_acc: 0.1720\n",
      "Epoch 6/2000\n",
      " - 1s - loss: 2.6890 - acc: 0.1686 - val_loss: 2.5758 - val_acc: 0.1895\n",
      "Epoch 7/2000\n",
      " - 1s - loss: 2.5621 - acc: 0.2080 - val_loss: 2.4522 - val_acc: 0.2362\n",
      "Epoch 8/2000\n",
      " - 0s - loss: 2.4546 - acc: 0.2343 - val_loss: 2.3347 - val_acc: 0.2741\n",
      "Epoch 9/2000\n",
      " - 1s - loss: 2.3328 - acc: 0.2540 - val_loss: 2.2625 - val_acc: 0.3032\n",
      "Epoch 10/2000\n",
      " - 1s - loss: 2.2731 - acc: 0.2818 - val_loss: 2.1399 - val_acc: 0.3061\n",
      "Epoch 11/2000\n",
      " - 0s - loss: 2.1824 - acc: 0.2942 - val_loss: 2.0712 - val_acc: 0.3236\n",
      "Epoch 12/2000\n",
      " - 0s - loss: 2.1195 - acc: 0.3051 - val_loss: 2.0605 - val_acc: 0.2974\n",
      "Epoch 13/2000\n",
      " - 0s - loss: 2.1009 - acc: 0.3109 - val_loss: 2.0259 - val_acc: 0.3353\n",
      "Epoch 14/2000\n",
      " - 0s - loss: 2.0525 - acc: 0.3248 - val_loss: 2.0243 - val_acc: 0.3732\n",
      "Epoch 15/2000\n",
      " - 1s - loss: 2.0157 - acc: 0.3409 - val_loss: 1.9152 - val_acc: 0.3469\n",
      "Epoch 16/2000\n",
      " - 1s - loss: 1.9398 - acc: 0.3708 - val_loss: 1.8527 - val_acc: 0.3557\n",
      "Epoch 17/2000\n",
      " - 1s - loss: 1.9279 - acc: 0.3635 - val_loss: 1.8471 - val_acc: 0.3848\n",
      "Epoch 18/2000\n",
      " - 1s - loss: 1.8902 - acc: 0.3876 - val_loss: 1.7880 - val_acc: 0.3878\n",
      "Epoch 19/2000\n",
      " - 0s - loss: 1.8467 - acc: 0.3686 - val_loss: 1.7241 - val_acc: 0.4315\n",
      "Epoch 20/2000\n",
      " - 0s - loss: 1.7892 - acc: 0.4073 - val_loss: 1.7235 - val_acc: 0.4111\n",
      "Epoch 21/2000\n",
      " - 1s - loss: 1.8110 - acc: 0.4036 - val_loss: 1.7076 - val_acc: 0.4227\n",
      "Epoch 22/2000\n",
      " - 1s - loss: 1.7562 - acc: 0.4161 - val_loss: 1.7416 - val_acc: 0.3936\n",
      "Epoch 23/2000\n",
      " - 0s - loss: 1.7245 - acc: 0.4146 - val_loss: 1.6610 - val_acc: 0.4344\n",
      "Epoch 24/2000\n",
      " - 1s - loss: 1.7066 - acc: 0.4292 - val_loss: 1.6412 - val_acc: 0.4519\n",
      "Epoch 25/2000\n",
      " - 1s - loss: 1.7025 - acc: 0.4336 - val_loss: 1.6181 - val_acc: 0.4402\n",
      "Epoch 26/2000\n",
      " - 1s - loss: 1.6626 - acc: 0.4474 - val_loss: 1.5088 - val_acc: 0.5131\n",
      "Epoch 27/2000\n",
      " - 1s - loss: 1.6402 - acc: 0.4569 - val_loss: 1.5958 - val_acc: 0.4431\n",
      "Epoch 28/2000\n",
      " - 1s - loss: 1.6162 - acc: 0.4613 - val_loss: 1.5628 - val_acc: 0.4577\n",
      "Epoch 29/2000\n",
      " - 1s - loss: 1.6100 - acc: 0.4562 - val_loss: 1.5364 - val_acc: 0.4898\n",
      "Epoch 30/2000\n",
      " - 1s - loss: 1.6186 - acc: 0.4540 - val_loss: 1.5330 - val_acc: 0.4810\n",
      "Epoch 31/2000\n",
      " - 1s - loss: 1.6081 - acc: 0.4533 - val_loss: 1.4764 - val_acc: 0.5481\n",
      "Epoch 32/2000\n",
      " - 1s - loss: 1.5522 - acc: 0.4723 - val_loss: 1.4294 - val_acc: 0.5394\n",
      "Epoch 33/2000\n",
      " - 0s - loss: 1.5098 - acc: 0.4818 - val_loss: 1.4237 - val_acc: 0.5423\n",
      "Epoch 34/2000\n",
      " - 1s - loss: 1.5365 - acc: 0.4912 - val_loss: 1.4314 - val_acc: 0.5160\n",
      "Epoch 35/2000\n",
      " - 1s - loss: 1.4997 - acc: 0.4949 - val_loss: 1.3787 - val_acc: 0.5364\n",
      "Epoch 36/2000\n",
      " - 1s - loss: 1.5151 - acc: 0.4803 - val_loss: 1.3635 - val_acc: 0.5510\n",
      "Epoch 37/2000\n",
      " - 1s - loss: 1.4770 - acc: 0.5036 - val_loss: 1.3916 - val_acc: 0.5773\n",
      "Epoch 38/2000\n",
      " - 1s - loss: 1.4797 - acc: 0.5015 - val_loss: 1.3782 - val_acc: 0.5364\n",
      "Epoch 39/2000\n",
      " - 1s - loss: 1.4611 - acc: 0.5022 - val_loss: 1.3055 - val_acc: 0.5918\n",
      "Epoch 40/2000\n",
      " - 1s - loss: 1.4650 - acc: 0.4832 - val_loss: 1.3405 - val_acc: 0.5685\n",
      "Epoch 41/2000\n",
      " - 1s - loss: 1.3933 - acc: 0.5234 - val_loss: 1.2496 - val_acc: 0.6064\n",
      "Epoch 42/2000\n",
      " - 1s - loss: 1.4066 - acc: 0.5321 - val_loss: 1.2627 - val_acc: 0.5656\n",
      "Epoch 43/2000\n",
      " - 1s - loss: 1.4110 - acc: 0.5248 - val_loss: 1.2729 - val_acc: 0.5452\n",
      "Epoch 44/2000\n",
      " - 1s - loss: 1.4287 - acc: 0.5124 - val_loss: 1.2133 - val_acc: 0.6181\n",
      "Epoch 45/2000\n",
      " - 1s - loss: 1.3786 - acc: 0.5321 - val_loss: 1.2385 - val_acc: 0.5977\n",
      "Epoch 46/2000\n",
      " - 1s - loss: 1.3935 - acc: 0.5234 - val_loss: 1.1871 - val_acc: 0.6239\n",
      "Epoch 47/2000\n",
      " - 1s - loss: 1.3875 - acc: 0.5277 - val_loss: 1.1900 - val_acc: 0.6035\n",
      "Epoch 48/2000\n",
      " - 1s - loss: 1.3577 - acc: 0.5234 - val_loss: 1.2028 - val_acc: 0.6152\n",
      "Epoch 49/2000\n",
      " - 1s - loss: 1.3420 - acc: 0.5336 - val_loss: 1.1921 - val_acc: 0.5948\n",
      "Epoch 50/2000\n",
      " - 1s - loss: 1.3415 - acc: 0.5277 - val_loss: 1.2867 - val_acc: 0.5948\n",
      "Epoch 51/2000\n",
      " - 1s - loss: 1.3337 - acc: 0.5277 - val_loss: 1.2206 - val_acc: 0.6064\n",
      "Epoch 52/2000\n",
      " - 1s - loss: 1.3478 - acc: 0.5431 - val_loss: 1.2140 - val_acc: 0.5831\n",
      "Epoch 53/2000\n",
      " - 1s - loss: 1.2923 - acc: 0.5474 - val_loss: 1.2022 - val_acc: 0.6385\n",
      "Epoch 54/2000\n",
      " - 1s - loss: 1.3108 - acc: 0.5526 - val_loss: 1.1428 - val_acc: 0.6239\n",
      "Epoch 55/2000\n",
      " - 1s - loss: 1.3223 - acc: 0.5606 - val_loss: 1.2674 - val_acc: 0.5627\n",
      "Epoch 56/2000\n",
      " - 0s - loss: 1.3116 - acc: 0.5474 - val_loss: 1.1925 - val_acc: 0.5889\n",
      "Epoch 57/2000\n",
      " - 1s - loss: 1.2791 - acc: 0.5569 - val_loss: 1.2367 - val_acc: 0.6064\n",
      "Epoch 58/2000\n",
      " - 0s - loss: 1.3030 - acc: 0.5504 - val_loss: 1.1791 - val_acc: 0.6122\n",
      "Epoch 59/2000\n",
      " - 1s - loss: 1.2761 - acc: 0.5453 - val_loss: 1.2262 - val_acc: 0.5773\n",
      "Epoch 60/2000\n",
      " - 1s - loss: 1.3020 - acc: 0.5409 - val_loss: 1.1002 - val_acc: 0.6501\n",
      "Epoch 61/2000\n",
      " - 1s - loss: 1.2424 - acc: 0.5861 - val_loss: 1.1095 - val_acc: 0.6356\n",
      "Epoch 62/2000\n",
      " - 1s - loss: 1.2951 - acc: 0.5650 - val_loss: 1.1090 - val_acc: 0.6327\n",
      "Epoch 63/2000\n",
      " - 1s - loss: 1.2442 - acc: 0.5752 - val_loss: 1.1741 - val_acc: 0.6356\n",
      "Epoch 64/2000\n",
      " - 1s - loss: 1.2549 - acc: 0.5664 - val_loss: 1.1232 - val_acc: 0.6327\n",
      "Epoch 65/2000\n",
      " - 1s - loss: 1.1968 - acc: 0.6000 - val_loss: 1.1556 - val_acc: 0.6239\n",
      "Epoch 66/2000\n",
      " - 1s - loss: 1.3172 - acc: 0.5526 - val_loss: 1.2498 - val_acc: 0.5743\n",
      "Epoch 67/2000\n",
      " - 1s - loss: 1.2672 - acc: 0.5664 - val_loss: 1.0614 - val_acc: 0.6501\n",
      "Epoch 68/2000\n",
      " - 1s - loss: 1.1951 - acc: 0.5993 - val_loss: 1.1220 - val_acc: 0.6356\n",
      "Epoch 69/2000\n",
      " - 1s - loss: 1.2031 - acc: 0.5854 - val_loss: 1.0824 - val_acc: 0.6822\n",
      "Epoch 70/2000\n",
      " - 1s - loss: 1.1719 - acc: 0.5964 - val_loss: 1.1173 - val_acc: 0.6064\n",
      "Epoch 71/2000\n",
      " - 1s - loss: 1.2443 - acc: 0.5759 - val_loss: 1.0476 - val_acc: 0.6472\n",
      "Epoch 72/2000\n",
      " - 1s - loss: 1.2049 - acc: 0.5891 - val_loss: 1.0784 - val_acc: 0.6676\n",
      "Epoch 73/2000\n",
      " - 1s - loss: 1.1446 - acc: 0.5985 - val_loss: 1.0475 - val_acc: 0.6647\n",
      "Epoch 74/2000\n",
      " - 1s - loss: 1.1766 - acc: 0.5978 - val_loss: 1.0608 - val_acc: 0.6618\n",
      "Epoch 75/2000\n",
      " - 1s - loss: 1.1555 - acc: 0.6095 - val_loss: 1.0763 - val_acc: 0.6443\n",
      "Epoch 76/2000\n",
      " - 1s - loss: 1.1568 - acc: 0.5949 - val_loss: 1.0408 - val_acc: 0.6676\n",
      "Epoch 77/2000\n",
      " - 0s - loss: 1.1608 - acc: 0.6161 - val_loss: 1.1095 - val_acc: 0.6327\n",
      "Epoch 78/2000\n",
      " - 1s - loss: 1.1372 - acc: 0.5920 - val_loss: 1.0439 - val_acc: 0.6706\n",
      "Epoch 79/2000\n",
      " - 1s - loss: 1.1246 - acc: 0.5927 - val_loss: 1.1051 - val_acc: 0.6676\n",
      "Epoch 80/2000\n",
      " - 1s - loss: 1.1441 - acc: 0.5971 - val_loss: 1.0419 - val_acc: 0.6472\n",
      "Epoch 81/2000\n",
      " - 1s - loss: 1.1744 - acc: 0.5927 - val_loss: 1.0352 - val_acc: 0.6414\n",
      "Epoch 82/2000\n",
      " - 1s - loss: 1.1405 - acc: 0.6044 - val_loss: 0.9981 - val_acc: 0.6822\n",
      "Epoch 83/2000\n",
      " - 1s - loss: 1.1465 - acc: 0.6036 - val_loss: 1.0369 - val_acc: 0.6851\n",
      "Epoch 84/2000\n",
      " - 1s - loss: 1.1268 - acc: 0.6102 - val_loss: 0.9943 - val_acc: 0.6822\n",
      "Epoch 85/2000\n",
      " - 1s - loss: 1.1238 - acc: 0.6270 - val_loss: 1.0255 - val_acc: 0.6910\n",
      "Epoch 86/2000\n",
      " - 0s - loss: 1.1283 - acc: 0.5971 - val_loss: 0.9671 - val_acc: 0.7143\n",
      "Epoch 87/2000\n",
      " - 1s - loss: 1.1651 - acc: 0.6000 - val_loss: 1.0235 - val_acc: 0.6793\n",
      "Epoch 88/2000\n",
      " - 1s - loss: 1.1061 - acc: 0.6088 - val_loss: 0.9804 - val_acc: 0.7085\n",
      "Epoch 89/2000\n",
      " - 1s - loss: 1.1080 - acc: 0.5985 - val_loss: 0.9901 - val_acc: 0.6822\n",
      "Epoch 90/2000\n",
      " - 1s - loss: 1.0671 - acc: 0.6139 - val_loss: 1.0174 - val_acc: 0.6589\n",
      "Epoch 91/2000\n",
      " - 1s - loss: 1.0910 - acc: 0.6088 - val_loss: 0.9985 - val_acc: 0.6764\n",
      "Epoch 92/2000\n",
      " - 1s - loss: 1.0785 - acc: 0.6285 - val_loss: 1.0140 - val_acc: 0.6764\n",
      "Epoch 93/2000\n",
      " - 1s - loss: 1.1198 - acc: 0.6102 - val_loss: 1.0364 - val_acc: 0.6793\n",
      "Epoch 94/2000\n",
      " - 1s - loss: 1.0682 - acc: 0.6204 - val_loss: 0.9759 - val_acc: 0.7172\n",
      "Epoch 95/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 1.1017 - acc: 0.6102 - val_loss: 0.9967 - val_acc: 0.7026\n",
      "Epoch 96/2000\n",
      " - 1s - loss: 1.1031 - acc: 0.6117 - val_loss: 1.0140 - val_acc: 0.6939\n",
      "Epoch 97/2000\n",
      " - 1s - loss: 1.0773 - acc: 0.6343 - val_loss: 0.9724 - val_acc: 0.7172\n",
      "Epoch 98/2000\n",
      " - 1s - loss: 1.0979 - acc: 0.6204 - val_loss: 0.9570 - val_acc: 0.7055\n",
      "Epoch 99/2000\n",
      " - 1s - loss: 1.0724 - acc: 0.6350 - val_loss: 1.0144 - val_acc: 0.6443\n",
      "Epoch 100/2000\n",
      " - 1s - loss: 1.0580 - acc: 0.6423 - val_loss: 0.9604 - val_acc: 0.7143\n",
      "Epoch 101/2000\n",
      " - 1s - loss: 1.0717 - acc: 0.6277 - val_loss: 0.9890 - val_acc: 0.6997\n",
      "Epoch 102/2000\n",
      " - 1s - loss: 1.0760 - acc: 0.6204 - val_loss: 0.9742 - val_acc: 0.6880\n",
      "Epoch 103/2000\n",
      " - 1s - loss: 1.0773 - acc: 0.6277 - val_loss: 1.0092 - val_acc: 0.6822\n",
      "Epoch 104/2000\n",
      " - 1s - loss: 1.0634 - acc: 0.6358 - val_loss: 0.9582 - val_acc: 0.6822\n",
      "Epoch 105/2000\n",
      " - 1s - loss: 1.0630 - acc: 0.6270 - val_loss: 1.0078 - val_acc: 0.6880\n",
      "Epoch 106/2000\n",
      " - 2s - loss: 1.0833 - acc: 0.6255 - val_loss: 0.9280 - val_acc: 0.7318\n",
      "Epoch 107/2000\n",
      " - 2s - loss: 1.1154 - acc: 0.5920 - val_loss: 0.9452 - val_acc: 0.7114\n",
      "Epoch 108/2000\n",
      " - 1s - loss: 1.0373 - acc: 0.6409 - val_loss: 1.0056 - val_acc: 0.6939\n",
      "Epoch 109/2000\n",
      " - 1s - loss: 1.0777 - acc: 0.6285 - val_loss: 1.0299 - val_acc: 0.6706\n",
      "Epoch 110/2000\n",
      " - 1s - loss: 1.0564 - acc: 0.6394 - val_loss: 0.9281 - val_acc: 0.7055\n",
      "Epoch 111/2000\n",
      " - 1s - loss: 1.0240 - acc: 0.6489 - val_loss: 0.9853 - val_acc: 0.6676\n",
      "Epoch 112/2000\n",
      " - 1s - loss: 1.0798 - acc: 0.6073 - val_loss: 0.9632 - val_acc: 0.6968\n",
      "Epoch 113/2000\n",
      " - 1s - loss: 1.1069 - acc: 0.6102 - val_loss: 0.8942 - val_acc: 0.7318\n",
      "Epoch 114/2000\n",
      " - 1s - loss: 1.0203 - acc: 0.6321 - val_loss: 0.9510 - val_acc: 0.6997\n",
      "Epoch 115/2000\n",
      " - 1s - loss: 1.1150 - acc: 0.6022 - val_loss: 0.9222 - val_acc: 0.6997\n",
      "Epoch 116/2000\n",
      " - 1s - loss: 1.0347 - acc: 0.6511 - val_loss: 0.8897 - val_acc: 0.7201\n",
      "Epoch 117/2000\n",
      " - 1s - loss: 1.0291 - acc: 0.6343 - val_loss: 1.0050 - val_acc: 0.6618\n",
      "Epoch 118/2000\n",
      " - 1s - loss: 1.1122 - acc: 0.6226 - val_loss: 0.9880 - val_acc: 0.7114\n",
      "Epoch 119/2000\n",
      " - 1s - loss: 1.0247 - acc: 0.6431 - val_loss: 0.9594 - val_acc: 0.7318\n",
      "Epoch 120/2000\n",
      " - 1s - loss: 1.0048 - acc: 0.6401 - val_loss: 0.9132 - val_acc: 0.7259\n",
      "Epoch 121/2000\n",
      " - 1s - loss: 1.0409 - acc: 0.6372 - val_loss: 0.9638 - val_acc: 0.6880\n",
      "Epoch 122/2000\n",
      " - 1s - loss: 1.0579 - acc: 0.6190 - val_loss: 0.9715 - val_acc: 0.7085\n",
      "Epoch 123/2000\n",
      " - 1s - loss: 1.0687 - acc: 0.6263 - val_loss: 0.9210 - val_acc: 0.7289\n",
      "Epoch 124/2000\n",
      " - 1s - loss: 1.0048 - acc: 0.6489 - val_loss: 0.9981 - val_acc: 0.6910\n",
      "Epoch 125/2000\n",
      " - 1s - loss: 1.0694 - acc: 0.6212 - val_loss: 0.9138 - val_acc: 0.7230\n",
      "Epoch 126/2000\n",
      " - 1s - loss: 1.0305 - acc: 0.6270 - val_loss: 0.9278 - val_acc: 0.7230\n",
      "Epoch 127/2000\n",
      " - 1s - loss: 1.0068 - acc: 0.6431 - val_loss: 0.9301 - val_acc: 0.7085\n",
      "Epoch 128/2000\n",
      " - 1s - loss: 0.9804 - acc: 0.6577 - val_loss: 0.8966 - val_acc: 0.7114\n",
      "Epoch 129/2000\n",
      " - 1s - loss: 0.9970 - acc: 0.6533 - val_loss: 0.9903 - val_acc: 0.6735\n",
      "Epoch 130/2000\n",
      " - 1s - loss: 1.0244 - acc: 0.6416 - val_loss: 0.9145 - val_acc: 0.7143\n",
      "Epoch 131/2000\n",
      " - 1s - loss: 1.0693 - acc: 0.6190 - val_loss: 0.9707 - val_acc: 0.7026\n",
      "Epoch 132/2000\n",
      " - 1s - loss: 1.0635 - acc: 0.6409 - val_loss: 0.9296 - val_acc: 0.6997\n",
      "Epoch 133/2000\n",
      " - 1s - loss: 1.0264 - acc: 0.6431 - val_loss: 0.9066 - val_acc: 0.7318\n",
      "Epoch 134/2000\n",
      " - 1s - loss: 0.9873 - acc: 0.6518 - val_loss: 0.8761 - val_acc: 0.7289\n",
      "Epoch 135/2000\n",
      " - 1s - loss: 1.0233 - acc: 0.6496 - val_loss: 0.8934 - val_acc: 0.7259\n",
      "Epoch 136/2000\n",
      " - 1s - loss: 1.0202 - acc: 0.6482 - val_loss: 1.0328 - val_acc: 0.6910\n",
      "Epoch 137/2000\n",
      " - 1s - loss: 1.0358 - acc: 0.6350 - val_loss: 1.0551 - val_acc: 0.6560\n",
      "Epoch 138/2000\n",
      " - 1s - loss: 1.0300 - acc: 0.6350 - val_loss: 0.9237 - val_acc: 0.7026\n",
      "Epoch 139/2000\n",
      " - 1s - loss: 1.0107 - acc: 0.6686 - val_loss: 0.8801 - val_acc: 0.7230\n",
      "Epoch 140/2000\n",
      " - 1s - loss: 0.9710 - acc: 0.6664 - val_loss: 0.9131 - val_acc: 0.7230\n",
      "Epoch 141/2000\n",
      " - 1s - loss: 0.9752 - acc: 0.6628 - val_loss: 0.8878 - val_acc: 0.7143\n",
      "Epoch 142/2000\n",
      " - 1s - loss: 1.0102 - acc: 0.6474 - val_loss: 0.9117 - val_acc: 0.7347\n",
      "Epoch 143/2000\n",
      " - 1s - loss: 0.9851 - acc: 0.6380 - val_loss: 1.0029 - val_acc: 0.6851\n",
      "Epoch 144/2000\n",
      " - 1s - loss: 1.0302 - acc: 0.6350 - val_loss: 0.9744 - val_acc: 0.6764\n",
      "Epoch 145/2000\n",
      " - 1s - loss: 0.9972 - acc: 0.6540 - val_loss: 0.9333 - val_acc: 0.7085\n",
      "Epoch 146/2000\n",
      " - 1s - loss: 0.9900 - acc: 0.6526 - val_loss: 0.9303 - val_acc: 0.7055\n",
      "Epoch 147/2000\n",
      " - 1s - loss: 0.9743 - acc: 0.6672 - val_loss: 0.9506 - val_acc: 0.6968\n",
      "Epoch 148/2000\n",
      " - 1s - loss: 0.9756 - acc: 0.6672 - val_loss: 0.9540 - val_acc: 0.7114\n",
      "Epoch 149/2000\n",
      " - 1s - loss: 0.9681 - acc: 0.6482 - val_loss: 0.9182 - val_acc: 0.7114\n",
      "Epoch 150/2000\n",
      " - 1s - loss: 0.9329 - acc: 0.6715 - val_loss: 0.9212 - val_acc: 0.7289\n",
      "Epoch 151/2000\n",
      " - 1s - loss: 0.9716 - acc: 0.6518 - val_loss: 0.9123 - val_acc: 0.7055\n",
      "Epoch 152/2000\n",
      " - 1s - loss: 0.9956 - acc: 0.6372 - val_loss: 0.9119 - val_acc: 0.7085\n",
      "Epoch 153/2000\n",
      " - 1s - loss: 0.9446 - acc: 0.6737 - val_loss: 0.8930 - val_acc: 0.7085\n",
      "Epoch 154/2000\n",
      " - 1s - loss: 0.9459 - acc: 0.6650 - val_loss: 0.9034 - val_acc: 0.7230\n",
      "Epoch 155/2000\n",
      " - 0s - loss: 0.9870 - acc: 0.6474 - val_loss: 0.9561 - val_acc: 0.7055\n",
      "Epoch 156/2000\n",
      " - 1s - loss: 0.9786 - acc: 0.6686 - val_loss: 0.9164 - val_acc: 0.6910\n",
      "Epoch 157/2000\n",
      " - 1s - loss: 0.9740 - acc: 0.6482 - val_loss: 0.9678 - val_acc: 0.7085\n",
      "Epoch 158/2000\n",
      " - 1s - loss: 0.9339 - acc: 0.6679 - val_loss: 0.8716 - val_acc: 0.7318\n",
      "Epoch 159/2000\n",
      " - 1s - loss: 0.8924 - acc: 0.7000 - val_loss: 0.8916 - val_acc: 0.7230\n",
      "Epoch 160/2000\n",
      " - 1s - loss: 0.8929 - acc: 0.6971 - val_loss: 0.9250 - val_acc: 0.7114\n",
      "Epoch 161/2000\n",
      " - 1s - loss: 0.9719 - acc: 0.6504 - val_loss: 0.8644 - val_acc: 0.7638\n",
      "Epoch 162/2000\n",
      " - 1s - loss: 0.9541 - acc: 0.6650 - val_loss: 0.9398 - val_acc: 0.7201\n",
      "Epoch 163/2000\n",
      " - 1s - loss: 1.0232 - acc: 0.6321 - val_loss: 0.9099 - val_acc: 0.7143\n",
      "Epoch 164/2000\n",
      " - 1s - loss: 0.9198 - acc: 0.6752 - val_loss: 0.8891 - val_acc: 0.7085\n",
      "Epoch 165/2000\n",
      " - 1s - loss: 0.9338 - acc: 0.6723 - val_loss: 0.8870 - val_acc: 0.7318\n",
      "Epoch 166/2000\n",
      " - 1s - loss: 0.9031 - acc: 0.6796 - val_loss: 0.8710 - val_acc: 0.7434\n",
      "Epoch 167/2000\n",
      " - 1s - loss: 0.9632 - acc: 0.6591 - val_loss: 0.9367 - val_acc: 0.6793\n",
      "Epoch 168/2000\n",
      " - 1s - loss: 0.9254 - acc: 0.6708 - val_loss: 0.8660 - val_acc: 0.7114\n",
      "Epoch 169/2000\n",
      " - 1s - loss: 0.9719 - acc: 0.6540 - val_loss: 0.9035 - val_acc: 0.7201\n",
      "Epoch 170/2000\n",
      " - 1s - loss: 0.9387 - acc: 0.6672 - val_loss: 0.9202 - val_acc: 0.7464\n",
      "Epoch 171/2000\n",
      " - 1s - loss: 0.9399 - acc: 0.6672 - val_loss: 0.8964 - val_acc: 0.7172\n",
      "Epoch 172/2000\n",
      " - 1s - loss: 0.9765 - acc: 0.6569 - val_loss: 0.8885 - val_acc: 0.7259\n",
      "Epoch 173/2000\n",
      " - 1s - loss: 0.9166 - acc: 0.6803 - val_loss: 0.9353 - val_acc: 0.7201\n",
      "Epoch 174/2000\n",
      " - 1s - loss: 0.8991 - acc: 0.6730 - val_loss: 0.8753 - val_acc: 0.7085\n",
      "Epoch 175/2000\n",
      " - 1s - loss: 0.9040 - acc: 0.6847 - val_loss: 0.8912 - val_acc: 0.6997\n",
      "Epoch 176/2000\n",
      " - 1s - loss: 0.9274 - acc: 0.6796 - val_loss: 0.8251 - val_acc: 0.7289\n",
      "Epoch 177/2000\n",
      " - 1s - loss: 0.9354 - acc: 0.6693 - val_loss: 0.8411 - val_acc: 0.7638\n",
      "Epoch 178/2000\n",
      " - 1s - loss: 0.9527 - acc: 0.6438 - val_loss: 0.9123 - val_acc: 0.7055\n",
      "Epoch 179/2000\n",
      " - 1s - loss: 0.9126 - acc: 0.7000 - val_loss: 0.8692 - val_acc: 0.7201\n",
      "Epoch 180/2000\n",
      " - 1s - loss: 0.9011 - acc: 0.6752 - val_loss: 0.9500 - val_acc: 0.7026\n",
      "Epoch 181/2000\n",
      " - 1s - loss: 0.9900 - acc: 0.6730 - val_loss: 0.8773 - val_acc: 0.7289\n",
      "Epoch 182/2000\n",
      " - 1s - loss: 0.9379 - acc: 0.6628 - val_loss: 0.8942 - val_acc: 0.7259\n",
      "Epoch 183/2000\n",
      " - 1s - loss: 0.9486 - acc: 0.6737 - val_loss: 0.8852 - val_acc: 0.7172\n",
      "Epoch 184/2000\n",
      " - 1s - loss: 0.9070 - acc: 0.6766 - val_loss: 0.8616 - val_acc: 0.7376\n",
      "Epoch 185/2000\n",
      " - 1s - loss: 0.9150 - acc: 0.6825 - val_loss: 0.9004 - val_acc: 0.7201\n",
      "Epoch 186/2000\n",
      " - 1s - loss: 0.8816 - acc: 0.6869 - val_loss: 0.9278 - val_acc: 0.7259\n",
      "Epoch 187/2000\n",
      " - 1s - loss: 0.9074 - acc: 0.6774 - val_loss: 0.8577 - val_acc: 0.7347\n",
      "Epoch 188/2000\n",
      " - 1s - loss: 0.8989 - acc: 0.6803 - val_loss: 0.8634 - val_acc: 0.7434\n",
      "Epoch 189/2000\n",
      " - 1s - loss: 0.8519 - acc: 0.6971 - val_loss: 0.8349 - val_acc: 0.7376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/2000\n",
      " - 0s - loss: 0.9005 - acc: 0.6745 - val_loss: 0.9099 - val_acc: 0.7347\n",
      "Epoch 191/2000\n",
      " - 1s - loss: 0.9221 - acc: 0.6796 - val_loss: 0.8508 - val_acc: 0.7464\n",
      "Epoch 192/2000\n",
      " - 1s - loss: 0.8804 - acc: 0.6934 - val_loss: 0.9033 - val_acc: 0.7055\n",
      "Epoch 193/2000\n",
      " - 1s - loss: 0.9423 - acc: 0.6745 - val_loss: 1.0928 - val_acc: 0.6676\n",
      "Epoch 194/2000\n",
      " - 1s - loss: 0.9386 - acc: 0.6540 - val_loss: 0.8964 - val_acc: 0.7318\n",
      "Epoch 195/2000\n",
      " - 1s - loss: 0.9107 - acc: 0.6708 - val_loss: 0.9202 - val_acc: 0.7405\n",
      "Epoch 196/2000\n",
      " - 1s - loss: 0.9051 - acc: 0.6934 - val_loss: 0.9206 - val_acc: 0.7230\n",
      "Epoch 197/2000\n",
      " - 1s - loss: 0.9005 - acc: 0.6620 - val_loss: 0.8871 - val_acc: 0.7464\n",
      "Epoch 198/2000\n",
      " - 1s - loss: 0.8852 - acc: 0.6803 - val_loss: 0.9055 - val_acc: 0.6997\n",
      "Epoch 199/2000\n",
      " - 1s - loss: 0.9406 - acc: 0.6599 - val_loss: 0.9004 - val_acc: 0.7464\n",
      "Epoch 200/2000\n",
      " - 1s - loss: 0.8937 - acc: 0.6613 - val_loss: 0.8482 - val_acc: 0.7405\n",
      "Epoch 201/2000\n",
      " - 1s - loss: 0.9787 - acc: 0.6723 - val_loss: 0.9751 - val_acc: 0.7114\n",
      "Epoch 202/2000\n",
      " - 1s - loss: 0.9190 - acc: 0.6891 - val_loss: 0.8578 - val_acc: 0.7055\n",
      "Epoch 203/2000\n",
      " - 1s - loss: 0.8825 - acc: 0.6854 - val_loss: 0.8761 - val_acc: 0.7085\n",
      "Epoch 204/2000\n",
      " - 1s - loss: 0.9168 - acc: 0.6672 - val_loss: 0.9167 - val_acc: 0.7143\n",
      "Epoch 205/2000\n",
      " - 1s - loss: 0.8581 - acc: 0.6971 - val_loss: 0.8888 - val_acc: 0.7230\n",
      "Epoch 206/2000\n",
      " - 1s - loss: 1.3263 - acc: 0.5898 - val_loss: 1.0201 - val_acc: 0.6735\n",
      "Epoch 207/2000\n",
      " - 1s - loss: 0.9430 - acc: 0.6672 - val_loss: 0.8310 - val_acc: 0.7259\n",
      "Epoch 208/2000\n",
      " - 1s - loss: 0.9229 - acc: 0.6759 - val_loss: 0.8267 - val_acc: 0.7609\n",
      "Epoch 209/2000\n",
      " - 1s - loss: 0.8883 - acc: 0.7029 - val_loss: 0.8586 - val_acc: 0.7464\n",
      "Epoch 210/2000\n",
      " - 1s - loss: 0.8666 - acc: 0.6971 - val_loss: 0.8495 - val_acc: 0.7405\n",
      "Epoch 211/2000\n",
      " - 1s - loss: 0.8378 - acc: 0.7000 - val_loss: 0.9139 - val_acc: 0.7201\n",
      "Epoch 212/2000\n",
      " - 1s - loss: 0.8627 - acc: 0.7066 - val_loss: 0.8834 - val_acc: 0.7376\n",
      "Epoch 213/2000\n",
      " - 1s - loss: 0.8386 - acc: 0.6985 - val_loss: 0.8293 - val_acc: 0.7464\n",
      "Epoch 214/2000\n",
      " - 1s - loss: 0.8547 - acc: 0.7051 - val_loss: 0.8712 - val_acc: 0.7668\n",
      "Epoch 215/2000\n",
      " - 1s - loss: 0.8470 - acc: 0.6993 - val_loss: 0.8233 - val_acc: 0.7493\n",
      "Epoch 216/2000\n",
      " - 1s - loss: 0.8782 - acc: 0.6920 - val_loss: 0.9036 - val_acc: 0.7289\n",
      "Epoch 217/2000\n",
      " - 1s - loss: 0.8569 - acc: 0.6891 - val_loss: 0.8581 - val_acc: 0.7230\n",
      "Epoch 218/2000\n",
      " - 1s - loss: 0.8948 - acc: 0.6905 - val_loss: 0.8506 - val_acc: 0.7522\n",
      "Epoch 219/2000\n",
      " - 1s - loss: 0.8793 - acc: 0.6905 - val_loss: 0.8570 - val_acc: 0.7289\n",
      "Epoch 220/2000\n",
      " - 1s - loss: 0.8324 - acc: 0.7182 - val_loss: 0.8765 - val_acc: 0.7318\n",
      "Epoch 221/2000\n",
      " - 1s - loss: 0.8556 - acc: 0.7088 - val_loss: 0.8985 - val_acc: 0.7434\n",
      "Epoch 222/2000\n",
      " - 1s - loss: 0.8419 - acc: 0.7109 - val_loss: 0.8672 - val_acc: 0.7347\n",
      "Epoch 223/2000\n",
      " - 1s - loss: 0.8409 - acc: 0.7007 - val_loss: 0.8887 - val_acc: 0.7230\n",
      "Epoch 224/2000\n",
      " - 1s - loss: 0.8495 - acc: 0.7117 - val_loss: 0.8896 - val_acc: 0.7143\n",
      "Epoch 225/2000\n",
      " - 1s - loss: 0.8337 - acc: 0.7007 - val_loss: 0.9745 - val_acc: 0.7172\n",
      "Epoch 226/2000\n",
      " - 1s - loss: 0.8837 - acc: 0.6883 - val_loss: 0.8709 - val_acc: 0.7580\n",
      "Epoch 227/2000\n",
      " - 1s - loss: 0.8401 - acc: 0.7139 - val_loss: 0.8674 - val_acc: 0.7347\n",
      "Epoch 228/2000\n",
      " - 1s - loss: 0.8035 - acc: 0.7182 - val_loss: 0.8981 - val_acc: 0.7464\n",
      "Epoch 229/2000\n",
      " - 1s - loss: 0.7928 - acc: 0.7095 - val_loss: 0.8278 - val_acc: 0.7697\n",
      "Epoch 230/2000\n",
      " - 1s - loss: 0.8385 - acc: 0.7000 - val_loss: 0.8990 - val_acc: 0.7114\n",
      "Epoch 231/2000\n",
      " - 1s - loss: 0.8497 - acc: 0.7022 - val_loss: 0.9112 - val_acc: 0.6968\n",
      "Epoch 232/2000\n",
      " - 1s - loss: 0.8898 - acc: 0.6905 - val_loss: 0.9238 - val_acc: 0.7259\n",
      "Epoch 233/2000\n",
      " - 1s - loss: 0.9415 - acc: 0.6796 - val_loss: 0.8817 - val_acc: 0.7493\n",
      "Epoch 234/2000\n",
      " - 1s - loss: 0.8402 - acc: 0.6927 - val_loss: 0.8482 - val_acc: 0.7318\n",
      "Epoch 235/2000\n",
      " - 1s - loss: 0.8627 - acc: 0.6978 - val_loss: 0.9206 - val_acc: 0.7230\n",
      "Epoch 236/2000\n",
      " - 1s - loss: 0.8541 - acc: 0.7015 - val_loss: 0.8023 - val_acc: 0.7522\n",
      "Epoch 237/2000\n",
      " - 1s - loss: 0.8380 - acc: 0.7015 - val_loss: 0.8603 - val_acc: 0.7318\n",
      "Epoch 238/2000\n",
      " - 0s - loss: 0.8249 - acc: 0.7051 - val_loss: 0.8285 - val_acc: 0.7493\n",
      "Epoch 239/2000\n",
      " - 1s - loss: 0.8512 - acc: 0.6927 - val_loss: 0.8865 - val_acc: 0.7143\n",
      "Epoch 240/2000\n",
      " - 1s - loss: 0.8566 - acc: 0.6934 - val_loss: 0.7941 - val_acc: 0.7609\n",
      "Epoch 241/2000\n",
      " - 1s - loss: 0.8108 - acc: 0.7124 - val_loss: 0.9547 - val_acc: 0.7201\n",
      "Epoch 242/2000\n",
      " - 1s - loss: 0.8265 - acc: 0.7190 - val_loss: 0.8604 - val_acc: 0.7668\n",
      "Epoch 243/2000\n",
      " - 1s - loss: 0.8338 - acc: 0.7088 - val_loss: 0.8924 - val_acc: 0.7114\n",
      "Epoch 244/2000\n",
      " - 1s - loss: 0.8248 - acc: 0.6985 - val_loss: 0.8556 - val_acc: 0.7259\n",
      "Epoch 245/2000\n",
      " - 1s - loss: 0.8285 - acc: 0.7153 - val_loss: 0.8191 - val_acc: 0.7376\n",
      "Epoch 246/2000\n",
      " - 1s - loss: 0.8064 - acc: 0.7314 - val_loss: 0.8573 - val_acc: 0.7493\n",
      "Epoch 247/2000\n",
      " - 1s - loss: 0.8424 - acc: 0.7073 - val_loss: 0.8961 - val_acc: 0.7289\n",
      "Epoch 248/2000\n",
      " - 1s - loss: 0.8627 - acc: 0.6891 - val_loss: 0.9333 - val_acc: 0.7376\n",
      "Epoch 249/2000\n",
      " - 1s - loss: 0.8382 - acc: 0.7124 - val_loss: 0.8697 - val_acc: 0.7493\n",
      "Epoch 250/2000\n",
      " - 1s - loss: 0.8674 - acc: 0.7022 - val_loss: 0.9406 - val_acc: 0.7055\n",
      "Epoch 251/2000\n",
      " - 1s - loss: 0.9313 - acc: 0.6912 - val_loss: 0.8748 - val_acc: 0.7493\n",
      "Epoch 252/2000\n",
      " - 1s - loss: 0.8864 - acc: 0.6883 - val_loss: 0.8079 - val_acc: 0.7580\n",
      "Epoch 253/2000\n",
      " - 1s - loss: 0.8422 - acc: 0.7022 - val_loss: 0.9820 - val_acc: 0.7026\n",
      "Epoch 254/2000\n",
      " - 1s - loss: 0.8573 - acc: 0.7022 - val_loss: 0.9221 - val_acc: 0.7376\n",
      "Epoch 255/2000\n",
      " - 1s - loss: 0.8551 - acc: 0.7124 - val_loss: 1.0489 - val_acc: 0.6764\n",
      "Epoch 256/2000\n",
      " - 1s - loss: 0.8872 - acc: 0.6869 - val_loss: 0.9424 - val_acc: 0.7172\n",
      "Epoch 257/2000\n",
      " - 1s - loss: 0.9595 - acc: 0.6774 - val_loss: 1.3728 - val_acc: 0.6035\n",
      "Epoch 258/2000\n",
      " - 1s - loss: 1.0577 - acc: 0.6606 - val_loss: 0.8517 - val_acc: 0.7376\n",
      "Epoch 259/2000\n",
      " - 1s - loss: 0.8248 - acc: 0.7109 - val_loss: 0.8422 - val_acc: 0.7318\n",
      "Epoch 260/2000\n",
      " - 1s - loss: 0.8579 - acc: 0.7073 - val_loss: 0.8627 - val_acc: 0.7318\n",
      "Epoch 261/2000\n",
      " - 1s - loss: 0.8368 - acc: 0.7139 - val_loss: 0.8477 - val_acc: 0.7405\n",
      "Epoch 262/2000\n",
      " - 1s - loss: 0.9737 - acc: 0.6803 - val_loss: 0.8593 - val_acc: 0.7405\n",
      "Epoch 263/2000\n",
      " - 1s - loss: 0.8453 - acc: 0.7022 - val_loss: 0.8611 - val_acc: 0.7376\n",
      "Epoch 264/2000\n",
      " - 1s - loss: 0.7967 - acc: 0.7358 - val_loss: 0.9543 - val_acc: 0.7289\n",
      "Epoch 265/2000\n",
      " - 1s - loss: 0.8617 - acc: 0.7175 - val_loss: 0.8608 - val_acc: 0.7493\n",
      "Epoch 266/2000\n",
      " - 1s - loss: 0.7787 - acc: 0.7321 - val_loss: 0.8621 - val_acc: 0.7259\n",
      "Epoch 267/2000\n",
      " - 1s - loss: 0.8492 - acc: 0.6993 - val_loss: 0.8649 - val_acc: 0.7405\n",
      "Epoch 268/2000\n",
      " - 1s - loss: 0.7749 - acc: 0.7358 - val_loss: 0.8771 - val_acc: 0.7376\n",
      "Epoch 269/2000\n",
      " - 1s - loss: 0.7820 - acc: 0.7241 - val_loss: 0.9289 - val_acc: 0.7318\n",
      "Epoch 270/2000\n",
      " - 1s - loss: 0.8195 - acc: 0.7234 - val_loss: 0.9012 - val_acc: 0.7347\n",
      "Epoch 271/2000\n",
      " - 1s - loss: 0.8300 - acc: 0.7058 - val_loss: 0.8122 - val_acc: 0.7638\n",
      "Epoch 272/2000\n",
      " - 1s - loss: 0.8079 - acc: 0.7139 - val_loss: 0.8379 - val_acc: 0.7318\n",
      "Epoch 273/2000\n",
      " - 1s - loss: 0.7548 - acc: 0.7299 - val_loss: 0.8494 - val_acc: 0.7405\n",
      "Epoch 274/2000\n",
      " - 1s - loss: 0.8153 - acc: 0.7036 - val_loss: 0.9181 - val_acc: 0.7347\n",
      "Epoch 275/2000\n",
      " - 1s - loss: 0.8011 - acc: 0.7343 - val_loss: 0.8450 - val_acc: 0.7580\n",
      "Epoch 276/2000\n",
      " - 1s - loss: 0.8256 - acc: 0.7117 - val_loss: 0.8578 - val_acc: 0.7493\n",
      "Epoch 277/2000\n",
      " - 1s - loss: 0.7720 - acc: 0.7336 - val_loss: 0.9463 - val_acc: 0.7376\n",
      "Epoch 278/2000\n",
      " - 1s - loss: 0.7810 - acc: 0.7197 - val_loss: 0.8702 - val_acc: 0.7201\n",
      "Epoch 279/2000\n",
      " - 1s - loss: 0.7656 - acc: 0.7131 - val_loss: 0.9209 - val_acc: 0.7055\n",
      "Epoch 280/2000\n",
      " - 1s - loss: 0.8073 - acc: 0.7095 - val_loss: 0.9929 - val_acc: 0.6997\n",
      "Epoch 281/2000\n",
      " - 1s - loss: 0.8216 - acc: 0.7066 - val_loss: 0.8903 - val_acc: 0.7085\n",
      "Epoch 282/2000\n",
      " - 1s - loss: 0.7984 - acc: 0.7350 - val_loss: 0.8996 - val_acc: 0.7405\n",
      "Epoch 283/2000\n",
      " - 1s - loss: 0.8848 - acc: 0.6971 - val_loss: 0.9160 - val_acc: 0.7143\n",
      "Epoch 284/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.8083 - acc: 0.7204 - val_loss: 0.9409 - val_acc: 0.7376\n",
      "Epoch 285/2000\n",
      " - 1s - loss: 0.7965 - acc: 0.7153 - val_loss: 0.9264 - val_acc: 0.7493\n",
      "Epoch 286/2000\n",
      " - 1s - loss: 0.7888 - acc: 0.7219 - val_loss: 0.9305 - val_acc: 0.7493\n",
      "Epoch 287/2000\n",
      " - 1s - loss: 0.8078 - acc: 0.7117 - val_loss: 0.9769 - val_acc: 0.7172\n",
      "Epoch 288/2000\n",
      " - 1s - loss: 0.8550 - acc: 0.7124 - val_loss: 1.0005 - val_acc: 0.7201\n",
      "Epoch 289/2000\n",
      " - 1s - loss: 0.8009 - acc: 0.7190 - val_loss: 0.9088 - val_acc: 0.7289\n",
      "Epoch 290/2000\n",
      " - 1s - loss: 0.7796 - acc: 0.7328 - val_loss: 0.8466 - val_acc: 0.7143\n",
      "Epoch 291/2000\n",
      " - 1s - loss: 0.7742 - acc: 0.7307 - val_loss: 0.9347 - val_acc: 0.7230\n",
      "Epoch 292/2000\n",
      " - 1s - loss: 0.8362 - acc: 0.7102 - val_loss: 1.0042 - val_acc: 0.7172\n",
      "Epoch 293/2000\n",
      " - 1s - loss: 0.8273 - acc: 0.7226 - val_loss: 0.8912 - val_acc: 0.7230\n",
      "Epoch 294/2000\n",
      " - 1s - loss: 0.7973 - acc: 0.7292 - val_loss: 0.8406 - val_acc: 0.7493\n",
      "Epoch 295/2000\n",
      " - 1s - loss: 0.7428 - acc: 0.7431 - val_loss: 0.8900 - val_acc: 0.7580\n",
      "Epoch 296/2000\n",
      " - 1s - loss: 0.8090 - acc: 0.7102 - val_loss: 0.8654 - val_acc: 0.7172\n",
      "Epoch 297/2000\n",
      " - 1s - loss: 0.8396 - acc: 0.7131 - val_loss: 0.8655 - val_acc: 0.7522\n",
      "Epoch 298/2000\n",
      " - 1s - loss: 0.8118 - acc: 0.7161 - val_loss: 0.9030 - val_acc: 0.7143\n",
      "Epoch 299/2000\n",
      " - 1s - loss: 0.7562 - acc: 0.7343 - val_loss: 0.9247 - val_acc: 0.7230\n",
      "Epoch 300/2000\n",
      " - 1s - loss: 0.7825 - acc: 0.7336 - val_loss: 0.8535 - val_acc: 0.7405\n",
      "Epoch 301/2000\n",
      " - 1s - loss: 0.7802 - acc: 0.7153 - val_loss: 0.8631 - val_acc: 0.7259\n",
      "Epoch 302/2000\n",
      " - 1s - loss: 0.7598 - acc: 0.7234 - val_loss: 0.9038 - val_acc: 0.7434\n",
      "Epoch 303/2000\n",
      " - 1s - loss: 0.7797 - acc: 0.7015 - val_loss: 0.9236 - val_acc: 0.7143\n",
      "Epoch 304/2000\n",
      " - 1s - loss: 0.7382 - acc: 0.7453 - val_loss: 0.9404 - val_acc: 0.7085\n",
      "Epoch 305/2000\n",
      " - 1s - loss: 0.7765 - acc: 0.7321 - val_loss: 0.9880 - val_acc: 0.7405\n",
      "Epoch 306/2000\n",
      " - 1s - loss: 0.8786 - acc: 0.6934 - val_loss: 0.9244 - val_acc: 0.7114\n",
      "Epoch 307/2000\n",
      " - 1s - loss: 0.8116 - acc: 0.7102 - val_loss: 0.8830 - val_acc: 0.7318\n",
      "Epoch 308/2000\n",
      " - 1s - loss: 0.8732 - acc: 0.7036 - val_loss: 1.0037 - val_acc: 0.7347\n",
      "Epoch 309/2000\n",
      " - 1s - loss: 0.7942 - acc: 0.7263 - val_loss: 0.8467 - val_acc: 0.7376\n",
      "Epoch 310/2000\n",
      " - 1s - loss: 0.7375 - acc: 0.7467 - val_loss: 1.0342 - val_acc: 0.7230\n",
      "Epoch 311/2000\n",
      " - 1s - loss: 0.8315 - acc: 0.7000 - val_loss: 0.9875 - val_acc: 0.6968\n",
      "Epoch 312/2000\n",
      " - 1s - loss: 0.8232 - acc: 0.7146 - val_loss: 0.8958 - val_acc: 0.7347\n",
      "Epoch 313/2000\n",
      " - 1s - loss: 0.7920 - acc: 0.7343 - val_loss: 0.8873 - val_acc: 0.7434\n",
      "Epoch 314/2000\n",
      " - 1s - loss: 0.7688 - acc: 0.7168 - val_loss: 0.8687 - val_acc: 0.7259\n",
      "Epoch 315/2000\n",
      " - 1s - loss: 0.7760 - acc: 0.7190 - val_loss: 0.9756 - val_acc: 0.7026\n",
      "Epoch 316/2000\n",
      " - 1s - loss: 0.7578 - acc: 0.7409 - val_loss: 0.8946 - val_acc: 0.7405\n",
      "Epoch 317/2000\n",
      " - 1s - loss: 0.7634 - acc: 0.7234 - val_loss: 0.8214 - val_acc: 0.7434\n",
      "Epoch 318/2000\n",
      " - 1s - loss: 0.7448 - acc: 0.7321 - val_loss: 0.8974 - val_acc: 0.7493\n",
      "Epoch 319/2000\n",
      " - 1s - loss: 0.7261 - acc: 0.7387 - val_loss: 0.9656 - val_acc: 0.7376\n",
      "Epoch 320/2000\n",
      " - 1s - loss: 0.7162 - acc: 0.7438 - val_loss: 0.9431 - val_acc: 0.7259\n",
      "Epoch 321/2000\n",
      " - 1s - loss: 0.7900 - acc: 0.7241 - val_loss: 0.8605 - val_acc: 0.7143\n",
      "Epoch 322/2000\n",
      " - 1s - loss: 0.7353 - acc: 0.7343 - val_loss: 0.9146 - val_acc: 0.7405\n",
      "Epoch 323/2000\n",
      " - 1s - loss: 0.7577 - acc: 0.7350 - val_loss: 0.9819 - val_acc: 0.7114\n",
      "Epoch 324/2000\n",
      " - 1s - loss: 0.8298 - acc: 0.7109 - val_loss: 0.9637 - val_acc: 0.7143\n",
      "Epoch 325/2000\n",
      " - 1s - loss: 0.7752 - acc: 0.7146 - val_loss: 0.8556 - val_acc: 0.7318\n",
      "Epoch 326/2000\n",
      " - 1s - loss: 0.7566 - acc: 0.7336 - val_loss: 0.9054 - val_acc: 0.7493\n",
      "Epoch 327/2000\n",
      " - 1s - loss: 0.7033 - acc: 0.7526 - val_loss: 0.9648 - val_acc: 0.7172\n",
      "Epoch 328/2000\n",
      " - 1s - loss: 0.7598 - acc: 0.7270 - val_loss: 0.8798 - val_acc: 0.7289\n",
      "Epoch 329/2000\n",
      " - 1s - loss: 0.7410 - acc: 0.7270 - val_loss: 0.9005 - val_acc: 0.7230\n",
      "Epoch 330/2000\n",
      " - 1s - loss: 0.7659 - acc: 0.7241 - val_loss: 0.9455 - val_acc: 0.6968\n",
      "Epoch 331/2000\n",
      " - 1s - loss: 0.8088 - acc: 0.7226 - val_loss: 0.9702 - val_acc: 0.6968\n",
      "Epoch 332/2000\n",
      " - 1s - loss: 0.7726 - acc: 0.7292 - val_loss: 0.8576 - val_acc: 0.7522\n",
      "Epoch 333/2000\n",
      " - 1s - loss: 0.7483 - acc: 0.7394 - val_loss: 0.9379 - val_acc: 0.7522\n",
      "Epoch 334/2000\n",
      " - 1s - loss: 0.7391 - acc: 0.7234 - val_loss: 0.8852 - val_acc: 0.7318\n",
      "Epoch 335/2000\n",
      " - 1s - loss: 0.7763 - acc: 0.7365 - val_loss: 0.9536 - val_acc: 0.7259\n",
      "Epoch 336/2000\n",
      " - 1s - loss: 0.8021 - acc: 0.7219 - val_loss: 0.8907 - val_acc: 0.7464\n",
      "Epoch 337/2000\n",
      " - 1s - loss: 0.7249 - acc: 0.7358 - val_loss: 0.8425 - val_acc: 0.7493\n",
      "Epoch 338/2000\n",
      " - 1s - loss: 0.7238 - acc: 0.7467 - val_loss: 0.9826 - val_acc: 0.7143\n",
      "Epoch 339/2000\n",
      " - 1s - loss: 0.7681 - acc: 0.7285 - val_loss: 0.8650 - val_acc: 0.7405\n",
      "Epoch 340/2000\n",
      " - 1s - loss: 0.7979 - acc: 0.7234 - val_loss: 0.8966 - val_acc: 0.7201\n",
      "Epoch 341/2000\n",
      " - 1s - loss: 0.7265 - acc: 0.7372 - val_loss: 0.9467 - val_acc: 0.7143\n",
      "Epoch 342/2000\n",
      " - 1s - loss: 0.6765 - acc: 0.7533 - val_loss: 0.9522 - val_acc: 0.7172\n",
      "Epoch 343/2000\n",
      " - 1s - loss: 0.7777 - acc: 0.7343 - val_loss: 0.9341 - val_acc: 0.7318\n",
      "Epoch 344/2000\n",
      " - 1s - loss: 0.8018 - acc: 0.7182 - val_loss: 0.9749 - val_acc: 0.7376\n",
      "Epoch 345/2000\n",
      " - 1s - loss: 0.9024 - acc: 0.6971 - val_loss: 1.1791 - val_acc: 0.6822\n",
      "Epoch 346/2000\n",
      " - 0s - loss: 0.8870 - acc: 0.7051 - val_loss: 0.9036 - val_acc: 0.7609\n",
      "Epoch 347/2000\n",
      " - 1s - loss: 0.7520 - acc: 0.7511 - val_loss: 0.8716 - val_acc: 0.7493\n",
      "Epoch 348/2000\n",
      " - 1s - loss: 0.7414 - acc: 0.7365 - val_loss: 0.9826 - val_acc: 0.7230\n",
      "Epoch 349/2000\n",
      " - 1s - loss: 0.7059 - acc: 0.7679 - val_loss: 0.9116 - val_acc: 0.7259\n",
      "Epoch 350/2000\n",
      " - 1s - loss: 0.7592 - acc: 0.7372 - val_loss: 0.9603 - val_acc: 0.7318\n",
      "Epoch 351/2000\n",
      " - 1s - loss: 0.7579 - acc: 0.7358 - val_loss: 0.8950 - val_acc: 0.7405\n",
      "Epoch 352/2000\n",
      " - 1s - loss: 0.7304 - acc: 0.7358 - val_loss: 0.8933 - val_acc: 0.7318\n",
      "Epoch 353/2000\n",
      " - 1s - loss: 0.6979 - acc: 0.7431 - val_loss: 0.8291 - val_acc: 0.7609\n",
      "Epoch 354/2000\n",
      " - 1s - loss: 0.7340 - acc: 0.7307 - val_loss: 0.9865 - val_acc: 0.7055\n",
      "Epoch 355/2000\n",
      " - 1s - loss: 0.7908 - acc: 0.7226 - val_loss: 0.8641 - val_acc: 0.7376\n",
      "Epoch 356/2000\n",
      " - 1s - loss: 0.7806 - acc: 0.7460 - val_loss: 0.9356 - val_acc: 0.7026\n",
      "Epoch 357/2000\n",
      " - 1s - loss: 0.7999 - acc: 0.7263 - val_loss: 0.9017 - val_acc: 0.7201\n",
      "Epoch 358/2000\n",
      " - 1s - loss: 0.7150 - acc: 0.7540 - val_loss: 0.8617 - val_acc: 0.7493\n",
      "Epoch 359/2000\n",
      " - 1s - loss: 0.7279 - acc: 0.7423 - val_loss: 0.8732 - val_acc: 0.7318\n",
      "Epoch 360/2000\n",
      " - 1s - loss: 0.7598 - acc: 0.7365 - val_loss: 0.9248 - val_acc: 0.7230\n",
      "Epoch 361/2000\n",
      " - 1s - loss: 0.7621 - acc: 0.7336 - val_loss: 0.9978 - val_acc: 0.7085\n",
      "Epoch 362/2000\n",
      " - 1s - loss: 0.7429 - acc: 0.7314 - val_loss: 0.9626 - val_acc: 0.7172\n",
      "Epoch 363/2000\n",
      " - 1s - loss: 0.7384 - acc: 0.7584 - val_loss: 0.9343 - val_acc: 0.7201\n",
      "Epoch 364/2000\n",
      " - 1s - loss: 0.7338 - acc: 0.7606 - val_loss: 0.9095 - val_acc: 0.7230\n",
      "Epoch 365/2000\n",
      " - 1s - loss: 0.7350 - acc: 0.7482 - val_loss: 0.9738 - val_acc: 0.7259\n",
      "Epoch 366/2000\n",
      " - 1s - loss: 0.6700 - acc: 0.7672 - val_loss: 0.9780 - val_acc: 0.7201\n",
      "Epoch 367/2000\n",
      " - 1s - loss: 0.6966 - acc: 0.7591 - val_loss: 0.9918 - val_acc: 0.7259\n",
      "Epoch 368/2000\n",
      " - 1s - loss: 0.7369 - acc: 0.7474 - val_loss: 0.9568 - val_acc: 0.7230\n",
      "Epoch 369/2000\n",
      " - 1s - loss: 0.7408 - acc: 0.7234 - val_loss: 0.9477 - val_acc: 0.7376\n",
      "Epoch 370/2000\n",
      " - 1s - loss: 0.7391 - acc: 0.7350 - val_loss: 0.9074 - val_acc: 0.7230\n",
      "Epoch 371/2000\n",
      " - 1s - loss: 0.7061 - acc: 0.7489 - val_loss: 0.9945 - val_acc: 0.7230\n",
      "Epoch 372/2000\n",
      " - 1s - loss: 0.7105 - acc: 0.7620 - val_loss: 0.9522 - val_acc: 0.7230\n",
      "Epoch 373/2000\n",
      " - 1s - loss: 0.7615 - acc: 0.7358 - val_loss: 0.9920 - val_acc: 0.7143\n",
      "Epoch 374/2000\n",
      " - 1s - loss: 0.7771 - acc: 0.7401 - val_loss: 0.9517 - val_acc: 0.7376\n",
      "Epoch 375/2000\n",
      " - 1s - loss: 0.7048 - acc: 0.7526 - val_loss: 0.9778 - val_acc: 0.7289\n",
      "Epoch 376/2000\n",
      " - 1s - loss: 0.7017 - acc: 0.7496 - val_loss: 0.9526 - val_acc: 0.7493\n",
      "Epoch 377/2000\n",
      " - 1s - loss: 0.6789 - acc: 0.7562 - val_loss: 0.9325 - val_acc: 0.7318\n",
      "Epoch 378/2000\n",
      " - 1s - loss: 0.7936 - acc: 0.7241 - val_loss: 0.9677 - val_acc: 0.7289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/2000\n",
      " - 1s - loss: 0.7544 - acc: 0.7409 - val_loss: 0.9741 - val_acc: 0.7055\n",
      "Epoch 380/2000\n",
      " - 1s - loss: 0.7070 - acc: 0.7474 - val_loss: 0.9591 - val_acc: 0.7230\n",
      "Epoch 381/2000\n",
      " - 1s - loss: 0.7254 - acc: 0.7635 - val_loss: 1.0251 - val_acc: 0.7201\n",
      "Epoch 382/2000\n",
      " - 1s - loss: 0.7267 - acc: 0.7504 - val_loss: 0.9468 - val_acc: 0.7405\n",
      "Epoch 383/2000\n",
      " - 1s - loss: 0.6823 - acc: 0.7672 - val_loss: 0.9309 - val_acc: 0.7318\n",
      "Epoch 384/2000\n",
      " - 1s - loss: 0.7279 - acc: 0.7511 - val_loss: 1.0083 - val_acc: 0.7376\n",
      "Epoch 385/2000\n",
      " - 1s - loss: 0.8176 - acc: 0.7197 - val_loss: 1.0657 - val_acc: 0.6997\n",
      "Epoch 386/2000\n",
      " - 1s - loss: 0.7507 - acc: 0.7358 - val_loss: 0.9321 - val_acc: 0.7055\n",
      "Epoch 387/2000\n",
      " - 1s - loss: 0.7696 - acc: 0.7241 - val_loss: 0.8881 - val_acc: 0.7230\n",
      "Epoch 388/2000\n",
      " - 1s - loss: 0.7572 - acc: 0.7416 - val_loss: 0.9981 - val_acc: 0.7493\n",
      "Epoch 389/2000\n",
      " - 1s - loss: 0.7560 - acc: 0.7175 - val_loss: 0.9868 - val_acc: 0.7201\n",
      "Epoch 390/2000\n",
      " - 1s - loss: 0.7280 - acc: 0.7328 - val_loss: 0.8917 - val_acc: 0.7609\n",
      "Epoch 391/2000\n",
      " - 1s - loss: 0.7226 - acc: 0.7401 - val_loss: 1.0047 - val_acc: 0.7347\n",
      "Epoch 392/2000\n",
      " - 1s - loss: 0.8391 - acc: 0.7044 - val_loss: 0.8977 - val_acc: 0.7201\n",
      "Epoch 393/2000\n",
      " - 1s - loss: 0.6990 - acc: 0.7416 - val_loss: 0.9332 - val_acc: 0.7259\n",
      "Epoch 394/2000\n",
      " - 1s - loss: 0.7312 - acc: 0.7423 - val_loss: 0.9503 - val_acc: 0.7201\n",
      "Epoch 395/2000\n",
      " - 1s - loss: 0.7319 - acc: 0.7372 - val_loss: 1.0057 - val_acc: 0.7085\n",
      "Epoch 396/2000\n",
      " - 1s - loss: 0.7134 - acc: 0.7569 - val_loss: 0.9087 - val_acc: 0.7318\n",
      "Epoch 397/2000\n",
      " - 1s - loss: 0.6756 - acc: 0.7518 - val_loss: 0.9447 - val_acc: 0.7259\n",
      "Epoch 398/2000\n",
      " - 1s - loss: 0.6814 - acc: 0.7606 - val_loss: 0.9696 - val_acc: 0.7405\n",
      "Epoch 399/2000\n",
      " - 1s - loss: 0.7301 - acc: 0.7526 - val_loss: 0.9924 - val_acc: 0.7318\n",
      "Epoch 400/2000\n",
      " - 1s - loss: 0.7706 - acc: 0.7234 - val_loss: 0.9425 - val_acc: 0.7580\n",
      "Epoch 401/2000\n",
      " - 1s - loss: 0.6936 - acc: 0.7511 - val_loss: 0.9312 - val_acc: 0.7493\n",
      "Epoch 402/2000\n",
      " - 1s - loss: 0.7006 - acc: 0.7613 - val_loss: 0.9907 - val_acc: 0.7434\n",
      "Epoch 403/2000\n",
      " - 1s - loss: 0.6996 - acc: 0.7584 - val_loss: 0.9970 - val_acc: 0.7289\n",
      "Epoch 404/2000\n",
      " - 1s - loss: 0.7196 - acc: 0.7511 - val_loss: 0.9817 - val_acc: 0.7376\n",
      "Epoch 405/2000\n",
      " - 1s - loss: 0.7011 - acc: 0.7518 - val_loss: 1.0366 - val_acc: 0.6997\n",
      "Epoch 406/2000\n",
      " - 1s - loss: 0.7290 - acc: 0.7423 - val_loss: 0.9640 - val_acc: 0.7464\n",
      "Epoch 407/2000\n",
      " - 1s - loss: 0.7440 - acc: 0.7321 - val_loss: 0.9749 - val_acc: 0.7347\n",
      "Epoch 408/2000\n",
      " - 1s - loss: 0.7280 - acc: 0.7358 - val_loss: 1.0241 - val_acc: 0.7085\n",
      "Epoch 409/2000\n",
      " - 1s - loss: 0.7484 - acc: 0.7328 - val_loss: 0.8871 - val_acc: 0.7493\n",
      "Epoch 410/2000\n",
      " - 1s - loss: 0.6990 - acc: 0.7664 - val_loss: 1.0424 - val_acc: 0.7055\n",
      "Epoch 411/2000\n",
      " - 1s - loss: 0.7380 - acc: 0.7518 - val_loss: 0.9513 - val_acc: 0.7201\n",
      "Epoch 412/2000\n",
      " - 1s - loss: 0.7449 - acc: 0.7438 - val_loss: 0.8917 - val_acc: 0.7464\n",
      "Epoch 413/2000\n",
      " - 1s - loss: 0.8209 - acc: 0.7219 - val_loss: 1.1630 - val_acc: 0.6997\n",
      "Epoch 414/2000\n",
      " - 1s - loss: 0.7297 - acc: 0.7431 - val_loss: 0.9763 - val_acc: 0.7405\n",
      "Epoch 415/2000\n",
      " - 1s - loss: 0.7253 - acc: 0.7409 - val_loss: 0.9387 - val_acc: 0.7318\n",
      "Epoch 416/2000\n",
      " - 1s - loss: 0.7219 - acc: 0.7453 - val_loss: 1.0187 - val_acc: 0.7289\n",
      "Epoch 417/2000\n",
      " - 1s - loss: 0.6774 - acc: 0.7642 - val_loss: 0.8925 - val_acc: 0.7464\n",
      "Epoch 418/2000\n",
      " - 1s - loss: 0.6645 - acc: 0.7766 - val_loss: 0.8753 - val_acc: 0.7551\n",
      "Epoch 419/2000\n",
      " - 1s - loss: 0.6923 - acc: 0.7482 - val_loss: 1.0540 - val_acc: 0.7289\n",
      "Epoch 420/2000\n",
      " - 1s - loss: 0.7373 - acc: 0.7401 - val_loss: 0.9584 - val_acc: 0.7347\n",
      "Epoch 421/2000\n",
      " - 1s - loss: 0.7128 - acc: 0.7496 - val_loss: 0.9942 - val_acc: 0.7289\n",
      "Epoch 422/2000\n",
      " - 1s - loss: 0.6758 - acc: 0.7715 - val_loss: 1.0567 - val_acc: 0.7026\n",
      "Epoch 423/2000\n",
      " - 1s - loss: 0.6848 - acc: 0.7613 - val_loss: 1.0208 - val_acc: 0.7464\n",
      "Epoch 424/2000\n",
      " - 1s - loss: 0.7196 - acc: 0.7380 - val_loss: 1.0801 - val_acc: 0.7318\n",
      "Epoch 425/2000\n",
      " - 1s - loss: 0.7836 - acc: 0.7263 - val_loss: 0.9726 - val_acc: 0.7318\n",
      "Epoch 426/2000\n",
      " - 1s - loss: 0.8017 - acc: 0.7343 - val_loss: 0.9950 - val_acc: 0.7259\n",
      "Epoch 427/2000\n",
      " - 1s - loss: 0.7224 - acc: 0.7474 - val_loss: 0.9872 - val_acc: 0.7347\n",
      "Epoch 428/2000\n",
      " - 1s - loss: 0.6844 - acc: 0.7650 - val_loss: 0.9476 - val_acc: 0.7522\n",
      "Epoch 429/2000\n",
      " - 1s - loss: 0.6483 - acc: 0.7701 - val_loss: 1.0260 - val_acc: 0.7405\n",
      "Epoch 430/2000\n",
      " - 1s - loss: 0.7524 - acc: 0.7474 - val_loss: 0.9893 - val_acc: 0.7376\n",
      "Epoch 431/2000\n",
      " - 1s - loss: 0.7491 - acc: 0.7307 - val_loss: 0.9226 - val_acc: 0.7347\n",
      "Epoch 432/2000\n",
      " - 1s - loss: 0.7266 - acc: 0.7365 - val_loss: 1.0546 - val_acc: 0.7376\n",
      "Epoch 433/2000\n",
      " - 1s - loss: 0.7411 - acc: 0.7423 - val_loss: 0.9900 - val_acc: 0.7347\n",
      "Epoch 434/2000\n",
      " - 1s - loss: 0.6637 - acc: 0.7577 - val_loss: 1.0625 - val_acc: 0.6880\n",
      "Epoch 435/2000\n",
      " - 1s - loss: 0.7201 - acc: 0.7518 - val_loss: 0.9229 - val_acc: 0.7522\n",
      "Epoch 436/2000\n",
      " - 1s - loss: 0.7197 - acc: 0.7474 - val_loss: 0.9596 - val_acc: 0.7464\n",
      "Epoch 437/2000\n",
      " - 1s - loss: 0.6704 - acc: 0.7591 - val_loss: 0.9715 - val_acc: 0.7289\n",
      "Epoch 438/2000\n",
      " - 0s - loss: 0.6810 - acc: 0.7642 - val_loss: 1.0592 - val_acc: 0.7143\n",
      "Epoch 439/2000\n",
      " - 0s - loss: 0.8196 - acc: 0.7343 - val_loss: 1.0727 - val_acc: 0.7055\n",
      "Epoch 440/2000\n",
      " - 1s - loss: 0.7456 - acc: 0.7423 - val_loss: 1.0856 - val_acc: 0.7114\n",
      "Epoch 441/2000\n",
      " - 1s - loss: 0.6785 - acc: 0.7642 - val_loss: 1.0538 - val_acc: 0.7347\n",
      "Epoch 442/2000\n",
      " - 1s - loss: 0.7020 - acc: 0.7620 - val_loss: 1.0057 - val_acc: 0.7464\n",
      "Epoch 443/2000\n",
      " - 1s - loss: 0.7014 - acc: 0.7613 - val_loss: 0.9568 - val_acc: 0.7230\n",
      "Epoch 444/2000\n",
      " - 1s - loss: 0.6642 - acc: 0.7686 - val_loss: 0.9434 - val_acc: 0.7522\n",
      "Epoch 445/2000\n",
      " - 1s - loss: 0.6377 - acc: 0.7810 - val_loss: 0.9964 - val_acc: 0.7405\n",
      "Epoch 446/2000\n",
      " - 1s - loss: 0.6766 - acc: 0.7569 - val_loss: 1.0416 - val_acc: 0.7289\n",
      "Epoch 447/2000\n",
      " - 1s - loss: 0.7643 - acc: 0.7307 - val_loss: 1.0264 - val_acc: 0.7201\n",
      "Epoch 448/2000\n",
      " - 1s - loss: 0.7689 - acc: 0.7270 - val_loss: 1.1533 - val_acc: 0.7172\n",
      "Epoch 449/2000\n",
      " - 1s - loss: 0.7159 - acc: 0.7438 - val_loss: 1.0206 - val_acc: 0.7464\n",
      "Epoch 450/2000\n",
      " - 1s - loss: 0.7158 - acc: 0.7467 - val_loss: 1.0428 - val_acc: 0.7143\n",
      "Epoch 451/2000\n",
      " - 1s - loss: 0.7651 - acc: 0.7358 - val_loss: 1.0007 - val_acc: 0.7259\n",
      "Epoch 452/2000\n",
      " - 1s - loss: 0.7104 - acc: 0.7591 - val_loss: 0.9472 - val_acc: 0.7434\n",
      "Epoch 453/2000\n",
      " - 1s - loss: 0.7033 - acc: 0.7489 - val_loss: 0.9883 - val_acc: 0.7172\n",
      "Epoch 454/2000\n",
      " - 1s - loss: 0.6707 - acc: 0.7672 - val_loss: 1.0395 - val_acc: 0.7376\n",
      "Epoch 455/2000\n",
      " - 1s - loss: 0.6484 - acc: 0.7752 - val_loss: 1.0046 - val_acc: 0.7493\n",
      "Epoch 456/2000\n",
      " - 1s - loss: 0.6765 - acc: 0.7825 - val_loss: 0.9920 - val_acc: 0.7434\n",
      "Epoch 457/2000\n",
      " - 1s - loss: 0.6796 - acc: 0.7555 - val_loss: 1.0519 - val_acc: 0.7172\n",
      "Epoch 458/2000\n",
      " - 1s - loss: 0.7382 - acc: 0.7453 - val_loss: 1.0921 - val_acc: 0.7434\n",
      "Epoch 459/2000\n",
      " - 1s - loss: 0.6897 - acc: 0.7562 - val_loss: 1.0941 - val_acc: 0.7114\n",
      "Epoch 460/2000\n",
      " - 1s - loss: 0.6661 - acc: 0.7620 - val_loss: 1.1280 - val_acc: 0.7347\n",
      "Epoch 461/2000\n",
      " - 1s - loss: 0.6756 - acc: 0.7672 - val_loss: 1.0430 - val_acc: 0.7172\n",
      "Epoch 462/2000\n",
      " - 1s - loss: 1.2034 - acc: 0.6569 - val_loss: 1.1993 - val_acc: 0.6501\n",
      "Epoch 463/2000\n",
      " - 1s - loss: 0.8704 - acc: 0.6971 - val_loss: 1.0586 - val_acc: 0.7026\n",
      "Epoch 464/2000\n",
      " - 1s - loss: 0.7240 - acc: 0.7387 - val_loss: 0.9894 - val_acc: 0.7172\n",
      "Epoch 465/2000\n",
      " - 1s - loss: 0.7150 - acc: 0.7518 - val_loss: 0.9468 - val_acc: 0.7522\n",
      "Epoch 466/2000\n",
      " - 1s - loss: 0.7226 - acc: 0.7387 - val_loss: 1.0423 - val_acc: 0.7493\n",
      "Epoch 467/2000\n",
      " - 1s - loss: 0.7347 - acc: 0.7569 - val_loss: 0.9691 - val_acc: 0.7493\n",
      "Epoch 468/2000\n",
      " - 1s - loss: 0.6776 - acc: 0.7693 - val_loss: 1.0640 - val_acc: 0.7085\n",
      "Epoch 469/2000\n",
      " - 2s - loss: 0.7410 - acc: 0.7277 - val_loss: 0.9761 - val_acc: 0.7318\n",
      "Epoch 470/2000\n",
      " - 1s - loss: 0.7037 - acc: 0.7453 - val_loss: 1.0500 - val_acc: 0.7347\n",
      "Epoch 471/2000\n",
      " - 1s - loss: 0.7160 - acc: 0.7628 - val_loss: 0.9246 - val_acc: 0.7434\n",
      "Epoch 472/2000\n",
      " - 1s - loss: 0.6725 - acc: 0.7562 - val_loss: 0.9378 - val_acc: 0.7551\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6656 - acc: 0.7752 - val_loss: 0.9597 - val_acc: 0.7464\n",
      "Epoch 474/2000\n",
      " - 1s - loss: 0.7125 - acc: 0.7401 - val_loss: 1.0201 - val_acc: 0.7464\n",
      "Epoch 475/2000\n",
      " - 1s - loss: 0.7296 - acc: 0.7394 - val_loss: 0.9964 - val_acc: 0.7493\n",
      "Epoch 476/2000\n",
      " - 1s - loss: 0.6752 - acc: 0.7591 - val_loss: 0.9423 - val_acc: 0.7376\n",
      "Epoch 477/2000\n",
      " - 1s - loss: 0.6391 - acc: 0.7788 - val_loss: 0.9995 - val_acc: 0.7259\n",
      "Epoch 478/2000\n",
      " - 1s - loss: 0.7261 - acc: 0.7453 - val_loss: 1.0894 - val_acc: 0.7230\n",
      "Epoch 479/2000\n",
      " - 1s - loss: 0.6933 - acc: 0.7547 - val_loss: 0.9620 - val_acc: 0.7376\n",
      "Epoch 480/2000\n",
      " - 1s - loss: 0.7642 - acc: 0.7409 - val_loss: 0.9882 - val_acc: 0.7172\n",
      "Epoch 481/2000\n",
      " - 1s - loss: 0.6757 - acc: 0.7672 - val_loss: 1.0042 - val_acc: 0.7405\n",
      "Epoch 482/2000\n",
      " - 1s - loss: 0.6914 - acc: 0.7526 - val_loss: 0.9430 - val_acc: 0.7464\n",
      "Epoch 483/2000\n",
      " - 1s - loss: 0.6397 - acc: 0.7781 - val_loss: 0.9843 - val_acc: 0.7318\n",
      "Epoch 484/2000\n",
      " - 1s - loss: 0.7471 - acc: 0.7445 - val_loss: 1.0300 - val_acc: 0.7230\n",
      "Epoch 485/2000\n",
      " - 1s - loss: 0.7630 - acc: 0.7460 - val_loss: 0.8890 - val_acc: 0.7697\n",
      "Epoch 486/2000\n",
      " - 1s - loss: 0.6416 - acc: 0.7766 - val_loss: 0.9961 - val_acc: 0.7318\n",
      "Epoch 487/2000\n",
      " - 1s - loss: 0.7296 - acc: 0.7241 - val_loss: 0.9939 - val_acc: 0.7259\n",
      "Epoch 488/2000\n",
      " - 1s - loss: 0.6559 - acc: 0.7723 - val_loss: 0.9395 - val_acc: 0.7347\n",
      "Epoch 489/2000\n",
      " - 1s - loss: 0.6557 - acc: 0.7642 - val_loss: 1.0025 - val_acc: 0.7347\n",
      "Epoch 490/2000\n",
      " - 1s - loss: 0.6701 - acc: 0.7620 - val_loss: 1.0157 - val_acc: 0.7289\n",
      "Epoch 491/2000\n",
      " - 1s - loss: 0.6453 - acc: 0.7686 - val_loss: 0.9535 - val_acc: 0.7230\n",
      "Epoch 492/2000\n",
      " - 1s - loss: 0.6534 - acc: 0.7577 - val_loss: 1.0861 - val_acc: 0.7172\n",
      "Epoch 493/2000\n",
      " - 1s - loss: 0.6976 - acc: 0.7526 - val_loss: 1.0155 - val_acc: 0.7347\n",
      "Epoch 494/2000\n",
      " - 1s - loss: 0.6968 - acc: 0.7547 - val_loss: 1.0717 - val_acc: 0.7289\n",
      "Epoch 495/2000\n",
      " - 1s - loss: 0.6605 - acc: 0.7730 - val_loss: 0.9563 - val_acc: 0.7347\n",
      "Epoch 496/2000\n",
      " - 1s - loss: 0.7142 - acc: 0.7562 - val_loss: 1.0085 - val_acc: 0.7347\n",
      "Epoch 497/2000\n",
      " - 1s - loss: 0.6842 - acc: 0.7613 - val_loss: 1.0962 - val_acc: 0.7085\n",
      "Epoch 498/2000\n",
      " - 1s - loss: 0.6857 - acc: 0.7577 - val_loss: 1.0275 - val_acc: 0.7289\n",
      "Epoch 499/2000\n",
      " - 1s - loss: 0.7659 - acc: 0.7380 - val_loss: 1.0774 - val_acc: 0.7143\n",
      "Epoch 500/2000\n",
      " - 1s - loss: 0.7558 - acc: 0.7387 - val_loss: 1.0019 - val_acc: 0.7434\n",
      "Epoch 501/2000\n",
      " - 1s - loss: 0.7095 - acc: 0.7467 - val_loss: 1.1438 - val_acc: 0.7085\n",
      "Epoch 502/2000\n",
      " - 1s - loss: 0.7749 - acc: 0.7328 - val_loss: 1.0575 - val_acc: 0.7434\n",
      "Epoch 503/2000\n",
      " - 1s - loss: 0.6870 - acc: 0.7620 - val_loss: 1.0088 - val_acc: 0.7318\n",
      "Epoch 504/2000\n",
      " - 1s - loss: 0.6464 - acc: 0.7781 - val_loss: 1.1253 - val_acc: 0.7289\n",
      "Epoch 505/2000\n",
      " - 1s - loss: 0.7080 - acc: 0.7416 - val_loss: 1.0346 - val_acc: 0.7143\n",
      "Epoch 506/2000\n",
      " - 1s - loss: 0.7069 - acc: 0.7489 - val_loss: 1.0682 - val_acc: 0.7259\n",
      "Epoch 507/2000\n",
      " - 1s - loss: 0.7166 - acc: 0.7496 - val_loss: 0.9918 - val_acc: 0.7201\n",
      "Epoch 508/2000\n",
      " - 1s - loss: 0.6796 - acc: 0.7664 - val_loss: 0.9972 - val_acc: 0.7405\n",
      "Epoch 509/2000\n",
      " - 1s - loss: 0.6531 - acc: 0.7599 - val_loss: 1.0731 - val_acc: 0.7289\n",
      "Epoch 510/2000\n",
      " - 1s - loss: 0.6725 - acc: 0.7745 - val_loss: 1.0954 - val_acc: 0.7201\n",
      "Epoch 511/2000\n",
      " - 1s - loss: 0.6457 - acc: 0.7628 - val_loss: 1.0190 - val_acc: 0.7405\n",
      "Epoch 512/2000\n",
      " - 1s - loss: 0.6714 - acc: 0.7577 - val_loss: 1.0204 - val_acc: 0.7347\n",
      "Epoch 513/2000\n",
      " - 1s - loss: 0.6531 - acc: 0.7766 - val_loss: 1.0318 - val_acc: 0.7318\n",
      "Epoch 514/2000\n",
      " - 1s - loss: 0.6705 - acc: 0.7672 - val_loss: 1.0425 - val_acc: 0.7085\n",
      "Epoch 515/2000\n",
      " - 1s - loss: 0.6510 - acc: 0.7650 - val_loss: 1.0571 - val_acc: 0.7201\n",
      "Epoch 516/2000\n",
      " - 1s - loss: 0.7249 - acc: 0.7518 - val_loss: 1.0846 - val_acc: 0.7434\n",
      "Epoch 517/2000\n",
      " - 1s - loss: 0.7243 - acc: 0.7496 - val_loss: 1.0566 - val_acc: 0.7259\n",
      "Epoch 518/2000\n",
      " - 1s - loss: 0.7346 - acc: 0.7409 - val_loss: 1.0615 - val_acc: 0.7230\n",
      "Epoch 519/2000\n",
      " - 1s - loss: 0.7211 - acc: 0.7577 - val_loss: 1.2315 - val_acc: 0.6968\n",
      "Epoch 520/2000\n",
      " - 1s - loss: 0.7621 - acc: 0.7401 - val_loss: 1.0707 - val_acc: 0.7172\n",
      "Epoch 521/2000\n",
      " - 1s - loss: 0.6649 - acc: 0.7613 - val_loss: 1.0159 - val_acc: 0.7434\n",
      "Epoch 522/2000\n",
      " - 0s - loss: 0.6551 - acc: 0.7825 - val_loss: 1.1048 - val_acc: 0.7114\n",
      "Epoch 523/2000\n",
      " - 1s - loss: 0.7616 - acc: 0.7321 - val_loss: 1.0184 - val_acc: 0.7201\n",
      "Epoch 524/2000\n",
      " - 1s - loss: 0.7067 - acc: 0.7460 - val_loss: 1.0173 - val_acc: 0.7201\n",
      "Epoch 525/2000\n",
      " - 1s - loss: 0.6938 - acc: 0.7547 - val_loss: 1.0296 - val_acc: 0.7551\n",
      "Epoch 526/2000\n",
      " - 1s - loss: 0.6317 - acc: 0.7752 - val_loss: 1.0452 - val_acc: 0.7172\n",
      "Epoch 527/2000\n",
      " - 1s - loss: 0.6436 - acc: 0.7650 - val_loss: 1.0666 - val_acc: 0.7464\n",
      "Epoch 528/2000\n",
      " - 1s - loss: 0.6546 - acc: 0.7715 - val_loss: 1.0165 - val_acc: 0.7172\n",
      "Epoch 529/2000\n",
      " - 1s - loss: 0.6848 - acc: 0.7474 - val_loss: 0.9806 - val_acc: 0.7201\n",
      "Epoch 530/2000\n",
      " - 1s - loss: 0.6544 - acc: 0.7752 - val_loss: 1.0953 - val_acc: 0.7347\n",
      "Epoch 531/2000\n",
      " - 1s - loss: 0.7454 - acc: 0.7416 - val_loss: 1.1202 - val_acc: 0.7026\n",
      "Epoch 532/2000\n",
      " - 1s - loss: 0.7412 - acc: 0.7445 - val_loss: 1.0325 - val_acc: 0.7464\n",
      "Epoch 533/2000\n",
      " - 1s - loss: 0.6679 - acc: 0.7657 - val_loss: 1.0009 - val_acc: 0.7434\n",
      "Epoch 534/2000\n",
      " - 1s - loss: 0.6630 - acc: 0.7533 - val_loss: 1.1249 - val_acc: 0.7259\n",
      "Epoch 535/2000\n",
      " - 1s - loss: 0.6903 - acc: 0.7460 - val_loss: 1.1115 - val_acc: 0.6968\n",
      "Epoch 536/2000\n",
      " - 1s - loss: 0.6970 - acc: 0.7613 - val_loss: 1.0853 - val_acc: 0.7259\n",
      "Epoch 537/2000\n",
      " - 1s - loss: 0.6953 - acc: 0.7547 - val_loss: 1.1290 - val_acc: 0.7230\n",
      "Epoch 538/2000\n",
      " - 1s - loss: 0.6218 - acc: 0.7723 - val_loss: 1.0343 - val_acc: 0.7289\n",
      "Epoch 539/2000\n",
      " - 1s - loss: 0.6344 - acc: 0.7818 - val_loss: 1.0223 - val_acc: 0.7289\n",
      "Epoch 540/2000\n",
      " - 0s - loss: 0.6604 - acc: 0.7774 - val_loss: 0.9836 - val_acc: 0.7376\n",
      "Epoch 541/2000\n",
      " - 1s - loss: 0.6865 - acc: 0.7693 - val_loss: 1.1129 - val_acc: 0.7026\n",
      "Epoch 542/2000\n",
      " - 1s - loss: 0.7637 - acc: 0.7285 - val_loss: 1.0505 - val_acc: 0.7318\n",
      "Epoch 543/2000\n",
      " - 0s - loss: 0.6709 - acc: 0.7518 - val_loss: 1.0694 - val_acc: 0.7055\n",
      "Epoch 544/2000\n",
      " - 1s - loss: 0.6659 - acc: 0.7657 - val_loss: 1.0649 - val_acc: 0.7289\n",
      "Epoch 545/2000\n",
      " - 1s - loss: 0.6966 - acc: 0.7701 - val_loss: 1.0001 - val_acc: 0.7551\n",
      "Epoch 546/2000\n",
      " - 1s - loss: 0.7102 - acc: 0.7526 - val_loss: 1.2083 - val_acc: 0.6910\n",
      "Epoch 547/2000\n",
      " - 1s - loss: 0.6942 - acc: 0.7445 - val_loss: 1.0594 - val_acc: 0.7143\n",
      "Epoch 548/2000\n",
      " - 1s - loss: 0.6398 - acc: 0.7679 - val_loss: 1.0529 - val_acc: 0.7434\n",
      "Epoch 549/2000\n",
      " - 1s - loss: 0.6110 - acc: 0.7796 - val_loss: 1.0955 - val_acc: 0.7201\n",
      "Epoch 550/2000\n",
      " - 1s - loss: 0.7051 - acc: 0.7489 - val_loss: 1.1169 - val_acc: 0.7347\n",
      "Epoch 551/2000\n",
      " - 1s - loss: 0.6244 - acc: 0.7927 - val_loss: 1.0611 - val_acc: 0.7143\n",
      "Epoch 552/2000\n",
      " - 1s - loss: 0.7018 - acc: 0.7504 - val_loss: 1.0545 - val_acc: 0.7026\n",
      "Epoch 553/2000\n",
      " - 1s - loss: 0.6904 - acc: 0.7628 - val_loss: 1.0708 - val_acc: 0.7464\n",
      "Epoch 554/2000\n",
      " - 1s - loss: 0.7035 - acc: 0.7343 - val_loss: 1.0811 - val_acc: 0.7201\n",
      "Epoch 555/2000\n",
      " - 1s - loss: 0.6441 - acc: 0.7620 - val_loss: 1.0623 - val_acc: 0.7522\n",
      "Epoch 556/2000\n",
      " - 1s - loss: 0.6809 - acc: 0.7489 - val_loss: 1.1338 - val_acc: 0.6968\n",
      "Epoch 557/2000\n",
      " - 1s - loss: 0.6548 - acc: 0.7708 - val_loss: 1.0833 - val_acc: 0.7172\n",
      "Epoch 558/2000\n",
      " - 1s - loss: 0.6783 - acc: 0.7555 - val_loss: 1.1029 - val_acc: 0.7376\n",
      "Epoch 559/2000\n",
      " - 1s - loss: 0.7044 - acc: 0.7584 - val_loss: 1.1649 - val_acc: 0.7055\n",
      "Epoch 560/2000\n",
      " - 1s - loss: 0.6927 - acc: 0.7518 - val_loss: 1.0959 - val_acc: 0.7230\n",
      "Epoch 561/2000\n",
      " - 1s - loss: 0.7140 - acc: 0.7664 - val_loss: 1.1594 - val_acc: 0.7085\n",
      "Epoch 562/2000\n",
      " - 1s - loss: 0.7046 - acc: 0.7555 - val_loss: 1.1236 - val_acc: 0.7318\n",
      "Epoch 563/2000\n",
      " - 1s - loss: 0.7187 - acc: 0.7533 - val_loss: 1.1593 - val_acc: 0.7055\n",
      "Epoch 564/2000\n",
      " - 1s - loss: 0.6988 - acc: 0.7460 - val_loss: 1.1217 - val_acc: 0.7259\n",
      "Epoch 565/2000\n",
      " - 1s - loss: 0.6540 - acc: 0.7723 - val_loss: 1.0316 - val_acc: 0.7376\n",
      "Epoch 566/2000\n",
      " - 1s - loss: 0.6383 - acc: 0.7752 - val_loss: 1.1152 - val_acc: 0.7376\n",
      "Epoch 567/2000\n",
      " - 1s - loss: 0.6687 - acc: 0.7577 - val_loss: 1.0966 - val_acc: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/2000\n",
      " - 1s - loss: 0.6563 - acc: 0.7730 - val_loss: 1.0844 - val_acc: 0.7085\n",
      "Epoch 569/2000\n",
      " - 1s - loss: 0.7712 - acc: 0.7299 - val_loss: 1.0706 - val_acc: 0.7289\n",
      "Epoch 570/2000\n",
      " - 1s - loss: 0.7487 - acc: 0.7416 - val_loss: 1.0151 - val_acc: 0.7434\n",
      "Epoch 571/2000\n",
      " - 0s - loss: 0.6740 - acc: 0.7730 - val_loss: 1.0489 - val_acc: 0.7638\n",
      "Epoch 572/2000\n",
      " - 1s - loss: 0.6846 - acc: 0.7679 - val_loss: 1.0476 - val_acc: 0.7464\n",
      "Epoch 573/2000\n",
      " - 1s - loss: 0.6605 - acc: 0.7657 - val_loss: 1.0751 - val_acc: 0.7464\n",
      "Epoch 574/2000\n",
      " - 1s - loss: 0.6156 - acc: 0.7693 - val_loss: 1.0891 - val_acc: 0.7318\n",
      "Epoch 575/2000\n",
      " - 1s - loss: 0.6392 - acc: 0.7737 - val_loss: 1.0548 - val_acc: 0.7055\n",
      "Epoch 576/2000\n",
      " - 1s - loss: 0.6581 - acc: 0.7642 - val_loss: 1.1110 - val_acc: 0.7055\n",
      "Epoch 577/2000\n",
      " - 1s - loss: 0.6551 - acc: 0.7686 - val_loss: 1.0466 - val_acc: 0.7259\n",
      "Epoch 578/2000\n",
      " - 1s - loss: 0.6781 - acc: 0.7642 - val_loss: 1.1070 - val_acc: 0.7085\n",
      "Epoch 579/2000\n",
      " - 1s - loss: 0.7146 - acc: 0.7533 - val_loss: 1.1761 - val_acc: 0.7376\n",
      "Epoch 580/2000\n",
      " - 1s - loss: 0.6837 - acc: 0.7686 - val_loss: 1.1029 - val_acc: 0.7026\n",
      "Epoch 581/2000\n",
      " - 1s - loss: 0.6289 - acc: 0.7949 - val_loss: 1.0240 - val_acc: 0.7347\n",
      "Epoch 582/2000\n",
      " - 1s - loss: 0.6647 - acc: 0.7650 - val_loss: 1.0595 - val_acc: 0.7085\n",
      "Epoch 583/2000\n",
      " - 1s - loss: 0.6138 - acc: 0.7839 - val_loss: 1.1072 - val_acc: 0.7172\n",
      "Epoch 584/2000\n",
      " - 0s - loss: 0.6248 - acc: 0.7774 - val_loss: 1.0767 - val_acc: 0.7201\n",
      "Epoch 585/2000\n",
      " - 1s - loss: 0.6526 - acc: 0.7701 - val_loss: 1.0681 - val_acc: 0.7434\n",
      "Epoch 586/2000\n",
      " - 1s - loss: 0.6573 - acc: 0.7591 - val_loss: 1.2012 - val_acc: 0.7114\n",
      "Epoch 587/2000\n",
      " - 1s - loss: 0.6721 - acc: 0.7715 - val_loss: 1.0983 - val_acc: 0.7172\n",
      "Epoch 588/2000\n",
      " - 1s - loss: 0.6406 - acc: 0.7759 - val_loss: 1.0781 - val_acc: 0.7259\n",
      "Epoch 589/2000\n",
      " - 1s - loss: 0.6883 - acc: 0.7620 - val_loss: 1.1159 - val_acc: 0.7201\n",
      "Epoch 590/2000\n",
      " - 1s - loss: 0.6673 - acc: 0.7730 - val_loss: 1.1338 - val_acc: 0.7376\n",
      "Epoch 591/2000\n",
      " - 1s - loss: 0.6339 - acc: 0.7905 - val_loss: 1.0576 - val_acc: 0.7289\n",
      "Epoch 592/2000\n",
      " - 1s - loss: 0.6032 - acc: 0.7854 - val_loss: 1.1080 - val_acc: 0.7259\n",
      "Epoch 593/2000\n",
      " - 1s - loss: 0.6817 - acc: 0.7635 - val_loss: 1.1955 - val_acc: 0.6793\n",
      "Epoch 594/2000\n",
      " - 1s - loss: 0.7172 - acc: 0.7540 - val_loss: 1.1285 - val_acc: 0.7289\n",
      "Epoch 595/2000\n",
      " - 1s - loss: 0.6205 - acc: 0.7854 - val_loss: 1.1159 - val_acc: 0.7085\n",
      "Epoch 596/2000\n",
      " - 1s - loss: 0.6632 - acc: 0.7504 - val_loss: 1.2906 - val_acc: 0.6764\n",
      "Epoch 597/2000\n",
      " - 1s - loss: 0.7110 - acc: 0.7482 - val_loss: 1.1110 - val_acc: 0.7289\n",
      "Epoch 598/2000\n",
      " - 1s - loss: 0.7183 - acc: 0.7591 - val_loss: 1.0135 - val_acc: 0.7405\n",
      "Epoch 599/2000\n",
      " - 1s - loss: 0.7336 - acc: 0.7401 - val_loss: 1.1025 - val_acc: 0.7172\n",
      "Epoch 600/2000\n",
      " - 1s - loss: 0.7042 - acc: 0.7453 - val_loss: 1.0978 - val_acc: 0.7376\n",
      "Epoch 601/2000\n",
      " - 1s - loss: 0.7071 - acc: 0.7518 - val_loss: 1.0810 - val_acc: 0.7376\n",
      "Epoch 602/2000\n",
      " - 1s - loss: 0.6274 - acc: 0.7839 - val_loss: 1.1332 - val_acc: 0.7143\n",
      "Epoch 603/2000\n",
      " - 1s - loss: 0.5951 - acc: 0.7759 - val_loss: 1.0988 - val_acc: 0.7114\n",
      "Epoch 604/2000\n",
      " - 1s - loss: 0.6378 - acc: 0.7701 - val_loss: 1.1000 - val_acc: 0.7434\n",
      "Epoch 605/2000\n",
      " - 1s - loss: 0.6698 - acc: 0.7642 - val_loss: 1.1887 - val_acc: 0.7114\n",
      "Epoch 606/2000\n",
      " - 1s - loss: 0.7102 - acc: 0.7496 - val_loss: 1.1805 - val_acc: 0.7201\n",
      "Epoch 607/2000\n",
      " - 1s - loss: 0.6594 - acc: 0.7650 - val_loss: 1.1732 - val_acc: 0.7143\n",
      "Epoch 608/2000\n",
      " - 1s - loss: 0.6598 - acc: 0.7737 - val_loss: 1.0828 - val_acc: 0.7201\n",
      "Epoch 609/2000\n",
      " - 1s - loss: 0.6118 - acc: 0.7839 - val_loss: 1.0645 - val_acc: 0.7289\n",
      "Epoch 610/2000\n",
      " - 1s - loss: 0.6656 - acc: 0.7474 - val_loss: 1.1710 - val_acc: 0.7405\n",
      "Epoch 611/2000\n",
      " - 0s - loss: 0.6690 - acc: 0.7766 - val_loss: 1.1076 - val_acc: 0.7376\n",
      "Epoch 612/2000\n",
      " - 1s - loss: 0.7264 - acc: 0.7613 - val_loss: 1.0893 - val_acc: 0.7114\n",
      "Epoch 613/2000\n",
      " - 1s - loss: 0.6958 - acc: 0.7526 - val_loss: 1.0401 - val_acc: 0.7318\n",
      "Epoch 614/2000\n",
      " - 1s - loss: 0.6532 - acc: 0.7774 - val_loss: 1.1079 - val_acc: 0.7172\n",
      "Epoch 615/2000\n",
      " - 1s - loss: 0.7090 - acc: 0.7679 - val_loss: 1.0335 - val_acc: 0.7405\n",
      "Epoch 616/2000\n",
      " - 1s - loss: 0.6138 - acc: 0.7883 - val_loss: 1.0586 - val_acc: 0.7376\n",
      "Epoch 617/2000\n",
      " - 0s - loss: 0.6087 - acc: 0.7869 - val_loss: 1.1290 - val_acc: 0.7201\n",
      "Epoch 618/2000\n",
      " - 1s - loss: 0.6633 - acc: 0.7584 - val_loss: 1.1405 - val_acc: 0.7055\n",
      "Epoch 619/2000\n",
      " - 1s - loss: 0.6682 - acc: 0.7693 - val_loss: 1.1008 - val_acc: 0.7201\n",
      "Epoch 620/2000\n",
      " - 1s - loss: 0.6348 - acc: 0.7715 - val_loss: 1.0228 - val_acc: 0.7405\n",
      "Epoch 621/2000\n",
      " - 1s - loss: 0.6620 - acc: 0.7679 - val_loss: 1.0848 - val_acc: 0.7172\n",
      "Epoch 622/2000\n",
      " - 1s - loss: 0.9196 - acc: 0.7292 - val_loss: 1.4326 - val_acc: 0.6093\n",
      "Epoch 623/2000\n",
      " - 1s - loss: 1.0020 - acc: 0.6752 - val_loss: 1.0260 - val_acc: 0.7172\n",
      "Epoch 624/2000\n",
      " - 1s - loss: 0.7560 - acc: 0.7372 - val_loss: 1.2506 - val_acc: 0.6910\n",
      "Epoch 625/2000\n",
      " - 1s - loss: 0.7381 - acc: 0.7482 - val_loss: 1.2378 - val_acc: 0.6647\n",
      "Epoch 626/2000\n",
      " - 1s - loss: 0.7472 - acc: 0.7460 - val_loss: 1.1229 - val_acc: 0.6968\n",
      "Epoch 627/2000\n",
      " - 1s - loss: 0.6417 - acc: 0.7715 - val_loss: 1.0572 - val_acc: 0.7259\n",
      "Epoch 628/2000\n",
      " - 1s - loss: 0.5976 - acc: 0.7701 - val_loss: 1.0565 - val_acc: 0.7259\n",
      "Epoch 629/2000\n",
      " - 1s - loss: 0.7157 - acc: 0.7336 - val_loss: 1.0755 - val_acc: 0.7143\n",
      "Epoch 630/2000\n",
      " - 1s - loss: 0.6560 - acc: 0.7715 - val_loss: 1.0726 - val_acc: 0.7055\n",
      "Epoch 631/2000\n",
      " - 1s - loss: 0.6383 - acc: 0.7737 - val_loss: 0.9866 - val_acc: 0.7668\n",
      "Epoch 632/2000\n",
      " - 1s - loss: 0.6050 - acc: 0.7796 - val_loss: 1.0637 - val_acc: 0.7143\n",
      "Epoch 633/2000\n",
      " - 1s - loss: 0.6580 - acc: 0.7628 - val_loss: 1.0745 - val_acc: 0.7580\n",
      "Epoch 634/2000\n",
      " - 1s - loss: 0.6598 - acc: 0.7672 - val_loss: 1.0943 - val_acc: 0.7085\n",
      "Epoch 635/2000\n",
      " - 1s - loss: 0.6760 - acc: 0.7555 - val_loss: 1.0630 - val_acc: 0.7143\n",
      "Epoch 636/2000\n",
      " - 1s - loss: 0.6339 - acc: 0.7759 - val_loss: 1.1084 - val_acc: 0.7259\n",
      "Epoch 637/2000\n",
      " - 0s - loss: 0.6199 - acc: 0.7788 - val_loss: 1.0793 - val_acc: 0.7434\n",
      "Epoch 638/2000\n",
      " - 1s - loss: 0.6459 - acc: 0.7920 - val_loss: 1.1174 - val_acc: 0.7055\n",
      "Epoch 639/2000\n",
      " - 1s - loss: 0.6330 - acc: 0.7650 - val_loss: 1.1358 - val_acc: 0.7347\n",
      "Epoch 640/2000\n",
      " - 1s - loss: 0.7277 - acc: 0.7474 - val_loss: 1.1783 - val_acc: 0.6910\n",
      "Epoch 641/2000\n",
      " - 1s - loss: 0.6186 - acc: 0.7839 - val_loss: 1.0741 - val_acc: 0.7493\n",
      "Epoch 642/2000\n",
      " - 1s - loss: 0.6405 - acc: 0.7591 - val_loss: 1.0950 - val_acc: 0.7143\n",
      "Epoch 643/2000\n",
      " - 1s - loss: 0.6341 - acc: 0.7745 - val_loss: 1.0891 - val_acc: 0.7376\n",
      "Epoch 644/2000\n",
      " - 1s - loss: 0.6515 - acc: 0.7745 - val_loss: 1.1287 - val_acc: 0.6997\n",
      "Epoch 645/2000\n",
      " - 1s - loss: 0.6404 - acc: 0.7715 - val_loss: 1.1875 - val_acc: 0.7055\n",
      "Epoch 646/2000\n",
      " - 1s - loss: 0.6736 - acc: 0.7613 - val_loss: 1.1481 - val_acc: 0.7201\n",
      "Epoch 647/2000\n",
      " - 1s - loss: 0.6400 - acc: 0.7934 - val_loss: 1.1414 - val_acc: 0.7085\n",
      "Epoch 648/2000\n",
      " - 1s - loss: 0.7991 - acc: 0.7423 - val_loss: 1.2124 - val_acc: 0.7026\n",
      "Epoch 649/2000\n",
      " - 1s - loss: 0.7613 - acc: 0.7547 - val_loss: 1.1185 - val_acc: 0.7172\n",
      "Epoch 650/2000\n",
      " - 0s - loss: 0.6885 - acc: 0.7482 - val_loss: 1.0157 - val_acc: 0.7376\n",
      "Epoch 651/2000\n",
      " - 0s - loss: 0.6520 - acc: 0.7693 - val_loss: 1.1265 - val_acc: 0.7143\n",
      "Epoch 652/2000\n",
      " - 1s - loss: 0.7376 - acc: 0.7474 - val_loss: 1.2649 - val_acc: 0.6880\n",
      "Epoch 653/2000\n",
      " - 1s - loss: 0.7299 - acc: 0.7540 - val_loss: 1.0889 - val_acc: 0.7055\n",
      "Epoch 654/2000\n",
      " - 1s - loss: 0.6810 - acc: 0.7686 - val_loss: 1.1262 - val_acc: 0.7347\n",
      "Epoch 655/2000\n",
      " - 1s - loss: 0.7111 - acc: 0.7358 - val_loss: 1.0281 - val_acc: 0.7347\n",
      "Epoch 656/2000\n",
      " - 1s - loss: 0.6703 - acc: 0.7599 - val_loss: 1.0949 - val_acc: 0.7230\n",
      "Epoch 657/2000\n",
      " - 1s - loss: 0.6491 - acc: 0.7708 - val_loss: 1.0961 - val_acc: 0.7026\n",
      "Epoch 658/2000\n",
      " - 1s - loss: 0.5773 - acc: 0.7964 - val_loss: 1.0975 - val_acc: 0.7318\n",
      "Epoch 659/2000\n",
      " - 1s - loss: 0.6441 - acc: 0.7810 - val_loss: 1.1018 - val_acc: 0.7318\n",
      "Epoch 660/2000\n",
      " - 1s - loss: 0.6526 - acc: 0.7723 - val_loss: 1.1212 - val_acc: 0.7172\n",
      "Epoch 661/2000\n",
      " - 1s - loss: 0.6245 - acc: 0.7818 - val_loss: 1.0386 - val_acc: 0.7201\n",
      "Epoch 662/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6281 - acc: 0.7708 - val_loss: 1.1615 - val_acc: 0.7201\n",
      "Epoch 663/2000\n",
      " - 1s - loss: 0.6302 - acc: 0.7766 - val_loss: 1.0850 - val_acc: 0.7201\n",
      "Epoch 664/2000\n",
      " - 1s - loss: 0.5897 - acc: 0.7832 - val_loss: 1.1278 - val_acc: 0.6997\n",
      "Epoch 665/2000\n",
      " - 1s - loss: 0.6593 - acc: 0.7584 - val_loss: 1.1365 - val_acc: 0.7201\n",
      "Epoch 666/2000\n",
      " - 1s - loss: 0.6285 - acc: 0.7876 - val_loss: 1.2168 - val_acc: 0.6939\n",
      "Epoch 667/2000\n",
      " - 1s - loss: 0.6457 - acc: 0.7737 - val_loss: 1.1224 - val_acc: 0.7114\n",
      "Epoch 668/2000\n",
      " - 1s - loss: 0.6510 - acc: 0.7547 - val_loss: 1.1670 - val_acc: 0.7143\n",
      "Epoch 669/2000\n",
      " - 1s - loss: 0.6445 - acc: 0.7774 - val_loss: 1.1638 - val_acc: 0.7318\n",
      "Epoch 670/2000\n",
      " - 1s - loss: 0.6831 - acc: 0.7606 - val_loss: 1.3008 - val_acc: 0.6880\n",
      "Epoch 671/2000\n",
      " - 1s - loss: 0.7356 - acc: 0.7474 - val_loss: 1.1270 - val_acc: 0.7172\n",
      "Epoch 672/2000\n",
      " - 1s - loss: 0.6624 - acc: 0.7679 - val_loss: 1.1250 - val_acc: 0.7026\n",
      "Epoch 673/2000\n",
      " - 1s - loss: 0.6499 - acc: 0.7628 - val_loss: 1.1115 - val_acc: 0.7201\n",
      "Epoch 674/2000\n",
      " - 1s - loss: 0.6190 - acc: 0.7949 - val_loss: 1.0747 - val_acc: 0.7376\n",
      "Epoch 675/2000\n",
      " - 1s - loss: 0.6058 - acc: 0.7774 - val_loss: 1.2026 - val_acc: 0.7259\n",
      "Epoch 676/2000\n",
      " - 1s - loss: 0.6434 - acc: 0.7679 - val_loss: 1.2123 - val_acc: 0.6939\n",
      "Epoch 677/2000\n",
      " - 1s - loss: 0.7554 - acc: 0.7409 - val_loss: 1.1681 - val_acc: 0.7114\n",
      "Epoch 678/2000\n",
      " - 1s - loss: 0.6766 - acc: 0.7664 - val_loss: 1.1698 - val_acc: 0.6997\n",
      "Epoch 679/2000\n",
      " - 1s - loss: 0.6152 - acc: 0.7869 - val_loss: 1.1409 - val_acc: 0.7405\n",
      "Epoch 680/2000\n",
      " - 1s - loss: 0.7486 - acc: 0.7365 - val_loss: 1.1326 - val_acc: 0.7230\n",
      "Epoch 681/2000\n",
      " - 1s - loss: 0.7216 - acc: 0.7496 - val_loss: 1.1401 - val_acc: 0.7143\n",
      "Epoch 682/2000\n",
      " - 1s - loss: 0.6458 - acc: 0.7650 - val_loss: 1.2408 - val_acc: 0.7026\n",
      "Epoch 683/2000\n",
      " - 1s - loss: 0.7369 - acc: 0.7533 - val_loss: 1.1153 - val_acc: 0.7318\n",
      "Epoch 684/2000\n",
      " - 1s - loss: 0.7243 - acc: 0.7606 - val_loss: 1.1152 - val_acc: 0.7085\n",
      "Epoch 685/2000\n",
      " - 1s - loss: 0.6527 - acc: 0.7679 - val_loss: 1.1379 - val_acc: 0.7230\n",
      "Epoch 686/2000\n",
      " - 1s - loss: 0.6747 - acc: 0.7672 - val_loss: 1.6111 - val_acc: 0.6414\n",
      "Epoch 687/2000\n",
      " - 1s - loss: 0.9792 - acc: 0.6847 - val_loss: 1.1478 - val_acc: 0.7114\n",
      "Epoch 688/2000\n",
      " - 1s - loss: 0.7395 - acc: 0.7380 - val_loss: 1.1537 - val_acc: 0.6968\n",
      "Epoch 689/2000\n",
      " - 1s - loss: 0.6940 - acc: 0.7511 - val_loss: 1.1329 - val_acc: 0.7114\n",
      "Epoch 690/2000\n",
      " - 1s - loss: 0.6964 - acc: 0.7489 - val_loss: 1.1199 - val_acc: 0.7114\n",
      "Epoch 691/2000\n",
      " - 1s - loss: 0.6727 - acc: 0.7708 - val_loss: 1.1575 - val_acc: 0.7114\n",
      "Epoch 692/2000\n",
      " - 1s - loss: 0.6846 - acc: 0.7723 - val_loss: 1.2235 - val_acc: 0.6910\n",
      "Epoch 693/2000\n",
      " - 1s - loss: 0.6598 - acc: 0.7599 - val_loss: 1.1539 - val_acc: 0.7347\n",
      "Epoch 694/2000\n",
      " - 1s - loss: 0.6320 - acc: 0.7796 - val_loss: 1.0993 - val_acc: 0.7201\n",
      "Epoch 695/2000\n",
      " - 1s - loss: 0.6111 - acc: 0.7679 - val_loss: 1.0558 - val_acc: 0.7259\n",
      "Epoch 696/2000\n",
      " - 1s - loss: 0.6175 - acc: 0.7745 - val_loss: 1.1126 - val_acc: 0.7143\n",
      "Epoch 697/2000\n",
      " - 1s - loss: 0.6648 - acc: 0.7650 - val_loss: 1.2200 - val_acc: 0.7143\n",
      "Epoch 698/2000\n",
      " - 1s - loss: 0.6433 - acc: 0.7803 - val_loss: 1.1718 - val_acc: 0.7376\n",
      "Epoch 699/2000\n",
      " - 1s - loss: 0.6340 - acc: 0.7745 - val_loss: 1.1609 - val_acc: 0.7405\n",
      "Epoch 700/2000\n",
      " - 1s - loss: 0.8242 - acc: 0.7241 - val_loss: 1.1024 - val_acc: 0.6997\n",
      "Epoch 701/2000\n",
      " - 1s - loss: 0.6767 - acc: 0.7577 - val_loss: 1.0762 - val_acc: 0.7259\n",
      "Epoch 702/2000\n",
      " - 1s - loss: 0.6408 - acc: 0.7905 - val_loss: 1.0706 - val_acc: 0.7172\n",
      "Epoch 703/2000\n",
      " - 1s - loss: 0.6002 - acc: 0.7949 - val_loss: 1.0637 - val_acc: 0.7434\n",
      "Epoch 704/2000\n",
      " - 1s - loss: 0.5853 - acc: 0.8015 - val_loss: 1.0613 - val_acc: 0.7522\n",
      "Epoch 705/2000\n",
      " - 1s - loss: 0.6363 - acc: 0.7620 - val_loss: 1.0773 - val_acc: 0.7259\n",
      "Epoch 706/2000\n",
      " - 1s - loss: 0.6364 - acc: 0.7606 - val_loss: 1.1290 - val_acc: 0.7085\n",
      "Epoch 707/2000\n",
      " - 1s - loss: 0.6109 - acc: 0.7854 - val_loss: 1.2065 - val_acc: 0.7055\n",
      "Epoch 708/2000\n",
      " - 1s - loss: 0.6927 - acc: 0.7577 - val_loss: 1.1989 - val_acc: 0.7201\n",
      "Epoch 709/2000\n",
      " - 1s - loss: 0.7072 - acc: 0.7562 - val_loss: 1.1074 - val_acc: 0.7405\n",
      "Epoch 710/2000\n",
      " - 1s - loss: 0.6391 - acc: 0.7708 - val_loss: 1.1604 - val_acc: 0.7172\n",
      "Epoch 711/2000\n",
      " - 1s - loss: 0.6233 - acc: 0.7642 - val_loss: 1.0941 - val_acc: 0.7347\n",
      "Epoch 712/2000\n",
      " - 1s - loss: 0.7013 - acc: 0.7569 - val_loss: 1.1367 - val_acc: 0.7114\n",
      "Epoch 713/2000\n",
      " - 1s - loss: 0.6285 - acc: 0.7737 - val_loss: 1.1076 - val_acc: 0.7201\n",
      "Epoch 714/2000\n",
      " - 1s - loss: 0.6040 - acc: 0.7686 - val_loss: 1.1827 - val_acc: 0.6968\n",
      "Epoch 715/2000\n",
      " - 1s - loss: 0.6894 - acc: 0.7577 - val_loss: 1.1340 - val_acc: 0.7318\n",
      "Epoch 716/2000\n",
      " - 1s - loss: 0.6094 - acc: 0.7781 - val_loss: 1.0425 - val_acc: 0.7143\n",
      "Epoch 717/2000\n",
      " - 1s - loss: 0.6560 - acc: 0.7533 - val_loss: 1.1117 - val_acc: 0.7434\n",
      "Epoch 718/2000\n",
      " - 1s - loss: 0.6419 - acc: 0.7788 - val_loss: 1.1107 - val_acc: 0.7201\n",
      "Epoch 719/2000\n",
      " - 1s - loss: 0.6757 - acc: 0.7650 - val_loss: 1.1737 - val_acc: 0.7114\n",
      "Epoch 720/2000\n",
      " - 1s - loss: 0.6219 - acc: 0.7839 - val_loss: 1.1709 - val_acc: 0.7143\n",
      "Epoch 721/2000\n",
      " - 1s - loss: 0.6541 - acc: 0.7628 - val_loss: 1.1623 - val_acc: 0.7347\n",
      "Epoch 722/2000\n",
      " - 1s - loss: 0.6009 - acc: 0.7934 - val_loss: 1.1232 - val_acc: 0.7172\n",
      "Epoch 723/2000\n",
      " - 0s - loss: 0.6635 - acc: 0.7613 - val_loss: 1.1552 - val_acc: 0.7143\n",
      "Epoch 724/2000\n",
      " - 1s - loss: 0.6817 - acc: 0.7518 - val_loss: 1.0296 - val_acc: 0.7493\n",
      "Epoch 725/2000\n",
      " - 1s - loss: 0.6596 - acc: 0.7715 - val_loss: 1.0466 - val_acc: 0.7201\n",
      "Epoch 726/2000\n",
      " - 1s - loss: 0.6808 - acc: 0.7584 - val_loss: 1.0993 - val_acc: 0.7259\n",
      "Epoch 727/2000\n",
      " - 1s - loss: 0.6514 - acc: 0.7664 - val_loss: 1.0950 - val_acc: 0.7230\n",
      "Epoch 728/2000\n",
      " - 1s - loss: 0.6101 - acc: 0.7905 - val_loss: 1.1043 - val_acc: 0.7230\n",
      "Epoch 729/2000\n",
      " - 1s - loss: 0.6643 - acc: 0.7533 - val_loss: 1.1030 - val_acc: 0.7318\n",
      "Epoch 730/2000\n",
      " - 1s - loss: 0.6256 - acc: 0.7847 - val_loss: 1.0998 - val_acc: 0.7376\n",
      "Epoch 731/2000\n",
      " - 1s - loss: 0.5982 - acc: 0.7832 - val_loss: 1.2001 - val_acc: 0.7172\n",
      "Epoch 732/2000\n",
      " - 1s - loss: 0.6800 - acc: 0.7693 - val_loss: 1.2008 - val_acc: 0.7143\n",
      "Epoch 733/2000\n",
      " - 1s - loss: 0.6622 - acc: 0.7708 - val_loss: 1.0926 - val_acc: 0.7085\n",
      "Epoch 734/2000\n",
      " - 1s - loss: 0.6513 - acc: 0.7796 - val_loss: 1.1343 - val_acc: 0.7259\n",
      "Epoch 735/2000\n",
      " - 1s - loss: 0.6886 - acc: 0.7533 - val_loss: 1.1193 - val_acc: 0.7318\n",
      "Epoch 736/2000\n",
      " - 1s - loss: 0.6635 - acc: 0.7628 - val_loss: 1.0742 - val_acc: 0.7289\n",
      "Epoch 737/2000\n",
      " - 1s - loss: 0.6484 - acc: 0.7818 - val_loss: 1.1055 - val_acc: 0.7230\n",
      "Epoch 738/2000\n",
      " - 1s - loss: 0.7147 - acc: 0.7474 - val_loss: 1.1996 - val_acc: 0.7172\n",
      "Epoch 739/2000\n",
      " - 1s - loss: 0.6586 - acc: 0.7759 - val_loss: 1.1452 - val_acc: 0.7347\n",
      "Epoch 740/2000\n",
      " - 1s - loss: 0.6981 - acc: 0.7482 - val_loss: 1.3014 - val_acc: 0.6910\n",
      "Epoch 741/2000\n",
      " - 1s - loss: 0.6795 - acc: 0.7613 - val_loss: 1.0921 - val_acc: 0.7405\n",
      "Epoch 742/2000\n",
      " - 1s - loss: 0.6304 - acc: 0.7847 - val_loss: 1.1776 - val_acc: 0.7230\n",
      "Epoch 743/2000\n",
      " - 1s - loss: 0.6378 - acc: 0.7708 - val_loss: 1.1142 - val_acc: 0.7085\n",
      "Epoch 744/2000\n",
      " - 1s - loss: 0.6617 - acc: 0.7723 - val_loss: 1.1554 - val_acc: 0.7172\n",
      "Epoch 745/2000\n",
      " - 1s - loss: 0.5870 - acc: 0.7839 - val_loss: 1.1652 - val_acc: 0.7230\n",
      "Epoch 746/2000\n",
      " - 1s - loss: 0.5979 - acc: 0.7912 - val_loss: 1.2060 - val_acc: 0.7114\n",
      "Epoch 747/2000\n",
      " - 1s - loss: 0.6599 - acc: 0.7737 - val_loss: 1.0889 - val_acc: 0.7376\n",
      "Epoch 748/2000\n",
      " - 1s - loss: 0.6830 - acc: 0.7489 - val_loss: 1.2055 - val_acc: 0.6968\n",
      "Epoch 749/2000\n",
      " - 1s - loss: 0.7572 - acc: 0.7343 - val_loss: 1.0746 - val_acc: 0.7201\n",
      "Epoch 750/2000\n",
      " - 1s - loss: 0.7016 - acc: 0.7482 - val_loss: 1.2339 - val_acc: 0.7201\n",
      "Epoch 751/2000\n",
      " - 1s - loss: 0.7526 - acc: 0.7518 - val_loss: 1.1419 - val_acc: 0.7464\n",
      "Epoch 752/2000\n",
      " - 1s - loss: 0.7483 - acc: 0.7380 - val_loss: 1.1106 - val_acc: 0.7114\n",
      "Epoch 753/2000\n",
      " - 1s - loss: 0.6600 - acc: 0.7620 - val_loss: 1.0893 - val_acc: 0.7230\n",
      "Epoch 754/2000\n",
      " - 1s - loss: 0.6238 - acc: 0.7832 - val_loss: 1.0683 - val_acc: 0.7376\n",
      "Epoch 755/2000\n",
      " - 1s - loss: 0.6339 - acc: 0.7693 - val_loss: 1.1660 - val_acc: 0.7230\n",
      "Epoch 756/2000\n",
      " - 1s - loss: 0.6644 - acc: 0.7664 - val_loss: 1.1708 - val_acc: 0.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/2000\n",
      " - 1s - loss: 0.5961 - acc: 0.7869 - val_loss: 1.1245 - val_acc: 0.7201\n",
      "Epoch 758/2000\n",
      " - 1s - loss: 0.5683 - acc: 0.8036 - val_loss: 1.1699 - val_acc: 0.7230\n",
      "Epoch 759/2000\n",
      " - 1s - loss: 0.6444 - acc: 0.7672 - val_loss: 1.1266 - val_acc: 0.7172\n",
      "Epoch 760/2000\n",
      " - 1s - loss: 0.6957 - acc: 0.7606 - val_loss: 1.1511 - val_acc: 0.7230\n",
      "Epoch 761/2000\n",
      " - 1s - loss: 0.6405 - acc: 0.7737 - val_loss: 1.0937 - val_acc: 0.7551\n",
      "Epoch 762/2000\n",
      " - 1s - loss: 0.6391 - acc: 0.7723 - val_loss: 1.0782 - val_acc: 0.7347\n",
      "Epoch 763/2000\n",
      " - 1s - loss: 0.6326 - acc: 0.7715 - val_loss: 1.1200 - val_acc: 0.7259\n",
      "Epoch 764/2000\n",
      " - 0s - loss: 0.6528 - acc: 0.7693 - val_loss: 1.0849 - val_acc: 0.7201\n",
      "Epoch 765/2000\n",
      " - 1s - loss: 0.6110 - acc: 0.7839 - val_loss: 1.1392 - val_acc: 0.7289\n",
      "Epoch 766/2000\n",
      " - 1s - loss: 0.5826 - acc: 0.7942 - val_loss: 1.2170 - val_acc: 0.6822\n",
      "Epoch 767/2000\n",
      " - 1s - loss: 0.7372 - acc: 0.7409 - val_loss: 1.1778 - val_acc: 0.7201\n",
      "Epoch 768/2000\n",
      " - 1s - loss: 0.6505 - acc: 0.7613 - val_loss: 1.0127 - val_acc: 0.7609\n",
      "Epoch 769/2000\n",
      " - 1s - loss: 0.6528 - acc: 0.7715 - val_loss: 1.1881 - val_acc: 0.6880\n",
      "Epoch 770/2000\n",
      " - 1s - loss: 0.6581 - acc: 0.7613 - val_loss: 1.1693 - val_acc: 0.7026\n",
      "Epoch 771/2000\n",
      " - 1s - loss: 0.7156 - acc: 0.7599 - val_loss: 1.1989 - val_acc: 0.7172\n",
      "Epoch 772/2000\n",
      " - 1s - loss: 0.6274 - acc: 0.7818 - val_loss: 1.2164 - val_acc: 0.7172\n",
      "Epoch 773/2000\n",
      " - 1s - loss: 0.5889 - acc: 0.7905 - val_loss: 1.1344 - val_acc: 0.7114\n",
      "Epoch 774/2000\n",
      " - 1s - loss: 0.5819 - acc: 0.7752 - val_loss: 1.1176 - val_acc: 0.7259\n",
      "Epoch 775/2000\n",
      " - 1s - loss: 0.5843 - acc: 0.7876 - val_loss: 1.1289 - val_acc: 0.7289\n",
      "Epoch 776/2000\n",
      " - 1s - loss: 0.5942 - acc: 0.7832 - val_loss: 1.2785 - val_acc: 0.6968\n",
      "Epoch 777/2000\n",
      " - 1s - loss: 0.6408 - acc: 0.7715 - val_loss: 1.2376 - val_acc: 0.6968\n",
      "Epoch 778/2000\n",
      " - 1s - loss: 0.8274 - acc: 0.7270 - val_loss: 1.1582 - val_acc: 0.7318\n",
      "Epoch 779/2000\n",
      " - 1s - loss: 0.6960 - acc: 0.7577 - val_loss: 1.0564 - val_acc: 0.7143\n",
      "Epoch 780/2000\n",
      " - 1s - loss: 0.7234 - acc: 0.7292 - val_loss: 1.1811 - val_acc: 0.7376\n",
      "Epoch 781/2000\n",
      " - 1s - loss: 0.6003 - acc: 0.7854 - val_loss: 1.1698 - val_acc: 0.7376\n",
      "Epoch 782/2000\n",
      " - 1s - loss: 0.5894 - acc: 0.7796 - val_loss: 1.1162 - val_acc: 0.7172\n",
      "Epoch 783/2000\n",
      " - 1s - loss: 0.6307 - acc: 0.7730 - val_loss: 1.2216 - val_acc: 0.7201\n",
      "Epoch 784/2000\n",
      " - 1s - loss: 0.6318 - acc: 0.7759 - val_loss: 1.0868 - val_acc: 0.7289\n",
      "Epoch 785/2000\n",
      " - 1s - loss: 0.6059 - acc: 0.7869 - val_loss: 1.1570 - val_acc: 0.7289\n",
      "Epoch 786/2000\n",
      " - 1s - loss: 0.6714 - acc: 0.7803 - val_loss: 1.2362 - val_acc: 0.6706\n",
      "Epoch 787/2000\n",
      " - 1s - loss: 0.7139 - acc: 0.7547 - val_loss: 1.1691 - val_acc: 0.7055\n",
      "Epoch 788/2000\n",
      " - 1s - loss: 0.6299 - acc: 0.7737 - val_loss: 1.0305 - val_acc: 0.7289\n",
      "Epoch 789/2000\n",
      " - 1s - loss: 0.6163 - acc: 0.7818 - val_loss: 1.1222 - val_acc: 0.7259\n",
      "Epoch 790/2000\n",
      " - 1s - loss: 0.6676 - acc: 0.7730 - val_loss: 1.1564 - val_acc: 0.7172\n",
      "Epoch 791/2000\n",
      " - 1s - loss: 0.6171 - acc: 0.7861 - val_loss: 1.0686 - val_acc: 0.7026\n",
      "Epoch 792/2000\n",
      " - 1s - loss: 0.5852 - acc: 0.7949 - val_loss: 1.1437 - val_acc: 0.7434\n",
      "Epoch 793/2000\n",
      " - 1s - loss: 0.6122 - acc: 0.7839 - val_loss: 1.2097 - val_acc: 0.7172\n",
      "Epoch 794/2000\n",
      " - 1s - loss: 0.6444 - acc: 0.7723 - val_loss: 1.2418 - val_acc: 0.7143\n",
      "Epoch 795/2000\n",
      " - 1s - loss: 0.7231 - acc: 0.7482 - val_loss: 1.1168 - val_acc: 0.7143\n",
      "Epoch 796/2000\n",
      " - 1s - loss: 0.7709 - acc: 0.7343 - val_loss: 1.1601 - val_acc: 0.6735\n",
      "Epoch 797/2000\n",
      " - 1s - loss: 0.6682 - acc: 0.7547 - val_loss: 1.1219 - val_acc: 0.7230\n",
      "Epoch 798/2000\n",
      " - 1s - loss: 0.7801 - acc: 0.7526 - val_loss: 1.3701 - val_acc: 0.6764\n",
      "Epoch 799/2000\n",
      " - 1s - loss: 0.9081 - acc: 0.7051 - val_loss: 1.1256 - val_acc: 0.7055\n",
      "Epoch 800/2000\n",
      " - 0s - loss: 0.6248 - acc: 0.7839 - val_loss: 1.0906 - val_acc: 0.7347\n",
      "Epoch 801/2000\n",
      " - 0s - loss: 0.6789 - acc: 0.7650 - val_loss: 1.1077 - val_acc: 0.7259\n",
      "Epoch 802/2000\n",
      " - 1s - loss: 0.6302 - acc: 0.7730 - val_loss: 1.0799 - val_acc: 0.7289\n",
      "Epoch 803/2000\n",
      " - 1s - loss: 0.6648 - acc: 0.7818 - val_loss: 1.1265 - val_acc: 0.6910\n",
      "Epoch 804/2000\n",
      " - 1s - loss: 0.6664 - acc: 0.7708 - val_loss: 1.1250 - val_acc: 0.7464\n",
      "Epoch 805/2000\n",
      " - 1s - loss: 0.6360 - acc: 0.7642 - val_loss: 1.1803 - val_acc: 0.7318\n",
      "Epoch 806/2000\n",
      " - 1s - loss: 0.6423 - acc: 0.7905 - val_loss: 1.1547 - val_acc: 0.7201\n",
      "Epoch 807/2000\n",
      " - 1s - loss: 0.6219 - acc: 0.7628 - val_loss: 1.1711 - val_acc: 0.7201\n",
      "Epoch 808/2000\n",
      " - 1s - loss: 0.6240 - acc: 0.7839 - val_loss: 1.1428 - val_acc: 0.7347\n",
      "Epoch 809/2000\n",
      " - 0s - loss: 0.6244 - acc: 0.7723 - val_loss: 1.1096 - val_acc: 0.7201\n",
      "Epoch 810/2000\n",
      " - 0s - loss: 0.6053 - acc: 0.7876 - val_loss: 1.1520 - val_acc: 0.7259\n",
      "Epoch 811/2000\n",
      " - 1s - loss: 0.6223 - acc: 0.7810 - val_loss: 1.1586 - val_acc: 0.7085\n",
      "Epoch 812/2000\n",
      " - 1s - loss: 0.5864 - acc: 0.7788 - val_loss: 1.2373 - val_acc: 0.7055\n",
      "Epoch 813/2000\n",
      " - 1s - loss: 0.6784 - acc: 0.7591 - val_loss: 1.1978 - val_acc: 0.6851\n",
      "Epoch 814/2000\n",
      " - 1s - loss: 0.8288 - acc: 0.7131 - val_loss: 1.1787 - val_acc: 0.7114\n",
      "Epoch 815/2000\n",
      " - 1s - loss: 0.6371 - acc: 0.7810 - val_loss: 1.2872 - val_acc: 0.6793\n",
      "Epoch 816/2000\n",
      " - 1s - loss: 0.7242 - acc: 0.7467 - val_loss: 1.1860 - val_acc: 0.7055\n",
      "Epoch 817/2000\n",
      " - 1s - loss: 0.6852 - acc: 0.7628 - val_loss: 1.1372 - val_acc: 0.6910\n",
      "Epoch 818/2000\n",
      " - 1s - loss: 0.6247 - acc: 0.7847 - val_loss: 1.1352 - val_acc: 0.7318\n",
      "Epoch 819/2000\n",
      " - 1s - loss: 0.5980 - acc: 0.7752 - val_loss: 1.1510 - val_acc: 0.6968\n",
      "Epoch 820/2000\n",
      " - 1s - loss: 0.6454 - acc: 0.7693 - val_loss: 1.1266 - val_acc: 0.7201\n",
      "Epoch 821/2000\n",
      " - 1s - loss: 0.6148 - acc: 0.7825 - val_loss: 1.1068 - val_acc: 0.7201\n",
      "Epoch 822/2000\n",
      " - 1s - loss: 0.6521 - acc: 0.7708 - val_loss: 1.0860 - val_acc: 0.7289\n",
      "Epoch 823/2000\n",
      " - 1s - loss: 0.5879 - acc: 0.7985 - val_loss: 1.1567 - val_acc: 0.7026\n",
      "Epoch 824/2000\n",
      " - 1s - loss: 0.6485 - acc: 0.7650 - val_loss: 1.1957 - val_acc: 0.6822\n",
      "Epoch 825/2000\n",
      " - 1s - loss: 0.7298 - acc: 0.7599 - val_loss: 1.0346 - val_acc: 0.7026\n",
      "Epoch 826/2000\n",
      " - 1s - loss: 0.6216 - acc: 0.7810 - val_loss: 1.1476 - val_acc: 0.7143\n",
      "Epoch 827/2000\n",
      " - 0s - loss: 0.6274 - acc: 0.7781 - val_loss: 1.0825 - val_acc: 0.7172\n",
      "Epoch 828/2000\n",
      " - 1s - loss: 0.6090 - acc: 0.7766 - val_loss: 1.1175 - val_acc: 0.7172\n",
      "Epoch 829/2000\n",
      " - 1s - loss: 0.5990 - acc: 0.7839 - val_loss: 1.1121 - val_acc: 0.7172\n",
      "Epoch 830/2000\n",
      " - 1s - loss: 0.6404 - acc: 0.7796 - val_loss: 1.0635 - val_acc: 0.7172\n",
      "Epoch 831/2000\n",
      " - 1s - loss: 0.6148 - acc: 0.7861 - val_loss: 1.1233 - val_acc: 0.7230\n",
      "Epoch 832/2000\n",
      " - 1s - loss: 0.6338 - acc: 0.7745 - val_loss: 1.1453 - val_acc: 0.7026\n",
      "Epoch 833/2000\n",
      " - 1s - loss: 0.7911 - acc: 0.7328 - val_loss: 1.1539 - val_acc: 0.6735\n",
      "Epoch 834/2000\n",
      " - 1s - loss: 0.7232 - acc: 0.7394 - val_loss: 1.1198 - val_acc: 0.7026\n",
      "Epoch 835/2000\n",
      " - 1s - loss: 0.7201 - acc: 0.7496 - val_loss: 0.9235 - val_acc: 0.7143\n",
      "Epoch 836/2000\n",
      " - 0s - loss: 0.7033 - acc: 0.7526 - val_loss: 1.0873 - val_acc: 0.7376\n",
      "Epoch 837/2000\n",
      " - 1s - loss: 0.6225 - acc: 0.7752 - val_loss: 1.0834 - val_acc: 0.7172\n",
      "Epoch 838/2000\n",
      " - 1s - loss: 0.6232 - acc: 0.7825 - val_loss: 1.0810 - val_acc: 0.7085\n",
      "Epoch 839/2000\n",
      " - 1s - loss: 0.7238 - acc: 0.7584 - val_loss: 1.3016 - val_acc: 0.6589\n",
      "Epoch 840/2000\n",
      " - 1s - loss: 0.7231 - acc: 0.7482 - val_loss: 1.1766 - val_acc: 0.7143\n",
      "Epoch 841/2000\n",
      " - 1s - loss: 0.6152 - acc: 0.7854 - val_loss: 1.1534 - val_acc: 0.7376\n",
      "Epoch 842/2000\n",
      " - 1s - loss: 0.6540 - acc: 0.7489 - val_loss: 1.1010 - val_acc: 0.7026\n",
      "Epoch 843/2000\n",
      " - 1s - loss: 0.7133 - acc: 0.7628 - val_loss: 1.2935 - val_acc: 0.6968\n",
      "Epoch 844/2000\n",
      " - 1s - loss: 0.6720 - acc: 0.7555 - val_loss: 1.2909 - val_acc: 0.7085\n",
      "Epoch 845/2000\n",
      " - 1s - loss: 0.6316 - acc: 0.7569 - val_loss: 1.1037 - val_acc: 0.6997\n",
      "Epoch 846/2000\n",
      " - 1s - loss: 0.5894 - acc: 0.7869 - val_loss: 1.1674 - val_acc: 0.7143\n",
      "Epoch 847/2000\n",
      " - 1s - loss: 0.6560 - acc: 0.7672 - val_loss: 1.1369 - val_acc: 0.7143\n",
      "Epoch 848/2000\n",
      " - 1s - loss: 0.7050 - acc: 0.7562 - val_loss: 1.2026 - val_acc: 0.7085\n",
      "Epoch 849/2000\n",
      " - 1s - loss: 0.6258 - acc: 0.7606 - val_loss: 1.1195 - val_acc: 0.7318\n",
      "Epoch 850/2000\n",
      " - 1s - loss: 0.6058 - acc: 0.7847 - val_loss: 1.1509 - val_acc: 0.7114\n",
      "Epoch 851/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6286 - acc: 0.7869 - val_loss: 1.2850 - val_acc: 0.6880\n",
      "Epoch 852/2000\n",
      " - 1s - loss: 0.6725 - acc: 0.7540 - val_loss: 1.2210 - val_acc: 0.7230\n",
      "Epoch 853/2000\n",
      " - 1s - loss: 0.7590 - acc: 0.7387 - val_loss: 1.2924 - val_acc: 0.6939\n",
      "Epoch 854/2000\n",
      " - 1s - loss: 0.6769 - acc: 0.7540 - val_loss: 1.0594 - val_acc: 0.7172\n",
      "Epoch 855/2000\n",
      " - 1s - loss: 0.6827 - acc: 0.7584 - val_loss: 1.1416 - val_acc: 0.7143\n",
      "Epoch 856/2000\n",
      " - 1s - loss: 0.6200 - acc: 0.7730 - val_loss: 1.2396 - val_acc: 0.6968\n",
      "Epoch 857/2000\n",
      " - 1s - loss: 0.6902 - acc: 0.7628 - val_loss: 1.2939 - val_acc: 0.7026\n",
      "Epoch 858/2000\n",
      " - 1s - loss: 0.6475 - acc: 0.7745 - val_loss: 1.1543 - val_acc: 0.7230\n",
      "Epoch 859/2000\n",
      " - 1s - loss: 0.6265 - acc: 0.7672 - val_loss: 1.1096 - val_acc: 0.7143\n",
      "Epoch 860/2000\n",
      " - 0s - loss: 0.5910 - acc: 0.7788 - val_loss: 1.1456 - val_acc: 0.7230\n",
      "Epoch 861/2000\n",
      " - 1s - loss: 0.5938 - acc: 0.7993 - val_loss: 1.1279 - val_acc: 0.7143\n",
      "Epoch 862/2000\n",
      " - 1s - loss: 0.5720 - acc: 0.8015 - val_loss: 1.2049 - val_acc: 0.7055\n",
      "Epoch 863/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7891 - val_loss: 1.2742 - val_acc: 0.7172\n",
      "Epoch 864/2000\n",
      " - 1s - loss: 0.5837 - acc: 0.7978 - val_loss: 1.2513 - val_acc: 0.6910\n",
      "Epoch 865/2000\n",
      " - 1s - loss: 0.5845 - acc: 0.7942 - val_loss: 1.1589 - val_acc: 0.7026\n",
      "Epoch 866/2000\n",
      " - 1s - loss: 0.6039 - acc: 0.7839 - val_loss: 1.1208 - val_acc: 0.7318\n",
      "Epoch 867/2000\n",
      " - 1s - loss: 0.6723 - acc: 0.7628 - val_loss: 1.1557 - val_acc: 0.7259\n",
      "Epoch 868/2000\n",
      " - 1s - loss: 0.6758 - acc: 0.7526 - val_loss: 1.1716 - val_acc: 0.7259\n",
      "Epoch 869/2000\n",
      " - 1s - loss: 0.5951 - acc: 0.7861 - val_loss: 1.1491 - val_acc: 0.7376\n",
      "Epoch 870/2000\n",
      " - 1s - loss: 0.7280 - acc: 0.7599 - val_loss: 1.3479 - val_acc: 0.6764\n",
      "Epoch 871/2000\n",
      " - 1s - loss: 0.8714 - acc: 0.7015 - val_loss: 1.1703 - val_acc: 0.6997\n",
      "Epoch 872/2000\n",
      " - 1s - loss: 0.7578 - acc: 0.7234 - val_loss: 1.1056 - val_acc: 0.7085\n",
      "Epoch 873/2000\n",
      " - 1s - loss: 0.7305 - acc: 0.7569 - val_loss: 1.2087 - val_acc: 0.7201\n",
      "Epoch 874/2000\n",
      " - 1s - loss: 0.6481 - acc: 0.7781 - val_loss: 1.1253 - val_acc: 0.7289\n",
      "Epoch 875/2000\n",
      " - 1s - loss: 0.5826 - acc: 0.7905 - val_loss: 1.1412 - val_acc: 0.7055\n",
      "Epoch 876/2000\n",
      " - 1s - loss: 0.5841 - acc: 0.7920 - val_loss: 1.1315 - val_acc: 0.7347\n",
      "Epoch 877/2000\n",
      " - 1s - loss: 0.6215 - acc: 0.7679 - val_loss: 1.1289 - val_acc: 0.7347\n",
      "Epoch 878/2000\n",
      " - 1s - loss: 0.6008 - acc: 0.7891 - val_loss: 1.2082 - val_acc: 0.7201\n",
      "Epoch 879/2000\n",
      " - 1s - loss: 0.5879 - acc: 0.7847 - val_loss: 1.1950 - val_acc: 0.7259\n",
      "Epoch 880/2000\n",
      " - 1s - loss: 0.6461 - acc: 0.7664 - val_loss: 1.2203 - val_acc: 0.7085\n",
      "Epoch 881/2000\n",
      " - 1s - loss: 0.6056 - acc: 0.7912 - val_loss: 1.3515 - val_acc: 0.6647\n",
      "Epoch 882/2000\n",
      " - 1s - loss: 0.6086 - acc: 0.7730 - val_loss: 1.2543 - val_acc: 0.6910\n",
      "Epoch 883/2000\n",
      " - 1s - loss: 0.6039 - acc: 0.7679 - val_loss: 1.2194 - val_acc: 0.7114\n",
      "Epoch 884/2000\n",
      " - 1s - loss: 0.6098 - acc: 0.7876 - val_loss: 1.3112 - val_acc: 0.7055\n",
      "Epoch 885/2000\n",
      " - 1s - loss: 0.6104 - acc: 0.7985 - val_loss: 1.2420 - val_acc: 0.7289\n",
      "Epoch 886/2000\n",
      " - 1s - loss: 0.6300 - acc: 0.7679 - val_loss: 1.1854 - val_acc: 0.6997\n",
      "Epoch 887/2000\n",
      " - 1s - loss: 0.6717 - acc: 0.7547 - val_loss: 1.1750 - val_acc: 0.7114\n",
      "Epoch 888/2000\n",
      " - 1s - loss: 0.6752 - acc: 0.7584 - val_loss: 1.1922 - val_acc: 0.7143\n",
      "Epoch 889/2000\n",
      " - 1s - loss: 0.7096 - acc: 0.7518 - val_loss: 1.1083 - val_acc: 0.7055\n",
      "Epoch 890/2000\n",
      " - 1s - loss: 0.7010 - acc: 0.7416 - val_loss: 1.1345 - val_acc: 0.7143\n",
      "Epoch 891/2000\n",
      " - 1s - loss: 0.6273 - acc: 0.7715 - val_loss: 1.1845 - val_acc: 0.7230\n",
      "Epoch 892/2000\n",
      " - 1s - loss: 0.6231 - acc: 0.7847 - val_loss: 1.2023 - val_acc: 0.7201\n",
      "Epoch 893/2000\n",
      " - 0s - loss: 0.5992 - acc: 0.7861 - val_loss: 1.2322 - val_acc: 0.7201\n",
      "Epoch 894/2000\n",
      " - 1s - loss: 0.6745 - acc: 0.7569 - val_loss: 1.1797 - val_acc: 0.7230\n",
      "Epoch 895/2000\n",
      " - 1s - loss: 0.7048 - acc: 0.7591 - val_loss: 1.1644 - val_acc: 0.6997\n",
      "Epoch 896/2000\n",
      " - 1s - loss: 0.6586 - acc: 0.7788 - val_loss: 1.3363 - val_acc: 0.6968\n",
      "Epoch 897/2000\n",
      " - 1s - loss: 0.6454 - acc: 0.7715 - val_loss: 1.1118 - val_acc: 0.7289\n",
      "Epoch 898/2000\n",
      " - 0s - loss: 0.5868 - acc: 0.7839 - val_loss: 1.1703 - val_acc: 0.7143\n",
      "Epoch 899/2000\n",
      " - 1s - loss: 0.6302 - acc: 0.7737 - val_loss: 1.3155 - val_acc: 0.7026\n",
      "Epoch 900/2000\n",
      " - 1s - loss: 0.6692 - acc: 0.7898 - val_loss: 1.2192 - val_acc: 0.6822\n",
      "Epoch 901/2000\n",
      " - 1s - loss: 0.6526 - acc: 0.7613 - val_loss: 1.2520 - val_acc: 0.6968\n",
      "Epoch 902/2000\n",
      " - 1s - loss: 0.6299 - acc: 0.7679 - val_loss: 1.1288 - val_acc: 0.6997\n",
      "Epoch 903/2000\n",
      " - 1s - loss: 0.5986 - acc: 0.7883 - val_loss: 1.1936 - val_acc: 0.7259\n",
      "Epoch 904/2000\n",
      " - 1s - loss: 0.6435 - acc: 0.7723 - val_loss: 1.1961 - val_acc: 0.7259\n",
      "Epoch 905/2000\n",
      " - 1s - loss: 0.6768 - acc: 0.7628 - val_loss: 1.1690 - val_acc: 0.7201\n",
      "Epoch 906/2000\n",
      " - 1s - loss: 0.6897 - acc: 0.7591 - val_loss: 1.1409 - val_acc: 0.7201\n",
      "Epoch 907/2000\n",
      " - 1s - loss: 0.6325 - acc: 0.7737 - val_loss: 1.1529 - val_acc: 0.7289\n",
      "Epoch 908/2000\n",
      " - 1s - loss: 0.6101 - acc: 0.7883 - val_loss: 1.2907 - val_acc: 0.7172\n",
      "Epoch 909/2000\n",
      " - 1s - loss: 0.5868 - acc: 0.8066 - val_loss: 1.1623 - val_acc: 0.7289\n",
      "Epoch 910/2000\n",
      " - 1s - loss: 0.6287 - acc: 0.7869 - val_loss: 1.1605 - val_acc: 0.7201\n",
      "Epoch 911/2000\n",
      " - 1s - loss: 0.6230 - acc: 0.7803 - val_loss: 1.1881 - val_acc: 0.7055\n",
      "Epoch 912/2000\n",
      " - 1s - loss: 0.5936 - acc: 0.7876 - val_loss: 1.2639 - val_acc: 0.7085\n",
      "Epoch 913/2000\n",
      " - 1s - loss: 0.5850 - acc: 0.8007 - val_loss: 1.1350 - val_acc: 0.7143\n",
      "Epoch 914/2000\n",
      " - 1s - loss: 0.6183 - acc: 0.7796 - val_loss: 1.1802 - val_acc: 0.7085\n",
      "Epoch 915/2000\n",
      " - 1s - loss: 0.7573 - acc: 0.7365 - val_loss: 1.1501 - val_acc: 0.7230\n",
      "Epoch 916/2000\n",
      " - 1s - loss: 0.7608 - acc: 0.7482 - val_loss: 1.2580 - val_acc: 0.6997\n",
      "Epoch 917/2000\n",
      " - 1s - loss: 0.6523 - acc: 0.7635 - val_loss: 1.0983 - val_acc: 0.7434\n",
      "Epoch 918/2000\n",
      " - 1s - loss: 0.6485 - acc: 0.7642 - val_loss: 1.1459 - val_acc: 0.7201\n",
      "Epoch 919/2000\n",
      " - 1s - loss: 0.6221 - acc: 0.7891 - val_loss: 1.1560 - val_acc: 0.7085\n",
      "Epoch 920/2000\n",
      " - 1s - loss: 0.6031 - acc: 0.7832 - val_loss: 1.2465 - val_acc: 0.6968\n",
      "Epoch 921/2000\n",
      " - 1s - loss: 0.6906 - acc: 0.7664 - val_loss: 1.1096 - val_acc: 0.7464\n",
      "Epoch 922/2000\n",
      " - 1s - loss: 0.6810 - acc: 0.7504 - val_loss: 1.1161 - val_acc: 0.7347\n",
      "Epoch 923/2000\n",
      " - 1s - loss: 0.6436 - acc: 0.7672 - val_loss: 1.1780 - val_acc: 0.7055\n",
      "Epoch 924/2000\n",
      " - 1s - loss: 0.6025 - acc: 0.7832 - val_loss: 1.1323 - val_acc: 0.7318\n",
      "Epoch 925/2000\n",
      " - 0s - loss: 0.6171 - acc: 0.7818 - val_loss: 1.1196 - val_acc: 0.7172\n",
      "Epoch 926/2000\n",
      " - 1s - loss: 0.5683 - acc: 0.7934 - val_loss: 1.1508 - val_acc: 0.7143\n",
      "Epoch 927/2000\n",
      " - 1s - loss: 0.6019 - acc: 0.7818 - val_loss: 1.1887 - val_acc: 0.7201\n",
      "Epoch 928/2000\n",
      " - 1s - loss: 0.6220 - acc: 0.7788 - val_loss: 1.1561 - val_acc: 0.7172\n",
      "Epoch 929/2000\n",
      " - 1s - loss: 0.6211 - acc: 0.7752 - val_loss: 1.1333 - val_acc: 0.7405\n",
      "Epoch 930/2000\n",
      " - 1s - loss: 0.5846 - acc: 0.7971 - val_loss: 1.2399 - val_acc: 0.7114\n",
      "Epoch 931/2000\n",
      " - 1s - loss: 0.5925 - acc: 0.7905 - val_loss: 1.1743 - val_acc: 0.7289\n",
      "Epoch 932/2000\n",
      " - 1s - loss: 0.6015 - acc: 0.7832 - val_loss: 1.1387 - val_acc: 0.6968\n",
      "Epoch 933/2000\n",
      " - 1s - loss: 0.6377 - acc: 0.7832 - val_loss: 1.3040 - val_acc: 0.7055\n",
      "Epoch 934/2000\n",
      " - 1s - loss: 0.6731 - acc: 0.7482 - val_loss: 1.2909 - val_acc: 0.7055\n",
      "Epoch 935/2000\n",
      " - 1s - loss: 0.7684 - acc: 0.7350 - val_loss: 1.2184 - val_acc: 0.7055\n",
      "Epoch 936/2000\n",
      " - 1s - loss: 0.6901 - acc: 0.7650 - val_loss: 1.2529 - val_acc: 0.6880\n",
      "Epoch 937/2000\n",
      " - 1s - loss: 0.6153 - acc: 0.7759 - val_loss: 1.1821 - val_acc: 0.6997\n",
      "Epoch 938/2000\n",
      " - 1s - loss: 0.6514 - acc: 0.7759 - val_loss: 1.0693 - val_acc: 0.7347\n",
      "Epoch 939/2000\n",
      " - 1s - loss: 0.5860 - acc: 0.7861 - val_loss: 1.1805 - val_acc: 0.7405\n",
      "Epoch 940/2000\n",
      " - 1s - loss: 0.7860 - acc: 0.7380 - val_loss: 1.2659 - val_acc: 0.6735\n",
      "Epoch 941/2000\n",
      " - 2s - loss: 0.6483 - acc: 0.7810 - val_loss: 1.1357 - val_acc: 0.7230\n",
      "Epoch 942/2000\n",
      " - 2s - loss: 0.6353 - acc: 0.7693 - val_loss: 1.1820 - val_acc: 0.7172\n",
      "Epoch 943/2000\n",
      " - 1s - loss: 0.6995 - acc: 0.7599 - val_loss: 1.1435 - val_acc: 0.6910\n",
      "Epoch 944/2000\n",
      " - 1s - loss: 0.5847 - acc: 0.7788 - val_loss: 1.1683 - val_acc: 0.7259\n",
      "Epoch 945/2000\n",
      " - 1s - loss: 0.6135 - acc: 0.7825 - val_loss: 1.1723 - val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/2000\n",
      " - 1s - loss: 0.5617 - acc: 0.8175 - val_loss: 1.1919 - val_acc: 0.7259\n",
      "Epoch 947/2000\n",
      " - 1s - loss: 0.7088 - acc: 0.7496 - val_loss: 1.2026 - val_acc: 0.6968\n",
      "Epoch 948/2000\n",
      " - 1s - loss: 0.7853 - acc: 0.7372 - val_loss: 1.2910 - val_acc: 0.6793\n",
      "Epoch 949/2000\n",
      " - 1s - loss: 0.8445 - acc: 0.7029 - val_loss: 1.1138 - val_acc: 0.7055\n",
      "Epoch 950/2000\n",
      " - 1s - loss: 0.6472 - acc: 0.7620 - val_loss: 1.0937 - val_acc: 0.7085\n",
      "Epoch 951/2000\n",
      " - 1s - loss: 0.6265 - acc: 0.7781 - val_loss: 1.2401 - val_acc: 0.6910\n",
      "Epoch 952/2000\n",
      " - 1s - loss: 0.6215 - acc: 0.7723 - val_loss: 1.1846 - val_acc: 0.6939\n",
      "Epoch 953/2000\n",
      " - 1s - loss: 0.6636 - acc: 0.7664 - val_loss: 1.0762 - val_acc: 0.7114\n",
      "Epoch 954/2000\n",
      " - 1s - loss: 0.6058 - acc: 0.7730 - val_loss: 1.1209 - val_acc: 0.7259\n",
      "Epoch 955/2000\n",
      " - 1s - loss: 0.5908 - acc: 0.7949 - val_loss: 1.1440 - val_acc: 0.7114\n",
      "Epoch 956/2000\n",
      " - 1s - loss: 0.6194 - acc: 0.7759 - val_loss: 1.1932 - val_acc: 0.6997\n",
      "Epoch 957/2000\n",
      " - 1s - loss: 0.6230 - acc: 0.7810 - val_loss: 1.1927 - val_acc: 0.7055\n",
      "Epoch 958/2000\n",
      " - 1s - loss: 0.6116 - acc: 0.7693 - val_loss: 1.1550 - val_acc: 0.7230\n",
      "Epoch 959/2000\n",
      " - 1s - loss: 0.6197 - acc: 0.7730 - val_loss: 1.1319 - val_acc: 0.7347\n",
      "Epoch 960/2000\n",
      " - 1s - loss: 0.6213 - acc: 0.7737 - val_loss: 1.2836 - val_acc: 0.6968\n",
      "Epoch 961/2000\n",
      " - 1s - loss: 0.6218 - acc: 0.7803 - val_loss: 1.0884 - val_acc: 0.7114\n",
      "Epoch 962/2000\n",
      " - 1s - loss: 0.6051 - acc: 0.7810 - val_loss: 1.1290 - val_acc: 0.7085\n",
      "Epoch 963/2000\n",
      " - 1s - loss: 0.6063 - acc: 0.7745 - val_loss: 1.1808 - val_acc: 0.7289\n",
      "Epoch 964/2000\n",
      " - 1s - loss: 0.6249 - acc: 0.7759 - val_loss: 1.1785 - val_acc: 0.7405\n",
      "Epoch 965/2000\n",
      " - 1s - loss: 0.6678 - acc: 0.7584 - val_loss: 1.1968 - val_acc: 0.7026\n",
      "Epoch 966/2000\n",
      " - 1s - loss: 0.6125 - acc: 0.7898 - val_loss: 1.1126 - val_acc: 0.7347\n",
      "Epoch 967/2000\n",
      " - 0s - loss: 0.6164 - acc: 0.7766 - val_loss: 1.2791 - val_acc: 0.6851\n",
      "Epoch 968/2000\n",
      " - 0s - loss: 0.7717 - acc: 0.7453 - val_loss: 1.3205 - val_acc: 0.6822\n",
      "Epoch 969/2000\n",
      " - 0s - loss: 0.7551 - acc: 0.7467 - val_loss: 1.1897 - val_acc: 0.7172\n",
      "Epoch 970/2000\n",
      " - 0s - loss: 0.5961 - acc: 0.7985 - val_loss: 1.1930 - val_acc: 0.7201\n",
      "Epoch 971/2000\n",
      " - 0s - loss: 0.5951 - acc: 0.7927 - val_loss: 1.1393 - val_acc: 0.7259\n",
      "Epoch 972/2000\n",
      " - 1s - loss: 0.5636 - acc: 0.7978 - val_loss: 1.2300 - val_acc: 0.6997\n",
      "Epoch 973/2000\n",
      " - 1s - loss: 0.6138 - acc: 0.7847 - val_loss: 1.2730 - val_acc: 0.7143\n",
      "Epoch 974/2000\n",
      " - 1s - loss: 0.5732 - acc: 0.7934 - val_loss: 1.2116 - val_acc: 0.7143\n",
      "Epoch 975/2000\n",
      " - 1s - loss: 0.8254 - acc: 0.7321 - val_loss: 1.3421 - val_acc: 0.6618\n",
      "Epoch 976/2000\n",
      " - 1s - loss: 0.7819 - acc: 0.7438 - val_loss: 1.1419 - val_acc: 0.7114\n",
      "Epoch 977/2000\n",
      " - 1s - loss: 0.6940 - acc: 0.7650 - val_loss: 1.0890 - val_acc: 0.7376\n",
      "Epoch 978/2000\n",
      " - 1s - loss: 0.7218 - acc: 0.7555 - val_loss: 1.1979 - val_acc: 0.6764\n",
      "Epoch 979/2000\n",
      " - 1s - loss: 0.6898 - acc: 0.7474 - val_loss: 1.1630 - val_acc: 0.7143\n",
      "Epoch 980/2000\n",
      " - 1s - loss: 0.6244 - acc: 0.7861 - val_loss: 1.1735 - val_acc: 0.7230\n",
      "Epoch 981/2000\n",
      " - 1s - loss: 0.5965 - acc: 0.7796 - val_loss: 1.1682 - val_acc: 0.7085\n",
      "Epoch 982/2000\n",
      " - 1s - loss: 0.5815 - acc: 0.7949 - val_loss: 1.2082 - val_acc: 0.7172\n",
      "Epoch 983/2000\n",
      " - 1s - loss: 0.5878 - acc: 0.7847 - val_loss: 1.1693 - val_acc: 0.7376\n",
      "Epoch 984/2000\n",
      " - 1s - loss: 0.6074 - acc: 0.7891 - val_loss: 1.1427 - val_acc: 0.7230\n",
      "Epoch 985/2000\n",
      " - 1s - loss: 0.6261 - acc: 0.7854 - val_loss: 1.1268 - val_acc: 0.7230\n",
      "Epoch 986/2000\n",
      " - 1s - loss: 0.5970 - acc: 0.7781 - val_loss: 1.1561 - val_acc: 0.7201\n",
      "Epoch 987/2000\n",
      " - 1s - loss: 0.5909 - acc: 0.7883 - val_loss: 1.1995 - val_acc: 0.7230\n",
      "Epoch 988/2000\n",
      " - 1s - loss: 0.6276 - acc: 0.7693 - val_loss: 1.2949 - val_acc: 0.6851\n",
      "Epoch 989/2000\n",
      " - 1s - loss: 0.6450 - acc: 0.7825 - val_loss: 1.1812 - val_acc: 0.7085\n",
      "Epoch 990/2000\n",
      " - 1s - loss: 0.7320 - acc: 0.7431 - val_loss: 1.2911 - val_acc: 0.6939\n",
      "Epoch 991/2000\n",
      " - 1s - loss: 0.7887 - acc: 0.7409 - val_loss: 1.3900 - val_acc: 0.6531\n",
      "Epoch 992/2000\n",
      " - 1s - loss: 0.7450 - acc: 0.7409 - val_loss: 1.1481 - val_acc: 0.7347\n",
      "Epoch 993/2000\n",
      " - 0s - loss: 0.6824 - acc: 0.7664 - val_loss: 1.1490 - val_acc: 0.7085\n",
      "Epoch 994/2000\n",
      " - 1s - loss: 0.7226 - acc: 0.7518 - val_loss: 1.1618 - val_acc: 0.6939\n",
      "Epoch 995/2000\n",
      " - 1s - loss: 0.6215 - acc: 0.7796 - val_loss: 1.1163 - val_acc: 0.7347\n",
      "Epoch 996/2000\n",
      " - 1s - loss: 0.5463 - acc: 0.7956 - val_loss: 1.1604 - val_acc: 0.7230\n",
      "Epoch 997/2000\n",
      " - 1s - loss: 0.6009 - acc: 0.7912 - val_loss: 1.1267 - val_acc: 0.7230\n",
      "Epoch 998/2000\n",
      " - 1s - loss: 0.5653 - acc: 0.7883 - val_loss: 1.2275 - val_acc: 0.7085\n",
      "Epoch 999/2000\n",
      " - 1s - loss: 0.5664 - acc: 0.7978 - val_loss: 1.1448 - val_acc: 0.7114\n",
      "Epoch 1000/2000\n",
      " - 1s - loss: 0.6468 - acc: 0.7577 - val_loss: 1.2772 - val_acc: 0.6968\n",
      "Epoch 1001/2000\n",
      " - 1s - loss: 0.5644 - acc: 0.7949 - val_loss: 1.1960 - val_acc: 0.7026\n",
      "Epoch 1002/2000\n",
      " - 1s - loss: 0.6084 - acc: 0.7861 - val_loss: 1.1640 - val_acc: 0.7143\n",
      "Epoch 1003/2000\n",
      " - 1s - loss: 0.6233 - acc: 0.7693 - val_loss: 1.3131 - val_acc: 0.6939\n",
      "Epoch 1004/2000\n",
      " - 1s - loss: 0.6737 - acc: 0.7708 - val_loss: 1.2233 - val_acc: 0.7085\n",
      "Epoch 1005/2000\n",
      " - 0s - loss: 0.6994 - acc: 0.7657 - val_loss: 1.2366 - val_acc: 0.6997\n",
      "Epoch 1006/2000\n",
      " - 1s - loss: 0.6334 - acc: 0.7788 - val_loss: 1.3855 - val_acc: 0.6822\n",
      "Epoch 1007/2000\n",
      " - 1s - loss: 0.6841 - acc: 0.7613 - val_loss: 1.2788 - val_acc: 0.6939\n",
      "Epoch 1008/2000\n",
      " - 1s - loss: 0.6921 - acc: 0.7504 - val_loss: 1.1969 - val_acc: 0.7143\n",
      "Epoch 1009/2000\n",
      " - 1s - loss: 0.7036 - acc: 0.7540 - val_loss: 1.1829 - val_acc: 0.7026\n",
      "Epoch 1010/2000\n",
      " - 1s - loss: 0.7257 - acc: 0.7482 - val_loss: 1.0921 - val_acc: 0.7114\n",
      "Epoch 1011/2000\n",
      " - 1s - loss: 0.6818 - acc: 0.7650 - val_loss: 1.0764 - val_acc: 0.7201\n",
      "Epoch 1012/2000\n",
      " - 1s - loss: 0.5769 - acc: 0.8058 - val_loss: 1.2064 - val_acc: 0.7026\n",
      "Epoch 1013/2000\n",
      " - 1s - loss: 0.6161 - acc: 0.7774 - val_loss: 1.1462 - val_acc: 0.7085\n",
      "Epoch 1014/2000\n",
      " - 1s - loss: 0.6148 - acc: 0.7737 - val_loss: 1.1201 - val_acc: 0.7347\n",
      "Epoch 1015/2000\n",
      " - 1s - loss: 0.6238 - acc: 0.7766 - val_loss: 1.1915 - val_acc: 0.7230\n",
      "Epoch 1016/2000\n",
      " - 1s - loss: 0.6092 - acc: 0.7861 - val_loss: 1.1855 - val_acc: 0.7114\n",
      "Epoch 1017/2000\n",
      " - 1s - loss: 0.5633 - acc: 0.7978 - val_loss: 1.2111 - val_acc: 0.7230\n",
      "Epoch 1018/2000\n",
      " - 0s - loss: 0.5893 - acc: 0.7971 - val_loss: 1.1371 - val_acc: 0.7318\n",
      "Epoch 1019/2000\n",
      " - 0s - loss: 0.7158 - acc: 0.7504 - val_loss: 1.2418 - val_acc: 0.6997\n",
      "Epoch 1020/2000\n",
      " - 1s - loss: 0.7334 - acc: 0.7511 - val_loss: 1.1757 - val_acc: 0.7318\n",
      "Epoch 1021/2000\n",
      " - 1s - loss: 0.6880 - acc: 0.7526 - val_loss: 1.2266 - val_acc: 0.7172\n",
      "Epoch 1022/2000\n",
      " - 0s - loss: 0.6113 - acc: 0.7839 - val_loss: 1.2889 - val_acc: 0.6910\n",
      "Epoch 1023/2000\n",
      " - 0s - loss: 0.6254 - acc: 0.7810 - val_loss: 1.2455 - val_acc: 0.7201\n",
      "Epoch 1024/2000\n",
      " - 1s - loss: 0.6510 - acc: 0.7708 - val_loss: 1.1726 - val_acc: 0.7172\n",
      "Epoch 1025/2000\n",
      " - 1s - loss: 0.6114 - acc: 0.7869 - val_loss: 1.1039 - val_acc: 0.7172\n",
      "Epoch 1026/2000\n",
      " - 1s - loss: 0.5915 - acc: 0.7832 - val_loss: 1.1534 - val_acc: 0.7085\n",
      "Epoch 1027/2000\n",
      " - 1s - loss: 0.5665 - acc: 0.8029 - val_loss: 1.2075 - val_acc: 0.7201\n",
      "Epoch 1028/2000\n",
      " - 0s - loss: 0.5915 - acc: 0.7920 - val_loss: 1.2480 - val_acc: 0.7143\n",
      "Epoch 1029/2000\n",
      " - 1s - loss: 0.5698 - acc: 0.8015 - val_loss: 1.1199 - val_acc: 0.7172\n",
      "Epoch 1030/2000\n",
      " - 0s - loss: 0.5929 - acc: 0.7854 - val_loss: 1.1892 - val_acc: 0.7114\n",
      "Epoch 1031/2000\n",
      " - 0s - loss: 0.6064 - acc: 0.7854 - val_loss: 1.2058 - val_acc: 0.7143\n",
      "Epoch 1032/2000\n",
      " - 1s - loss: 0.6215 - acc: 0.7752 - val_loss: 1.1662 - val_acc: 0.7230\n",
      "Epoch 1033/2000\n",
      " - 1s - loss: 0.6740 - acc: 0.7796 - val_loss: 1.3791 - val_acc: 0.6501\n",
      "Epoch 1034/2000\n",
      " - 1s - loss: 0.7972 - acc: 0.7292 - val_loss: 1.2417 - val_acc: 0.7055\n",
      "Epoch 1035/2000\n",
      " - 1s - loss: 0.6518 - acc: 0.7642 - val_loss: 1.2712 - val_acc: 0.6939\n",
      "Epoch 1036/2000\n",
      " - 1s - loss: 0.6066 - acc: 0.8007 - val_loss: 1.1996 - val_acc: 0.7085\n",
      "Epoch 1037/2000\n",
      " - 1s - loss: 0.6198 - acc: 0.7876 - val_loss: 1.1578 - val_acc: 0.7464\n",
      "Epoch 1038/2000\n",
      " - 1s - loss: 0.6536 - acc: 0.7679 - val_loss: 1.2119 - val_acc: 0.6968\n",
      "Epoch 1039/2000\n",
      " - 1s - loss: 0.6410 - acc: 0.7796 - val_loss: 1.2247 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2000\n",
      " - 1s - loss: 0.6727 - acc: 0.7657 - val_loss: 1.1714 - val_acc: 0.7055\n",
      "Epoch 1041/2000\n",
      " - 1s - loss: 0.6150 - acc: 0.7869 - val_loss: 1.1802 - val_acc: 0.7085\n",
      "Epoch 1042/2000\n",
      " - 1s - loss: 0.5921 - acc: 0.7883 - val_loss: 1.1836 - val_acc: 0.7085\n",
      "Epoch 1043/2000\n",
      " - 0s - loss: 0.6632 - acc: 0.7606 - val_loss: 1.2345 - val_acc: 0.6851\n",
      "Epoch 1044/2000\n",
      " - 0s - loss: 0.6533 - acc: 0.7796 - val_loss: 1.2270 - val_acc: 0.6910\n",
      "Epoch 1045/2000\n",
      " - 1s - loss: 0.6147 - acc: 0.7752 - val_loss: 1.2046 - val_acc: 0.7172\n",
      "Epoch 1046/2000\n",
      " - 1s - loss: 0.5727 - acc: 0.8022 - val_loss: 1.2636 - val_acc: 0.7201\n",
      "Epoch 1047/2000\n",
      " - 1s - loss: 0.5903 - acc: 0.7861 - val_loss: 1.2617 - val_acc: 0.7172\n",
      "Epoch 1048/2000\n",
      " - 0s - loss: 0.6483 - acc: 0.7635 - val_loss: 1.1953 - val_acc: 0.6968\n",
      "Epoch 1049/2000\n",
      " - 1s - loss: 0.6027 - acc: 0.7752 - val_loss: 1.1564 - val_acc: 0.7143\n",
      "Epoch 1050/2000\n",
      " - 1s - loss: 0.6173 - acc: 0.7810 - val_loss: 1.1660 - val_acc: 0.7143\n",
      "Epoch 1051/2000\n",
      " - 1s - loss: 0.6551 - acc: 0.7715 - val_loss: 1.5904 - val_acc: 0.6297\n",
      "Epoch 1052/2000\n",
      " - 1s - loss: 0.9823 - acc: 0.6825 - val_loss: 1.2205 - val_acc: 0.6764\n",
      "Epoch 1053/2000\n",
      " - 1s - loss: 0.7443 - acc: 0.7453 - val_loss: 1.1068 - val_acc: 0.7201\n",
      "Epoch 1054/2000\n",
      " - 1s - loss: 0.6135 - acc: 0.7803 - val_loss: 1.1657 - val_acc: 0.6910\n",
      "Epoch 1055/2000\n",
      " - 1s - loss: 0.6113 - acc: 0.7810 - val_loss: 1.1526 - val_acc: 0.7172\n",
      "Epoch 1056/2000\n",
      " - 1s - loss: 0.5958 - acc: 0.7861 - val_loss: 1.1216 - val_acc: 0.7055\n",
      "Epoch 1057/2000\n",
      " - 2s - loss: 0.5686 - acc: 0.7861 - val_loss: 1.1183 - val_acc: 0.7230\n",
      "Epoch 1058/2000\n",
      " - 2s - loss: 0.5917 - acc: 0.7964 - val_loss: 1.1154 - val_acc: 0.7318\n",
      "Epoch 1059/2000\n",
      " - 2s - loss: 0.5592 - acc: 0.7854 - val_loss: 1.1929 - val_acc: 0.6880\n",
      "Epoch 1060/2000\n",
      " - 2s - loss: 0.5797 - acc: 0.7883 - val_loss: 1.1967 - val_acc: 0.7201\n",
      "Epoch 1061/2000\n",
      " - 2s - loss: 0.5638 - acc: 0.8051 - val_loss: 1.1702 - val_acc: 0.7143\n",
      "Epoch 1062/2000\n",
      " - 2s - loss: 0.5688 - acc: 0.7891 - val_loss: 1.1153 - val_acc: 0.7201\n",
      "Epoch 1063/2000\n",
      " - 2s - loss: 0.6557 - acc: 0.7810 - val_loss: 1.0652 - val_acc: 0.7289\n",
      "Epoch 1064/2000\n",
      " - 2s - loss: 0.6135 - acc: 0.7869 - val_loss: 1.1838 - val_acc: 0.7143\n",
      "Epoch 1065/2000\n",
      " - 2s - loss: 0.5483 - acc: 0.8000 - val_loss: 1.1915 - val_acc: 0.7114\n",
      "Epoch 1066/2000\n",
      " - 2s - loss: 0.6486 - acc: 0.7628 - val_loss: 1.2023 - val_acc: 0.7259\n",
      "Epoch 1067/2000\n",
      " - 1s - loss: 0.6483 - acc: 0.7825 - val_loss: 1.1756 - val_acc: 0.6968\n",
      "Epoch 1068/2000\n",
      " - 1s - loss: 0.6538 - acc: 0.7599 - val_loss: 1.2042 - val_acc: 0.7201\n",
      "Epoch 1069/2000\n",
      " - 2s - loss: 0.7589 - acc: 0.7401 - val_loss: 1.3272 - val_acc: 0.6735\n",
      "Epoch 1070/2000\n",
      " - 2s - loss: 0.7241 - acc: 0.7555 - val_loss: 1.1029 - val_acc: 0.7434\n",
      "Epoch 1071/2000\n",
      " - 2s - loss: 0.6426 - acc: 0.7672 - val_loss: 1.2262 - val_acc: 0.6822\n",
      "Epoch 1072/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7825 - val_loss: 1.1409 - val_acc: 0.7055\n",
      "Epoch 1073/2000\n",
      " - 1s - loss: 0.6187 - acc: 0.7759 - val_loss: 1.2977 - val_acc: 0.6851\n",
      "Epoch 1074/2000\n",
      " - 1s - loss: 0.6658 - acc: 0.7555 - val_loss: 1.2886 - val_acc: 0.6880\n",
      "Epoch 1075/2000\n",
      " - 1s - loss: 0.6152 - acc: 0.7774 - val_loss: 1.1635 - val_acc: 0.7055\n",
      "Epoch 1076/2000\n",
      " - 2s - loss: 0.6178 - acc: 0.7891 - val_loss: 1.2070 - val_acc: 0.7172\n",
      "Epoch 1077/2000\n",
      " - 2s - loss: 0.6077 - acc: 0.7766 - val_loss: 1.2786 - val_acc: 0.6910\n",
      "Epoch 1078/2000\n",
      " - 2s - loss: 0.5582 - acc: 0.8029 - val_loss: 1.1603 - val_acc: 0.7230\n",
      "Epoch 1079/2000\n",
      " - 2s - loss: 0.5925 - acc: 0.7781 - val_loss: 1.2257 - val_acc: 0.6997\n",
      "Epoch 1080/2000\n",
      " - 2s - loss: 0.6038 - acc: 0.7920 - val_loss: 1.1948 - val_acc: 0.7114\n",
      "Epoch 1081/2000\n",
      " - 2s - loss: 0.6217 - acc: 0.7891 - val_loss: 1.2638 - val_acc: 0.6968\n",
      "Epoch 1082/2000\n",
      " - 2s - loss: 0.5863 - acc: 0.7891 - val_loss: 1.1500 - val_acc: 0.7201\n",
      "Epoch 1083/2000\n",
      " - 2s - loss: 0.6001 - acc: 0.7956 - val_loss: 1.3314 - val_acc: 0.6851\n",
      "Epoch 1084/2000\n",
      " - 2s - loss: 0.7239 - acc: 0.7453 - val_loss: 1.1584 - val_acc: 0.7085\n",
      "Epoch 1085/2000\n",
      " - 2s - loss: 0.5951 - acc: 0.7905 - val_loss: 1.1184 - val_acc: 0.7289\n",
      "Epoch 1086/2000\n",
      " - 3s - loss: 0.5743 - acc: 0.8036 - val_loss: 1.1796 - val_acc: 0.7259\n",
      "Epoch 1087/2000\n",
      " - 2s - loss: 0.5564 - acc: 0.7978 - val_loss: 1.1922 - val_acc: 0.6968\n",
      "Epoch 1088/2000\n",
      " - 2s - loss: 0.5679 - acc: 0.8000 - val_loss: 1.1806 - val_acc: 0.7085\n",
      "Epoch 1089/2000\n",
      " - 2s - loss: 0.6244 - acc: 0.7942 - val_loss: 1.2748 - val_acc: 0.7289\n",
      "Epoch 1090/2000\n",
      " - 2s - loss: 0.5760 - acc: 0.7942 - val_loss: 1.0900 - val_acc: 0.7055\n",
      "Epoch 1091/2000\n",
      " - 2s - loss: 0.6026 - acc: 0.7730 - val_loss: 1.2082 - val_acc: 0.7230\n",
      "Epoch 1092/2000\n",
      " - 2s - loss: 0.6795 - acc: 0.7635 - val_loss: 1.2323 - val_acc: 0.7114\n",
      "Epoch 1093/2000\n",
      " - 2s - loss: 0.6829 - acc: 0.7657 - val_loss: 1.2021 - val_acc: 0.7259\n",
      "Epoch 1094/2000\n",
      " - 1s - loss: 0.6894 - acc: 0.7686 - val_loss: 1.1120 - val_acc: 0.7201\n",
      "Epoch 1095/2000\n",
      " - 2s - loss: 0.5596 - acc: 0.7927 - val_loss: 1.2770 - val_acc: 0.7259\n",
      "Epoch 1096/2000\n",
      " - 1s - loss: 0.6447 - acc: 0.7657 - val_loss: 1.2378 - val_acc: 0.6997\n",
      "Epoch 1097/2000\n",
      " - 1s - loss: 0.5892 - acc: 0.7905 - val_loss: 1.2157 - val_acc: 0.7347\n",
      "Epoch 1098/2000\n",
      " - 2s - loss: 0.6216 - acc: 0.7818 - val_loss: 1.2764 - val_acc: 0.7026\n",
      "Epoch 1099/2000\n",
      " - 2s - loss: 0.6442 - acc: 0.7635 - val_loss: 1.3321 - val_acc: 0.7026\n",
      "Epoch 1100/2000\n",
      " - 2s - loss: 0.6214 - acc: 0.7672 - val_loss: 1.2763 - val_acc: 0.6939\n",
      "Epoch 1101/2000\n",
      " - 2s - loss: 0.5937 - acc: 0.7839 - val_loss: 1.2119 - val_acc: 0.7230\n",
      "Epoch 1102/2000\n",
      " - 2s - loss: 0.6143 - acc: 0.7788 - val_loss: 1.1746 - val_acc: 0.7230\n",
      "Epoch 1103/2000\n",
      " - 2s - loss: 0.5840 - acc: 0.7964 - val_loss: 1.1184 - val_acc: 0.7347\n",
      "Epoch 1104/2000\n",
      " - 2s - loss: 0.5408 - acc: 0.8015 - val_loss: 1.2268 - val_acc: 0.7201\n",
      "Epoch 1105/2000\n",
      " - 2s - loss: 0.7703 - acc: 0.7438 - val_loss: 1.2868 - val_acc: 0.6706\n",
      "Epoch 1106/2000\n",
      " - 2s - loss: 0.8780 - acc: 0.7131 - val_loss: 1.2548 - val_acc: 0.7085\n",
      "Epoch 1107/2000\n",
      " - 2s - loss: 0.7764 - acc: 0.7504 - val_loss: 1.2814 - val_acc: 0.7026\n",
      "Epoch 1108/2000\n",
      " - 2s - loss: 0.8275 - acc: 0.7212 - val_loss: 1.2922 - val_acc: 0.6647\n",
      "Epoch 1109/2000\n",
      " - 2s - loss: 0.6813 - acc: 0.7547 - val_loss: 1.1502 - val_acc: 0.7172\n",
      "Epoch 1110/2000\n",
      " - 2s - loss: 0.6047 - acc: 0.7810 - val_loss: 1.2012 - val_acc: 0.6851\n",
      "Epoch 1111/2000\n",
      " - 2s - loss: 0.5990 - acc: 0.7737 - val_loss: 1.2304 - val_acc: 0.7230\n",
      "Epoch 1112/2000\n",
      " - 2s - loss: 0.6077 - acc: 0.7905 - val_loss: 1.2590 - val_acc: 0.6939\n",
      "Epoch 1113/2000\n",
      " - 2s - loss: 0.6469 - acc: 0.7759 - val_loss: 1.1601 - val_acc: 0.7085\n",
      "Epoch 1114/2000\n",
      " - 2s - loss: 0.5561 - acc: 0.7934 - val_loss: 1.1523 - val_acc: 0.7055\n",
      "Epoch 1115/2000\n",
      " - 2s - loss: 0.5848 - acc: 0.7927 - val_loss: 1.1939 - val_acc: 0.7143\n",
      "Epoch 1116/2000\n",
      " - 2s - loss: 0.6135 - acc: 0.7869 - val_loss: 1.1689 - val_acc: 0.7114\n",
      "Epoch 1117/2000\n",
      " - 2s - loss: 0.5913 - acc: 0.7905 - val_loss: 1.1393 - val_acc: 0.6997\n",
      "Epoch 1118/2000\n",
      " - 2s - loss: 0.6055 - acc: 0.7774 - val_loss: 1.2023 - val_acc: 0.7055\n",
      "Epoch 1119/2000\n",
      " - 2s - loss: 0.7129 - acc: 0.7635 - val_loss: 1.2815 - val_acc: 0.6851\n",
      "Epoch 1120/2000\n",
      " - 2s - loss: 0.6588 - acc: 0.7635 - val_loss: 1.2535 - val_acc: 0.6997\n",
      "Epoch 1121/2000\n",
      " - 2s - loss: 0.6756 - acc: 0.7599 - val_loss: 1.0771 - val_acc: 0.7289\n",
      "Epoch 1122/2000\n",
      " - 2s - loss: 0.5975 - acc: 0.7883 - val_loss: 1.1820 - val_acc: 0.7143\n",
      "Epoch 1123/2000\n",
      " - 2s - loss: 0.5980 - acc: 0.7891 - val_loss: 1.2365 - val_acc: 0.7143\n",
      "Epoch 1124/2000\n",
      " - 2s - loss: 0.6203 - acc: 0.7891 - val_loss: 1.2058 - val_acc: 0.7230\n",
      "Epoch 1125/2000\n",
      " - 2s - loss: 0.6360 - acc: 0.7737 - val_loss: 1.1743 - val_acc: 0.7230\n",
      "Epoch 1126/2000\n",
      " - 2s - loss: 0.5941 - acc: 0.7730 - val_loss: 1.2784 - val_acc: 0.6764\n",
      "Epoch 1127/2000\n",
      " - 2s - loss: 0.5865 - acc: 0.8015 - val_loss: 1.1975 - val_acc: 0.7201\n",
      "Epoch 1128/2000\n",
      " - 2s - loss: 0.5841 - acc: 0.7912 - val_loss: 1.1576 - val_acc: 0.7289\n",
      "Epoch 1129/2000\n",
      " - 2s - loss: 0.5678 - acc: 0.7891 - val_loss: 1.3322 - val_acc: 0.6997\n",
      "Epoch 1130/2000\n",
      " - 2s - loss: 0.6135 - acc: 0.7766 - val_loss: 1.2133 - val_acc: 0.6968\n",
      "Epoch 1131/2000\n",
      " - 2s - loss: 0.6801 - acc: 0.7642 - val_loss: 1.2531 - val_acc: 0.6910\n",
      "Epoch 1132/2000\n",
      " - 2s - loss: 0.7205 - acc: 0.7569 - val_loss: 1.2416 - val_acc: 0.6793\n",
      "Epoch 1133/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.6006 - acc: 0.7971 - val_loss: 1.1575 - val_acc: 0.6968\n",
      "Epoch 1134/2000\n",
      " - 2s - loss: 0.6375 - acc: 0.7752 - val_loss: 1.1839 - val_acc: 0.7201\n",
      "Epoch 1135/2000\n",
      " - 2s - loss: 0.6412 - acc: 0.7737 - val_loss: 1.0859 - val_acc: 0.7318\n",
      "Epoch 1136/2000\n",
      " - 2s - loss: 0.5959 - acc: 0.7869 - val_loss: 1.2604 - val_acc: 0.7143\n",
      "Epoch 1137/2000\n",
      " - 2s - loss: 0.5401 - acc: 0.8080 - val_loss: 1.0940 - val_acc: 0.7172\n",
      "Epoch 1138/2000\n",
      " - 2s - loss: 0.5822 - acc: 0.7956 - val_loss: 1.2186 - val_acc: 0.7201\n",
      "Epoch 1139/2000\n",
      " - 2s - loss: 0.6219 - acc: 0.7920 - val_loss: 1.1722 - val_acc: 0.7055\n",
      "Epoch 1140/2000\n",
      " - 2s - loss: 0.5639 - acc: 0.7971 - val_loss: 1.3632 - val_acc: 0.7026\n",
      "Epoch 1141/2000\n",
      " - 2s - loss: 0.6665 - acc: 0.7825 - val_loss: 1.3424 - val_acc: 0.6910\n",
      "Epoch 1142/2000\n",
      " - 2s - loss: 0.6018 - acc: 0.7803 - val_loss: 1.1946 - val_acc: 0.7143\n",
      "Epoch 1143/2000\n",
      " - 2s - loss: 0.5994 - acc: 0.7898 - val_loss: 1.1839 - val_acc: 0.7259\n",
      "Epoch 1144/2000\n",
      " - 2s - loss: 0.6133 - acc: 0.7847 - val_loss: 1.2156 - val_acc: 0.7085\n",
      "Epoch 1145/2000\n",
      " - 2s - loss: 0.6052 - acc: 0.7920 - val_loss: 1.2294 - val_acc: 0.7143\n",
      "Epoch 1146/2000\n",
      " - 2s - loss: 0.5484 - acc: 0.7832 - val_loss: 1.3604 - val_acc: 0.6910\n",
      "Epoch 1147/2000\n",
      " - 2s - loss: 0.6390 - acc: 0.7796 - val_loss: 1.2662 - val_acc: 0.7114\n",
      "Epoch 1148/2000\n",
      " - 2s - loss: 0.6613 - acc: 0.7613 - val_loss: 1.2065 - val_acc: 0.7201\n",
      "Epoch 1149/2000\n",
      " - 2s - loss: 0.5839 - acc: 0.7934 - val_loss: 1.1418 - val_acc: 0.7172\n",
      "Epoch 1150/2000\n",
      " - 2s - loss: 0.5974 - acc: 0.7796 - val_loss: 1.2745 - val_acc: 0.7143\n",
      "Epoch 1151/2000\n",
      " - 2s - loss: 0.5926 - acc: 0.8015 - val_loss: 1.3265 - val_acc: 0.6880\n",
      "Epoch 1152/2000\n",
      " - 2s - loss: 0.6298 - acc: 0.7745 - val_loss: 1.2131 - val_acc: 0.7085\n",
      "Epoch 1153/2000\n",
      " - 2s - loss: 0.6287 - acc: 0.7803 - val_loss: 1.1844 - val_acc: 0.7434\n",
      "Epoch 1154/2000\n",
      " - 2s - loss: 0.5782 - acc: 0.7978 - val_loss: 1.1757 - val_acc: 0.7230\n",
      "Epoch 1155/2000\n",
      " - 2s - loss: 0.6039 - acc: 0.7927 - val_loss: 1.2588 - val_acc: 0.7114\n",
      "Epoch 1156/2000\n",
      " - 2s - loss: 0.5892 - acc: 0.7832 - val_loss: 1.2871 - val_acc: 0.7085\n",
      "Epoch 1157/2000\n",
      " - 2s - loss: 0.5916 - acc: 0.7934 - val_loss: 1.2241 - val_acc: 0.7172\n",
      "Epoch 1158/2000\n",
      " - 2s - loss: 0.5720 - acc: 0.7810 - val_loss: 1.1989 - val_acc: 0.7405\n",
      "Epoch 1159/2000\n",
      " - 2s - loss: 0.6158 - acc: 0.7803 - val_loss: 1.1307 - val_acc: 0.7347\n",
      "Epoch 1160/2000\n",
      " - 2s - loss: 0.5697 - acc: 0.8000 - val_loss: 1.1553 - val_acc: 0.7143\n",
      "Epoch 1161/2000\n",
      " - 2s - loss: 0.7010 - acc: 0.7664 - val_loss: 1.1825 - val_acc: 0.6939\n",
      "Epoch 1162/2000\n",
      " - 2s - loss: 0.7444 - acc: 0.7401 - val_loss: 1.2929 - val_acc: 0.6997\n",
      "Epoch 1163/2000\n",
      " - 2s - loss: 0.6518 - acc: 0.7606 - val_loss: 1.1617 - val_acc: 0.6910\n",
      "Epoch 1164/2000\n",
      " - 2s - loss: 0.5903 - acc: 0.7891 - val_loss: 1.2230 - val_acc: 0.7259\n",
      "Epoch 1165/2000\n",
      " - 2s - loss: 0.5809 - acc: 0.7825 - val_loss: 1.1416 - val_acc: 0.7201\n",
      "Epoch 1166/2000\n",
      " - 2s - loss: 0.5655 - acc: 0.8044 - val_loss: 1.2495 - val_acc: 0.6851\n",
      "Epoch 1167/2000\n",
      " - 1s - loss: 0.6148 - acc: 0.7796 - val_loss: 1.1851 - val_acc: 0.7055\n",
      "Epoch 1168/2000\n",
      " - 1s - loss: 0.6632 - acc: 0.7730 - val_loss: 1.2868 - val_acc: 0.6822\n",
      "Epoch 1169/2000\n",
      " - 1s - loss: 0.7497 - acc: 0.7416 - val_loss: 1.1115 - val_acc: 0.7259\n",
      "Epoch 1170/2000\n",
      " - 2s - loss: 0.6536 - acc: 0.7635 - val_loss: 1.1061 - val_acc: 0.7464\n",
      "Epoch 1171/2000\n",
      " - 1s - loss: 0.5338 - acc: 0.8058 - val_loss: 1.1714 - val_acc: 0.7172\n",
      "Epoch 1172/2000\n",
      " - 2s - loss: 0.6466 - acc: 0.7759 - val_loss: 1.1781 - val_acc: 0.7055\n",
      "Epoch 1173/2000\n",
      " - 2s - loss: 0.6564 - acc: 0.7657 - val_loss: 1.2773 - val_acc: 0.6968\n",
      "Epoch 1174/2000\n",
      " - 2s - loss: 0.6296 - acc: 0.7920 - val_loss: 1.1913 - val_acc: 0.7201\n",
      "Epoch 1175/2000\n",
      " - 2s - loss: 0.6255 - acc: 0.7672 - val_loss: 1.2472 - val_acc: 0.7143\n",
      "Epoch 1176/2000\n",
      " - 2s - loss: 0.5575 - acc: 0.7978 - val_loss: 1.2891 - val_acc: 0.6939\n",
      "Epoch 1177/2000\n",
      " - 2s - loss: 0.5739 - acc: 0.7810 - val_loss: 1.2222 - val_acc: 0.7114\n",
      "Epoch 1178/2000\n",
      " - 2s - loss: 0.5785 - acc: 0.7898 - val_loss: 1.1331 - val_acc: 0.7259\n",
      "Epoch 1179/2000\n",
      " - 2s - loss: 0.6510 - acc: 0.7672 - val_loss: 1.1699 - val_acc: 0.7230\n",
      "Epoch 1180/2000\n",
      " - 2s - loss: 0.5543 - acc: 0.7985 - val_loss: 1.3131 - val_acc: 0.7055\n",
      "Epoch 1181/2000\n",
      " - 2s - loss: 0.5764 - acc: 0.7810 - val_loss: 1.3319 - val_acc: 0.7114\n",
      "Epoch 1182/2000\n",
      " - 2s - loss: 0.5983 - acc: 0.7854 - val_loss: 1.2079 - val_acc: 0.7026\n",
      "Epoch 1183/2000\n",
      " - 2s - loss: 0.5418 - acc: 0.8073 - val_loss: 1.2404 - val_acc: 0.7172\n",
      "Epoch 1184/2000\n",
      " - 2s - loss: 0.6472 - acc: 0.7672 - val_loss: 1.3789 - val_acc: 0.6851\n",
      "Epoch 1185/2000\n",
      " - 2s - loss: 0.7197 - acc: 0.7438 - val_loss: 1.1156 - val_acc: 0.7114\n",
      "Epoch 1186/2000\n",
      " - 2s - loss: 0.6135 - acc: 0.7825 - val_loss: 1.1984 - val_acc: 0.7318\n",
      "Epoch 1187/2000\n",
      " - 1s - loss: 0.6193 - acc: 0.7664 - val_loss: 1.1568 - val_acc: 0.7055\n",
      "Epoch 1188/2000\n",
      " - 1s - loss: 0.5739 - acc: 0.7964 - val_loss: 1.1896 - val_acc: 0.7259\n",
      "Epoch 1189/2000\n",
      " - 1s - loss: 0.6165 - acc: 0.7745 - val_loss: 1.1908 - val_acc: 0.7230\n",
      "Epoch 1190/2000\n",
      " - 1s - loss: 0.5754 - acc: 0.8066 - val_loss: 1.4074 - val_acc: 0.6706\n",
      "Epoch 1191/2000\n",
      " - 1s - loss: 0.6534 - acc: 0.7796 - val_loss: 1.2840 - val_acc: 0.6997\n",
      "Epoch 1192/2000\n",
      " - 1s - loss: 0.5606 - acc: 0.8095 - val_loss: 1.2434 - val_acc: 0.7143\n",
      "Epoch 1193/2000\n",
      " - 1s - loss: 0.6418 - acc: 0.7628 - val_loss: 1.2868 - val_acc: 0.6880\n",
      "Epoch 1194/2000\n",
      " - 1s - loss: 0.7179 - acc: 0.7606 - val_loss: 1.2297 - val_acc: 0.6764\n",
      "Epoch 1195/2000\n",
      " - 1s - loss: 0.6394 - acc: 0.7584 - val_loss: 1.2133 - val_acc: 0.7055\n",
      "Epoch 1196/2000\n",
      " - 1s - loss: 0.6330 - acc: 0.7599 - val_loss: 1.1841 - val_acc: 0.6997\n",
      "Epoch 1197/2000\n",
      " - 1s - loss: 0.6021 - acc: 0.7891 - val_loss: 1.2516 - val_acc: 0.7055\n",
      "Epoch 1198/2000\n",
      " - 1s - loss: 0.6273 - acc: 0.7730 - val_loss: 1.2287 - val_acc: 0.6822\n",
      "Epoch 1199/2000\n",
      " - 1s - loss: 0.6172 - acc: 0.7679 - val_loss: 1.3019 - val_acc: 0.6880\n",
      "Epoch 1200/2000\n",
      " - 1s - loss: 0.5945 - acc: 0.7759 - val_loss: 1.1995 - val_acc: 0.7143\n",
      "Epoch 1201/2000\n",
      " - 1s - loss: 0.5790 - acc: 0.7898 - val_loss: 1.2550 - val_acc: 0.6822\n",
      "Epoch 1202/2000\n",
      " - 1s - loss: 0.6066 - acc: 0.7942 - val_loss: 1.2412 - val_acc: 0.7172\n",
      "Epoch 1203/2000\n",
      " - 1s - loss: 0.6529 - acc: 0.7657 - val_loss: 1.1548 - val_acc: 0.7201\n",
      "Epoch 1204/2000\n",
      " - 1s - loss: 0.6561 - acc: 0.7620 - val_loss: 1.2169 - val_acc: 0.7289\n",
      "Epoch 1205/2000\n",
      " - 1s - loss: 0.6207 - acc: 0.7759 - val_loss: 1.1890 - val_acc: 0.7085\n",
      "Epoch 1206/2000\n",
      " - 1s - loss: 0.6619 - acc: 0.7657 - val_loss: 1.1602 - val_acc: 0.7230\n",
      "Epoch 1207/2000\n",
      " - 1s - loss: 0.6433 - acc: 0.7577 - val_loss: 1.1864 - val_acc: 0.7143\n",
      "Epoch 1208/2000\n",
      " - 1s - loss: 0.6567 - acc: 0.7672 - val_loss: 1.2783 - val_acc: 0.6968\n",
      "Epoch 1209/2000\n",
      " - 1s - loss: 0.6348 - acc: 0.7679 - val_loss: 1.2869 - val_acc: 0.6618\n",
      "Epoch 1210/2000\n",
      " - 1s - loss: 0.6144 - acc: 0.7708 - val_loss: 1.1219 - val_acc: 0.7143\n",
      "Epoch 1211/2000\n",
      " - 1s - loss: 0.5710 - acc: 0.7993 - val_loss: 1.2895 - val_acc: 0.7114\n",
      "Epoch 1212/2000\n",
      " - 1s - loss: 0.5879 - acc: 0.7883 - val_loss: 1.2846 - val_acc: 0.6939\n",
      "Epoch 1213/2000\n",
      " - 1s - loss: 0.7402 - acc: 0.7438 - val_loss: 1.4704 - val_acc: 0.6793\n",
      "Epoch 1214/2000\n",
      " - 1s - loss: 1.0144 - acc: 0.6876 - val_loss: 1.2499 - val_acc: 0.6910\n",
      "Epoch 1215/2000\n",
      " - 1s - loss: 0.6944 - acc: 0.7533 - val_loss: 1.1163 - val_acc: 0.7055\n",
      "Epoch 1216/2000\n",
      " - 1s - loss: 0.7797 - acc: 0.7445 - val_loss: 1.3438 - val_acc: 0.6764\n",
      "Epoch 1217/2000\n",
      " - 1s - loss: 0.6796 - acc: 0.7533 - val_loss: 1.1587 - val_acc: 0.7026\n",
      "Epoch 1218/2000\n",
      " - 1s - loss: 0.6660 - acc: 0.7679 - val_loss: 1.1625 - val_acc: 0.7055\n",
      "Epoch 1219/2000\n",
      " - 1s - loss: 0.7698 - acc: 0.7401 - val_loss: 1.4217 - val_acc: 0.6910\n",
      "Epoch 1220/2000\n",
      " - 1s - loss: 0.6279 - acc: 0.7818 - val_loss: 1.1170 - val_acc: 0.7114\n",
      "Epoch 1221/2000\n",
      " - 1s - loss: 0.5607 - acc: 0.7891 - val_loss: 1.2207 - val_acc: 0.7114\n",
      "Epoch 1222/2000\n",
      " - 1s - loss: 0.5934 - acc: 0.7949 - val_loss: 1.1618 - val_acc: 0.7318\n",
      "Epoch 1223/2000\n",
      " - 1s - loss: 0.6077 - acc: 0.7810 - val_loss: 1.2550 - val_acc: 0.6968\n",
      "Epoch 1224/2000\n",
      " - 1s - loss: 0.6562 - acc: 0.7708 - val_loss: 1.0817 - val_acc: 0.7259\n",
      "Epoch 1225/2000\n",
      " - 1s - loss: 0.6473 - acc: 0.7686 - val_loss: 1.1381 - val_acc: 0.7055\n",
      "Epoch 1226/2000\n",
      " - 1s - loss: 0.7242 - acc: 0.7672 - val_loss: 1.3106 - val_acc: 0.6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1227/2000\n",
      " - 1s - loss: 0.7741 - acc: 0.7365 - val_loss: 1.1766 - val_acc: 0.7085\n",
      "Epoch 1228/2000\n",
      " - 1s - loss: 0.6762 - acc: 0.7737 - val_loss: 1.0590 - val_acc: 0.7289\n",
      "Epoch 1229/2000\n",
      " - 1s - loss: 0.5753 - acc: 0.7956 - val_loss: 1.1211 - val_acc: 0.7347\n",
      "Epoch 1230/2000\n",
      " - 1s - loss: 0.6262 - acc: 0.7752 - val_loss: 1.0844 - val_acc: 0.7230\n",
      "Epoch 1231/2000\n",
      " - 1s - loss: 0.5738 - acc: 0.8022 - val_loss: 1.1621 - val_acc: 0.6997\n",
      "Epoch 1232/2000\n",
      " - 1s - loss: 0.6551 - acc: 0.7796 - val_loss: 1.1789 - val_acc: 0.7055\n",
      "Epoch 1233/2000\n",
      " - 1s - loss: 0.5816 - acc: 0.7861 - val_loss: 1.1712 - val_acc: 0.7143\n",
      "Epoch 1234/2000\n",
      " - 1s - loss: 0.5983 - acc: 0.7788 - val_loss: 1.2244 - val_acc: 0.7201\n",
      "Epoch 1235/2000\n",
      " - 1s - loss: 0.6047 - acc: 0.7861 - val_loss: 1.2036 - val_acc: 0.7026\n",
      "Epoch 1236/2000\n",
      " - 1s - loss: 0.6253 - acc: 0.7796 - val_loss: 1.2014 - val_acc: 0.7143\n",
      "Epoch 1237/2000\n",
      " - 1s - loss: 0.5533 - acc: 0.8007 - val_loss: 1.1586 - val_acc: 0.7172\n",
      "Epoch 1238/2000\n",
      " - 1s - loss: 0.6663 - acc: 0.7774 - val_loss: 1.1231 - val_acc: 0.7143\n",
      "Epoch 1239/2000\n",
      " - 1s - loss: 0.6335 - acc: 0.7774 - val_loss: 1.1846 - val_acc: 0.6997\n",
      "Epoch 1240/2000\n",
      " - 1s - loss: 0.5467 - acc: 0.8080 - val_loss: 1.1462 - val_acc: 0.7347\n",
      "Epoch 1241/2000\n",
      " - 1s - loss: 0.6224 - acc: 0.7832 - val_loss: 1.1224 - val_acc: 0.7318\n",
      "Epoch 1242/2000\n",
      " - 1s - loss: 0.6015 - acc: 0.7796 - val_loss: 1.1914 - val_acc: 0.7201\n",
      "Epoch 1243/2000\n",
      " - 1s - loss: 0.5665 - acc: 0.8073 - val_loss: 1.2396 - val_acc: 0.7026\n",
      "Epoch 1244/2000\n",
      " - 1s - loss: 0.5827 - acc: 0.7883 - val_loss: 1.2262 - val_acc: 0.7085\n",
      "Epoch 1245/2000\n",
      " - 1s - loss: 0.7598 - acc: 0.7380 - val_loss: 1.3119 - val_acc: 0.6589\n",
      "Epoch 1246/2000\n",
      " - 1s - loss: 0.7035 - acc: 0.7569 - val_loss: 1.2092 - val_acc: 0.7085\n",
      "Epoch 1247/2000\n",
      " - 1s - loss: 0.6094 - acc: 0.7686 - val_loss: 1.1657 - val_acc: 0.7259\n",
      "Epoch 1248/2000\n",
      " - 1s - loss: 0.5850 - acc: 0.8000 - val_loss: 1.3069 - val_acc: 0.6822\n",
      "Epoch 1249/2000\n",
      " - 1s - loss: 0.6686 - acc: 0.7562 - val_loss: 1.1829 - val_acc: 0.7085\n",
      "Epoch 1250/2000\n",
      " - 1s - loss: 0.5804 - acc: 0.7832 - val_loss: 1.2424 - val_acc: 0.6880\n",
      "Epoch 1251/2000\n",
      " - 1s - loss: 0.6855 - acc: 0.7723 - val_loss: 1.1481 - val_acc: 0.7230\n",
      "Epoch 1252/2000\n",
      " - 1s - loss: 0.8640 - acc: 0.7175 - val_loss: 1.1463 - val_acc: 0.6851\n",
      "Epoch 1253/2000\n",
      " - 1s - loss: 0.7402 - acc: 0.7555 - val_loss: 1.1399 - val_acc: 0.7026\n",
      "Epoch 1254/2000\n",
      " - 1s - loss: 0.6159 - acc: 0.7861 - val_loss: 1.1759 - val_acc: 0.7026\n",
      "Epoch 1255/2000\n",
      " - 1s - loss: 0.6335 - acc: 0.7672 - val_loss: 1.3041 - val_acc: 0.6997\n",
      "Epoch 1256/2000\n",
      " - 1s - loss: 0.6005 - acc: 0.7876 - val_loss: 1.1684 - val_acc: 0.7026\n",
      "Epoch 1257/2000\n",
      " - 1s - loss: 0.5946 - acc: 0.7956 - val_loss: 1.2090 - val_acc: 0.7172\n",
      "Epoch 1258/2000\n",
      " - 1s - loss: 0.7115 - acc: 0.7562 - val_loss: 1.1138 - val_acc: 0.7055\n",
      "Epoch 1259/2000\n",
      " - 1s - loss: 0.7210 - acc: 0.7496 - val_loss: 1.1804 - val_acc: 0.7026\n",
      "Epoch 1260/2000\n",
      " - 1s - loss: 0.6222 - acc: 0.7876 - val_loss: 1.1278 - val_acc: 0.7143\n",
      "Epoch 1261/2000\n",
      " - 1s - loss: 0.5956 - acc: 0.7774 - val_loss: 1.1569 - val_acc: 0.7230\n",
      "Epoch 1262/2000\n",
      " - 1s - loss: 0.5783 - acc: 0.7825 - val_loss: 1.1928 - val_acc: 0.6880\n",
      "Epoch 1263/2000\n",
      " - 1s - loss: 0.6143 - acc: 0.7803 - val_loss: 1.1795 - val_acc: 0.6851\n",
      "Epoch 1264/2000\n",
      " - 1s - loss: 0.5703 - acc: 0.7752 - val_loss: 1.2771 - val_acc: 0.7055\n",
      "Epoch 1265/2000\n",
      " - 1s - loss: 0.6880 - acc: 0.7679 - val_loss: 1.1635 - val_acc: 0.7085\n",
      "Epoch 1266/2000\n",
      " - 1s - loss: 0.6107 - acc: 0.7905 - val_loss: 1.2817 - val_acc: 0.6968\n",
      "Epoch 1267/2000\n",
      " - 1s - loss: 0.5947 - acc: 0.7883 - val_loss: 1.1367 - val_acc: 0.7230\n",
      "Epoch 1268/2000\n",
      " - 1s - loss: 0.5617 - acc: 0.8073 - val_loss: 1.1833 - val_acc: 0.7230\n",
      "Epoch 1269/2000\n",
      " - 1s - loss: 0.5693 - acc: 0.8015 - val_loss: 1.1809 - val_acc: 0.7201\n",
      "Epoch 1270/2000\n",
      " - 1s - loss: 0.6178 - acc: 0.7832 - val_loss: 1.3606 - val_acc: 0.7085\n",
      "Epoch 1271/2000\n",
      " - 0s - loss: 0.6609 - acc: 0.7664 - val_loss: 1.2227 - val_acc: 0.7026\n",
      "Epoch 1272/2000\n",
      " - 1s - loss: 0.5854 - acc: 0.7832 - val_loss: 1.1833 - val_acc: 0.7026\n",
      "Epoch 1273/2000\n",
      " - 1s - loss: 0.5595 - acc: 0.7891 - val_loss: 1.2058 - val_acc: 0.7055\n",
      "Epoch 1274/2000\n",
      " - 1s - loss: 0.5651 - acc: 0.7956 - val_loss: 1.2163 - val_acc: 0.7318\n",
      "Epoch 1275/2000\n",
      " - 1s - loss: 0.5918 - acc: 0.7934 - val_loss: 1.2142 - val_acc: 0.7201\n",
      "Epoch 1276/2000\n",
      " - 1s - loss: 0.6250 - acc: 0.7737 - val_loss: 1.3066 - val_acc: 0.7172\n",
      "Epoch 1277/2000\n",
      " - 1s - loss: 0.5907 - acc: 0.7912 - val_loss: 1.2023 - val_acc: 0.7230\n",
      "Epoch 1278/2000\n",
      " - 0s - loss: 0.5839 - acc: 0.7891 - val_loss: 1.2880 - val_acc: 0.6968\n",
      "Epoch 1279/2000\n",
      " - 1s - loss: 0.6167 - acc: 0.7766 - val_loss: 1.2858 - val_acc: 0.7026\n",
      "Epoch 1280/2000\n",
      " - 1s - loss: 0.5868 - acc: 0.7839 - val_loss: 1.2219 - val_acc: 0.7026\n",
      "Epoch 1281/2000\n",
      " - 1s - loss: 0.5745 - acc: 0.8007 - val_loss: 1.3665 - val_acc: 0.6706\n",
      "Epoch 1282/2000\n",
      " - 1s - loss: 0.6440 - acc: 0.7766 - val_loss: 1.3459 - val_acc: 0.7055\n",
      "Epoch 1283/2000\n",
      " - 1s - loss: 0.8358 - acc: 0.7190 - val_loss: 1.1549 - val_acc: 0.6968\n",
      "Epoch 1284/2000\n",
      " - 1s - loss: 0.6859 - acc: 0.7635 - val_loss: 1.2454 - val_acc: 0.7055\n",
      "Epoch 1285/2000\n",
      " - 1s - loss: 0.6424 - acc: 0.7920 - val_loss: 1.2186 - val_acc: 0.6997\n",
      "Epoch 1286/2000\n",
      " - 1s - loss: 0.6082 - acc: 0.7693 - val_loss: 1.1268 - val_acc: 0.7085\n",
      "Epoch 1287/2000\n",
      " - 1s - loss: 0.5879 - acc: 0.7839 - val_loss: 1.1238 - val_acc: 0.7230\n",
      "Epoch 1288/2000\n",
      " - 1s - loss: 0.5728 - acc: 0.7803 - val_loss: 1.1601 - val_acc: 0.7201\n",
      "Epoch 1289/2000\n",
      " - 1s - loss: 0.5711 - acc: 0.7905 - val_loss: 1.1484 - val_acc: 0.7318\n",
      "Epoch 1290/2000\n",
      " - 1s - loss: 0.5880 - acc: 0.7854 - val_loss: 1.2634 - val_acc: 0.6997\n",
      "Epoch 1291/2000\n",
      " - 1s - loss: 0.8755 - acc: 0.7175 - val_loss: 1.4365 - val_acc: 0.6706\n",
      "Epoch 1292/2000\n",
      " - 1s - loss: 0.8013 - acc: 0.7248 - val_loss: 1.2976 - val_acc: 0.6939\n",
      "Epoch 1293/2000\n",
      " - 1s - loss: 0.6098 - acc: 0.7788 - val_loss: 1.2423 - val_acc: 0.6968\n",
      "Epoch 1294/2000\n",
      " - 1s - loss: 0.5733 - acc: 0.7927 - val_loss: 1.1932 - val_acc: 0.7055\n",
      "Epoch 1295/2000\n",
      " - 1s - loss: 0.5745 - acc: 0.7847 - val_loss: 1.3091 - val_acc: 0.7026\n",
      "Epoch 1296/2000\n",
      " - 1s - loss: 0.5690 - acc: 0.7861 - val_loss: 1.1611 - val_acc: 0.7172\n",
      "Epoch 1297/2000\n",
      " - 1s - loss: 0.5939 - acc: 0.7920 - val_loss: 1.2538 - val_acc: 0.7201\n",
      "Epoch 1298/2000\n",
      " - 1s - loss: 0.6200 - acc: 0.7723 - val_loss: 1.1726 - val_acc: 0.7172\n",
      "Epoch 1299/2000\n",
      " - 1s - loss: 0.5823 - acc: 0.7978 - val_loss: 1.2667 - val_acc: 0.7114\n",
      "Epoch 1300/2000\n",
      " - 1s - loss: 0.6426 - acc: 0.7781 - val_loss: 1.2244 - val_acc: 0.7085\n",
      "Epoch 1301/2000\n",
      " - 1s - loss: 0.6307 - acc: 0.7818 - val_loss: 1.2076 - val_acc: 0.7085\n",
      "Epoch 1302/2000\n",
      " - 1s - loss: 0.5942 - acc: 0.7679 - val_loss: 1.3239 - val_acc: 0.7201\n",
      "Epoch 1303/2000\n",
      " - 1s - loss: 0.7054 - acc: 0.7701 - val_loss: 1.2454 - val_acc: 0.6968\n",
      "Epoch 1304/2000\n",
      " - 1s - loss: 0.6136 - acc: 0.7803 - val_loss: 1.3143 - val_acc: 0.7026\n",
      "Epoch 1305/2000\n",
      " - 1s - loss: 0.6390 - acc: 0.7715 - val_loss: 1.2489 - val_acc: 0.6939\n",
      "Epoch 1306/2000\n",
      " - 1s - loss: 0.5609 - acc: 0.8058 - val_loss: 1.1483 - val_acc: 0.7289\n",
      "Epoch 1307/2000\n",
      " - 1s - loss: 0.5454 - acc: 0.8044 - val_loss: 1.1523 - val_acc: 0.7143\n",
      "Epoch 1308/2000\n",
      " - 1s - loss: 0.5534 - acc: 0.7985 - val_loss: 1.1819 - val_acc: 0.7259\n",
      "Epoch 1309/2000\n",
      " - 1s - loss: 0.5613 - acc: 0.7964 - val_loss: 1.2474 - val_acc: 0.7085\n",
      "Epoch 1310/2000\n",
      " - 1s - loss: 0.6232 - acc: 0.7708 - val_loss: 1.2899 - val_acc: 0.6851\n",
      "Epoch 1311/2000\n",
      " - 1s - loss: 0.6327 - acc: 0.7745 - val_loss: 1.3152 - val_acc: 0.6939\n",
      "Epoch 1312/2000\n",
      " - 1s - loss: 0.6296 - acc: 0.7781 - val_loss: 1.1157 - val_acc: 0.7055\n",
      "Epoch 1313/2000\n",
      " - 1s - loss: 0.5984 - acc: 0.7766 - val_loss: 1.1602 - val_acc: 0.6822\n",
      "Epoch 1314/2000\n",
      " - 1s - loss: 0.5600 - acc: 0.8015 - val_loss: 1.2410 - val_acc: 0.7085\n",
      "Epoch 1315/2000\n",
      " - 1s - loss: 0.5785 - acc: 0.7861 - val_loss: 1.3422 - val_acc: 0.6735\n",
      "Epoch 1316/2000\n",
      " - 1s - loss: 0.7728 - acc: 0.7350 - val_loss: 1.7240 - val_acc: 0.6181\n",
      "Epoch 1317/2000\n",
      " - 1s - loss: 0.9960 - acc: 0.7000 - val_loss: 1.2411 - val_acc: 0.6706\n",
      "Epoch 1318/2000\n",
      " - 1s - loss: 0.7647 - acc: 0.7453 - val_loss: 1.2408 - val_acc: 0.7201\n",
      "Epoch 1319/2000\n",
      " - 1s - loss: 0.5820 - acc: 0.7956 - val_loss: 1.1173 - val_acc: 0.7347\n",
      "Epoch 1320/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6171 - acc: 0.7737 - val_loss: 1.1300 - val_acc: 0.7318\n",
      "Epoch 1321/2000\n",
      " - 1s - loss: 0.5310 - acc: 0.8241 - val_loss: 1.1368 - val_acc: 0.7172\n",
      "Epoch 1322/2000\n",
      " - 1s - loss: 0.6030 - acc: 0.7869 - val_loss: 1.1552 - val_acc: 0.7259\n",
      "Epoch 1323/2000\n",
      " - 1s - loss: 0.5658 - acc: 0.7985 - val_loss: 1.1603 - val_acc: 0.7259\n",
      "Epoch 1324/2000\n",
      " - 1s - loss: 0.5937 - acc: 0.7985 - val_loss: 1.1971 - val_acc: 0.7114\n",
      "Epoch 1325/2000\n",
      " - 1s - loss: 0.5830 - acc: 0.8000 - val_loss: 1.2054 - val_acc: 0.7143\n",
      "Epoch 1326/2000\n",
      " - 1s - loss: 0.6912 - acc: 0.7613 - val_loss: 1.1174 - val_acc: 0.7172\n",
      "Epoch 1327/2000\n",
      " - 1s - loss: 0.6598 - acc: 0.7620 - val_loss: 1.2503 - val_acc: 0.7055\n",
      "Epoch 1328/2000\n",
      " - 1s - loss: 0.6471 - acc: 0.7650 - val_loss: 1.2402 - val_acc: 0.7026\n",
      "Epoch 1329/2000\n",
      " - 1s - loss: 0.5581 - acc: 0.8036 - val_loss: 1.1857 - val_acc: 0.7172\n",
      "Epoch 1330/2000\n",
      " - 1s - loss: 0.5902 - acc: 0.8015 - val_loss: 1.1075 - val_acc: 0.7434\n",
      "Epoch 1331/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7818 - val_loss: 1.1078 - val_acc: 0.7085\n",
      "Epoch 1332/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7869 - val_loss: 1.1463 - val_acc: 0.7055\n",
      "Epoch 1333/2000\n",
      " - 1s - loss: 0.6017 - acc: 0.7876 - val_loss: 1.1861 - val_acc: 0.6910\n",
      "Epoch 1334/2000\n",
      " - 1s - loss: 0.6019 - acc: 0.7796 - val_loss: 1.2865 - val_acc: 0.7114\n",
      "Epoch 1335/2000\n",
      " - 1s - loss: 0.5801 - acc: 0.7912 - val_loss: 1.2188 - val_acc: 0.7026\n",
      "Epoch 1336/2000\n",
      " - 1s - loss: 0.6331 - acc: 0.7752 - val_loss: 1.2155 - val_acc: 0.7114\n",
      "Epoch 1337/2000\n",
      " - 0s - loss: 0.6253 - acc: 0.7701 - val_loss: 1.1130 - val_acc: 0.7230\n",
      "Epoch 1338/2000\n",
      " - 1s - loss: 0.6383 - acc: 0.7715 - val_loss: 1.1873 - val_acc: 0.7172\n",
      "Epoch 1339/2000\n",
      " - 1s - loss: 0.5665 - acc: 0.7832 - val_loss: 1.2627 - val_acc: 0.7026\n",
      "Epoch 1340/2000\n",
      " - 1s - loss: 0.6056 - acc: 0.7839 - val_loss: 1.2771 - val_acc: 0.6968\n",
      "Epoch 1341/2000\n",
      " - 1s - loss: 0.5705 - acc: 0.7927 - val_loss: 1.2583 - val_acc: 0.7085\n",
      "Epoch 1342/2000\n",
      " - 1s - loss: 0.5633 - acc: 0.7934 - val_loss: 1.2486 - val_acc: 0.6968\n",
      "Epoch 1343/2000\n",
      " - 1s - loss: 0.5860 - acc: 0.7847 - val_loss: 1.2568 - val_acc: 0.7114\n",
      "Epoch 1344/2000\n",
      " - 1s - loss: 0.5734 - acc: 0.8022 - val_loss: 1.2015 - val_acc: 0.6997\n",
      "Epoch 1345/2000\n",
      " - 0s - loss: 0.6370 - acc: 0.7628 - val_loss: 1.1706 - val_acc: 0.7172\n",
      "Epoch 1346/2000\n",
      " - 1s - loss: 0.5890 - acc: 0.7810 - val_loss: 1.2997 - val_acc: 0.6880\n",
      "Epoch 1347/2000\n",
      " - 1s - loss: 0.5739 - acc: 0.8007 - val_loss: 1.2327 - val_acc: 0.6968\n",
      "Epoch 1348/2000\n",
      " - 1s - loss: 0.6101 - acc: 0.7774 - val_loss: 1.2070 - val_acc: 0.6968\n",
      "Epoch 1349/2000\n",
      " - 1s - loss: 0.6651 - acc: 0.7642 - val_loss: 1.2015 - val_acc: 0.7114\n",
      "Epoch 1350/2000\n",
      " - 1s - loss: 0.6086 - acc: 0.7788 - val_loss: 1.3159 - val_acc: 0.6880\n",
      "Epoch 1351/2000\n",
      " - 1s - loss: 0.6076 - acc: 0.7964 - val_loss: 1.1759 - val_acc: 0.7085\n",
      "Epoch 1352/2000\n",
      " - 1s - loss: 0.5636 - acc: 0.8117 - val_loss: 1.2226 - val_acc: 0.7026\n",
      "Epoch 1353/2000\n",
      " - 1s - loss: 0.5210 - acc: 0.8080 - val_loss: 1.2933 - val_acc: 0.6706\n",
      "Epoch 1354/2000\n",
      " - 1s - loss: 0.6343 - acc: 0.7642 - val_loss: 1.2070 - val_acc: 0.7172\n",
      "Epoch 1355/2000\n",
      " - 1s - loss: 0.6208 - acc: 0.7672 - val_loss: 1.1629 - val_acc: 0.7143\n",
      "Epoch 1356/2000\n",
      " - 1s - loss: 0.6093 - acc: 0.7730 - val_loss: 1.1780 - val_acc: 0.7114\n",
      "Epoch 1357/2000\n",
      " - 1s - loss: 0.6870 - acc: 0.7693 - val_loss: 1.2566 - val_acc: 0.6968\n",
      "Epoch 1358/2000\n",
      " - 1s - loss: 0.6646 - acc: 0.7547 - val_loss: 1.1975 - val_acc: 0.6880\n",
      "Epoch 1359/2000\n",
      " - 1s - loss: 0.7437 - acc: 0.7445 - val_loss: 1.2779 - val_acc: 0.6880\n",
      "Epoch 1360/2000\n",
      " - 1s - loss: 0.7524 - acc: 0.7409 - val_loss: 1.1474 - val_acc: 0.7289\n",
      "Epoch 1361/2000\n",
      " - 1s - loss: 0.5795 - acc: 0.7927 - val_loss: 1.3141 - val_acc: 0.7026\n",
      "Epoch 1362/2000\n",
      " - 1s - loss: 0.5906 - acc: 0.7942 - val_loss: 1.2648 - val_acc: 0.7055\n",
      "Epoch 1363/2000\n",
      " - 1s - loss: 0.5750 - acc: 0.7891 - val_loss: 1.1519 - val_acc: 0.7055\n",
      "Epoch 1364/2000\n",
      " - 1s - loss: 0.5766 - acc: 0.7847 - val_loss: 1.2036 - val_acc: 0.7026\n",
      "Epoch 1365/2000\n",
      " - 0s - loss: 0.6385 - acc: 0.7679 - val_loss: 1.2222 - val_acc: 0.7055\n",
      "Epoch 1366/2000\n",
      " - 0s - loss: 0.5571 - acc: 0.7927 - val_loss: 1.1964 - val_acc: 0.7114\n",
      "Epoch 1367/2000\n",
      " - 1s - loss: 0.7704 - acc: 0.7642 - val_loss: 1.4348 - val_acc: 0.6676\n",
      "Epoch 1368/2000\n",
      " - 0s - loss: 0.8412 - acc: 0.7277 - val_loss: 1.2421 - val_acc: 0.6822\n",
      "Epoch 1369/2000\n",
      " - 1s - loss: 0.6698 - acc: 0.7715 - val_loss: 1.1810 - val_acc: 0.7026\n",
      "Epoch 1370/2000\n",
      " - 1s - loss: 0.6439 - acc: 0.7912 - val_loss: 1.3043 - val_acc: 0.7114\n",
      "Epoch 1371/2000\n",
      " - 1s - loss: 0.6376 - acc: 0.7628 - val_loss: 1.2413 - val_acc: 0.6706\n",
      "Epoch 1372/2000\n",
      " - 1s - loss: 0.5999 - acc: 0.7781 - val_loss: 1.2325 - val_acc: 0.7085\n",
      "Epoch 1373/2000\n",
      " - 1s - loss: 0.6088 - acc: 0.7876 - val_loss: 1.1404 - val_acc: 0.7085\n",
      "Epoch 1374/2000\n",
      " - 1s - loss: 0.5689 - acc: 0.8007 - val_loss: 1.2851 - val_acc: 0.6910\n",
      "Epoch 1375/2000\n",
      " - 0s - loss: 0.5661 - acc: 0.7964 - val_loss: 1.2563 - val_acc: 0.6968\n",
      "Epoch 1376/2000\n",
      " - 1s - loss: 0.6072 - acc: 0.7847 - val_loss: 1.2087 - val_acc: 0.6997\n",
      "Epoch 1377/2000\n",
      " - 1s - loss: 0.6215 - acc: 0.7934 - val_loss: 1.1158 - val_acc: 0.7026\n",
      "Epoch 1378/2000\n",
      " - 1s - loss: 0.5699 - acc: 0.8036 - val_loss: 1.1816 - val_acc: 0.7055\n",
      "Epoch 1379/2000\n",
      " - 1s - loss: 0.5690 - acc: 0.8051 - val_loss: 1.1602 - val_acc: 0.7143\n",
      "Epoch 1380/2000\n",
      " - 1s - loss: 0.6062 - acc: 0.7869 - val_loss: 1.1201 - val_acc: 0.7318\n",
      "Epoch 1381/2000\n",
      " - 1s - loss: 0.5870 - acc: 0.7942 - val_loss: 1.1765 - val_acc: 0.7376\n",
      "Epoch 1382/2000\n",
      " - 1s - loss: 0.5998 - acc: 0.7934 - val_loss: 1.2375 - val_acc: 0.7143\n",
      "Epoch 1383/2000\n",
      " - 1s - loss: 0.5949 - acc: 0.7810 - val_loss: 1.1756 - val_acc: 0.7085\n",
      "Epoch 1384/2000\n",
      " - 1s - loss: 0.6202 - acc: 0.7788 - val_loss: 1.2709 - val_acc: 0.7026\n",
      "Epoch 1385/2000\n",
      " - 1s - loss: 0.5424 - acc: 0.8029 - val_loss: 1.2819 - val_acc: 0.7143\n",
      "Epoch 1386/2000\n",
      " - 1s - loss: 0.5456 - acc: 0.7949 - val_loss: 1.2307 - val_acc: 0.7055\n",
      "Epoch 1387/2000\n",
      " - 1s - loss: 0.6164 - acc: 0.7876 - val_loss: 1.1998 - val_acc: 0.7085\n",
      "Epoch 1388/2000\n",
      " - 1s - loss: 0.7678 - acc: 0.7474 - val_loss: 1.2773 - val_acc: 0.6997\n",
      "Epoch 1389/2000\n",
      " - 1s - loss: 0.7440 - acc: 0.7394 - val_loss: 1.2242 - val_acc: 0.7085\n",
      "Epoch 1390/2000\n",
      " - 1s - loss: 0.7090 - acc: 0.7482 - val_loss: 1.1678 - val_acc: 0.6910\n",
      "Epoch 1391/2000\n",
      " - 1s - loss: 0.6541 - acc: 0.7723 - val_loss: 1.0556 - val_acc: 0.7201\n",
      "Epoch 1392/2000\n",
      " - 1s - loss: 0.6017 - acc: 0.7891 - val_loss: 1.1502 - val_acc: 0.7259\n",
      "Epoch 1393/2000\n",
      " - 1s - loss: 0.7336 - acc: 0.7489 - val_loss: 1.1810 - val_acc: 0.6880\n",
      "Epoch 1394/2000\n",
      " - 1s - loss: 0.6672 - acc: 0.7672 - val_loss: 1.1293 - val_acc: 0.7230\n",
      "Epoch 1395/2000\n",
      " - 1s - loss: 0.5774 - acc: 0.7883 - val_loss: 1.1118 - val_acc: 0.7201\n",
      "Epoch 1396/2000\n",
      " - 1s - loss: 0.5147 - acc: 0.8102 - val_loss: 1.0703 - val_acc: 0.7376\n",
      "Epoch 1397/2000\n",
      " - 1s - loss: 0.5598 - acc: 0.7956 - val_loss: 1.1569 - val_acc: 0.7114\n",
      "Epoch 1398/2000\n",
      " - 1s - loss: 0.5699 - acc: 0.7956 - val_loss: 1.1363 - val_acc: 0.7172\n",
      "Epoch 1399/2000\n",
      " - 1s - loss: 0.5984 - acc: 0.7861 - val_loss: 1.1519 - val_acc: 0.7085\n",
      "Epoch 1400/2000\n",
      " - 1s - loss: 0.5340 - acc: 0.8036 - val_loss: 1.3359 - val_acc: 0.6968\n",
      "Epoch 1401/2000\n",
      " - 1s - loss: 0.5955 - acc: 0.7825 - val_loss: 1.1762 - val_acc: 0.7230\n",
      "Epoch 1402/2000\n",
      " - 1s - loss: 0.6334 - acc: 0.7883 - val_loss: 1.2577 - val_acc: 0.6735\n",
      "Epoch 1403/2000\n",
      " - 0s - loss: 0.7384 - acc: 0.7555 - val_loss: 1.1999 - val_acc: 0.6968\n",
      "Epoch 1404/2000\n",
      " - 1s - loss: 0.6451 - acc: 0.7781 - val_loss: 1.1672 - val_acc: 0.7114\n",
      "Epoch 1405/2000\n",
      " - 1s - loss: 0.5698 - acc: 0.7985 - val_loss: 1.1087 - val_acc: 0.7259\n",
      "Epoch 1406/2000\n",
      " - 1s - loss: 0.6109 - acc: 0.7664 - val_loss: 1.1294 - val_acc: 0.7114\n",
      "Epoch 1407/2000\n",
      " - 1s - loss: 0.7121 - acc: 0.7540 - val_loss: 1.1189 - val_acc: 0.7055\n",
      "Epoch 1408/2000\n",
      " - 1s - loss: 0.6477 - acc: 0.7693 - val_loss: 1.2089 - val_acc: 0.7172\n",
      "Epoch 1409/2000\n",
      " - 1s - loss: 0.6843 - acc: 0.7620 - val_loss: 1.2565 - val_acc: 0.7026\n",
      "Epoch 1410/2000\n",
      " - 1s - loss: 0.6192 - acc: 0.7774 - val_loss: 1.2661 - val_acc: 0.6851\n",
      "Epoch 1411/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7818 - val_loss: 1.2067 - val_acc: 0.7172\n",
      "Epoch 1412/2000\n",
      " - 1s - loss: 0.5935 - acc: 0.7810 - val_loss: 1.1373 - val_acc: 0.7143\n",
      "Epoch 1413/2000\n",
      " - 1s - loss: 0.6570 - acc: 0.7657 - val_loss: 1.1040 - val_acc: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1414/2000\n",
      " - 1s - loss: 0.5519 - acc: 0.7956 - val_loss: 1.1883 - val_acc: 0.7259\n",
      "Epoch 1415/2000\n",
      " - 1s - loss: 0.6089 - acc: 0.7905 - val_loss: 1.2235 - val_acc: 0.7143\n",
      "Epoch 1416/2000\n",
      " - 1s - loss: 0.6456 - acc: 0.7701 - val_loss: 1.4318 - val_acc: 0.6880\n",
      "Epoch 1417/2000\n",
      " - 1s - loss: 0.7248 - acc: 0.7467 - val_loss: 1.3606 - val_acc: 0.7026\n",
      "Epoch 1418/2000\n",
      " - 1s - loss: 0.6411 - acc: 0.7774 - val_loss: 1.1570 - val_acc: 0.7055\n",
      "Epoch 1419/2000\n",
      " - 1s - loss: 0.5468 - acc: 0.8066 - val_loss: 1.2205 - val_acc: 0.7085\n",
      "Epoch 1420/2000\n",
      " - 1s - loss: 0.7170 - acc: 0.7591 - val_loss: 1.4223 - val_acc: 0.6968\n",
      "Epoch 1421/2000\n",
      " - 1s - loss: 0.6559 - acc: 0.7730 - val_loss: 1.2622 - val_acc: 0.7055\n",
      "Epoch 1422/2000\n",
      " - 1s - loss: 0.6382 - acc: 0.7737 - val_loss: 1.2482 - val_acc: 0.7085\n",
      "Epoch 1423/2000\n",
      " - 1s - loss: 0.5723 - acc: 0.8051 - val_loss: 1.2103 - val_acc: 0.7085\n",
      "Epoch 1424/2000\n",
      " - 1s - loss: 0.5778 - acc: 0.7920 - val_loss: 1.3283 - val_acc: 0.7026\n",
      "Epoch 1425/2000\n",
      " - 1s - loss: 0.6244 - acc: 0.7810 - val_loss: 1.1463 - val_acc: 0.7376\n",
      "Epoch 1426/2000\n",
      " - 1s - loss: 0.6142 - acc: 0.7737 - val_loss: 1.1921 - val_acc: 0.6968\n",
      "Epoch 1427/2000\n",
      " - 1s - loss: 0.6223 - acc: 0.7839 - val_loss: 1.2781 - val_acc: 0.6997\n",
      "Epoch 1428/2000\n",
      " - 1s - loss: 0.6048 - acc: 0.7752 - val_loss: 1.1688 - val_acc: 0.7289\n",
      "Epoch 1429/2000\n",
      " - 1s - loss: 0.5804 - acc: 0.7803 - val_loss: 1.2261 - val_acc: 0.7055\n",
      "Epoch 1430/2000\n",
      " - 2s - loss: 0.6122 - acc: 0.7788 - val_loss: 1.1144 - val_acc: 0.7230\n",
      "Epoch 1431/2000\n",
      " - 1s - loss: 0.6133 - acc: 0.7847 - val_loss: 1.1537 - val_acc: 0.6968\n",
      "Epoch 1432/2000\n",
      " - 1s - loss: 0.8070 - acc: 0.7365 - val_loss: 1.2005 - val_acc: 0.6764\n",
      "Epoch 1433/2000\n",
      " - 2s - loss: 0.6361 - acc: 0.7708 - val_loss: 1.2202 - val_acc: 0.6939\n",
      "Epoch 1434/2000\n",
      " - 2s - loss: 0.6451 - acc: 0.7810 - val_loss: 1.3273 - val_acc: 0.6793\n",
      "Epoch 1435/2000\n",
      " - 2s - loss: 0.5979 - acc: 0.7956 - val_loss: 1.2707 - val_acc: 0.7055\n",
      "Epoch 1436/2000\n",
      " - 2s - loss: 0.6118 - acc: 0.7766 - val_loss: 1.2039 - val_acc: 0.7026\n",
      "Epoch 1437/2000\n",
      " - 1s - loss: 0.5571 - acc: 0.8073 - val_loss: 1.1925 - val_acc: 0.7143\n",
      "Epoch 1438/2000\n",
      " - 1s - loss: 0.5588 - acc: 0.7978 - val_loss: 1.1584 - val_acc: 0.7259\n",
      "Epoch 1439/2000\n",
      " - 1s - loss: 0.9027 - acc: 0.7255 - val_loss: 1.1691 - val_acc: 0.6939\n",
      "Epoch 1440/2000\n",
      " - 0s - loss: 0.6842 - acc: 0.7635 - val_loss: 1.1738 - val_acc: 0.6968\n",
      "Epoch 1441/2000\n",
      " - 1s - loss: 0.5926 - acc: 0.7942 - val_loss: 1.1234 - val_acc: 0.7289\n",
      "Epoch 1442/2000\n",
      " - 1s - loss: 0.6433 - acc: 0.7635 - val_loss: 1.1420 - val_acc: 0.7114\n",
      "Epoch 1443/2000\n",
      " - 1s - loss: 0.5780 - acc: 0.8066 - val_loss: 1.1937 - val_acc: 0.7172\n",
      "Epoch 1444/2000\n",
      " - 1s - loss: 0.6131 - acc: 0.7803 - val_loss: 1.1668 - val_acc: 0.7143\n",
      "Epoch 1445/2000\n",
      " - 1s - loss: 0.5736 - acc: 0.7869 - val_loss: 1.2062 - val_acc: 0.7172\n",
      "Epoch 1446/2000\n",
      " - 1s - loss: 0.5660 - acc: 0.7956 - val_loss: 1.2123 - val_acc: 0.7143\n",
      "Epoch 1447/2000\n",
      " - 1s - loss: 0.5592 - acc: 0.7861 - val_loss: 1.1528 - val_acc: 0.7230\n",
      "Epoch 1448/2000\n",
      " - 0s - loss: 0.5704 - acc: 0.7956 - val_loss: 1.3266 - val_acc: 0.6910\n",
      "Epoch 1449/2000\n",
      " - 1s - loss: 0.6472 - acc: 0.7672 - val_loss: 1.2362 - val_acc: 0.7114\n",
      "Epoch 1450/2000\n",
      " - 1s - loss: 0.5785 - acc: 0.7876 - val_loss: 1.1517 - val_acc: 0.7318\n",
      "Epoch 1451/2000\n",
      " - 1s - loss: 0.6375 - acc: 0.7861 - val_loss: 1.2800 - val_acc: 0.7114\n",
      "Epoch 1452/2000\n",
      " - 1s - loss: 0.6384 - acc: 0.7810 - val_loss: 1.2655 - val_acc: 0.6997\n",
      "Epoch 1453/2000\n",
      " - 1s - loss: 0.5628 - acc: 0.7847 - val_loss: 1.3313 - val_acc: 0.6880\n",
      "Epoch 1454/2000\n",
      " - 1s - loss: 0.6254 - acc: 0.7723 - val_loss: 1.0955 - val_acc: 0.7143\n",
      "Epoch 1455/2000\n",
      " - 1s - loss: 0.5646 - acc: 0.7883 - val_loss: 1.1417 - val_acc: 0.7114\n",
      "Epoch 1456/2000\n",
      " - 1s - loss: 0.6107 - acc: 0.7854 - val_loss: 1.1490 - val_acc: 0.6939\n",
      "Epoch 1457/2000\n",
      " - 1s - loss: 0.5741 - acc: 0.7920 - val_loss: 1.1257 - val_acc: 0.7085\n",
      "Epoch 1458/2000\n",
      " - 1s - loss: 0.5530 - acc: 0.7898 - val_loss: 1.1336 - val_acc: 0.7201\n",
      "Epoch 1459/2000\n",
      " - 1s - loss: 0.5725 - acc: 0.7985 - val_loss: 1.2054 - val_acc: 0.7143\n",
      "Epoch 1460/2000\n",
      " - 1s - loss: 0.5874 - acc: 0.7942 - val_loss: 1.1962 - val_acc: 0.7026\n",
      "Epoch 1461/2000\n",
      " - 1s - loss: 0.5724 - acc: 0.7985 - val_loss: 1.2025 - val_acc: 0.7143\n",
      "Epoch 1462/2000\n",
      " - 1s - loss: 0.5642 - acc: 0.7964 - val_loss: 1.1915 - val_acc: 0.6910\n",
      "Epoch 1463/2000\n",
      " - 1s - loss: 0.5798 - acc: 0.7971 - val_loss: 1.2029 - val_acc: 0.6880\n",
      "Epoch 1464/2000\n",
      " - 1s - loss: 0.6058 - acc: 0.7781 - val_loss: 1.2548 - val_acc: 0.6968\n",
      "Epoch 1465/2000\n",
      " - 1s - loss: 0.6200 - acc: 0.7737 - val_loss: 1.2078 - val_acc: 0.7055\n",
      "Epoch 1466/2000\n",
      " - 1s - loss: 0.5390 - acc: 0.8000 - val_loss: 1.2749 - val_acc: 0.6910\n",
      "Epoch 1467/2000\n",
      " - 1s - loss: 0.5645 - acc: 0.7905 - val_loss: 1.2590 - val_acc: 0.6910\n",
      "Epoch 1468/2000\n",
      " - 1s - loss: 0.6016 - acc: 0.7825 - val_loss: 1.2435 - val_acc: 0.7085\n",
      "Epoch 1469/2000\n",
      " - 0s - loss: 0.6524 - acc: 0.7788 - val_loss: 1.1970 - val_acc: 0.7055\n",
      "Epoch 1470/2000\n",
      " - 1s - loss: 0.5915 - acc: 0.7949 - val_loss: 1.2492 - val_acc: 0.6793\n",
      "Epoch 1471/2000\n",
      " - 1s - loss: 0.5912 - acc: 0.7942 - val_loss: 1.1447 - val_acc: 0.7289\n",
      "Epoch 1472/2000\n",
      " - 1s - loss: 0.6243 - acc: 0.7752 - val_loss: 1.2309 - val_acc: 0.6822\n",
      "Epoch 1473/2000\n",
      " - 0s - loss: 0.6025 - acc: 0.7803 - val_loss: 1.3145 - val_acc: 0.6939\n",
      "Epoch 1474/2000\n",
      " - 0s - loss: 0.5709 - acc: 0.7898 - val_loss: 1.1845 - val_acc: 0.7085\n",
      "Epoch 1475/2000\n",
      " - 0s - loss: 0.5807 - acc: 0.8007 - val_loss: 1.2129 - val_acc: 0.6968\n",
      "Epoch 1476/2000\n",
      " - 0s - loss: 0.5845 - acc: 0.7920 - val_loss: 1.2561 - val_acc: 0.6939\n",
      "Epoch 1477/2000\n",
      " - 1s - loss: 0.5582 - acc: 0.7883 - val_loss: 1.2615 - val_acc: 0.7201\n",
      "Epoch 1478/2000\n",
      " - 1s - loss: 0.5820 - acc: 0.7942 - val_loss: 1.2949 - val_acc: 0.6880\n",
      "Epoch 1479/2000\n",
      " - 1s - loss: 0.6175 - acc: 0.7825 - val_loss: 1.1596 - val_acc: 0.6939\n",
      "Epoch 1480/2000\n",
      " - 1s - loss: 0.5493 - acc: 0.7905 - val_loss: 1.1338 - val_acc: 0.7055\n",
      "Epoch 1481/2000\n",
      " - 1s - loss: 0.5626 - acc: 0.7971 - val_loss: 1.2033 - val_acc: 0.6910\n",
      "Epoch 1482/2000\n",
      " - 1s - loss: 0.6059 - acc: 0.7781 - val_loss: 1.3267 - val_acc: 0.6910\n",
      "Epoch 1483/2000\n",
      " - 1s - loss: 0.6223 - acc: 0.7766 - val_loss: 1.0636 - val_acc: 0.7405\n",
      "Epoch 1484/2000\n",
      " - 1s - loss: 0.5845 - acc: 0.7905 - val_loss: 1.5042 - val_acc: 0.6414\n",
      "Epoch 1485/2000\n",
      " - 1s - loss: 1.0641 - acc: 0.6905 - val_loss: 1.2999 - val_acc: 0.7114\n",
      "Epoch 1486/2000\n",
      " - 1s - loss: 0.8007 - acc: 0.7219 - val_loss: 1.1916 - val_acc: 0.6851\n",
      "Epoch 1487/2000\n",
      " - 1s - loss: 0.6912 - acc: 0.7591 - val_loss: 1.1201 - val_acc: 0.7114\n",
      "Epoch 1488/2000\n",
      " - 1s - loss: 0.6581 - acc: 0.7584 - val_loss: 1.1064 - val_acc: 0.7259\n",
      "Epoch 1489/2000\n",
      " - 1s - loss: 0.5564 - acc: 0.8022 - val_loss: 1.1120 - val_acc: 0.7085\n",
      "Epoch 1490/2000\n",
      " - 1s - loss: 0.5416 - acc: 0.8073 - val_loss: 1.1650 - val_acc: 0.7114\n",
      "Epoch 1491/2000\n",
      " - 1s - loss: 0.5431 - acc: 0.7971 - val_loss: 1.2501 - val_acc: 0.7114\n",
      "Epoch 1492/2000\n",
      " - 1s - loss: 0.5406 - acc: 0.7985 - val_loss: 1.1689 - val_acc: 0.7055\n",
      "Epoch 1493/2000\n",
      " - 1s - loss: 0.5894 - acc: 0.7839 - val_loss: 1.2168 - val_acc: 0.6968\n",
      "Epoch 1494/2000\n",
      " - 1s - loss: 0.5901 - acc: 0.8000 - val_loss: 1.2508 - val_acc: 0.6997\n",
      "Epoch 1495/2000\n",
      " - 1s - loss: 0.7581 - acc: 0.7504 - val_loss: 1.1429 - val_acc: 0.6910\n",
      "Epoch 1496/2000\n",
      " - 1s - loss: 0.6958 - acc: 0.7591 - val_loss: 1.1800 - val_acc: 0.6851\n",
      "Epoch 1497/2000\n",
      " - 0s - loss: 0.5595 - acc: 0.7832 - val_loss: 1.1938 - val_acc: 0.6880\n",
      "Epoch 1498/2000\n",
      " - 1s - loss: 0.5491 - acc: 0.7993 - val_loss: 1.2291 - val_acc: 0.6968\n",
      "Epoch 1499/2000\n",
      " - 0s - loss: 0.6122 - acc: 0.7796 - val_loss: 1.1262 - val_acc: 0.7201\n",
      "Epoch 1500/2000\n",
      " - 1s - loss: 0.5829 - acc: 0.8022 - val_loss: 1.2114 - val_acc: 0.6968\n",
      "Epoch 1501/2000\n",
      " - 0s - loss: 0.5578 - acc: 0.7927 - val_loss: 1.1463 - val_acc: 0.7114\n",
      "Epoch 1502/2000\n",
      " - 1s - loss: 0.5276 - acc: 0.8117 - val_loss: 1.2249 - val_acc: 0.6910\n",
      "Epoch 1503/2000\n",
      " - 1s - loss: 0.6165 - acc: 0.7869 - val_loss: 1.1769 - val_acc: 0.7201\n",
      "Epoch 1504/2000\n",
      " - 1s - loss: 0.5484 - acc: 0.8124 - val_loss: 1.2424 - val_acc: 0.6939\n",
      "Epoch 1505/2000\n",
      " - 1s - loss: 0.6859 - acc: 0.7723 - val_loss: 1.4146 - val_acc: 0.6793\n",
      "Epoch 1506/2000\n",
      " - 1s - loss: 0.6728 - acc: 0.7774 - val_loss: 1.2772 - val_acc: 0.7172\n",
      "Epoch 1507/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6606 - acc: 0.7847 - val_loss: 1.0604 - val_acc: 0.7376\n",
      "Epoch 1508/2000\n",
      " - 1s - loss: 0.6137 - acc: 0.7869 - val_loss: 1.2003 - val_acc: 0.7114\n",
      "Epoch 1509/2000\n",
      " - 1s - loss: 0.5728 - acc: 0.7920 - val_loss: 1.2399 - val_acc: 0.6910\n",
      "Epoch 1510/2000\n",
      " - 1s - loss: 0.5948 - acc: 0.7905 - val_loss: 1.0689 - val_acc: 0.7085\n",
      "Epoch 1511/2000\n",
      " - 1s - loss: 0.5965 - acc: 0.7869 - val_loss: 1.1637 - val_acc: 0.7114\n",
      "Epoch 1512/2000\n",
      " - 1s - loss: 0.5993 - acc: 0.7825 - val_loss: 1.2963 - val_acc: 0.6851\n",
      "Epoch 1513/2000\n",
      " - 1s - loss: 0.7171 - acc: 0.7496 - val_loss: 1.2316 - val_acc: 0.7026\n",
      "Epoch 1514/2000\n",
      " - 1s - loss: 0.6318 - acc: 0.7854 - val_loss: 1.3014 - val_acc: 0.6851\n",
      "Epoch 1515/2000\n",
      " - 0s - loss: 0.7324 - acc: 0.7547 - val_loss: 1.1230 - val_acc: 0.7376\n",
      "Epoch 1516/2000\n",
      " - 1s - loss: 0.5904 - acc: 0.7825 - val_loss: 1.1720 - val_acc: 0.7172\n",
      "Epoch 1517/2000\n",
      " - 1s - loss: 0.5865 - acc: 0.7891 - val_loss: 1.1382 - val_acc: 0.7085\n",
      "Epoch 1518/2000\n",
      " - 1s - loss: 0.5909 - acc: 0.7854 - val_loss: 1.2954 - val_acc: 0.6764\n",
      "Epoch 1519/2000\n",
      " - 1s - loss: 0.8459 - acc: 0.7234 - val_loss: 1.6158 - val_acc: 0.6472\n",
      "Epoch 1520/2000\n",
      " - 1s - loss: 0.9045 - acc: 0.6956 - val_loss: 1.3175 - val_acc: 0.6618\n",
      "Epoch 1521/2000\n",
      " - 1s - loss: 0.7437 - acc: 0.7307 - val_loss: 1.1632 - val_acc: 0.6997\n",
      "Epoch 1522/2000\n",
      " - 1s - loss: 0.5800 - acc: 0.7920 - val_loss: 1.1193 - val_acc: 0.7259\n",
      "Epoch 1523/2000\n",
      " - 1s - loss: 0.5686 - acc: 0.7956 - val_loss: 1.0929 - val_acc: 0.7172\n",
      "Epoch 1524/2000\n",
      " - 1s - loss: 0.5465 - acc: 0.7956 - val_loss: 1.0840 - val_acc: 0.7347\n",
      "Epoch 1525/2000\n",
      " - 1s - loss: 0.5470 - acc: 0.8036 - val_loss: 1.1284 - val_acc: 0.7201\n",
      "Epoch 1526/2000\n",
      " - 1s - loss: 0.5248 - acc: 0.7964 - val_loss: 1.1452 - val_acc: 0.7172\n",
      "Epoch 1527/2000\n",
      " - 1s - loss: 0.5899 - acc: 0.7876 - val_loss: 1.0970 - val_acc: 0.7318\n",
      "Epoch 1528/2000\n",
      " - 1s - loss: 0.5924 - acc: 0.7715 - val_loss: 1.1869 - val_acc: 0.7143\n",
      "Epoch 1529/2000\n",
      " - 1s - loss: 0.6665 - acc: 0.7810 - val_loss: 1.4222 - val_acc: 0.6560\n",
      "Epoch 1530/2000\n",
      " - 0s - loss: 0.7184 - acc: 0.7701 - val_loss: 1.2108 - val_acc: 0.7055\n",
      "Epoch 1531/2000\n",
      " - 1s - loss: 0.6525 - acc: 0.7839 - val_loss: 1.1097 - val_acc: 0.7201\n",
      "Epoch 1532/2000\n",
      " - 0s - loss: 0.5974 - acc: 0.7949 - val_loss: 1.0992 - val_acc: 0.7172\n",
      "Epoch 1533/2000\n",
      " - 1s - loss: 0.5266 - acc: 0.8015 - val_loss: 1.2023 - val_acc: 0.7143\n",
      "Epoch 1534/2000\n",
      " - 1s - loss: 0.5527 - acc: 0.8051 - val_loss: 1.2694 - val_acc: 0.6880\n",
      "Epoch 1535/2000\n",
      " - 0s - loss: 0.5759 - acc: 0.7993 - val_loss: 1.1651 - val_acc: 0.7143\n",
      "Epoch 1536/2000\n",
      " - 0s - loss: 0.5557 - acc: 0.7964 - val_loss: 1.1524 - val_acc: 0.7114\n",
      "Epoch 1537/2000\n",
      " - 0s - loss: 0.5245 - acc: 0.8029 - val_loss: 1.1315 - val_acc: 0.7055\n",
      "Epoch 1538/2000\n",
      " - 1s - loss: 0.5456 - acc: 0.7971 - val_loss: 1.2469 - val_acc: 0.7143\n",
      "Epoch 1539/2000\n",
      " - 1s - loss: 0.5525 - acc: 0.8109 - val_loss: 1.1222 - val_acc: 0.7230\n",
      "Epoch 1540/2000\n",
      " - 0s - loss: 0.5569 - acc: 0.8051 - val_loss: 1.1658 - val_acc: 0.7026\n",
      "Epoch 1541/2000\n",
      " - 1s - loss: 0.5821 - acc: 0.7818 - val_loss: 1.2226 - val_acc: 0.7085\n",
      "Epoch 1542/2000\n",
      " - 1s - loss: 0.5431 - acc: 0.8088 - val_loss: 1.1529 - val_acc: 0.7172\n",
      "Epoch 1543/2000\n",
      " - 1s - loss: 0.5459 - acc: 0.8080 - val_loss: 1.2177 - val_acc: 0.6706\n",
      "Epoch 1544/2000\n",
      " - 1s - loss: 0.5459 - acc: 0.7912 - val_loss: 1.1452 - val_acc: 0.7259\n",
      "Epoch 1545/2000\n",
      " - 1s - loss: 0.5523 - acc: 0.8015 - val_loss: 1.2029 - val_acc: 0.7026\n",
      "Epoch 1546/2000\n",
      " - 1s - loss: 0.6704 - acc: 0.7715 - val_loss: 1.2875 - val_acc: 0.6735\n",
      "Epoch 1547/2000\n",
      " - 1s - loss: 0.6307 - acc: 0.7723 - val_loss: 1.1581 - val_acc: 0.7055\n",
      "Epoch 1548/2000\n",
      " - 1s - loss: 0.6550 - acc: 0.7737 - val_loss: 1.3330 - val_acc: 0.6706\n",
      "Epoch 1549/2000\n",
      " - 0s - loss: 0.6395 - acc: 0.7715 - val_loss: 1.1338 - val_acc: 0.7289\n",
      "Epoch 1550/2000\n",
      " - 1s - loss: 0.5967 - acc: 0.7971 - val_loss: 1.1243 - val_acc: 0.7085\n",
      "Epoch 1551/2000\n",
      " - 1s - loss: 0.5657 - acc: 0.8029 - val_loss: 1.2194 - val_acc: 0.7085\n",
      "Epoch 1552/2000\n",
      " - 1s - loss: 0.5551 - acc: 0.7964 - val_loss: 1.2325 - val_acc: 0.6968\n",
      "Epoch 1553/2000\n",
      " - 1s - loss: 0.5626 - acc: 0.7971 - val_loss: 1.2911 - val_acc: 0.6968\n",
      "Epoch 1554/2000\n",
      " - 1s - loss: 0.6479 - acc: 0.7642 - val_loss: 1.2898 - val_acc: 0.7085\n",
      "Epoch 1555/2000\n",
      " - 1s - loss: 0.5703 - acc: 0.8088 - val_loss: 1.1747 - val_acc: 0.7230\n",
      "Epoch 1556/2000\n",
      " - 1s - loss: 0.6365 - acc: 0.7745 - val_loss: 1.3447 - val_acc: 0.6560\n",
      "Epoch 1557/2000\n",
      " - 1s - loss: 0.7837 - acc: 0.7431 - val_loss: 1.3311 - val_acc: 0.6822\n",
      "Epoch 1558/2000\n",
      " - 1s - loss: 0.8247 - acc: 0.7307 - val_loss: 1.1874 - val_acc: 0.7376\n",
      "Epoch 1559/2000\n",
      " - 1s - loss: 0.6795 - acc: 0.7657 - val_loss: 1.0644 - val_acc: 0.6968\n",
      "Epoch 1560/2000\n",
      " - 1s - loss: 0.6210 - acc: 0.7701 - val_loss: 1.1163 - val_acc: 0.7055\n",
      "Epoch 1561/2000\n",
      " - 1s - loss: 0.6127 - acc: 0.7832 - val_loss: 1.1316 - val_acc: 0.7114\n",
      "Epoch 1562/2000\n",
      " - 1s - loss: 0.6329 - acc: 0.7774 - val_loss: 1.1480 - val_acc: 0.7230\n",
      "Epoch 1563/2000\n",
      " - 1s - loss: 0.5651 - acc: 0.7934 - val_loss: 1.2346 - val_acc: 0.7055\n",
      "Epoch 1564/2000\n",
      " - 1s - loss: 0.5783 - acc: 0.7883 - val_loss: 1.1751 - val_acc: 0.7085\n",
      "Epoch 1565/2000\n",
      " - 1s - loss: 0.5655 - acc: 0.8022 - val_loss: 1.1908 - val_acc: 0.7114\n",
      "Epoch 1566/2000\n",
      " - 1s - loss: 0.5411 - acc: 0.7956 - val_loss: 1.2011 - val_acc: 0.6910\n",
      "Epoch 1567/2000\n",
      " - 1s - loss: 0.6528 - acc: 0.7672 - val_loss: 1.1234 - val_acc: 0.7143\n",
      "Epoch 1568/2000\n",
      " - 1s - loss: 0.5769 - acc: 0.8000 - val_loss: 1.3069 - val_acc: 0.6706\n",
      "Epoch 1569/2000\n",
      " - 1s - loss: 0.6238 - acc: 0.7635 - val_loss: 1.2022 - val_acc: 0.6793\n",
      "Epoch 1570/2000\n",
      " - 0s - loss: 0.6003 - acc: 0.7686 - val_loss: 1.3007 - val_acc: 0.6793\n",
      "Epoch 1571/2000\n",
      " - 1s - loss: 0.6508 - acc: 0.7599 - val_loss: 1.4000 - val_acc: 0.6851\n",
      "Epoch 1572/2000\n",
      " - 0s - loss: 0.7694 - acc: 0.7380 - val_loss: 1.3312 - val_acc: 0.6910\n",
      "Epoch 1573/2000\n",
      " - 1s - loss: 0.6958 - acc: 0.7730 - val_loss: 1.2031 - val_acc: 0.7114\n",
      "Epoch 1574/2000\n",
      " - 1s - loss: 0.6601 - acc: 0.7672 - val_loss: 1.1073 - val_acc: 0.7289\n",
      "Epoch 1575/2000\n",
      " - 1s - loss: 0.6167 - acc: 0.7693 - val_loss: 1.1036 - val_acc: 0.7259\n",
      "Epoch 1576/2000\n",
      " - 1s - loss: 0.5665 - acc: 0.7883 - val_loss: 1.1792 - val_acc: 0.7172\n",
      "Epoch 1577/2000\n",
      " - 0s - loss: 0.5582 - acc: 0.8058 - val_loss: 1.1652 - val_acc: 0.7259\n",
      "Epoch 1578/2000\n",
      " - 1s - loss: 0.5475 - acc: 0.8058 - val_loss: 1.2505 - val_acc: 0.7085\n",
      "Epoch 1579/2000\n",
      " - 0s - loss: 0.5624 - acc: 0.7978 - val_loss: 1.2364 - val_acc: 0.6997\n",
      "Epoch 1580/2000\n",
      " - 1s - loss: 0.6781 - acc: 0.7628 - val_loss: 1.2213 - val_acc: 0.6939\n",
      "Epoch 1581/2000\n",
      " - 1s - loss: 0.6629 - acc: 0.7715 - val_loss: 1.2473 - val_acc: 0.7085\n",
      "Epoch 1582/2000\n",
      " - 1s - loss: 0.6311 - acc: 0.7891 - val_loss: 1.1573 - val_acc: 0.7055\n",
      "Epoch 1583/2000\n",
      " - 1s - loss: 0.6901 - acc: 0.7788 - val_loss: 1.3682 - val_acc: 0.6764\n",
      "Epoch 1584/2000\n",
      " - 1s - loss: 0.6054 - acc: 0.7796 - val_loss: 1.1206 - val_acc: 0.7172\n",
      "Epoch 1585/2000\n",
      " - 1s - loss: 0.5440 - acc: 0.8015 - val_loss: 1.1200 - val_acc: 0.7026\n",
      "Epoch 1586/2000\n",
      " - 0s - loss: 0.5743 - acc: 0.7956 - val_loss: 1.2189 - val_acc: 0.7172\n",
      "Epoch 1587/2000\n",
      " - 0s - loss: 0.5880 - acc: 0.7978 - val_loss: 1.2576 - val_acc: 0.7026\n",
      "Epoch 1588/2000\n",
      " - 0s - loss: 0.6057 - acc: 0.8000 - val_loss: 1.2319 - val_acc: 0.6851\n",
      "Epoch 1589/2000\n",
      " - 1s - loss: 0.5730 - acc: 0.7964 - val_loss: 1.2586 - val_acc: 0.6968\n",
      "Epoch 1590/2000\n",
      " - 0s - loss: 0.6090 - acc: 0.7876 - val_loss: 1.1453 - val_acc: 0.7026\n",
      "Epoch 1591/2000\n",
      " - 0s - loss: 0.6209 - acc: 0.7839 - val_loss: 1.1847 - val_acc: 0.7026\n",
      "Epoch 1592/2000\n",
      " - 0s - loss: 0.5417 - acc: 0.8007 - val_loss: 1.1383 - val_acc: 0.7347\n",
      "Epoch 1593/2000\n",
      " - 0s - loss: 0.5723 - acc: 0.7949 - val_loss: 1.2282 - val_acc: 0.6910\n",
      "Epoch 1594/2000\n",
      " - 1s - loss: 0.6159 - acc: 0.7956 - val_loss: 1.1612 - val_acc: 0.7230\n",
      "Epoch 1595/2000\n",
      " - 1s - loss: 0.5466 - acc: 0.8044 - val_loss: 1.2716 - val_acc: 0.6822\n",
      "Epoch 1596/2000\n",
      " - 1s - loss: 0.5347 - acc: 0.8102 - val_loss: 1.2813 - val_acc: 0.6735\n",
      "Epoch 1597/2000\n",
      " - 1s - loss: 0.6011 - acc: 0.7869 - val_loss: 1.1688 - val_acc: 0.7201\n",
      "Epoch 1598/2000\n",
      " - 0s - loss: 0.5687 - acc: 0.7883 - val_loss: 1.1250 - val_acc: 0.7143\n",
      "Epoch 1599/2000\n",
      " - 0s - loss: 0.6130 - acc: 0.7825 - val_loss: 1.2525 - val_acc: 0.6968\n",
      "Epoch 1600/2000\n",
      " - 0s - loss: 0.6214 - acc: 0.7803 - val_loss: 1.2089 - val_acc: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      " - 1s - loss: 0.6124 - acc: 0.7774 - val_loss: 1.1556 - val_acc: 0.7230\n",
      "Epoch 1602/2000\n",
      " - 1s - loss: 0.5879 - acc: 0.7891 - val_loss: 1.2116 - val_acc: 0.7055\n",
      "Epoch 1603/2000\n",
      " - 0s - loss: 0.5797 - acc: 0.7920 - val_loss: 1.1802 - val_acc: 0.7085\n",
      "Epoch 1604/2000\n",
      " - 0s - loss: 0.5673 - acc: 0.7942 - val_loss: 1.2612 - val_acc: 0.7085\n",
      "Epoch 1605/2000\n",
      " - 1s - loss: 0.7034 - acc: 0.7628 - val_loss: 1.3727 - val_acc: 0.6764\n",
      "Epoch 1606/2000\n",
      " - 1s - loss: 0.7237 - acc: 0.7562 - val_loss: 1.1142 - val_acc: 0.7230\n",
      "Epoch 1607/2000\n",
      " - 0s - loss: 0.6404 - acc: 0.7825 - val_loss: 1.3064 - val_acc: 0.6851\n",
      "Epoch 1608/2000\n",
      " - 1s - loss: 0.6263 - acc: 0.7883 - val_loss: 1.1242 - val_acc: 0.7318\n",
      "Epoch 1609/2000\n",
      " - 0s - loss: 0.5860 - acc: 0.7869 - val_loss: 1.2068 - val_acc: 0.7026\n",
      "Epoch 1610/2000\n",
      " - 0s - loss: 0.6071 - acc: 0.7832 - val_loss: 1.2046 - val_acc: 0.7085\n",
      "Epoch 1611/2000\n",
      " - 1s - loss: 0.5811 - acc: 0.7978 - val_loss: 1.2734 - val_acc: 0.6997\n",
      "Epoch 1612/2000\n",
      " - 1s - loss: 0.5438 - acc: 0.8058 - val_loss: 1.1371 - val_acc: 0.6997\n",
      "Epoch 1613/2000\n",
      " - 1s - loss: 0.5850 - acc: 0.7942 - val_loss: 1.2166 - val_acc: 0.7026\n",
      "Epoch 1614/2000\n",
      " - 0s - loss: 0.8063 - acc: 0.7270 - val_loss: 1.0829 - val_acc: 0.7143\n",
      "Epoch 1615/2000\n",
      " - 1s - loss: 0.7918 - acc: 0.7445 - val_loss: 1.1438 - val_acc: 0.7026\n",
      "Epoch 1616/2000\n",
      " - 1s - loss: 0.7959 - acc: 0.7299 - val_loss: 1.1481 - val_acc: 0.7085\n",
      "Epoch 1617/2000\n",
      " - 1s - loss: 0.6442 - acc: 0.7745 - val_loss: 1.2799 - val_acc: 0.7230\n",
      "Epoch 1618/2000\n",
      " - 1s - loss: 0.5778 - acc: 0.7876 - val_loss: 1.2193 - val_acc: 0.6851\n",
      "Epoch 1619/2000\n",
      " - 1s - loss: 0.5457 - acc: 0.8146 - val_loss: 1.1703 - val_acc: 0.6997\n",
      "Epoch 1620/2000\n",
      " - 1s - loss: 0.5634 - acc: 0.7978 - val_loss: 1.1826 - val_acc: 0.7230\n",
      "Epoch 1621/2000\n",
      " - 1s - loss: 0.5540 - acc: 0.8029 - val_loss: 1.1880 - val_acc: 0.7143\n",
      "Epoch 1622/2000\n",
      " - 1s - loss: 0.5703 - acc: 0.8000 - val_loss: 1.0337 - val_acc: 0.7026\n",
      "Epoch 1623/2000\n",
      " - 1s - loss: 0.6436 - acc: 0.7788 - val_loss: 1.4570 - val_acc: 0.6472\n",
      "Epoch 1624/2000\n",
      " - 1s - loss: 0.7660 - acc: 0.7423 - val_loss: 1.0458 - val_acc: 0.7026\n",
      "Epoch 1625/2000\n",
      " - 1s - loss: 0.5893 - acc: 0.7964 - val_loss: 1.2111 - val_acc: 0.6939\n",
      "Epoch 1626/2000\n",
      " - 1s - loss: 0.5831 - acc: 0.7891 - val_loss: 1.1628 - val_acc: 0.6851\n",
      "Epoch 1627/2000\n",
      " - 0s - loss: 0.5731 - acc: 0.7964 - val_loss: 1.1394 - val_acc: 0.7114\n",
      "Epoch 1628/2000\n",
      " - 1s - loss: 0.5208 - acc: 0.8117 - val_loss: 1.1743 - val_acc: 0.7055\n",
      "Epoch 1629/2000\n",
      " - 1s - loss: 0.5446 - acc: 0.8022 - val_loss: 1.0865 - val_acc: 0.7143\n",
      "Epoch 1630/2000\n",
      " - 0s - loss: 0.5686 - acc: 0.7964 - val_loss: 1.1453 - val_acc: 0.7114\n",
      "Epoch 1631/2000\n",
      " - 0s - loss: 0.5842 - acc: 0.7832 - val_loss: 1.1482 - val_acc: 0.7055\n",
      "Epoch 1632/2000\n",
      " - 0s - loss: 0.5377 - acc: 0.8161 - val_loss: 1.1325 - val_acc: 0.6880\n",
      "Epoch 1633/2000\n",
      " - 1s - loss: 0.5902 - acc: 0.7876 - val_loss: 1.2259 - val_acc: 0.6880\n",
      "Epoch 1634/2000\n",
      " - 1s - loss: 0.6168 - acc: 0.7847 - val_loss: 1.1443 - val_acc: 0.7230\n",
      "Epoch 1635/2000\n",
      " - 1s - loss: 0.5748 - acc: 0.7912 - val_loss: 1.2761 - val_acc: 0.6851\n",
      "Epoch 1636/2000\n",
      " - 1s - loss: 0.6089 - acc: 0.7759 - val_loss: 1.2508 - val_acc: 0.6997\n",
      "Epoch 1637/2000\n",
      " - 0s - loss: 0.5974 - acc: 0.7964 - val_loss: 1.1401 - val_acc: 0.7172\n",
      "Epoch 1638/2000\n",
      " - 0s - loss: 0.5512 - acc: 0.8073 - val_loss: 1.1050 - val_acc: 0.7376\n",
      "Epoch 1639/2000\n",
      " - 0s - loss: 0.6017 - acc: 0.7788 - val_loss: 1.3267 - val_acc: 0.6851\n",
      "Epoch 1640/2000\n",
      " - 1s - loss: 0.6336 - acc: 0.7905 - val_loss: 1.1740 - val_acc: 0.6968\n",
      "Epoch 1641/2000\n",
      " - 1s - loss: 0.5959 - acc: 0.7839 - val_loss: 1.1191 - val_acc: 0.7172\n",
      "Epoch 1642/2000\n",
      " - 1s - loss: 0.5626 - acc: 0.7898 - val_loss: 1.1333 - val_acc: 0.7114\n",
      "Epoch 1643/2000\n",
      " - 1s - loss: 0.6116 - acc: 0.7985 - val_loss: 1.1865 - val_acc: 0.7172\n",
      "Epoch 1644/2000\n",
      " - 0s - loss: 0.5506 - acc: 0.8051 - val_loss: 1.2433 - val_acc: 0.6968\n",
      "Epoch 1645/2000\n",
      " - 1s - loss: 0.6060 - acc: 0.7912 - val_loss: 1.2156 - val_acc: 0.6880\n",
      "Epoch 1646/2000\n",
      " - 1s - loss: 0.6335 - acc: 0.7796 - val_loss: 1.2911 - val_acc: 0.6910\n",
      "Epoch 1647/2000\n",
      " - 0s - loss: 0.6741 - acc: 0.7591 - val_loss: 1.1704 - val_acc: 0.7085\n",
      "Epoch 1648/2000\n",
      " - 0s - loss: 0.5657 - acc: 0.7927 - val_loss: 1.1901 - val_acc: 0.7143\n",
      "Epoch 1649/2000\n",
      " - 1s - loss: 0.5481 - acc: 0.7883 - val_loss: 1.1021 - val_acc: 0.7143\n",
      "Epoch 1650/2000\n",
      " - 1s - loss: 0.5669 - acc: 0.7891 - val_loss: 1.1560 - val_acc: 0.6997\n",
      "Epoch 1651/2000\n",
      " - 0s - loss: 0.5408 - acc: 0.8044 - val_loss: 1.1763 - val_acc: 0.7230\n",
      "Epoch 1652/2000\n",
      " - 1s - loss: 0.5601 - acc: 0.7920 - val_loss: 1.2036 - val_acc: 0.7085\n",
      "Epoch 1653/2000\n",
      " - 1s - loss: 0.5975 - acc: 0.7869 - val_loss: 1.3554 - val_acc: 0.6764\n",
      "Epoch 1654/2000\n",
      " - 1s - loss: 0.8551 - acc: 0.7066 - val_loss: 1.2228 - val_acc: 0.6968\n",
      "Epoch 1655/2000\n",
      " - 1s - loss: 0.7559 - acc: 0.7460 - val_loss: 1.1096 - val_acc: 0.7230\n",
      "Epoch 1656/2000\n",
      " - 1s - loss: 0.6300 - acc: 0.7730 - val_loss: 1.2261 - val_acc: 0.6968\n",
      "Epoch 1657/2000\n",
      " - 0s - loss: 0.5513 - acc: 0.8044 - val_loss: 1.1792 - val_acc: 0.7085\n",
      "Epoch 1658/2000\n",
      " - 0s - loss: 0.6373 - acc: 0.7861 - val_loss: 1.2308 - val_acc: 0.6851\n",
      "Epoch 1659/2000\n",
      " - 1s - loss: 0.7059 - acc: 0.7672 - val_loss: 1.2898 - val_acc: 0.6764\n",
      "Epoch 1660/2000\n",
      " - 1s - loss: 0.6537 - acc: 0.7657 - val_loss: 1.0626 - val_acc: 0.7143\n",
      "Epoch 1661/2000\n",
      " - 0s - loss: 0.5840 - acc: 0.7949 - val_loss: 1.1826 - val_acc: 0.6939\n",
      "Epoch 1662/2000\n",
      " - 1s - loss: 0.5433 - acc: 0.7985 - val_loss: 1.0835 - val_acc: 0.7114\n",
      "Epoch 1663/2000\n",
      " - 1s - loss: 0.5550 - acc: 0.7985 - val_loss: 1.1562 - val_acc: 0.6880\n",
      "Epoch 1664/2000\n",
      " - 1s - loss: 0.5502 - acc: 0.8066 - val_loss: 1.2116 - val_acc: 0.6939\n",
      "Epoch 1665/2000\n",
      " - 1s - loss: 0.7122 - acc: 0.7562 - val_loss: 1.1537 - val_acc: 0.6822\n",
      "Epoch 1666/2000\n",
      " - 1s - loss: 0.6615 - acc: 0.7599 - val_loss: 1.2558 - val_acc: 0.6910\n",
      "Epoch 1667/2000\n",
      " - 0s - loss: 0.7427 - acc: 0.7416 - val_loss: 1.1061 - val_acc: 0.7259\n",
      "Epoch 1668/2000\n",
      " - 0s - loss: 0.6607 - acc: 0.7642 - val_loss: 1.1546 - val_acc: 0.6851\n",
      "Epoch 1669/2000\n",
      " - 0s - loss: 0.5488 - acc: 0.8015 - val_loss: 1.1185 - val_acc: 0.7026\n",
      "Epoch 1670/2000\n",
      " - 1s - loss: 0.5747 - acc: 0.7869 - val_loss: 1.1762 - val_acc: 0.7143\n",
      "Epoch 1671/2000\n",
      " - 1s - loss: 0.5729 - acc: 0.7978 - val_loss: 1.2358 - val_acc: 0.7026\n",
      "Epoch 1672/2000\n",
      " - 1s - loss: 0.5804 - acc: 0.7898 - val_loss: 1.1405 - val_acc: 0.7230\n",
      "Epoch 1673/2000\n",
      " - 1s - loss: 0.5725 - acc: 0.7839 - val_loss: 1.0813 - val_acc: 0.7201\n",
      "Epoch 1674/2000\n",
      " - 1s - loss: 0.5433 - acc: 0.8109 - val_loss: 1.1893 - val_acc: 0.7230\n",
      "Epoch 1675/2000\n",
      " - 1s - loss: 0.5454 - acc: 0.8088 - val_loss: 1.1559 - val_acc: 0.7114\n",
      "Epoch 1676/2000\n",
      " - 1s - loss: 0.6094 - acc: 0.7920 - val_loss: 1.2739 - val_acc: 0.6968\n",
      "Epoch 1677/2000\n",
      " - 0s - loss: 0.5712 - acc: 0.7985 - val_loss: 1.0622 - val_acc: 0.7347\n",
      "Epoch 1678/2000\n",
      " - 1s - loss: 0.5547 - acc: 0.7934 - val_loss: 1.1942 - val_acc: 0.7085\n",
      "Epoch 1679/2000\n",
      " - 0s - loss: 0.5757 - acc: 0.7854 - val_loss: 1.1367 - val_acc: 0.7259\n",
      "Epoch 1680/2000\n",
      " - 1s - loss: 0.5678 - acc: 0.7985 - val_loss: 1.1795 - val_acc: 0.7201\n",
      "Epoch 1681/2000\n",
      " - 1s - loss: 0.6213 - acc: 0.7759 - val_loss: 1.4075 - val_acc: 0.6910\n",
      "Epoch 1682/2000\n",
      " - 0s - loss: 0.7546 - acc: 0.7401 - val_loss: 1.1640 - val_acc: 0.6968\n",
      "Epoch 1683/2000\n",
      " - 1s - loss: 0.7415 - acc: 0.7540 - val_loss: 1.2017 - val_acc: 0.7114\n",
      "Epoch 1684/2000\n",
      " - 1s - loss: 0.6225 - acc: 0.7854 - val_loss: 1.1546 - val_acc: 0.7026\n",
      "Epoch 1685/2000\n",
      " - 1s - loss: 0.5736 - acc: 0.7978 - val_loss: 1.1084 - val_acc: 0.7201\n",
      "Epoch 1686/2000\n",
      " - 1s - loss: 0.5930 - acc: 0.7839 - val_loss: 1.2420 - val_acc: 0.6822\n",
      "Epoch 1687/2000\n",
      " - 1s - loss: 0.6646 - acc: 0.7569 - val_loss: 1.0512 - val_acc: 0.7201\n",
      "Epoch 1688/2000\n",
      " - 1s - loss: 0.5753 - acc: 0.7891 - val_loss: 1.2302 - val_acc: 0.7085\n",
      "Epoch 1689/2000\n",
      " - 1s - loss: 0.6011 - acc: 0.7927 - val_loss: 1.2824 - val_acc: 0.7026\n",
      "Epoch 1690/2000\n",
      " - 0s - loss: 0.7250 - acc: 0.7635 - val_loss: 1.2605 - val_acc: 0.6793\n",
      "Epoch 1691/2000\n",
      " - 0s - loss: 0.6937 - acc: 0.7620 - val_loss: 1.0831 - val_acc: 0.6997\n",
      "Epoch 1692/2000\n",
      " - 1s - loss: 0.6439 - acc: 0.7672 - val_loss: 1.1099 - val_acc: 0.7201\n",
      "Epoch 1693/2000\n",
      " - 1s - loss: 0.5702 - acc: 0.7912 - val_loss: 1.0682 - val_acc: 0.7376\n",
      "Epoch 1694/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.5360 - acc: 0.8073 - val_loss: 1.0726 - val_acc: 0.7289\n",
      "Epoch 1695/2000\n",
      " - 0s - loss: 0.5605 - acc: 0.7942 - val_loss: 1.0828 - val_acc: 0.7201\n",
      "Epoch 1696/2000\n",
      " - 0s - loss: 0.6365 - acc: 0.7810 - val_loss: 1.2822 - val_acc: 0.6793\n",
      "Epoch 1697/2000\n",
      " - 0s - loss: 0.6403 - acc: 0.7745 - val_loss: 1.3015 - val_acc: 0.6939\n",
      "Epoch 1698/2000\n",
      " - 0s - loss: 0.6323 - acc: 0.7664 - val_loss: 1.1425 - val_acc: 0.6939\n",
      "Epoch 1699/2000\n",
      " - 0s - loss: 0.5347 - acc: 0.8102 - val_loss: 1.0462 - val_acc: 0.7085\n",
      "Epoch 1700/2000\n",
      " - 0s - loss: 0.6094 - acc: 0.7847 - val_loss: 1.0762 - val_acc: 0.7230\n",
      "Epoch 1701/2000\n",
      " - 1s - loss: 0.5763 - acc: 0.8000 - val_loss: 1.1566 - val_acc: 0.7172\n",
      "Epoch 1702/2000\n",
      " - 1s - loss: 0.5655 - acc: 0.7985 - val_loss: 1.1531 - val_acc: 0.7172\n",
      "Epoch 1703/2000\n",
      " - 1s - loss: 0.5383 - acc: 0.8073 - val_loss: 1.1946 - val_acc: 0.6997\n",
      "Epoch 1704/2000\n",
      " - 0s - loss: 0.6004 - acc: 0.7825 - val_loss: 1.1395 - val_acc: 0.7114\n",
      "Epoch 1705/2000\n",
      " - 0s - loss: 0.6386 - acc: 0.7796 - val_loss: 1.2413 - val_acc: 0.7026\n",
      "Epoch 1706/2000\n",
      " - 1s - loss: 0.6486 - acc: 0.7745 - val_loss: 1.1727 - val_acc: 0.7026\n",
      "Epoch 1707/2000\n",
      " - 0s - loss: 0.5734 - acc: 0.7927 - val_loss: 1.2761 - val_acc: 0.6764\n",
      "Epoch 1708/2000\n",
      " - 1s - loss: 0.5308 - acc: 0.8190 - val_loss: 1.2513 - val_acc: 0.7085\n",
      "Epoch 1709/2000\n",
      " - 0s - loss: 0.5632 - acc: 0.8080 - val_loss: 1.1095 - val_acc: 0.7172\n",
      "Epoch 1710/2000\n",
      " - 1s - loss: 0.5901 - acc: 0.7847 - val_loss: 1.2143 - val_acc: 0.6968\n",
      "Epoch 1711/2000\n",
      " - 0s - loss: 0.6395 - acc: 0.7693 - val_loss: 1.0855 - val_acc: 0.7230\n",
      "Epoch 1712/2000\n",
      " - 0s - loss: 0.5772 - acc: 0.7934 - val_loss: 1.0929 - val_acc: 0.6968\n",
      "Epoch 1713/2000\n",
      " - 1s - loss: 0.7541 - acc: 0.7562 - val_loss: 1.1380 - val_acc: 0.7026\n",
      "Epoch 1714/2000\n",
      " - 1s - loss: 0.8656 - acc: 0.7080 - val_loss: 1.1393 - val_acc: 0.7114\n",
      "Epoch 1715/2000\n",
      " - 0s - loss: 0.6063 - acc: 0.7854 - val_loss: 1.1619 - val_acc: 0.7259\n",
      "Epoch 1716/2000\n",
      " - 0s - loss: 0.6601 - acc: 0.7803 - val_loss: 1.2132 - val_acc: 0.6764\n",
      "Epoch 1717/2000\n",
      " - 0s - loss: 0.6207 - acc: 0.7832 - val_loss: 1.1694 - val_acc: 0.6968\n",
      "Epoch 1718/2000\n",
      " - 1s - loss: 0.5591 - acc: 0.7934 - val_loss: 1.1411 - val_acc: 0.6968\n",
      "Epoch 1719/2000\n",
      " - 1s - loss: 0.5998 - acc: 0.7825 - val_loss: 1.1340 - val_acc: 0.7114\n",
      "Epoch 1720/2000\n",
      " - 1s - loss: 0.5448 - acc: 0.8073 - val_loss: 1.1530 - val_acc: 0.6997\n",
      "Epoch 1721/2000\n",
      " - 1s - loss: 0.5504 - acc: 0.7854 - val_loss: 1.1542 - val_acc: 0.7085\n",
      "Epoch 1722/2000\n",
      " - 1s - loss: 0.5584 - acc: 0.7971 - val_loss: 1.1265 - val_acc: 0.6939\n",
      "Epoch 1723/2000\n",
      " - 1s - loss: 0.5673 - acc: 0.7832 - val_loss: 1.1516 - val_acc: 0.7143\n",
      "Epoch 1724/2000\n",
      " - 1s - loss: 0.5887 - acc: 0.7759 - val_loss: 1.1106 - val_acc: 0.7230\n",
      "Epoch 1725/2000\n",
      " - 1s - loss: 0.5744 - acc: 0.7847 - val_loss: 1.4061 - val_acc: 0.6793\n",
      "Epoch 1726/2000\n",
      " - 0s - loss: 0.5711 - acc: 0.7971 - val_loss: 1.2595 - val_acc: 0.6910\n",
      "Epoch 1727/2000\n",
      " - 1s - loss: 0.5315 - acc: 0.8153 - val_loss: 1.1662 - val_acc: 0.7201\n",
      "Epoch 1728/2000\n",
      " - 1s - loss: 0.5878 - acc: 0.7912 - val_loss: 1.1949 - val_acc: 0.7143\n",
      "Epoch 1729/2000\n",
      " - 1s - loss: 0.5348 - acc: 0.8007 - val_loss: 1.1935 - val_acc: 0.6793\n",
      "Epoch 1730/2000\n",
      " - 1s - loss: 0.5148 - acc: 0.8204 - val_loss: 1.2162 - val_acc: 0.7055\n",
      "Epoch 1731/2000\n",
      " - 1s - loss: 0.5556 - acc: 0.7978 - val_loss: 1.2216 - val_acc: 0.7026\n",
      "Epoch 1732/2000\n",
      " - 1s - loss: 0.5631 - acc: 0.7912 - val_loss: 1.2303 - val_acc: 0.7085\n",
      "Epoch 1733/2000\n",
      " - 1s - loss: 0.5771 - acc: 0.7781 - val_loss: 1.2109 - val_acc: 0.7143\n",
      "Epoch 1734/2000\n",
      " - 1s - loss: 0.6094 - acc: 0.7796 - val_loss: 1.2170 - val_acc: 0.6939\n",
      "Epoch 1735/2000\n",
      " - 1s - loss: 0.5462 - acc: 0.8029 - val_loss: 1.1626 - val_acc: 0.7143\n",
      "Epoch 1736/2000\n",
      " - 1s - loss: 0.5895 - acc: 0.7861 - val_loss: 1.3269 - val_acc: 0.6939\n",
      "Epoch 1737/2000\n",
      " - 1s - loss: 0.5945 - acc: 0.7847 - val_loss: 1.1739 - val_acc: 0.7143\n",
      "Epoch 1738/2000\n",
      " - 1s - loss: 0.6358 - acc: 0.7708 - val_loss: 1.1387 - val_acc: 0.7230\n",
      "Epoch 1739/2000\n",
      " - 1s - loss: 0.5915 - acc: 0.7934 - val_loss: 1.1567 - val_acc: 0.7143\n",
      "Epoch 1740/2000\n",
      " - 1s - loss: 0.5783 - acc: 0.7934 - val_loss: 1.2304 - val_acc: 0.7055\n",
      "Epoch 1741/2000\n",
      " - 1s - loss: 0.5894 - acc: 0.7788 - val_loss: 1.4078 - val_acc: 0.6735\n",
      "Epoch 1742/2000\n",
      " - 1s - loss: 0.6716 - acc: 0.7737 - val_loss: 1.2196 - val_acc: 0.6880\n",
      "Epoch 1743/2000\n",
      " - 1s - loss: 0.6278 - acc: 0.7693 - val_loss: 1.2236 - val_acc: 0.6793\n",
      "Epoch 1744/2000\n",
      " - 1s - loss: 0.5701 - acc: 0.7898 - val_loss: 1.2251 - val_acc: 0.7055\n",
      "Epoch 1745/2000\n",
      " - 1s - loss: 0.5993 - acc: 0.7876 - val_loss: 1.1750 - val_acc: 0.7143\n",
      "Epoch 1746/2000\n",
      " - 1s - loss: 0.6523 - acc: 0.7672 - val_loss: 1.1295 - val_acc: 0.6618\n",
      "Epoch 1747/2000\n",
      " - 1s - loss: 0.7090 - acc: 0.7650 - val_loss: 1.2102 - val_acc: 0.7026\n",
      "Epoch 1748/2000\n",
      " - 1s - loss: 0.5843 - acc: 0.7876 - val_loss: 1.1943 - val_acc: 0.6939\n",
      "Epoch 1749/2000\n",
      " - 1s - loss: 0.6059 - acc: 0.7912 - val_loss: 1.1756 - val_acc: 0.6968\n",
      "Epoch 1750/2000\n",
      " - 1s - loss: 0.6871 - acc: 0.7620 - val_loss: 1.3191 - val_acc: 0.6735\n",
      "Epoch 1751/2000\n",
      " - 1s - loss: 0.5869 - acc: 0.7854 - val_loss: 1.1205 - val_acc: 0.7114\n",
      "Epoch 1752/2000\n",
      " - 0s - loss: 0.6017 - acc: 0.7839 - val_loss: 1.0772 - val_acc: 0.7347\n",
      "Epoch 1753/2000\n",
      " - 1s - loss: 0.5622 - acc: 0.7883 - val_loss: 1.1933 - val_acc: 0.6880\n",
      "Epoch 1754/2000\n",
      " - 0s - loss: 0.5931 - acc: 0.7956 - val_loss: 1.1275 - val_acc: 0.7230\n",
      "Epoch 1755/2000\n",
      " - 1s - loss: 0.6075 - acc: 0.7956 - val_loss: 1.1918 - val_acc: 0.7026\n",
      "Epoch 1756/2000\n",
      " - 1s - loss: 0.5664 - acc: 0.7971 - val_loss: 1.2620 - val_acc: 0.6880\n",
      "Epoch 1757/2000\n",
      " - 1s - loss: 0.5967 - acc: 0.7818 - val_loss: 1.2881 - val_acc: 0.6793\n",
      "Epoch 1758/2000\n",
      " - 1s - loss: 0.6346 - acc: 0.7723 - val_loss: 1.1090 - val_acc: 0.7085\n",
      "Epoch 1759/2000\n",
      " - 1s - loss: 0.6051 - acc: 0.7905 - val_loss: 1.0795 - val_acc: 0.7230\n",
      "Epoch 1760/2000\n",
      " - 0s - loss: 0.5406 - acc: 0.8015 - val_loss: 1.1393 - val_acc: 0.6997\n",
      "Epoch 1761/2000\n",
      " - 1s - loss: 0.8112 - acc: 0.7540 - val_loss: 1.3925 - val_acc: 0.6851\n",
      "Epoch 1762/2000\n",
      " - 1s - loss: 0.9222 - acc: 0.7007 - val_loss: 1.1824 - val_acc: 0.6939\n",
      "Epoch 1763/2000\n",
      " - 1s - loss: 0.6316 - acc: 0.7737 - val_loss: 1.0214 - val_acc: 0.7201\n",
      "Epoch 1764/2000\n",
      " - 0s - loss: 0.6047 - acc: 0.7730 - val_loss: 1.0747 - val_acc: 0.7172\n",
      "Epoch 1765/2000\n",
      " - 1s - loss: 0.5606 - acc: 0.8015 - val_loss: 1.2331 - val_acc: 0.6880\n",
      "Epoch 1766/2000\n",
      " - 0s - loss: 0.5719 - acc: 0.7964 - val_loss: 1.0376 - val_acc: 0.7289\n",
      "Epoch 1767/2000\n",
      " - 1s - loss: 0.5778 - acc: 0.7942 - val_loss: 1.1656 - val_acc: 0.7085\n",
      "Epoch 1768/2000\n",
      " - 1s - loss: 0.5598 - acc: 0.8007 - val_loss: 1.2036 - val_acc: 0.7085\n",
      "Epoch 1769/2000\n",
      " - 1s - loss: 0.5781 - acc: 0.7788 - val_loss: 1.0454 - val_acc: 0.7114\n",
      "Epoch 1770/2000\n",
      " - 1s - loss: 0.5795 - acc: 0.7905 - val_loss: 1.2333 - val_acc: 0.6880\n",
      "Epoch 1771/2000\n",
      " - 1s - loss: 0.5420 - acc: 0.8051 - val_loss: 1.2478 - val_acc: 0.6997\n",
      "Epoch 1772/2000\n",
      " - 0s - loss: 0.5710 - acc: 0.7883 - val_loss: 1.1712 - val_acc: 0.7055\n",
      "Epoch 1773/2000\n",
      " - 0s - loss: 0.5502 - acc: 0.8102 - val_loss: 1.1150 - val_acc: 0.7055\n",
      "Epoch 1774/2000\n",
      " - 1s - loss: 0.5394 - acc: 0.7985 - val_loss: 1.1281 - val_acc: 0.6939\n",
      "Epoch 1775/2000\n",
      " - 0s - loss: 0.5259 - acc: 0.8161 - val_loss: 1.1433 - val_acc: 0.7201\n",
      "Epoch 1776/2000\n",
      " - 1s - loss: 0.5494 - acc: 0.7971 - val_loss: 1.1691 - val_acc: 0.6968\n",
      "Epoch 1777/2000\n",
      " - 1s - loss: 0.6769 - acc: 0.7708 - val_loss: 1.0554 - val_acc: 0.7201\n",
      "Epoch 1778/2000\n",
      " - 1s - loss: 0.8895 - acc: 0.7219 - val_loss: 1.1574 - val_acc: 0.6997\n",
      "Epoch 1779/2000\n",
      " - 1s - loss: 0.6572 - acc: 0.7781 - val_loss: 1.1903 - val_acc: 0.6968\n",
      "Epoch 1780/2000\n",
      " - 1s - loss: 0.8020 - acc: 0.7263 - val_loss: 1.1081 - val_acc: 0.6793\n",
      "Epoch 1781/2000\n",
      " - 0s - loss: 0.7117 - acc: 0.7555 - val_loss: 1.0637 - val_acc: 0.7055\n",
      "Epoch 1782/2000\n",
      " - 1s - loss: 0.6597 - acc: 0.7693 - val_loss: 1.1166 - val_acc: 0.7230\n",
      "Epoch 1783/2000\n",
      " - 1s - loss: 0.5859 - acc: 0.7971 - val_loss: 1.1900 - val_acc: 0.6822\n",
      "Epoch 1784/2000\n",
      " - 1s - loss: 0.5913 - acc: 0.7993 - val_loss: 1.1949 - val_acc: 0.6939\n",
      "Epoch 1785/2000\n",
      " - 1s - loss: 0.5722 - acc: 0.7993 - val_loss: 1.1687 - val_acc: 0.7026\n",
      "Epoch 1786/2000\n",
      " - 0s - loss: 0.5576 - acc: 0.8029 - val_loss: 1.2093 - val_acc: 0.6910\n",
      "Epoch 1787/2000\n",
      " - 1s - loss: 0.5233 - acc: 0.8051 - val_loss: 1.1925 - val_acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1788/2000\n",
      " - 0s - loss: 0.5544 - acc: 0.7964 - val_loss: 1.2090 - val_acc: 0.7172\n",
      "Epoch 1789/2000\n",
      " - 1s - loss: 0.5543 - acc: 0.8044 - val_loss: 1.1938 - val_acc: 0.7143\n",
      "Epoch 1790/2000\n",
      " - 0s - loss: 0.5749 - acc: 0.7956 - val_loss: 1.1623 - val_acc: 0.7143\n",
      "Epoch 1791/2000\n",
      " - 1s - loss: 0.5739 - acc: 0.7912 - val_loss: 1.0634 - val_acc: 0.7259\n",
      "Epoch 1792/2000\n",
      " - 1s - loss: 0.6083 - acc: 0.7964 - val_loss: 1.1616 - val_acc: 0.6851\n",
      "Epoch 1793/2000\n",
      " - 1s - loss: 0.5989 - acc: 0.7949 - val_loss: 1.1723 - val_acc: 0.7143\n",
      "Epoch 1794/2000\n",
      " - 1s - loss: 0.6203 - acc: 0.7781 - val_loss: 1.2568 - val_acc: 0.6880\n",
      "Epoch 1795/2000\n",
      " - 1s - loss: 0.5528 - acc: 0.7920 - val_loss: 1.1519 - val_acc: 0.7085\n",
      "Epoch 1796/2000\n",
      " - 1s - loss: 0.5669 - acc: 0.8029 - val_loss: 1.2459 - val_acc: 0.6939\n",
      "Epoch 1797/2000\n",
      " - 0s - loss: 0.5906 - acc: 0.7978 - val_loss: 1.2340 - val_acc: 0.6910\n",
      "Epoch 1798/2000\n",
      " - 1s - loss: 0.5545 - acc: 0.7993 - val_loss: 1.2117 - val_acc: 0.7026\n",
      "Epoch 1799/2000\n",
      " - 1s - loss: 0.5492 - acc: 0.7971 - val_loss: 1.2142 - val_acc: 0.6939\n",
      "Epoch 1800/2000\n",
      " - 0s - loss: 0.5655 - acc: 0.7993 - val_loss: 1.2930 - val_acc: 0.6822\n",
      "Epoch 1801/2000\n",
      " - 1s - loss: 0.7266 - acc: 0.7482 - val_loss: 1.1125 - val_acc: 0.7026\n",
      "Epoch 1802/2000\n",
      " - 0s - loss: 0.6920 - acc: 0.7672 - val_loss: 1.1955 - val_acc: 0.6793\n",
      "Epoch 1803/2000\n",
      " - 1s - loss: 0.6543 - acc: 0.7759 - val_loss: 1.1731 - val_acc: 0.6822\n",
      "Epoch 1804/2000\n",
      " - 1s - loss: 0.6033 - acc: 0.7664 - val_loss: 1.0821 - val_acc: 0.7085\n",
      "Epoch 1805/2000\n",
      " - 1s - loss: 0.5575 - acc: 0.7985 - val_loss: 1.1256 - val_acc: 0.6939\n",
      "Epoch 1806/2000\n",
      " - 1s - loss: 0.5792 - acc: 0.7876 - val_loss: 1.0768 - val_acc: 0.7172\n",
      "Epoch 1807/2000\n",
      " - 1s - loss: 0.5685 - acc: 0.7898 - val_loss: 1.1472 - val_acc: 0.7085\n",
      "Epoch 1808/2000\n",
      " - 1s - loss: 0.5263 - acc: 0.8117 - val_loss: 1.2601 - val_acc: 0.6997\n",
      "Epoch 1809/2000\n",
      " - 1s - loss: 0.5601 - acc: 0.8088 - val_loss: 1.1408 - val_acc: 0.7143\n",
      "Epoch 1810/2000\n",
      " - 1s - loss: 0.5767 - acc: 0.7942 - val_loss: 1.1658 - val_acc: 0.6880\n",
      "Epoch 1811/2000\n",
      " - 1s - loss: 0.6028 - acc: 0.7847 - val_loss: 1.1766 - val_acc: 0.6939\n",
      "Epoch 1812/2000\n",
      " - 1s - loss: 0.5261 - acc: 0.8139 - val_loss: 1.1718 - val_acc: 0.7026\n",
      "Epoch 1813/2000\n",
      " - 1s - loss: 0.5506 - acc: 0.7985 - val_loss: 1.1055 - val_acc: 0.7055\n",
      "Epoch 1814/2000\n",
      " - 1s - loss: 0.5734 - acc: 0.8015 - val_loss: 1.1208 - val_acc: 0.7026\n",
      "Epoch 1815/2000\n",
      " - 1s - loss: 0.5316 - acc: 0.8117 - val_loss: 1.1850 - val_acc: 0.7055\n",
      "Epoch 1816/2000\n",
      " - 1s - loss: 0.7171 - acc: 0.7606 - val_loss: 1.2838 - val_acc: 0.6647\n",
      "Epoch 1817/2000\n",
      " - 1s - loss: 0.7498 - acc: 0.7547 - val_loss: 1.1274 - val_acc: 0.7143\n",
      "Epoch 1818/2000\n",
      " - 1s - loss: 0.8086 - acc: 0.7518 - val_loss: 1.0861 - val_acc: 0.6997\n",
      "Epoch 1819/2000\n",
      " - 0s - loss: 0.7002 - acc: 0.7584 - val_loss: 1.1200 - val_acc: 0.7201\n",
      "Epoch 1820/2000\n",
      " - 1s - loss: 0.6021 - acc: 0.7818 - val_loss: 1.0029 - val_acc: 0.7289\n",
      "Epoch 1821/2000\n",
      " - 1s - loss: 0.5624 - acc: 0.8044 - val_loss: 1.0830 - val_acc: 0.6968\n",
      "Epoch 1822/2000\n",
      " - 1s - loss: 0.6250 - acc: 0.7774 - val_loss: 1.0951 - val_acc: 0.7114\n",
      "Epoch 1823/2000\n",
      " - 1s - loss: 0.5946 - acc: 0.7942 - val_loss: 1.1534 - val_acc: 0.6939\n",
      "Epoch 1824/2000\n",
      " - 1s - loss: 0.6789 - acc: 0.7642 - val_loss: 1.2020 - val_acc: 0.7026\n",
      "Epoch 1825/2000\n",
      " - 1s - loss: 0.5942 - acc: 0.7854 - val_loss: 1.1162 - val_acc: 0.7114\n",
      "Epoch 1826/2000\n",
      " - 1s - loss: 0.5636 - acc: 0.7956 - val_loss: 1.0479 - val_acc: 0.6997\n",
      "Epoch 1827/2000\n",
      " - 1s - loss: 0.5687 - acc: 0.7759 - val_loss: 1.1675 - val_acc: 0.6764\n",
      "Epoch 1828/2000\n",
      " - 1s - loss: 0.5086 - acc: 0.8226 - val_loss: 1.2051 - val_acc: 0.7085\n",
      "Epoch 1829/2000\n",
      " - 1s - loss: 0.5227 - acc: 0.8051 - val_loss: 1.0896 - val_acc: 0.7085\n",
      "Epoch 1830/2000\n",
      " - 1s - loss: 0.5309 - acc: 0.8015 - val_loss: 1.1568 - val_acc: 0.7026\n",
      "Epoch 1831/2000\n",
      " - 1s - loss: 0.5569 - acc: 0.8153 - val_loss: 1.2011 - val_acc: 0.6910\n",
      "Epoch 1832/2000\n",
      " - 1s - loss: 0.6717 - acc: 0.7635 - val_loss: 1.2512 - val_acc: 0.6880\n",
      "Epoch 1833/2000\n",
      " - 1s - loss: 0.7306 - acc: 0.7496 - val_loss: 1.2394 - val_acc: 0.7085\n",
      "Epoch 1834/2000\n",
      " - 1s - loss: 0.6144 - acc: 0.7737 - val_loss: 1.1566 - val_acc: 0.7026\n",
      "Epoch 1835/2000\n",
      " - 1s - loss: 0.5921 - acc: 0.7927 - val_loss: 1.1684 - val_acc: 0.7026\n",
      "Epoch 1836/2000\n",
      " - 1s - loss: 0.5919 - acc: 0.7745 - val_loss: 1.1087 - val_acc: 0.6968\n",
      "Epoch 1837/2000\n",
      " - 1s - loss: 0.5546 - acc: 0.8088 - val_loss: 1.1891 - val_acc: 0.6968\n",
      "Epoch 1838/2000\n",
      " - 1s - loss: 0.6318 - acc: 0.7796 - val_loss: 1.1194 - val_acc: 0.7201\n",
      "Epoch 1839/2000\n",
      " - 0s - loss: 0.7239 - acc: 0.7555 - val_loss: 1.1293 - val_acc: 0.7172\n",
      "Epoch 1840/2000\n",
      " - 1s - loss: 0.6777 - acc: 0.7569 - val_loss: 1.1744 - val_acc: 0.6764\n",
      "Epoch 1841/2000\n",
      " - 1s - loss: 0.5947 - acc: 0.7964 - val_loss: 1.1922 - val_acc: 0.6910\n",
      "Epoch 1842/2000\n",
      " - 1s - loss: 0.5150 - acc: 0.7985 - val_loss: 1.1333 - val_acc: 0.6939\n",
      "Epoch 1843/2000\n",
      " - 1s - loss: 0.5898 - acc: 0.7898 - val_loss: 1.0080 - val_acc: 0.7143\n",
      "Epoch 1844/2000\n",
      " - 1s - loss: 0.5820 - acc: 0.7832 - val_loss: 1.2679 - val_acc: 0.6822\n",
      "Epoch 1845/2000\n",
      " - 1s - loss: 0.5872 - acc: 0.7978 - val_loss: 1.1330 - val_acc: 0.7143\n",
      "Epoch 1846/2000\n",
      " - 1s - loss: 0.6979 - acc: 0.7591 - val_loss: 1.1343 - val_acc: 0.6997\n",
      "Epoch 1847/2000\n",
      " - 0s - loss: 0.5535 - acc: 0.7993 - val_loss: 1.2247 - val_acc: 0.6735\n",
      "Epoch 1848/2000\n",
      " - 1s - loss: 0.5789 - acc: 0.7978 - val_loss: 1.2838 - val_acc: 0.6968\n",
      "Epoch 1849/2000\n",
      " - 1s - loss: 0.5767 - acc: 0.7861 - val_loss: 1.2823 - val_acc: 0.6735\n",
      "Epoch 1850/2000\n",
      " - 0s - loss: 0.5549 - acc: 0.8036 - val_loss: 1.3241 - val_acc: 0.6676\n",
      "Epoch 1851/2000\n",
      " - 1s - loss: 0.5667 - acc: 0.8022 - val_loss: 1.2077 - val_acc: 0.6939\n",
      "Epoch 1852/2000\n",
      " - 0s - loss: 0.5487 - acc: 0.8058 - val_loss: 1.1263 - val_acc: 0.7055\n",
      "Epoch 1853/2000\n",
      " - 1s - loss: 0.5486 - acc: 0.7993 - val_loss: 1.1492 - val_acc: 0.6910\n",
      "Epoch 1854/2000\n",
      " - 0s - loss: 0.5657 - acc: 0.7920 - val_loss: 1.1305 - val_acc: 0.7201\n",
      "Epoch 1855/2000\n",
      " - 1s - loss: 0.5617 - acc: 0.7847 - val_loss: 1.3010 - val_acc: 0.7026\n",
      "Epoch 1856/2000\n",
      " - 1s - loss: 0.6470 - acc: 0.7752 - val_loss: 1.1846 - val_acc: 0.7026\n",
      "Epoch 1857/2000\n",
      " - 0s - loss: 0.6525 - acc: 0.7591 - val_loss: 1.2423 - val_acc: 0.6764\n",
      "Epoch 1858/2000\n",
      " - 1s - loss: 0.6541 - acc: 0.7723 - val_loss: 1.1758 - val_acc: 0.7085\n",
      "Epoch 1859/2000\n",
      " - 1s - loss: 0.5430 - acc: 0.8095 - val_loss: 1.1409 - val_acc: 0.6851\n",
      "Epoch 1860/2000\n",
      " - 1s - loss: 0.5640 - acc: 0.7964 - val_loss: 1.1395 - val_acc: 0.6880\n",
      "Epoch 1861/2000\n",
      " - 1s - loss: 0.6026 - acc: 0.7810 - val_loss: 1.1502 - val_acc: 0.7026\n",
      "Epoch 1862/2000\n",
      " - 1s - loss: 0.6974 - acc: 0.7737 - val_loss: 1.0926 - val_acc: 0.6939\n",
      "Epoch 1863/2000\n",
      " - 1s - loss: 0.5681 - acc: 0.7942 - val_loss: 1.2764 - val_acc: 0.6793\n",
      "Epoch 1864/2000\n",
      " - 1s - loss: 0.6921 - acc: 0.7642 - val_loss: 1.1067 - val_acc: 0.7172\n",
      "Epoch 1865/2000\n",
      " - 1s - loss: 0.5955 - acc: 0.7847 - val_loss: 1.1007 - val_acc: 0.7143\n",
      "Epoch 1866/2000\n",
      " - 1s - loss: 0.5563 - acc: 0.8080 - val_loss: 1.1204 - val_acc: 0.7026\n",
      "Epoch 1867/2000\n",
      " - 1s - loss: 0.5342 - acc: 0.8036 - val_loss: 1.2044 - val_acc: 0.6997\n",
      "Epoch 1868/2000\n",
      " - 1s - loss: 0.5818 - acc: 0.8044 - val_loss: 1.1987 - val_acc: 0.7026\n",
      "Epoch 1869/2000\n",
      " - 0s - loss: 0.5783 - acc: 0.7876 - val_loss: 1.1387 - val_acc: 0.6968\n",
      "Epoch 1870/2000\n",
      " - 1s - loss: 0.5390 - acc: 0.8058 - val_loss: 1.1386 - val_acc: 0.7201\n",
      "Epoch 1871/2000\n",
      " - 1s - loss: 0.5810 - acc: 0.7920 - val_loss: 1.2046 - val_acc: 0.7085\n",
      "Epoch 1872/2000\n",
      " - 1s - loss: 0.5552 - acc: 0.7934 - val_loss: 1.2898 - val_acc: 0.6910\n",
      "Epoch 1873/2000\n",
      " - 1s - loss: 0.5414 - acc: 0.8029 - val_loss: 1.2070 - val_acc: 0.6997\n",
      "Epoch 1874/2000\n",
      " - 1s - loss: 0.5512 - acc: 0.8088 - val_loss: 1.1312 - val_acc: 0.7143\n",
      "Epoch 1875/2000\n",
      " - 1s - loss: 0.7897 - acc: 0.7270 - val_loss: 1.1724 - val_acc: 0.6880\n",
      "Epoch 1876/2000\n",
      " - 1s - loss: 0.8053 - acc: 0.7321 - val_loss: 1.1226 - val_acc: 0.6997\n",
      "Epoch 1877/2000\n",
      " - 1s - loss: 0.7397 - acc: 0.7518 - val_loss: 0.9922 - val_acc: 0.7434\n",
      "Epoch 1878/2000\n",
      " - 1s - loss: 0.6350 - acc: 0.7730 - val_loss: 1.1357 - val_acc: 0.6939\n",
      "Epoch 1879/2000\n",
      " - 1s - loss: 0.5646 - acc: 0.8051 - val_loss: 1.1530 - val_acc: 0.7026\n",
      "Epoch 1880/2000\n",
      " - 1s - loss: 0.5366 - acc: 0.8066 - val_loss: 1.1331 - val_acc: 0.7085\n",
      "Epoch 1881/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.5469 - acc: 0.7956 - val_loss: 1.1128 - val_acc: 0.7085\n",
      "Epoch 1882/2000\n",
      " - 1s - loss: 0.5985 - acc: 0.7854 - val_loss: 1.0867 - val_acc: 0.6851\n",
      "Epoch 1883/2000\n",
      " - 1s - loss: 0.6085 - acc: 0.7796 - val_loss: 1.3561 - val_acc: 0.6851\n",
      "Epoch 1884/2000\n",
      " - 1s - loss: 0.5431 - acc: 0.7993 - val_loss: 1.1352 - val_acc: 0.7143\n",
      "Epoch 1885/2000\n",
      " - 1s - loss: 0.5316 - acc: 0.8051 - val_loss: 1.2252 - val_acc: 0.7055\n",
      "Epoch 1886/2000\n",
      " - 1s - loss: 0.5895 - acc: 0.7759 - val_loss: 1.1794 - val_acc: 0.6880\n",
      "Epoch 1887/2000\n",
      " - 1s - loss: 0.5825 - acc: 0.7891 - val_loss: 1.1591 - val_acc: 0.7055\n",
      "Epoch 1888/2000\n",
      " - 1s - loss: 0.5893 - acc: 0.7723 - val_loss: 1.1368 - val_acc: 0.7026\n",
      "Epoch 1889/2000\n",
      " - 1s - loss: 0.5333 - acc: 0.8007 - val_loss: 1.1750 - val_acc: 0.6997\n",
      "Epoch 1890/2000\n",
      " - 1s - loss: 0.5840 - acc: 0.7949 - val_loss: 1.1696 - val_acc: 0.6997\n",
      "Epoch 1891/2000\n",
      " - 1s - loss: 0.5618 - acc: 0.7971 - val_loss: 1.1442 - val_acc: 0.7114\n",
      "Epoch 1892/2000\n",
      " - 1s - loss: 0.5958 - acc: 0.7818 - val_loss: 1.2743 - val_acc: 0.7172\n",
      "Epoch 1893/2000\n",
      " - 1s - loss: 0.5918 - acc: 0.7883 - val_loss: 1.1787 - val_acc: 0.7114\n",
      "Epoch 1894/2000\n",
      " - 1s - loss: 0.6271 - acc: 0.7876 - val_loss: 1.2380 - val_acc: 0.6735\n",
      "Epoch 1895/2000\n",
      " - 1s - loss: 0.7507 - acc: 0.7504 - val_loss: 1.0925 - val_acc: 0.7230\n",
      "Epoch 1896/2000\n",
      " - 1s - loss: 0.5790 - acc: 0.7993 - val_loss: 1.1285 - val_acc: 0.7259\n",
      "Epoch 1897/2000\n",
      " - 1s - loss: 0.5404 - acc: 0.8051 - val_loss: 1.1567 - val_acc: 0.6910\n",
      "Epoch 1898/2000\n",
      " - 1s - loss: 0.5542 - acc: 0.8015 - val_loss: 1.1735 - val_acc: 0.7055\n",
      "Epoch 1899/2000\n",
      " - 1s - loss: 0.6249 - acc: 0.7766 - val_loss: 1.2478 - val_acc: 0.6851\n",
      "Epoch 1900/2000\n",
      " - 1s - loss: 0.9884 - acc: 0.7029 - val_loss: 1.1579 - val_acc: 0.6851\n",
      "Epoch 1901/2000\n",
      " - 1s - loss: 0.8494 - acc: 0.7204 - val_loss: 1.0912 - val_acc: 0.7026\n",
      "Epoch 1902/2000\n",
      " - 1s - loss: 0.7810 - acc: 0.7409 - val_loss: 1.1363 - val_acc: 0.6764\n",
      "Epoch 1903/2000\n",
      " - 2s - loss: 0.7485 - acc: 0.7372 - val_loss: 1.1035 - val_acc: 0.6910\n",
      "Epoch 1904/2000\n",
      " - 1s - loss: 0.8674 - acc: 0.7343 - val_loss: 1.1475 - val_acc: 0.6764\n",
      "Epoch 1905/2000\n",
      " - 1s - loss: 0.6719 - acc: 0.7686 - val_loss: 0.9529 - val_acc: 0.7347\n",
      "Epoch 1906/2000\n",
      " - 1s - loss: 0.6435 - acc: 0.7672 - val_loss: 1.1247 - val_acc: 0.7289\n",
      "Epoch 1907/2000\n",
      " - 1s - loss: 0.6055 - acc: 0.7810 - val_loss: 1.0375 - val_acc: 0.7201\n",
      "Epoch 1908/2000\n",
      " - 1s - loss: 0.5276 - acc: 0.8058 - val_loss: 1.1423 - val_acc: 0.7085\n",
      "Epoch 1909/2000\n",
      " - 1s - loss: 0.6383 - acc: 0.7701 - val_loss: 1.0445 - val_acc: 0.7230\n",
      "Epoch 1910/2000\n",
      " - 2s - loss: 0.5990 - acc: 0.7810 - val_loss: 1.1811 - val_acc: 0.6997\n",
      "Epoch 1911/2000\n",
      " - 1s - loss: 0.6013 - acc: 0.7737 - val_loss: 1.0396 - val_acc: 0.6997\n",
      "Epoch 1912/2000\n",
      " - 1s - loss: 0.5155 - acc: 0.8146 - val_loss: 1.0933 - val_acc: 0.6968\n",
      "Epoch 1913/2000\n",
      " - 1s - loss: 0.5653 - acc: 0.7927 - val_loss: 1.0560 - val_acc: 0.7114\n",
      "Epoch 1914/2000\n",
      " - 1s - loss: 0.5855 - acc: 0.7942 - val_loss: 1.1158 - val_acc: 0.7289\n",
      "Epoch 1915/2000\n",
      " - 1s - loss: 0.5492 - acc: 0.8102 - val_loss: 1.1564 - val_acc: 0.6968\n",
      "Epoch 1916/2000\n",
      " - 1s - loss: 0.5757 - acc: 0.8015 - val_loss: 1.2167 - val_acc: 0.6793\n",
      "Epoch 1917/2000\n",
      " - 1s - loss: 0.5669 - acc: 0.7949 - val_loss: 1.1754 - val_acc: 0.7085\n",
      "Epoch 1918/2000\n",
      " - 1s - loss: 0.5523 - acc: 0.7942 - val_loss: 1.1083 - val_acc: 0.7172\n",
      "Epoch 1919/2000\n",
      " - 0s - loss: 0.5776 - acc: 0.7927 - val_loss: 1.1322 - val_acc: 0.7201\n",
      "Epoch 1920/2000\n",
      " - 1s - loss: 0.6438 - acc: 0.7715 - val_loss: 1.0972 - val_acc: 0.7172\n",
      "Epoch 1921/2000\n",
      " - 1s - loss: 0.5481 - acc: 0.7964 - val_loss: 1.1913 - val_acc: 0.6851\n",
      "Epoch 1922/2000\n",
      " - 0s - loss: 0.5979 - acc: 0.7876 - val_loss: 1.1165 - val_acc: 0.7318\n",
      "Epoch 1923/2000\n",
      " - 1s - loss: 0.5509 - acc: 0.7993 - val_loss: 1.1873 - val_acc: 0.7172\n",
      "Epoch 1924/2000\n",
      " - 1s - loss: 0.5846 - acc: 0.7825 - val_loss: 1.1414 - val_acc: 0.7143\n",
      "Epoch 1925/2000\n",
      " - 1s - loss: 0.5482 - acc: 0.8015 - val_loss: 1.2437 - val_acc: 0.7172\n",
      "Epoch 1926/2000\n",
      " - 1s - loss: 0.5186 - acc: 0.8263 - val_loss: 1.2445 - val_acc: 0.6968\n",
      "Epoch 1927/2000\n",
      " - 0s - loss: 0.5265 - acc: 0.8139 - val_loss: 1.2119 - val_acc: 0.7026\n",
      "Epoch 1928/2000\n",
      " - 1s - loss: 0.5499 - acc: 0.8146 - val_loss: 1.2390 - val_acc: 0.6968\n",
      "Epoch 1929/2000\n",
      " - 1s - loss: 0.5408 - acc: 0.8146 - val_loss: 1.1880 - val_acc: 0.6997\n",
      "Epoch 1930/2000\n",
      " - 0s - loss: 0.5021 - acc: 0.8015 - val_loss: 1.1121 - val_acc: 0.6997\n",
      "Epoch 1931/2000\n",
      " - 1s - loss: 0.5600 - acc: 0.8051 - val_loss: 1.2021 - val_acc: 0.7259\n",
      "Epoch 1932/2000\n",
      " - 0s - loss: 0.5650 - acc: 0.7964 - val_loss: 1.1666 - val_acc: 0.7085\n",
      "Epoch 1933/2000\n",
      " - 1s - loss: 0.5335 - acc: 0.8117 - val_loss: 1.2490 - val_acc: 0.6968\n",
      "Epoch 1934/2000\n",
      " - 1s - loss: 0.6637 - acc: 0.7672 - val_loss: 1.2066 - val_acc: 0.6968\n",
      "Epoch 1935/2000\n",
      " - 1s - loss: 0.6096 - acc: 0.7796 - val_loss: 1.1215 - val_acc: 0.7259\n",
      "Epoch 1936/2000\n",
      " - 1s - loss: 0.6297 - acc: 0.7869 - val_loss: 1.2425 - val_acc: 0.7026\n",
      "Epoch 1937/2000\n",
      " - 0s - loss: 0.6259 - acc: 0.7650 - val_loss: 1.2570 - val_acc: 0.6851\n",
      "Epoch 1938/2000\n",
      " - 1s - loss: 0.5868 - acc: 0.7971 - val_loss: 1.1880 - val_acc: 0.7085\n",
      "Epoch 1939/2000\n",
      " - 1s - loss: 0.6078 - acc: 0.7883 - val_loss: 1.1553 - val_acc: 0.6997\n",
      "Epoch 1940/2000\n",
      " - 0s - loss: 0.5716 - acc: 0.8007 - val_loss: 1.1604 - val_acc: 0.7085\n",
      "Epoch 1941/2000\n",
      " - 1s - loss: 0.6394 - acc: 0.7759 - val_loss: 1.0631 - val_acc: 0.7289\n",
      "Epoch 1942/2000\n",
      " - 1s - loss: 0.5562 - acc: 0.7993 - val_loss: 1.1383 - val_acc: 0.7259\n",
      "Epoch 1943/2000\n",
      " - 0s - loss: 0.7469 - acc: 0.7628 - val_loss: 1.2334 - val_acc: 0.6910\n",
      "Epoch 1944/2000\n",
      " - 1s - loss: 0.7838 - acc: 0.7328 - val_loss: 1.1006 - val_acc: 0.7085\n",
      "Epoch 1945/2000\n",
      " - 1s - loss: 0.6284 - acc: 0.7672 - val_loss: 1.0917 - val_acc: 0.7114\n",
      "Epoch 1946/2000\n",
      " - 1s - loss: 0.5246 - acc: 0.8153 - val_loss: 1.1303 - val_acc: 0.7055\n",
      "Epoch 1947/2000\n",
      " - 1s - loss: 0.5497 - acc: 0.7978 - val_loss: 1.1409 - val_acc: 0.7085\n",
      "Epoch 1948/2000\n",
      " - 1s - loss: 0.5401 - acc: 0.8066 - val_loss: 1.2970 - val_acc: 0.6851\n",
      "Epoch 1949/2000\n",
      " - 1s - loss: 0.6561 - acc: 0.7701 - val_loss: 1.1588 - val_acc: 0.6851\n",
      "Epoch 1950/2000\n",
      " - 2s - loss: 0.6028 - acc: 0.7905 - val_loss: 1.1594 - val_acc: 0.6880\n",
      "Epoch 1951/2000\n",
      " - 1s - loss: 0.6640 - acc: 0.7723 - val_loss: 1.1491 - val_acc: 0.6968\n",
      "Epoch 1952/2000\n",
      " - 2s - loss: 0.6004 - acc: 0.7818 - val_loss: 1.2233 - val_acc: 0.6851\n",
      "Epoch 1953/2000\n",
      " - 2s - loss: 0.5376 - acc: 0.8029 - val_loss: 1.2121 - val_acc: 0.6910\n",
      "Epoch 1954/2000\n",
      " - 1s - loss: 0.5912 - acc: 0.7927 - val_loss: 1.2384 - val_acc: 0.6997\n",
      "Epoch 1955/2000\n",
      " - 1s - loss: 0.5246 - acc: 0.8051 - val_loss: 1.1481 - val_acc: 0.6968\n",
      "Epoch 1956/2000\n",
      " - 1s - loss: 0.5095 - acc: 0.8175 - val_loss: 1.1982 - val_acc: 0.6851\n",
      "Epoch 1957/2000\n",
      " - 1s - loss: 0.5865 - acc: 0.7876 - val_loss: 1.0681 - val_acc: 0.6997\n",
      "Epoch 1958/2000\n",
      " - 2s - loss: 0.6156 - acc: 0.7891 - val_loss: 1.2420 - val_acc: 0.7055\n",
      "Epoch 1959/2000\n",
      " - 1s - loss: 1.0007 - acc: 0.7058 - val_loss: 1.2621 - val_acc: 0.6939\n",
      "Epoch 1960/2000\n",
      " - 1s - loss: 0.8447 - acc: 0.7168 - val_loss: 1.1237 - val_acc: 0.7026\n",
      "Epoch 1961/2000\n",
      " - 1s - loss: 0.7069 - acc: 0.7511 - val_loss: 1.0622 - val_acc: 0.7085\n",
      "Epoch 1962/2000\n",
      " - 1s - loss: 0.6117 - acc: 0.7818 - val_loss: 1.0592 - val_acc: 0.6997\n",
      "Epoch 1963/2000\n",
      " - 1s - loss: 0.5703 - acc: 0.7912 - val_loss: 1.1600 - val_acc: 0.6939\n",
      "Epoch 1964/2000\n",
      " - 1s - loss: 0.5773 - acc: 0.7883 - val_loss: 1.0731 - val_acc: 0.7230\n",
      "Epoch 1965/2000\n",
      " - 1s - loss: 0.5567 - acc: 0.8080 - val_loss: 1.2242 - val_acc: 0.7143\n",
      "Epoch 1966/2000\n",
      " - 1s - loss: 0.6099 - acc: 0.7788 - val_loss: 1.1433 - val_acc: 0.7172\n",
      "Epoch 1967/2000\n",
      " - 1s - loss: 0.6295 - acc: 0.7766 - val_loss: 1.1745 - val_acc: 0.6910\n",
      "Epoch 1968/2000\n",
      " - 1s - loss: 0.6027 - acc: 0.8015 - val_loss: 1.2350 - val_acc: 0.6997\n",
      "Epoch 1969/2000\n",
      " - 1s - loss: 0.5943 - acc: 0.7861 - val_loss: 1.1267 - val_acc: 0.7085\n",
      "Epoch 1970/2000\n",
      " - 1s - loss: 0.5784 - acc: 0.7956 - val_loss: 1.2554 - val_acc: 0.7055\n",
      "Epoch 1971/2000\n",
      " - 1s - loss: 0.5741 - acc: 0.7839 - val_loss: 1.1979 - val_acc: 0.7026\n",
      "Epoch 1972/2000\n",
      " - 1s - loss: 0.5901 - acc: 0.7993 - val_loss: 1.0213 - val_acc: 0.7172\n",
      "Epoch 1973/2000\n",
      " - 1s - loss: 0.5811 - acc: 0.7839 - val_loss: 1.0986 - val_acc: 0.6939\n",
      "Epoch 1974/2000\n",
      " - 1s - loss: 0.5883 - acc: 0.7730 - val_loss: 1.0913 - val_acc: 0.7376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1975/2000\n",
      " - 0s - loss: 0.5101 - acc: 0.8204 - val_loss: 1.1147 - val_acc: 0.7201\n",
      "Epoch 1976/2000\n",
      " - 1s - loss: 0.5596 - acc: 0.7912 - val_loss: 1.1064 - val_acc: 0.7230\n",
      "Epoch 1977/2000\n",
      " - 1s - loss: 0.5413 - acc: 0.8058 - val_loss: 1.1126 - val_acc: 0.7230\n",
      "Epoch 1978/2000\n",
      " - 1s - loss: 0.5176 - acc: 0.8146 - val_loss: 1.0746 - val_acc: 0.7172\n",
      "Epoch 1979/2000\n",
      " - 1s - loss: 0.5257 - acc: 0.8044 - val_loss: 1.1916 - val_acc: 0.6939\n",
      "Epoch 1980/2000\n",
      " - 1s - loss: 0.5630 - acc: 0.7854 - val_loss: 1.1463 - val_acc: 0.7114\n",
      "Epoch 1981/2000\n",
      " - 0s - loss: 0.5598 - acc: 0.7993 - val_loss: 1.1671 - val_acc: 0.7143\n",
      "Epoch 1982/2000\n",
      " - 1s - loss: 0.6343 - acc: 0.7796 - val_loss: 1.1093 - val_acc: 0.7201\n",
      "Epoch 1983/2000\n",
      " - 1s - loss: 0.6917 - acc: 0.7511 - val_loss: 1.1617 - val_acc: 0.7055\n",
      "Epoch 1984/2000\n",
      " - 1s - loss: 0.6383 - acc: 0.7788 - val_loss: 1.0677 - val_acc: 0.7289\n",
      "Epoch 1985/2000\n",
      " - 0s - loss: 0.5549 - acc: 0.8066 - val_loss: 1.1471 - val_acc: 0.7026\n",
      "Epoch 1986/2000\n",
      " - 0s - loss: 0.5386 - acc: 0.8044 - val_loss: 1.0527 - val_acc: 0.7143\n",
      "Epoch 1987/2000\n",
      " - 0s - loss: 0.5774 - acc: 0.8066 - val_loss: 1.1550 - val_acc: 0.7259\n",
      "Epoch 1988/2000\n",
      " - 1s - loss: 0.5685 - acc: 0.7942 - val_loss: 1.2059 - val_acc: 0.7259\n",
      "Epoch 1989/2000\n",
      " - 0s - loss: 0.5713 - acc: 0.7912 - val_loss: 1.1464 - val_acc: 0.7055\n",
      "Epoch 1990/2000\n",
      " - 0s - loss: 0.5856 - acc: 0.7956 - val_loss: 1.2115 - val_acc: 0.6968\n",
      "Epoch 1991/2000\n",
      " - 1s - loss: 0.6170 - acc: 0.7854 - val_loss: 1.0802 - val_acc: 0.7230\n",
      "Epoch 1992/2000\n",
      " - 1s - loss: 0.5948 - acc: 0.7825 - val_loss: 1.1466 - val_acc: 0.7114\n",
      "Epoch 1993/2000\n",
      " - 1s - loss: 0.5771 - acc: 0.8022 - val_loss: 1.0332 - val_acc: 0.7259\n",
      "Epoch 1994/2000\n",
      " - 1s - loss: 0.6510 - acc: 0.7883 - val_loss: 1.3000 - val_acc: 0.6822\n",
      "Epoch 1995/2000\n",
      " - 0s - loss: 0.8071 - acc: 0.7343 - val_loss: 1.0068 - val_acc: 0.7493\n",
      "Epoch 1996/2000\n",
      " - 1s - loss: 0.5658 - acc: 0.7912 - val_loss: 1.0658 - val_acc: 0.7172\n",
      "Epoch 1997/2000\n",
      " - 0s - loss: 0.5361 - acc: 0.7985 - val_loss: 1.0671 - val_acc: 0.7230\n",
      "Epoch 1998/2000\n",
      " - 1s - loss: 0.5456 - acc: 0.7956 - val_loss: 1.1077 - val_acc: 0.7143\n",
      "Epoch 1999/2000\n",
      " - 0s - loss: 0.5689 - acc: 0.8044 - val_loss: 1.1343 - val_acc: 0.6997\n",
      "Epoch 2000/2000\n",
      " - 1s - loss: 0.5543 - acc: 0.7883 - val_loss: 1.2099 - val_acc: 0.7085\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_history = model.fit(X_train, Y_train, \n",
    "                          batch_size = 32, \n",
    "                          epochs = 2000, \n",
    "                          verbose = 2,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [checkpoint]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4FNX6xz/vbhodpEOA0KsUiSiiiB3shfsTvDYUsWG/KpbrxXZt99rbxd4RUREFxEJXEAIiUgWREmroLSHZ7Pn9MbN9dlPIJoF9P8+TJzszZ2bend0933Pe8573iDEGRVEURQFwVbQBiqIoSuVBRUFRFEXxo6KgKIqi+FFRUBRFUfyoKCiKoih+VBQURVEUPyoKSsIjIm4R2ScizeN0/VYisi8e11aUskZFQTnssCtw359XRHKDtv9e0usZYwqNMdWNMetKYUsbEYmY7CMiH4rISPv6q40x1YtxraEiMq2kNihKWZJU0QYoSkkJrmBFZA0w1BjzQ7TyIpJkjPGUh20VSaK8TyW+aE9BOeIQkcdE5FMR+URE9gKXi0hvEZkjIrtEZJOIvCgiyXb5JBExIpJhb39oH58kIntFZLaItDwEe0J6EyJyrYissa+9WkQGicjRwMvASXaPZ5tdtrZtT459zn0iIvaxoSIyw7Z1B/CY/f46Bt2rsYgcEJG6pbVfSSxUFJQjlYuAj4FawKeAB7gNqAf0AfoD18c4/zLgn8BRwDrg0bIwSkRqAs8CZxhjati2LDLG/A4MB2barqx69imvAlWBVsCpwLXAlUGXPAFYBtQHHgbGAJeHvY/JxpjtZWG/cuSjoqAcqcwyxnxtjPEaY3KNMfOMMb8YYzzGmNXAKODkGOePNcZkGWMKgI+A7rFuZrfQ/X/A/8UoboAuIpJmjNlkjFka5ZrJ9nVGGGP22nY/B1wRVGydMeY1e1wkF3gPuMzXm7DLfhDLdkUJRkVBOVJZH7whIh1EZIKIbBaRPcAjWL2GaGwOen0AiDlQbIypHfyH1WJ3KrcHGAzcDGwWkW9EpF2UyzYA3MDaoH1rgaZB2yHv0xjzE1av6EQR6QI0BybEsl1RglFRUI5UwiOC/gcsBtoYY2oCDwEScVY5YIyZZIw5HWgMrLJtg0ibtwKFQIugfc2BDcGXc7jF+1gupCuAMcaYg2Vht5IYqCgoiUINYDew3x6IjTWeEDfsgd/zRKQqkA/sx6r4AbYA6b4BcNt1NRb4t4hUtwe77wA+LOI2HwADscYT3o/D21COYFQUlEThLuAqYC9Wy/zTCrLDDdwNbAK2Yw0UD7ePfQ+sBLaIiM99dROWePwFTMcaM4hZ0Rtj1gC/A/nGmJ/L2H7lCEd0kR1FOfIQkfeB1caYkRVti3J4oZPXFOUIQ0RaARcAR1e0Lcrhh7qPFOUIQkSeAH4D/l2atB2Kou4jRVEUxY/2FBRFURQ/h92YQr169UxGRkZFm6EoinJYMX/+/G3GmPpFlTvsRCEjI4OsrKyKNkNRFOWwQkTWFl1K3UeKoihKECoKiqIoih8VBUVRFMWPioKiKIriR0VBURRF8aOioCiKovhRUVAURVH8qCgoiqJUAPsPevhiQTaVLdWQioKiKAB8MncdbR+YSKG3clVSlZnc/EJe+nElBYXeEp/72ISl3DnmN+at2RkHy0qPioKiFIOd+/NZuWVvRZsRVx79ZikFhYa8gsKiCx/mzF+7g1emrgLgjy17yRgxgZkrc0p8ndemreK/3//B6Hnriy4cRs5ea5XUXQfy/fvW7zjApt25AGSMmMDwjxeU+LqHioqCohSDc16cyRnPzahoM+KKb8Fqbzm5M4wxh+w6Mcbw0o8rWb55DxkjJvDdks1FnwRc8tpsnpm8AoC7xvwGwMTfN0WUm7ZiKxkjJrB1b17I/j+27GXxht0c9Fg9hDdmrC62zX/m7OPtWX/hdllPfM7qHazfcYDBo+Zw0tNT6f3EFH/ZbxZtKnf3koqCohSDjbvzii5UAfyyejsHPWXbsvcGeUJGjl/CiM8XOZb7dN46tu4p/XNped9EWt43MWTfjv35DH0vi237DrInr8Cx17J88x4m25X/0k17+O/3f9D/+ZkAvDXrr4jyXyzI5sM5gbQ/k4Iq/7yCQn7fsBvA0W3mE4wlG/f4963YvJczn5vBuS/NYov9/tftOOD/HLbvO8iSjdY1w8UE4G+vz+aRb5biKbTu9/ZPfzHii0XMXr09oizA5kN4xqUhrqIgIv1FZIWIrBKREQ7Hm4vIVBH5VUQWicjZ8bRHUYrioKeQxycsZU9eQanO37w7j2krtkY9vnLL3mJX4qNm/EnGiAl4gyqrvXkFfLEgmynLt5AxYgKXjprDo98sdTw/Y8QEMkZMYN9BDwDfLt7MTR/Njyi3cP0uFq7fhYjVci0IUoV3f14T4hrZuT+f7J0H2Lo3j3s//53r3reSUy7K3sXI8UvYm1fA4xOW0u+Zqcxfu8PRrhd/XOl33YRzz9jf+GHZFjIf+4GuI7/jTLt3tml3Lh/OWYsxhv7Pz+T6D+ZjjOHLBRtCzv/lrx18u3gzeQWF7Nyfz2PfWH77B8ctBuDNmau58aOAS+aJicv8r52GBbbvt1w7efmF/op+9LzA2kWTFgd6Jpe98Qt/5uyj52M/cM6Ls8gYMYFej/9I/+dnsGbbfjbvzmPr3jx22Nf8cXnge/LTqlBByBgxwf+69xNTWLV1X7m59eKWJVVE3MArwBlANjBPRMYbY4K/wQ8CY4wxr4lIJ2AikBEvm5TDgwP5Hhas3cWJbes5Ht+wK5c+T07h6+EncnR6rRJf/6CnkJ9XbeeUDg0ijn2xYANvzPyLrXsP8sKgHiW+9kWv/sSm3Xn89q8zOfelmfxnYDda1K3GuIUb+FvPdM54bgaXHJPOlb1b8PTk5fy0ajs/3NmXo6qlsjpnH5kZRwFWD+DfE5cDsG3fQZZt3kv39Np0e+S7iHtOXrKFxy4MrLxZ6DWMCnJnzPlzO6d3asgNH1qCsCevgHyPl3rVUwG48JWfQq6X+dgPTLrtJBasCx0ALfQaejz6PQC3nNoGgN+yd5Pv8XL+y9Y15qzezvLN1tjLJa/NZs2T5/jP37w7j7rVU3j2+z8i3sN3SzYz7INIwVq34wCvTlvF4g27mfj7Zr/AAUz/I4c3HXoGvvfpxGMTloVsvzc70IP4fEE2zwzsisslbNiVy4w/AmMMPiGpXTWZU4O+Nz73EcD8tTs57b/TI+65fPNe+v1nWlSbisPpz1rXHT3seI5vVfeQrlUU8Uyd3QtYZYxZDSAio7HWjQ0WBQPUtF/XAjbG0R6lEuH1Gvbne6iRlhxx7NZPfuWHZVuZ98Dp1K+RGnF8it3C+jRrHUenR1+GeNeBfJ77/g/uP6cjqUlu//57xi7iq4UbGXtDbzIzjuLDOWtpUbcqJ7Wtj8dulX+1cCMvDOrBsk17aH5U1Yhr3/fF79SrnsJdZ7YHrJbsb+t3scl2Mw3/eAHrd+Ry6ag5/nOqpVo/t88XZPPlr9n4OgCnPzuD1vWr8WfOftY8eQ4Fhd6Q84Z//Ctz1zi3ugGMga178hj4+mzev6YXSzft4alvl/uPD30/K6RyHvD8TDbsymXNk+cw+09nl8WbM//i8wXZIftenhJo3b8U9PrNWQEB8gmCj8UbdnPuS7P82+0b1nC835NB9obz9LcrAuUmBcrtzi1Zb27Y+0Wn3N+4O5emtavQ58kpjsd3HSjgi7DeSXmStWZH3EUhnu6jpkDwkHy2vS+YkcDlIpKN1Uu4xelCIjJMRLJEJCsnp+QRAkrZs+tAPtv3HfRv5+YXMuSdufy1bX+R505ZvoWnJi/n6JHfsetAPnd/9huzVm7zH5+1ynrtNYa/tu1nse3z9eGx+/mfzlvPqq1WJWSM4a4xv5EVVHk+M3kF781ey1e/hrY1pq2wvkOXjpqDp9DLg+MWc8VbcwFwSaDc2u37GfDCTK59b55/31Vvz2XT7lw+mbuOl6as4qaP5rN04x56PzGFGz4MuCVmBr0fH/+0XRjWews99mfOfv+zWb/jQMixWIIAVk/i2veyWLfjAFe/M5ebPoqMWAl2R2zYZUW37D/oYfAbcyLKAuwMiogBa2xhTJZzhE1wpR1OsCAArHCI4PJ6Datziv7ehBMsTMXhu6VbiiyTtWan47hEZSHZHf9h4Hj2FMRhX/hIzmDgXWPMf0WkN/CBiHQxxoR494wxo4BRAJmZmRpEXQno/ojlRvC1QGeuzGHqihxmrpzOvf07cF3fVgDsO+jBLUKVFDfPff8HL/y4MuQ6m/fk8dn8bD6bn+2/Vl6B9fEXeg2n2N3uFwZ159yuTTjj2enUqZYCQEGh4fRnZ/DxdcfRpWktPl+QzaTFm7jzjHa0b1TDHzseHk2z33ZBFHoNbR6Y5N+/aus+PssKtI5Pfsa695zVgUp5+h853DM2MPA68ffNTPy9eBEvxeGad0u3gJRvsHTN9gNFlAzQ+V+Tox6bsjx0XOTdn9eUyq7icPaLM0t13qqt+8rYErj904Vlfs2yxKnnXNbEUxSygWZB2+lEuoeuBfoDGGNmi0gaUA+IPlKnVEp8LV+P1/D4xGVc0L0JtaumcNJTUzDAwofO5H8z/ow4zxc1ApYLpnGtKv5tX4sW4LbRC+maXpvV2/ZDWG/ksjd+8b8u9Bq/37iG7a75z3craNOgOiO/XsLiDXuIhs9vWxROvQCl9IS7nJTo5JbDYHM8+yLzgLYi0lJEUoBBwPiwMuuA0wBEpCOQBqh/qBxYtmkPf+bs485PF/rD6qJRUOjl7s9+Y/2OA6zauo8vwnzNQEQsda9//0i7Byex80ABuw5Yvt98T+xZn+/+vCbkOn97fXbI8VOKMVgXPPC31+4RbNuXz8DXZ8cUBEU5HDi5XZFLLB8ycespGGM8IjIcmAy4gbeNMUtE5BEgyxgzHrgLeENE7sByLV1tKlsikCOEVVv30rBmmn9gd8ALgRZ6arKLJy7uyuBRc/hjy16eH9Sdk9rW5+Nf1tGgRirrdhzgs/nZbNqdx9JNe/whdcEUFvGxjft1Q4QfPZwkl0TErStKOK/+/RjHcZPypPlRVVm3o/iuurIivU5k0ENZE0/3EcaYiVgDyMH7Hgp6vRToE08bFIvTn51Bt2a1+ermyMedmuTmyUnL/ZNnrnhrLv+7oif3f/l7SDnfAHAw437dUCw/7EtTVhZZxu3SuZSHA5kt6pC1Nn75ekYPO55Bo5wHwAHOPrpxia9Zr3oK2/ZFNmZKwv1nd/CHCZeVIFzcoylf/Fpx0UxO6K+wIlj1A6z84ZAvU+g1xZpk5YvW+W39Lq5+Zy4H8j2hx71eXp9u+fv7uRZyout3rneIGXeiuANzfxYjuqQkqQIShe7Napf63B/uPLkMLQkwqFfzEpU/pX19uqXX4pXLjuHMTg2LLF8l2V1kmXeGHBux762rMvn29pMcy8fqpX51cx9WPNbf8djZRzfyvz6uZV0uPiY8gPLQqFklMiQbysdNFA0VhbLkwA4rR0BBHhwMi4zwFsLLx8KScfDhJfDRJfDVcPjmzkAZY2C/c9y4EyPHL6HryO846Cmkz5NTeHDc78xfu4OMERNYYw/G7s0r4KJXf/afM21FDo9+EzqB58M5gRma76Y8zYcpT5TgTUMq+VQl9rjEIPcUJqTcF7NMeQyiVTSpSSX7yf39uJJVwMEkuZwCAItH3xiVUkmuKwLvDOnFV8NP5JyujUkLq/AHHdssZHtY31Yc3bQWt57W1vF6vnxBThZUS02iQ6OaDkciI9A6NArMl+jWrDapSW5u7Nc64ryzOgdEISXJhTjeuWjeuDIzZPu/f+vGW1dlckH3JiH7m9a2Ai0a10oLmVtSnqgolBV7t8DTLWHG0/DqcfBEWItixUTY9oclBD5+/QCy3gpsz3sTnmkFOZEzPp3IXvAt57t+pmDrSjbsyuXDOeu45LXZCF6yp7/L94s3cuErP/nDFX18MnddlCuWju9T7mZp2jUxyzyZ/CadXWtjlikprWUD3aVkserliVNrr6QhhYcilG6HynvoiS25sneLkH0Tbz2J1y/vGbLvlcuiz+Z2um405tx3Wsh2eOXcqFaa//X53Zpw/9kdcbmEO053FoWMutF96t4Y3YHwIa/wShrg3v4dqJ4a6lEPnheQkuQiz05RMqBLI0pCep0qIduX9EzntI4NI3qCQ/pkAOA6BEE/VFQUyop9dqz6sm9g55rI459ebv0vcHCjfH4d5O603EoA39vDLr+PhblvRL3lO65HeTHlZaqPOi5k/0WuWZz4+/00GjOA3jvGlfCNlJzmruIHjNWi7GLLf0y9m3GpD0XsTylha7xjY+fWpRPB7oSiEIff9T39O0Tse3fIsf4WY60wd8KB/EJO79iQYfa8Dx9PXBx9JrcPp4rlwXM7hVTEAJ2a1Axp/Q/o0ogaacm8d02vCLEYemLLYvcUJtx6Ig1rht5rc1hiweCWd3C9LSLUq27NR6mWYvUujm5ai4+GHg9A1ZTI4dBYLqJgMZp+dz+aOcxSB1jwzzO4NLMZbRtUB8JEwe3ioD2HJlZPysfYG3oHvZ/A/rRkV9B+CekR+PJPuZ2+POWEikKZUcwP0TiEZf4+Bua+GWjO/GFPqPr8Wpj4j5CiyzbtYfPiGaxeG73VXVss4TnatYbHkt8BYE3aZTyU9D5dZDWd5S/aSjZVbJdPuuQwM+U2xqc8EPWa7yQ/xdzUmwB4OflFFqdeQydZQzKh4xN92sSegn9j0tcxjwOkUEBHid2rmF3v8ajHWtWr5n898rxORd5v2aZAqOrk2/tyfrcmUcuKSERLuyjO6tyQY5pbLcLqqZH+8pPb1ff3KpLdwqx7T2HM9VaFckr7Brx5VSb3n90x5BxfpdGoZhpPX9LVn4vIqUw4ToFibrdVtnOTmrxmC8HJ7erTP6xF3LlpzWL3FMIFDmKnpggPPKxbzepVtbFTY1x8TFO/oLUM+ox9+CLgxjkEU/gu3ahmGi3qRp7rIyXJxVMDu/rvk+SWkGO+ZIZNaldxPP/9a3rx+Y0nMP3ufv60JhAqfq4YFb7vSEl6Y2WNikKZU8qIWncyrAyaYfrdg4HX2/+EwgKY9hQTXr6TRmPPo9U7XUNOr88uarOXm9zjaCmheeFvdX8BwDVJ3/JN6oNMSH2A71PvYXTKYwx3f8ms1Nto5sqhqyv69P5T3L/RQHYBcK57DtUlj4mp93N/0kf+Mu0b1uDNKyMHAIO53P09zSV2uoFHk95hUup9jLqwKUexhxvd4wl/ro33LYl6fvBkqAyHygNCffUjBlit9zM7NaR9oxp0aBzwNye7Q3+cbhH6tHFO1Hf3We1Dtmva4b8uEb/1ThWCiPgrrW378kmvU5VeLY9izZPn0L6Rc64gX+3Rp009/u/YZv4cTMGUJJirJC3T4Ipy1BU9Gdgz3bmcgwHBocvhzzYcn0mpdms9OLV1/Rqp/PbQmSHlfb0Bp8F5j5359fObToh5z8C9I20L7imk2b3ROlUDwjf59r70bVefni3q0KJutZDPOviZxRIF33sILzPA9Qs9pOgIvrJARaGs8H2IWwL5bfj5ZRhZy/orinlvhW7//JL/5T1vfs3DD90B0/7NP5I/czz9heSXeSz5He5JHsMVSaGRTXcmj3U8p5trddTrufDSzK68awa5fMakPBxS7jhXIEHZ5Bu6UsVrlU2hwHHwubrk8XnKSP+2U6s802Xl0jmzVRrz273Hvcmj+fgs6/m2kM3MT73e0eb0tHwasJN5qTfSXqxxE6eEewA3nRJoWXey3UcH8q1WYF6Bl36uX5mbehPDTwjNpFroNVH7hDeeHBio/MeZ7Ti9U0MeSnqfK7Y85a/03S4hlXx/L82H09yPEHJ34sLLWa65/JhyF2IsW02MRkh4Rf/O1ZZgO/nefS4hY7ACJmLMOwmu7M/s3Ij//K2bczmHSt937wu7N+Hb2/uG9LrC7+irmH3XCR+PqFU19LONNaZQYK9dULUYkU0QyIEV3HtJSXL5e04Z9aox/8HTmXb3KXx83XFc2btFhIC7BKqQR5rk06peNf94SKxOgE/4fF6r6Xf3Y+KtJ/Faygt8mfqvYtl+qMR1nkJi4fBJfxfdHRPB7uiDv0/n/guc6zY/R8leCkzZfZyfpTxMT9dKCo3glsAPo5crNPlZS1dQq/+tM2DbH5zW5D3e2nEVAHv63McL00LfW+0gkXl6YFe+/i2b81yzmeA9nkJctHbZPZ33L0DssZreLaozYSBs/uoD6kpkWoQkPMziavJSk0mTAoYlfcNdBTfRs0Udf5kVj/Wn/YPfAqEVZjXbpeNzDRz0FPJuyjMAnLb+JSZIb6qTywLTjryCQo5LWU3H5M0sK2hE1RS3X0xcLmH5o/1xu4Rkt4uvf9vINUnfwl4wabf57zsz9XYayC7GnrfEv+BLTHfBwb3wVAY/pR5FNfKoKQfItd/WcS2PinpaeGvXlyrcqe703f8o7zYrYOK0h+Ckuxyv6xOQ41sF7v3JdcdTv0YKpz87I6JcMG09q3CL4YrevWld3/Lbvzi4B7d+8muE+8h3uq/VXNQyyLGSxfkq26oO7jsnnD6NZLeLIX0yGNyrOVVSAtc5oXU9Tmgd2XsUEZalXcMGUw+Rixh6UiseHLeYPXmeiLJ+O309BfvNx3J1xQsVhSOEDq71dKDk68RGo6fL6qoGC4ITIS3ebVbUlE8QAGr+9AT/DBO0ZClkqHsCbxaeQ1qym99q3E7Ngm00LtjBVhPU9d8XSDQn346g89aldHb4Td/sHocLu1svls86jUDLuz47+SJlJKlTLwOsQXl3Xg7/TX6VhwqG0C29NoN7NeO6k6zB3PygeRxdNo/ju1RrsD4j72PyPIXU+mgAk9zwqPdyLk/5mRkd7mBKnuWCCg65DH5yvgrP7RK/G25gz3S/68WpVe3HDm9uLIHEfF0aV2fOfafRsGb0aKZoyQGcehc+UajvtYMGlk/0i8I/z+3kX8gnLXczXVb8j1TO5l7vW7ClFjTsRO/WdWH5RK51T+CtwnPs9xRZSb9x8B+QCgtd/weeg/DNHXTflc/xrvYYEzp+0di7ib8nfcy0JGt9rlgD3A+e05GTWqTBF9fDWf/273/0wi7UTEtiwdqdvDd7LSnz/ge1mkKnC6JeK+RZBT2qZLcgdnLH4uDT5KZiTfr0FKVqBHo7LoCJd8MxV0GjLsW6X1mholBc8g/A9lVQkAtptaBuG9i6BP7XF06+F1qdUtEWHlY8mPwRw1K/g11dqVlg/Wj6u+fRwxUlxHSr8+piAHcnj4nYd457Li941kNBHiOSP6GZKwd+eoEpl03kQN0u1Jp4BZe4Z3GJexYshScuHug/99yuDeDXyPt8k3I/W7YHfPf/TP4QPNDyj1u4CmDRG9CoqxWSfNwNmMa3+st6jaEauVTb4zBB75s7uDLrbU5LrUufgwG3IbuzwZ2C4ziV5yCNDuZAQQtICUTSVOcAz9b8lDPzv4ePujG9YQonb7kjcN7+7VTP3YALLx1lLUtMS8AShTEpD9Nzr+23lkCFfu2JLfk9exfjFm6k+6JHqbl5GjNPP5oGsz6DT36B2+2Z76MH889k/KKQvGc9VK0B1SJb0UkugZXfwcKPaA6MTgFWPQaF26zxNeDufc/QPukPunYcTsuGrbiidwvYugxePR6GTILaLajPTnKow9CTWsHsV2HRaKhSB7AmsV1xfAtYP5cLxp3BP2+diYy6zDJg5O4Im/w8lcHN0oWp3BgiCk7jDLEIHxfIL/QyIuljbkj6BtgN21ZCjUaQGnA7+XSjpmcHzB9lzWu6u3zGEnyoKBSXL66D5d8EtjucG9ie/pT1p5SIBt4ceD7QCooqCKXku9R74fF7yag3AOysDK2+OBuumwprgzKifn4t1MmADQugTgt6jrvJ8XpdXGvokrsm+g1/fgmOudJ6/cvr1D0hMOhuDLyf8iRdxgX9wPdshM+Hwlpr1bKmYk9cXPgJ7PgTZlguLG5zWCM5dwe8fqL1Pbx4FMx+lSTa8VnKI3TMt911m34jIk7q5Z4Mzd3JgaQLuTVpHAMOPgErf6D29lxaBrsGgyu0rcvptWsS4+iGq9DqgTWoZQuRRPYGarKPK93fk/rKZdbxf+2E7PmwO9CTtVw9DpXsDyPhrMdh1Q+091g9z9pVkrivwVzY4YXV9ue2dDz88hrz0qweHAC2bbjDqrWlXwGQ9Ne0yPs5kbuTTGbS29WXozbtB6K4cLb/CX9Nh0znOTrhYyAFhYabk+w6Y9qTMO0JaHIMXDeFjzv9wujcXn73kfjew/6tsOCD4tldRqgoFJe1oUsWhgiEUqnpWXu/XxQA2OCQwuPN0yL3lZTcXXbL3uLYaoH5G8YEXHJ+xt8a8b2qwQEYd0NouXfPjbzX6yda/5d/A1P/DbNf5iL3MDq6IsemXkh+mbsLrrdmy+daD+IE19LA/T66hJbhJx3ca83Cd7nh1eO5DMP9fEz1JHsy3fSnrf8718AzbaBaYEB+UdqwwHV8Idhvnhr6Ptf9AE6ur/W/wJzX4NvAku7p1QXet3tdZ9qhyAcDYcRN2GZF5+XZrX93KvXZxX7S4Msb4TdbNH79MHCfglwGu3/kSvf3cKC31bs4uAeSAwLwScrjMBPgY2t+zXvnQ8fzoNd1VoE3TrHueczVjqFe4QP95/4W1NiYZmcN2LgAHq7NCcAJddvwH+/HJOGhijdoPtP44ZQncrglJc3MzDRZWaVbiOSQeKYN7I9vVu+PPaew0LTh6eToE9aUSs5J/4CZ/4nY/VTVu7j3wH/jc8+j/wa/O0eRFcW7njO5Oily3WcAjr8J+j/hj57be28ONT4cABtK+Psb8i28E5pbyJtSA1fd1rCphIvanPogTHkscn+z42G9nUSv5clWC74kdL4YlnwBXS+FRZ+GHNptqlJLghLg+VxPvqjCB7dCzgqrV1SvHayYAJ0utATu7bOsMiPWwZNFpCxJSuOpzOkc+9P1nOqO8lxiub2KQETmG2Mip3KHm1HqOyQK+7fBM5E5UeLBm4Xn0EhiL72oVHIcBAGInyCA5YYqJVEFAWDOqyH+7hopLig8GL3O+wpqAAAgAElEQVR8NN6JTDbnyt9bckEAZ0GAgCBAyQUBLEGACEEAQgUBYMW3/qAKwOql/M9OxHfiHTDrOWg3IDAJFWDVj0Xb4ErC6zXRBQGs3GpxziasohCLKY9buYzKiK3dbuKvX6eExPYH40XIMymOx8qFPreBKxkadLT87MrhQbhrsywJHitb/k3ARZPIfHJp6PauIJfdrOes/8GCADB2SNHXzd8XskhUtDKkFT8tS2mIq+SISH8RWSEiq0RkhMPx50Rkof33h4gdq1dZKENB8HFz/m1RjxmEPAKiMCT/7pJd/LopJSs/6JPQ7ea94bR/wtEDnctXFI27V7QFCsBnV4VWgIrFa72LLlNM3Ps2xS7wx7dldq9oxE0URMQNvAIMADoBg0UkJBGNMeYOY0x3Y0x34CXgi3jZUxkYOz+bbdRil7EGs/odDHUpGIRcAoNvmWcM4uyD/w4ps6/lAAB2dbk69OJ120DT0ORlS7xF5OjpcDa/db43sN086MudZs8XuPwQPpJ/lFE00bBpkB6WPsMpIkdRDnP++cclsQtsjv/3Pp49hV7AKmPMamNMPjAaiDVjZDDwSYzjhx2mWmgmRd+QfgHW5Jdck8rl+feFHN9hAj7cYX1bsS6lDa95zvPvq17HivKImFR2hZ0N9eI3/bsWDAhfEju4/JcAFIrlQfypzoVQJWji2Ii11qBWm2JE5QybBtXtxVPSglJ6VK8P189wOqNkiMDQsEWJqkafyXvIVC9ZWmRFKTdcRaQ2KItbxPHaTSFkim22vS8CEWkBtAQc/R8iMkxEskQkKycnvhFAZcW0wm58xpmOxwrsoRw3XmZ5AymQDcLJXa088s8WDCTJJXx+4wl47Xju3Z0ug+TQ7IzZrqZww09Q216spOvfrP997+GK3hmBgvXah1bQra0QQeO1QgzFId48gnOiDJY26QF3rbDEoc3pocfqtQu8Pt45/t+RMx6JfVyKN6u0VFzw8qGdn1aMXFeVlFXtnfNKhdDYOdeRUg50PK/oModIPEXBafpftPjXQcBYY4zjiiLGmFHGmExjTGb9+hW3TF1xWVSlF1cX3Mv6XVakhtfYycbsR3JV/gje9ZzJJkJbu8YIzw3qwZJh66h25v2ICC3qVuV/nvOY5OpHrfOfgl7DoMO5VO92IQAN6tSInAY/cjec+kDg9cjdMHyu44/Za2ePNLFE4YpxcMqD0ONK6HF5YP9xN8LV9hLcIpY4RHzsQdvusFZOtC/4KQ9Yg96nPQSXfx55/LwXwBUUI9G6DOYYBLvJmh0H10y20jz0LeG4DsCgj0tW/uI4hSDfPDdy37FDY57SpnExemD9Yq+gp5Qxvt+JOxWaHhP328VTFLKB4LX20oFosXODOIJcR17bJeMTAVeYq2elSWek52pM2OM3CG6X0LlJLa63M26mJbt58JLeHH3LJ1bUQd3WMOgjpKa1eHnKoeZdt3VYYoW5tT4FTr4bklLgglcg045MOuMRyIjMXR9CsNg0Ck33TeeL/C8LTwxKvuYbGznprsieR5szoOfV1qQqH393zgJbIoLdUSnVoPnxlig55cgpomL1j8cUl67/V7LyAFWKUXk79abChTi1JvS9J3Rf/ciFgEII/xz99wv6rOtkFGleudKgc0Vb4EyG85rSADQ8Gi4aBRf9z95RPnPK4ikK84C2ItJSRFKwKv4IJ7eItAfqALPjaEvJyNsTM3WwEze3+Jo78m8EYMNeK6Ga16GzdPnxgQksx2bU4cFzAounREvK/H/HNiO9TvhKUb6yJfyiXPBKSDSPKbQ7Z8VxH/k4+xlrMk6SQ/hseH6Y4O1GR8M9f8Gw6VCjiZUv6qwnoFU/a7o/kOVtH30c475sGPxJpL0liduu1x4u/ShSSIJmIocITt2wxWv63R/9u+GrCJOrWM+nS2QUV9TE29F6O33vtuyt0QSGBnlX25/tXD4Yp+fiDe+MC7QIW2Pg+hlw/8bovaRaTeFsh/kYlwTGs+h1vRXdVrsFtIucp1DuDJtaMfct6neVUt15/z1/wQ0zodulgV5xOU00jpsoGGM8wHBgMrAMGGOMWSIij4jI+UFFBwOjTWWZWr13MzzZLGSafXE4QJpfBDz+6R+hFUCT2lV47MKj+fBaO1OnS6xEXjYlegC+QeHwqJyi6HE5XB80uceXhqAkouByR/ebh3+MIZV3ktUib9Id7lpmve59E1z5Fb4koe1axpj1mVoj4ILyiU2z4yLLuWOsgzx8LnQ8F5LCyrhT4SiHSYrJVUIH95LTnO8JgeittFrWn++9B/U2dt8UtN7G4E/hsshkftQPWmUtKc2y965loa6Ds6KvPOcnuKcwdIolaC1PDisjkfuSUq3e0qlBCz2Fi2Ov6+CqoFQvN8yCLsGRMwY6nA23L4LLIieE8bd3i7a/OAQnojzjEWhxItwRtgBT9YaRn3dxCZ5B3DDITVsr/HsaRewf2mG5Q9sNcD5+wcuWC3bQx5Y7FuCqr63fhu877hOFljF6FWVIXOcpGGMmGmPaGWNaG2Met/c9ZIwZH1RmpDGmZDVwPNmdbf3/bXSJTvMa+NVYg8SfF1ofXnhPwbc4Sacm1uSTG04OrYT6tCnBeEmNRtYAc7TB32LiG1MIaR0fCt0Hh+0IHlMoemJezbQSTN67eZ7zmIOIlW4CrMFvJwrDFrVJSoHrfoRbFsS+Z+tTrdZbuMsF4Nznrc/EnxXUFsj2gTV4a1cLChRo3x/anRVaFixXnY9g95kI3LHUGtSvUju0knIieNwlvSf0uzcyWZy4rB5Fz6tjX8vjsAiQ115as+XJVi8wmFb9QrdrNIHgaLzOF8GZ9uzkThfGvncsmgTNYek2GIZMgFphK8Hdbgvx+S9RIi583frvS3I4bDoMtWcmZ4ZPRnNo0p1wi/WZnXyP9fyDSapipdSoVs9ywXY4BwY8aYlQy76hZV1uuOkXuPRDygOd0RyOr6WbV/x5dD9k3MX05TlAw0DGRgKugj2mCjUll9xUa/3io6qlhCzW7WNQryJyo4RTFnnW/T2FMhKFNqfDGY9Cvbb2dWMMNB8q9ds57x/0kWXHaf+Mfm5GX+h+OSy0f2juVCspWpU6kWXrtbPSpP8zkNbZGlQPIznN+TMJfgbRxDd47e4O50K3yyz7a4atTFcrKIDPa6/7cPK9gZnHx14H894IvZfTewq3zRdSHK3D7pTewpc87qigdHpXfgXr5kDDMB/+Xcus/8GrEJ5wi/X3RTEinsAKo86eD1NtMel6qRWQ4JtFHPwd7ncfLPsGzn8x4OY85spABf/7WMhZDrs3wLnPWZ/dc0cHFrs67oZAA+f8lwKCkp5pVdzr7LQaqTWtMaFjrgqkugAYPBraB/UOfM/XZ0dJBapBEeM8ZYiKQgTFdOJc8SV8YA2UDl3e07GIr6cwprAfi7ytqN7oEi51KOfBTRKFFBS9BkeZY+yeQsyB5pLSJ7COQOgYQ6xB8TLwHqYfa+WeCR+cHjYdRoW7SFLgwles5GW5O0Nb1eFc+ZWVpydE1Gx7w3PcBONUwbrccO0PkRV1u/6wepptWypc9Fp0e3x0PM+q2HpdHxCFc/4TEAVfJRnuGmx1Cqy2fexH+wa5o3w2TTOtBHgeezGlGo0Dx5ofBwPfCa38WvWL7CUURbh9NZvCng2h+xp0tnpprU+1wq73bIwcCwn+DvcbYf1Fw2nW/rXfwbN25Xv6w5HHnajfIdBbv3ctPGVPGG0f5i7qfrnVO+hycdn1yuOEikI4sYY2ug2G3+yBztanRi9n801hb25KGs/Hhaex2jTh2tTYfs2KEAVfa7NY8xQOleIsUlLChUz8jFhv+f+deiNNYqTJSKtli0KMH2r1+tD2jNB9vu9JTHt936XgnkISNHMYBzruhhKPY9HvfmvuR9SJfA73B2scw5NnRZ6lhufRCfv+D5lk9RL+nAKTRsAtYWnHu1xcMpudCP/u3bLA6qn/117Q6L7sUNdjnQzn6KZD7e3WDBK85LTYZX3fs9SggeIqta0xDadoMpcrMIeokqOiEI6JUTNf+JpfFA7kewiPBwonpW4zemwf5d+OHj0aOo+hPDFl7T6KRfUGRZcpLaVNEnblV/DH5NDZ3MXBV4E07gYrJjqXcRKOaM9ZxAo/rN/e+bgTLldAEJocY+XmL+r+YPWSwiPHoombr2ynC4q9hGWJCb91chokB80qD8rUGpPybIE3OQZOHwnd/x66f8iE8rMhTqgoRBCjpyACty9m2wEvmQ9NZk0RjYnXL+/JgBdmFnlHt0vACye1Lf+JeWn2NyAtNf7T52MS7+Cz5GrOoa51MuC4Yvq0g2na01rBrXG3wIIpxSGWm6qbk3OxmFz5FewNS6bmixDrc3vxr1MRQYBldc+y6O3esaR4DSQRy1V5BKKiEExBbuRawJe8FZJG+rsNyX7ZuKfgupiXq1sttDUWbY1X3153nPOkO9GtaU1YC12bxTGXULGIc2X0QOnXHIhKaWaXxuszTqsZ2ltKqWG1uA9hUZZywzdg3rRnaCqUS96CA9uLf52y6O2GRy4lICoKwXx5AywdF7rPN8AGXPd+Ft8v3eLfHlN4CrGoVz2Vn0ecype/buCZyStilgVK708/BNwtesPPz+NKL3JBpvKhAp7BIXPjz5EhrmDNBF/yRdEzhMuaK7+KnFdQmfGJwnE3hA4AlzSFeyUfwD1cUFEIZo2DqydIFIIFoTi4XEKT2lVIsgcTiqzuKqJCbN8f7v4zKLZeKTHh4Zc+elxhzTwu72fbql8pTqpAMT7hVvhrRrGCNxy5aJS19kl5BEskACoKPvZuce6q1kznxfbvs2Fx0WMDPr686QQmLwkISJGOEb8YVNAPszIIQk07/r7h0bHLHU6IVI5nWyIqYEyhSXe4+xDW3uh26aGNxyghqCj4eOt05/3t+/Pah9+SW4SrKJgezevQo7nDhKGi6vzD0XVSVqRnWivH6SprFUN5fff+scpaUlKptGh/y0eMZQZzCxwzevv5W890vh5+YtTjxQ+uSGBRAGugUf3CFUu8o4+q1w+dAa1UOrSnEIOFF07hlqdjr3scnK7irasyqZISWakZu0suRVX66hM9cmneG9ZVnkTAkSR4g0Txo6IAMO8tx90Xjt5cosuc1rGh4/5iN74S2X10pHPlVyFBC5WXypGsWKk4VBQAJtxZLreJXudX8ECzEn+SUkufvllRyhH1V5SSTo1rMqRPRtleVHsKSkXR1g60qAwL4igVivYUSkGDGqlMvK3kC15ola9UWpr0ODxmPytxJ649BRHpLyIrRGSViDimgBSR/xORpSKyRERKuOJ5GZBb/HUTfNRIK5mWFrmoXCL0EJpWkhnTiqLEJG49BRFxA68AZwDZwDwRGW+MWRpUpi1wH9DHGLNTROKYRjMK3zgnC/tXwVUh2+d2bcw3i6yEY9VSS/fYotb9qTUPk0HIUnLvWiuttaIolZ54uo96AauMMasBRGQ0cAEQnHHuOuAVY8xOAGPM1jja48yBHY673ys8K2Q7OJndLae2LdEtiow+uuZbWPndkVtxljQttaIoFUY83UdNgfVB29n2vmDaAe1E5CcRmSMijqNcIjJMRLJEJCsnJ6dsrSyG6+aDa3v510J4/tLunNHJOfS0yFtFG1Wo2xqOv7FU11QURSlL4ikKTjVgeJs5CWgL9AMGA2+KSESz0hgzyhiTaYzJrF+/jNcc8C2BGIWXL+vBSW3r07S21YqvVaXk6w5o5LeiKIcL8RSFbKBZ0HY6EJ7UPhv4yhhTYIz5C1iBJRKVgicvPppzu1oLp99+ejtevqwH/dqXXJTO7Gz1LPp3aVRESUVRlIolnqIwD2grIi1FJAUYBIwPKzMOOAVAROphuZNWx9GmEjGoV3P/65QkF+d2bRJ1oZxYdGhUkzVPnkOXprXK0jxFUZQyJ26iYIzxAMOBycAyYIwxZomIPCIi59vFJgPbRWQpMBW42xhTgqWWFEVRlLIkrpPXjDETgYlh+x4Kem2AO+0/RVEUpYJJ7BnNhZ6IXWu8DfnRewyfXHd8BRikKIpSsSR27iOHCWM/eI/hUc8VtKpfrQIMUhRFqVgSXBQORuzaTxoAKe7EfjSKoiQmCe4+CojC/mrNeW93d17zWGPgpU1loSiKcjiT2DVfkPsot9DF055B/u2UJO0pKIqSeCR2zbdzTeC1N3LQWVEUJdFIbFH44KLAa+P1v1z40BkVYIyiKErFk9iiEMS3TW7yv05LdlegJYqiKBWHioLN7NQ+gJU0NVkjjxRFSVC09gO8ksSERZtoXCuNv544B7crAVZCUxRFcUBFATgn71EANu0+glc/UxRFKQYqCkB+gkfmKoqi+FBRADxYA8vvX9Orgi1RFEWpWFQUAGMvEte3XRmv6qYoinKYkbii8OdU/8vtpmYFGqIoilJ5iKsoiEh/EVkhIqtEZITD8atFJEdEFtp/Q+NpTwgfXAjA7y2vZT9VGHRssyJOUBRFOfKJ2wiriLiBV4AzsNZinici440xS8OKfmqMGR4vO4pi8958AEYM6FBRJiiKolQa4tlT6AWsMsasNsbkA6OBC+J4v1KxdPM+AJ2boCiKQnxFoSmwPmg7294XziUiskhExoqIow9HRIaJSJaIZOXk5JSpkV5jPYIkV+IOryiKoviIZ03o1PQ2YdtfAxnGmK7AD8B7ThcyxowyxmQaYzLr1y/bCCGvbab2FBRFUeIrCtlAcMs/HdgYXMAYs90Y41vp5g2gZxztcaSrazUASSoKiqIocRWFeUBbEWkpIinAIGB8cAERaRy0eT6wLI72OHKGewEALhUFRVGU+EUfGWM8IjIcmAy4gbeNMUtE5BEgyxgzHrhVRM4HPMAO4Op42aMoiqIUTVyT/hhjJgITw/Y9FPT6PuC+eNpQFPcVXMvnN55QkSYoiqJUGhI+5OZAzTb0bFGnos1QFEWpFCS8KCQlp1S0CYqiKJUGFYUUFQVFURQfCS8Ke/M16khRFMVHwovCipzcijZBURSl0pDwotCuWcOKNkFRFKXSkPCicO95PSraBEVRlEpDsURBRC4SkVpB27VF5ML4mVV+ZDRqUNEmKIqiVBqK21P4lzFmt2/DGLML+Fd8TCoHvIWB10mpFWeHoihKJaO4ouBULq6zoeNKYQEAy5M7gWj0kaIoio/iikKWiDwrIq1FpJWIPAfMj6dhcWXFBAB+q35iBRuiKIpSuSiuKNwC5AOfAmOAXODmeBkVd8ZeA0ByirqOFEVRgimWC8gYsx8YEWdbyp0UFQVFUZQQiht99L2I1A7ariMik+NnVvlQ37utok1QFEWpVBTXfVTPjjgCwBizEzjsYzlzC3WQWVEUJZjiioJXRJr7NkQkg8j1lg87qletWtEmKIqiVCqKKwoPALNE5AMR+QCYTjEWxxGR/iKyQkRWiUjUMQkRGSgiRkQyi2lPmdCyXrXyvJ2iKEqlp1iiYIz5FsgEVmBFIN2FFYEUFRFxA68AA4BOwGAR6eRQrgZwK/BLiSwvA5ISPsmHoihKKMWKPhKRocBtQDqwEDgemA2cGuO0XsAqY8xq+xqjgQuApWHlHgWeBv5RIsvLgJpVksv7loqiKJWa4raVbwOOBdYaY04BegA5RZzTFFgftJ1t7/MjIj2AZsaYb2JdSESGiUiWiGTl5BR12+Ij6ECzoihKMMUVhTxjTB6AiKQaY5YD7Ys4x6nG9Q9Oi4gLeA7LFRUTY8woY0ymMSazfv36xTS5GGTojGZFUZRgipu/KNuepzAO+F5EdgIbizoHaBa0nR52Tg2gCzBNrPxDjYDxInK+MSarmHaVimxTj4XeNpzbonc8b6MoinLYUdwZzRfZL0eKyFSgFvBtEafNA9qKSEtgAzAIuCzomruBer5tEZkG/CPegkChh8Zs50ujvQRFUZRwSpzp1BgzvZjlPCIyHJgMuIG3jTFLROQRIMsYM76k9y4TCg/iFsNeU6VCbq8oilKZiWv6a2PMRGBi2L6HopTtF09b/OTuBMBzGGf+VhRFiRcJF6nv/XgQAIK3gi1RFEWpfCScKLi2/F7RJiiKolRaEk4UFEVRlOgkrCic361JRZugKIpS6UhYUaiV5q5oExRFUSodCSsKpGjabEVRlHASVhRMlXpFF1IURUkwEk4UNjY/F4D9rc+uYEsURVEqHwknCh5JYZM5ipRknbymKIoSTsLVjIUeD2LcVE9NuLeuKIpSJAlXMxZ6CgAXNVUUFEVRIki4mjH54A4Er/YUFEVRHEi4mrHFrl+skRSXrrqmKIoSTsINNCuKoijRSSxR8BZWtAWKoiiVmriKgoj0F5EVIrJKREY4HL9BRH4XkYUiMktEOsXTHjx5cb28oijK4U7cREFE3MArwACgEzDYodL/2BhztDGmO/A08Gy87AGgIDeul1cURTnciWdPoRewyhiz2hiTD4wGLgguYIzZE7RZDTBxtAd2/BXXyyuKohzuxDP6qCmwPmg7GzguvJCI3AzcCaQApzpdSESGAcMAmjdvXnqLCg6U/lxFUZQEIJ49BaeYz4iegDHmFWNMa+Be4EGnCxljRhljMo0xmfXr1y+9RV4PAD/V+1vpr6EoinIEE09RyAaaBW2nAxtjlB8NXBhHe/zRR6sanhXX2yiKohyuxFMU5gFtRaSliKQAg4DxwQVEpG3Q5jnAyjjaQ4EnH4DUlLR43kZRFOWwJW5jCsYYj4gMByYDbuBtY8wSEXkEyDLGjAeGi8jpQAGwE7gqXvYAHDyYTzKQmpISz9soiqIctsQ1zYUxZiIwMWzfQ0Gvb4vn/cPxFFg9heRkFQVFURQnEmpGs5UhFdxJCZfySVEUpVgkligU+kQhuYItURRFqZwklCh4C62QVHeSuo8URVGcSChR8LmPXOo+UhRFcSShRMHY7qNkdR8piqI4klCi4PX43EcqCoqiKE4klij4Bpo1JFVRFMWRBBMFq6eQpD0FRVEURxJKFIxPFJJVFBRFUZxIMFGwZzRrT0FRFMWRhBIFb2EhHuMiOSmh3raiKEqxSaja0XgL8OAm2Z1Qb1tRFKXYJFbtWOjBg5skFQVFURRHEqp2NF4PhbhIdjstCqcoiqIkligU2u4jV0K9bUVRlGKTWLWj10Mhbh1oVhRFiUJca0cR6S8iK0RklYiMcDh+p4gsFZFFIvKjiLSIpz14CynATZJL3UeKoihOxE0URMQNvAIMADoBg0WkU1ixX4FMY0xXYCzwdLzsAWvyWqFxafSRoihKFOJZO/YCVhljVhtj8oHRwAXBBYwxU40xB+zNOUB6HO1BvB4KxY1bewqKoiiOxFMUmgLrg7az7X3RuBaY5HRARIaJSJaIZOXk5JTeIntMQVEURXEmnqLg1Bw3jgVFLgcygWecjhtjRhljMo0xmfXr1y+9QcaDV0VBURQlKvFcgiwbaBa0nQ5sDC8kIqcDDwAnG2MOxtEexOvBIyoKiqIo0YhnT2Ee0FZEWopICjAIGB9cQER6AP8DzjfGbI2jLQC4vXnkS2q8b6MoinLYEjdRMMZ4gOHAZGAZMMYYs0REHhGR8+1izwDVgc9EZKGIjI9yuTIhqfAgBSoKiqIoUYnrCvbGmInAxLB9DwW9Pj2e9w8nyXuQfKlanrdUFEU5rEiogP0k70E8oktxKoqiRCOhRMFlCil06QI7iqIo0Ug4UUCjjxRFUaKSUKIgFGJUFBRFUaKSUKLgMoXgUlFQFEWJRoKJglfdR4qiKDFILFGgEKM9BUVRlKgklihoT0FRFCUmiSUKeMEV1/l6iqIohzUJJgqFiLqPFEVRopJQzWY3Xo0+UpRKRkFBAdnZ2eTl5VW0KUcEaWlppKenk5xcuom6CSUKSWhIqqJUNrKzs6lRowYZGRmI6KqIh4Ixhu3bt5OdnU3Lli1LdY3EcR95vQCIjikoSqUiLy+PunXrqiCUASJC3bp1D6nXlTiiYAqt/yoKilLpUEEoOw71WSaOKHg9ADrQrCiKEoO4ioKI9BeRFSKySkRGOBzvKyILRMQjIgPjaQteq6cgbhUFRVEC7Nq1i1dffbXE55199tns2rUrDhZVLHETBRFxA68AA4BOwGAR6RRWbB1wNfBxvOzwYbwFtmHqPlIUJUA0USgsLIx53sSJE6ldu3a8zKow4llD9gJWGWNWA4jIaOACYKmvgDFmjX3MG0c7ACgoKCQFcGlPQVEqLQ9/vYSlG/eU6TU7NanJv87rHPX4iBEj+PPPP+nevTvJyclUr16dxo0bs3DhQpYuXcqFF17I+vXrycvL47bbbmPYsGEAZGRkkJWVxb59+xgwYAAnnngiP//8M02bNuWrr76iSpUqZfo+yot4uo+aAuuDtrPtfSVGRIaJSJaIZOXk5JTKGE+h1VMQt/YUFEUJ8OSTT9K6dWsWLlzIM888w9y5c3n88cdZutRqv7799tvMnz+frKwsXnzxRbZv3x5xjZUrV3LzzTezZMkSateuzeeff17eb6PMiGcN6TQEbkpzIWPMKGAUQGZmZqmu4SmwRUFzHylKpSVWi7686NWrV0iM/4svvsiXX34JwPr161m5ciV169YNOadly5Z0794dgJ49e7JmzZpys7esiacoZAPNgrbTgY1xvF9MCj129JH2FBRFiUG1atX8r6dNm8YPP/zA7NmzqVq1Kv369XOcA5Camup/7Xa7yc3NLRdb40E83UfzgLYi0lJEUoBBwPg43i8mHo/VU3CpKCiKEkSNGjXYu3ev47Hdu3dTp04dqlatyvLly5kzZ045W1f+xK2GNMZ4RGQ4MBlwA28bY5aIyCNAljFmvIgcC3wJ1AHOE5GHjTFx6T+anWsAqOo58kLIFEUpPXXr1qVPnz506dKFKlWq0LBhQ/+x/v378/rrr9O1a1fat2/P8ccfX4GWlg9iTKlc9BVGZmamycrKKvF5u7+4g1qL3mZd+nk0H/phHCxTFKU0LFu2jI4dO1a0GfHl0CQAAAwFSURBVEcUTs9UROYbYzKLOjdhZjTvb3QcAGvbXlXBliiKolReEkYUPPZAsys5rYItURRFqbwkjijYsxOTk3WgWVEUJRoJIwq+kNSkJBUFRVGUaCSMKHjshHjJKgqKoihRSRhRKPSoKCiKohRFwoiCt9ByHyUnlW7dUkVRFIDq1asDsHHjRgYOdM74369fP4oKnX/++ec5cOCAf7uypOJOGFEo9ImCDjQrilIGNGnShLFjx5b6/HBRqCypuBOmhizU6CNFqfxMGgGbfy/bazY6GgY8GfXwvffeS4sWLbjpppsAGDlyJCLCjBkz2LlzJwUFBTz22GNccMEFIeetWbOGc889l8WLF5Obm8uQIUNYunQpHTt2DMl9dOONNzJv3jxyc3MZOHAgDz/8MC+++CIbN27klFNOoV69ekydOtWfirtevXo8++yzvP322wAMHTqU22+/nTVr1pRLiu4E6inomIKiKJEMGjSITz/91L89ZswYhgwZwpdffsmCBQuYOnUqd911F7GyP7z22mtUrVqVRYsW8cADDzB//nz/sccff5ysrCwWLVrE9OnTWbRoEbfeeitNmjRh6tSpTJ06NeRa8+fP55133uGXX35hzpw5vPHGG/z6669A+aToTpga0uc+SlFRUJTKS4wWfbzo0aMHW7duZePGjeTk5FCnTh0aN27MHXfcwYwZM3C5XGzYsIEtW7bQqFEjx2vMmDGDW2+9FYCuXbvStWtX/7ExY8YwatQoPB4PmzZtYunSpSHHw5k1axYXXXSRP1vrxRdfzMyZMzn//PPLJUV3wtSQYqzF3VKSdaBZUZRQBg4cyNixY9m8eTODBg3io48+Iicnh/nz55OcnExGRoZjyuxgRCKXkPnrr7/4z3/+w7x586hTpw5XX311kdeJ1SMpjxTdCeM+6t2yDgBpKSoKiqKEMmjQIEaPHs3YsWMZOHAgu3fvpkGDBiQnJzN16lTWrl0b8/y+ffvy0UcfAbB48WIWLVoEwJ49e6hWrRq1atViy5YtTJo0yX9OtJTdffv2Zdy4cRw4cID9+/fz5ZdfctJJJ5Xhu41NwvQUMPYi3JIwOqgoSjHp3Lkze/fupWnTpjRu3Ji///3vnHfeeWRmZtK9e3c6dOgQ8/wbb7yRIUOG0LVrV7p3706vXr0A6NatGz169KBz5860atWKPn36+M8ZNmwYAwYMoHHjxiHjCscccwxXX321/xpDhw6lR48e5baaW8Kkzmb5BFj0KVz8BiSlFl1eUZRyQVNnlz2Hkjo7cXoKHc6x/hRFUZSoxNWXIiL9RWSFiKwSkREOx1NF5FP7+C8ikhFPexRFUZTYxE0URMQNvAIMADoBg0WkU1ixa4Gdxpg2wHPAU/GyR1GUysvh5sauzBzqs4xnT6EXsMoYs9oYkw+MBi4IK3MB8J79eixwmjjFdSmKcsSSlpbG9u3bVRjKAGMM27dvJy2t9IuJxXNMoSmwPmg7GzguWhljjEdEdgN1gW3BhURkGDAMoHnz5vGyV1GUCiA9PZ3s7GxycnIq2pQjgrS0NNLT00t9fjxFwanFH94UKE4ZjDGjgFFgRR8dummKolQWkpOTadmyZUWbodjE032UDTQL2k4HNkYrIyJJQC1gRxxtUhRFUWIQT1GYB7QVkZYikgIMAsaHlRkPXGW/HghMMepYVBRFqTDi5j6yxwiGA5MBN/C2MWaJiDwCZBljxgNvAR+IyCqsHsKgeNmjKIqiFM1hN6NZRHKA2IlIolOPsEHsSoLaVTIqq11QeW1Tu0rGkWhXC2NM/aIKHXaicCiISFZxpnmXN2pXyaisdkHltU3tKhmJbJdmh1MURVH8qCgoiqIofhJNFEZVtAFRULtKRmW1CyqvbWpXyUhYuxJqTEFRFEWJTaL1FBRFUZQYqCgoiqIofhJGFIpa2yHO924mIlNFZJmILBGR2+z9I0Vkg4gstP/ODjrnPtvWFSJyVhxtWyMiv9v3z7L3HSUi34vISvt/HXu/iMiLtl2LROSYONnUPuiZLBSRPSJye0U8LxF5W0S2isjioH0lfj4icpVdfqWIXOV0rzKw6xkRWW7f+0sRqW3vzxCR3KDn9nrQOT3tz3+VbfshZSmOYleJP7ey/r1GsevTIJvWiMhCe395Pq9odUPFfceMMUf8H9aM6j+BVkAK8BvQqRzv3xg4xn5dA/gDa42JkcA/HMp3sm1MBVratrvjZNsaoF7YvqeBEfbrEcBT9uuzgUlYiQyPB34pp89uM9CiIp4X0Bc4Blhc2ucDHAWstv/XsV/XiYNdZwJJ9uunguzKCC4Xdp25QG/b5knAgDjYVaLPLR6/Vye7wo7/F3ioAp5XtLqhwr5jidJTKM7aDnHDGLPJGLPAfr0XWIaVNjwaFwCjjTEHjTF/Aauw3kN5EbzOxXvAhUH73zcWc4DaItI4zracBvxpjIk1iz1uz8sYM4PIJI3/3979hUhVhnEc/z6sIltm9FeisLS2m6A0lpDKLiLMooQKUhEM8yYpKoLwYm+76SZClCJJorCIqMirWtkLITIDrU2lP5p01bT+6Y9FIbo9XbzPnM6OM+OMzjlnYn8fGObs49nxmeecOe8575l9327rcy+ww91/cfdfgR3Asl7n5e6j7n46fvycNAhlS5HbHHff5enI8mbuvfQsrzZabbeef17b5RVn+48C77R7jYLq1erYUNk+Nl0ahWZzO7Q7KBfG0pSji4DdEXoqLgO31i8RKTdfB0bNbI+leSsA5rp7DdJOC1xZQV51K5n6Ya26XtB9faqo2+OkM8q6+Wb2pZntNLMlEbs6cikjr262W9n1WgJMuPvBXKz0ejUcGyrbx6ZLo9DRvA2FJ2E2G3gfeNbdTwCvANcDC4Ea6RIWys33Dne/lTRt6pNmdlebdUuto6XRdZcD70WoH+rVTqs8yq7bCHAa2BahGjDP3RcBzwFvm9mcEvPqdruVvT1XMfXEo/R6NTk2tFy1RQ49y226NAqdzO1QKDObSdro29z9AwB3n3D3SXf/B9jCf10epeXr7j/F8xHgw8hhot4tFM9Hys4r3AfsdfeJyLHyeoVu61NafnGD8QFgdXRxEN0zx2N5D6m//sbIK9/FVEhe57DdyqzXDOBh4N1cvqXWq9mxgQr3senSKHQyt0Nhos/ydeAbd38pF8/3xz8E1L8ZsR1YaWazzGw+MES6wdXrvC40s4vqy6QblfuZOs/FY8BHubzWxDcgFgO/1y9xCzLlDK7qeuV0W59PgKVmdkl0nSyNWE+Z2TJgA7Dc3f/Kxa8ws4FYXkCqz+HI7Q8zWxz76Jrce+llXt1utzI/r/cA37p71i1UZr1aHRuoch87nzvn/6cH6a7996RWf6Tk//tO0qXc18BX8bgfeAvYF/HtwFW53xmJXL/jPL/h0CavBaRvdowDB+p1Ic2TPQYcjOdLI27A5shrHzBcYM0uAI4DF+dipdeL1CjVgFOks7F151IfUh//oXisLSivQ6R+5fo+9mqs+0hs33FgL/Bg7nWGSQfpH4BNxCgHPc6r6+3W689rs7wi/gbwRMO6Zdar1bGhsn1Mw1yIiEhmunQfiYhIB9QoiIhIRo2CiIhk1CiIiEhGjYKIiGTUKIg0MLNJmzpKa89G1bU0Auf+s68pUo0ZVScg0of+dveFVSchUgVdKYh0yNKY+y+a2RfxuCHi15rZWAz4NmZm8yI+19K8BuPxuD1easDMtlgaP3/UzAYre1MiDdQoiJxpsKH7aEXu3064+22kv2Z9OWKbSMMZ30wahG5jxDcCO939FtJY/gciPgRsdvebgN9If0Er0hf0F80iDczsT3ef3ST+I3C3ux+OQcx+dvfLzOwYaeiGUxGvufvlZnYUuMbdT+Ze4zrSuPdD8fMGYKa7v1D8OxM5O10piHTHWyy3WqeZk7nlSXRvT/qIGgWR7qzIPe+K5c9II3kCrAY+jeUxYD2AmQ3EmPwifU1nKCJnGrSYxD187O71r6XOMrPdpBOqVRF7GthqZs8DR4G1EX8GeM3M1pGuCNaTRuoU6Vu6pyDSobinMOzux6rORaQo6j4SEZGMrhRERCSjKwUREcmoURARkYwaBRERyahREBGRjBoFERHJ/AtPc/fsAN9wAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history, 'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 690us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.36596739375507"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before saving: are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_10_10_20_tanh_100_1000_50.h5\")\n",
    "#for this\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST-SEE: \n",
    "* https://www.kaggle.com/randyrose2017/for-beginners-using-keras-to-build-models\n",
    "* https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d\n",
    "* https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n",
    "## Just liked:\n",
    "* https://missinglink.ai/guides/neural-network-concepts/classification-neural-networks-neural-network-right-choice/\n",
    "## Full-house:\n",
    "https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why rerunning with same configuration gives different output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = Sequential()\n",
    "model_load.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))\n",
    "model_load.add(Dense(units = 10, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 20, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_weights('/home/amanzhol/Documents/Capstone/MAIN Work/models/model_10_10_20_tanh_100_1000_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to compile before evaluating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model_load.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Ms. Asma Salem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='AsmaSalemResults.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "predictions = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing confustion matrix from source:\n",
    "https://stackoverflow.com/questions/50920908/get-confusion-matrix-from-a-keras-multiclass-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FAR, FRR and EER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stats.stackexchange.com/questions/272962/are-far-and-frr-the-same-as-fpr-and-fnr-respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ConfusionMatrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='PerformanceMetrics.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edit:\n",
    "this is the format for confusion_matrix():\n",
    "[[TP,FN]\n",
    "[FP,TN]]\n",
    "And classification report gives all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measure(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus\n",
    "TP = 6\n",
    "FP = 1\n",
    "TN = 11\n",
    "FN = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAR(FP, TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FRR(FN, TP):\n",
    "    return FN/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAR(FP, TN) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRR(FN, TP) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (Performance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ms. Asma Results\n",
    "* FAR = 0.3%\n",
    "* FRR = 1.5%\n",
    "* EER = 0.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* How to have several FAR, FRR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read for Confusion Matrix - Get Items FP/FN/TP/TN - Python\n",
    "* https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python\n",
    "* https://classeval.wordpress.com/introduction/basic-evaluation-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
