{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keystroke Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "The dataset is taken from http://www.vmonaco.com/keystroke-datasets.\n",
    "Specifically from https://ms.sapientia.ro/~manyi/keystroke.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read:\n",
    "* https://appliedmachinelearning.blog/2017/07/26/user-verification-based-on-keystroke-dynamics-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('dataset2_norm.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holdtime1', 'holdtime2', 'holdtime3', 'holdtime4', 'holdtime5',\n",
       "       'holdtime6', 'holdtime7', 'holdtime8', 'holdtime9', 'holdtime10',\n",
       "       'holdtime11', 'holdtime12', 'holdtime13', 'holdtime14', 'downdown1',\n",
       "       'downdown2', 'downdown3', 'downdown4', 'downdown5', 'downdown6',\n",
       "       'downdown7', 'downdown8', 'downdown9', 'downdown10', 'downdown11',\n",
       "       'downdown12', 'downdown13', 'updown1', 'updown2', 'updown3', 'updown4',\n",
       "       'updown5', 'updown6', 'updown7', 'updown8', 'updown9', 'updown10',\n",
       "       'updown11', 'updown12', 'updown13', 'pressure1', 'pressure2',\n",
       "       'pressure3', 'pressure4', 'pressure5', 'pressure6', 'pressure7',\n",
       "       'pressure8', 'pressure9', 'pressure10', 'pressure11', 'pressure12',\n",
       "       'pressure13', 'pressure14', 'fingerarea1', 'fingerarea2', 'fingerarea3',\n",
       "       'fingerarea4', 'fingerarea5', 'fingerarea6', 'fingerarea7',\n",
       "       'fingerarea8', 'fingerarea9', 'fingerarea10', 'fingerarea11',\n",
       "       'fingerarea12', 'fingerarea13', 'fingerarea14', 'meanholdtime',\n",
       "       'meanpressure', 'meanfingerarea', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['user_id'].values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holdtime1</th>\n",
       "      <th>holdtime2</th>\n",
       "      <th>holdtime3</th>\n",
       "      <th>holdtime4</th>\n",
       "      <th>holdtime5</th>\n",
       "      <th>holdtime6</th>\n",
       "      <th>holdtime7</th>\n",
       "      <th>holdtime8</th>\n",
       "      <th>holdtime9</th>\n",
       "      <th>holdtime10</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerarea9</th>\n",
       "      <th>fingerarea10</th>\n",
       "      <th>fingerarea11</th>\n",
       "      <th>fingerarea12</th>\n",
       "      <th>fingerarea13</th>\n",
       "      <th>fingerarea14</th>\n",
       "      <th>meanholdtime</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meanfingerarea</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435345</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.445704</td>\n",
       "      <td>0.369322</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478448</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.454455</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.415323</td>\n",
       "      <td>0.338936</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.404412</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469828</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.271709</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.455577</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holdtime1  holdtime2  holdtime3  holdtime4  holdtime5  holdtime6  \\\n",
       "0   0.538793   0.462222   0.362903   0.274510   0.300366   0.384259   \n",
       "1   0.435345   0.382222   0.354839   0.285714   0.106227   0.328704   \n",
       "2   0.478448   0.453333   0.399194   0.338936   0.340659   0.375000   \n",
       "3   0.396552   0.444444   0.415323   0.338936   0.366300   0.416667   \n",
       "4   0.469828   0.453333   0.290323   0.271709   0.340659   0.361111   \n",
       "\n",
       "   holdtime7  holdtime8  holdtime9  holdtime10   ...     fingerarea9  \\\n",
       "0   0.430147   0.467290      0.240    0.374429   ...        0.296296   \n",
       "1   0.363971   0.485981      0.344    0.365297   ...        0.259259   \n",
       "2   0.338235   0.345794      0.296    0.365297   ...        0.296296   \n",
       "3   0.404412   0.640187      0.276    0.410959   ...        0.370370   \n",
       "4   0.408088   0.635514      0.324    0.378995   ...        0.333333   \n",
       "\n",
       "   fingerarea10  fingerarea11  fingerarea12  fingerarea13  fingerarea14  \\\n",
       "0      0.296296      0.222222      0.211470      0.283154      0.185185   \n",
       "1      0.185185      0.185185      0.354839      0.211470      0.148148   \n",
       "2      0.333333      0.222222      0.283154      0.175627      0.185185   \n",
       "3      0.185185      0.222222      0.283154      0.247312      0.296296   \n",
       "4      0.222222      0.222222      0.211470      0.318996      0.074074   \n",
       "\n",
       "   meanholdtime  meanpressure  meanfingerarea  user_id  \n",
       "0      0.447030      0.387546        0.364089     b'1'  \n",
       "1      0.423762      0.445704        0.369322     b'1'  \n",
       "2      0.454455      0.464092        0.371658     b'1'  \n",
       "3      0.522772      0.397230        0.396828     b'1'  \n",
       "4      0.493564      0.455577        0.365646     b'1'  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.mean(a == b'37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As it can be seen the number of samples per user are 51. Since the user are 42 users, there in total 51 * 42 = 2142 samples. Number of features is 71."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the dataset is 2142 * 72."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good source for Pandas: https://chrisalbon.com/python/data_wrangling/pandas_replace_values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_unique = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b'10', b'20',\n",
       "       b'21', b'24', b'25', b'26', b'27', b'28', b'29', b'35', b'36',\n",
       "       b'37', b'38', b'40', b'41', b'50', b'51', b'53', b'54', b'55',\n",
       "       b'65', b'66', b'68', b'69', b'70', b'71', b'73', b'80', b'81',\n",
       "       b'82', b'83', b'84', b'85'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_id[user_id == b'20'] = b'11'\\nuser_id[user_id == b'21'] = b'12'\\nuser_id[user_id == b'24'] = b'13'\\nuser_id[user_id == b'25'] = b'14'\\nuser_id[user_id == b'26'] = b'15'\\nuser_id[user_id == b'27'] = b'16'\\nuser_id[user_id == b'28'] = b'17'\\nuser_id[user_id == b'29'] = b'18'\\nuser_id[user_id == b'35'] = b'19'\\nuser_id[user_id == b'35'] = b'20'\\nuser_id[user_id == b'37'] = b'21'\\nuser_id[user_id == b'38'] = b'22'\\nuser_id[user_id == b'20'] = b'11'\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "user_id[user_id == b'21'] = b'12'\n",
    "user_id[user_id == b'24'] = b'13'\n",
    "user_id[user_id == b'25'] = b'14'\n",
    "user_id[user_id == b'26'] = b'15'\n",
    "user_id[user_id == b'27'] = b'16'\n",
    "user_id[user_id == b'28'] = b'17'\n",
    "user_id[user_id == b'29'] = b'18'\n",
    "user_id[user_id == b'35'] = b'19'\n",
    "user_id[user_id == b'35'] = b'20'\n",
    "user_id[user_id == b'37'] = b'21'\n",
    "user_id[user_id == b'38'] = b'22'\n",
    "user_id[user_id == b'20'] = b'11'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1 Creating Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n",
      "Wall time: 5.96 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "label = []\n",
    "for i in range(42):\n",
    "    for j in range(51):\n",
    "        label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == 0) * 2142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.2 Input Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.iloc[:,:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 71)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanzhol/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[51].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the dataset into the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 71)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.6000000000001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2142 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, train_test_split splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 10, \n",
    "                activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 20, \n",
    "                activation = 'tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "model.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                720       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 42)                882       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                430       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 42)                882       \n",
      "=================================================================\n",
      "Total params: 1,932\n",
      "Trainable params: 1,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanzhol/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.3, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       Congratulations for myself, I have build my first Deep Learning Neural Network model using Keras with understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', \n",
    "                   mode = 'auto', \n",
    "                   patience=50, \n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 Âµs, sys: 0 ns, total: 5 Âµs\n",
      "Wall time: 10.3 Âµs\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/448\n",
      " - 0s - loss: 0.4972 - acc: 0.8686 - val_loss: 1.6265 - val_acc: 0.7114\n",
      "Epoch 2/448\n",
      " - 0s - loss: 0.4953 - acc: 0.8672 - val_loss: 1.6338 - val_acc: 0.7114\n",
      "Epoch 3/448\n",
      " - 0s - loss: 0.4920 - acc: 0.8715 - val_loss: 1.6297 - val_acc: 0.7085\n",
      "Epoch 4/448\n",
      " - 0s - loss: 0.4881 - acc: 0.8708 - val_loss: 1.6337 - val_acc: 0.7085\n",
      "Epoch 5/448\n",
      " - 0s - loss: 0.4842 - acc: 0.8693 - val_loss: 1.6357 - val_acc: 0.7143\n",
      "Epoch 6/448\n",
      " - 0s - loss: 0.4792 - acc: 0.8737 - val_loss: 1.6450 - val_acc: 0.7143\n",
      "Epoch 7/448\n",
      " - 0s - loss: 0.4760 - acc: 0.8723 - val_loss: 1.6501 - val_acc: 0.7085\n",
      "Epoch 8/448\n",
      " - 0s - loss: 0.4728 - acc: 0.8752 - val_loss: 1.6479 - val_acc: 0.7114\n",
      "Epoch 9/448\n",
      " - 0s - loss: 0.4709 - acc: 0.8745 - val_loss: 1.6471 - val_acc: 0.7055\n",
      "Epoch 10/448\n",
      " - 0s - loss: 0.4665 - acc: 0.8759 - val_loss: 1.6476 - val_acc: 0.7114\n",
      "Epoch 11/448\n",
      " - 0s - loss: 0.4659 - acc: 0.8715 - val_loss: 1.6505 - val_acc: 0.7114\n",
      "Epoch 12/448\n",
      " - 0s - loss: 0.4630 - acc: 0.8723 - val_loss: 1.6453 - val_acc: 0.7143\n",
      "Epoch 13/448\n",
      " - 0s - loss: 0.4604 - acc: 0.8752 - val_loss: 1.6589 - val_acc: 0.7114\n",
      "Epoch 14/448\n",
      " - 0s - loss: 0.4592 - acc: 0.8737 - val_loss: 1.6587 - val_acc: 0.7143\n",
      "Epoch 15/448\n",
      " - 0s - loss: 0.4528 - acc: 0.8745 - val_loss: 1.6594 - val_acc: 0.7085\n",
      "Epoch 16/448\n",
      " - 0s - loss: 0.4515 - acc: 0.8745 - val_loss: 1.6589 - val_acc: 0.7085\n",
      "Epoch 17/448\n",
      " - 0s - loss: 0.4519 - acc: 0.8745 - val_loss: 1.6611 - val_acc: 0.7085\n",
      "Epoch 18/448\n",
      " - 0s - loss: 0.4451 - acc: 0.8766 - val_loss: 1.6621 - val_acc: 0.7085\n",
      "Epoch 19/448\n",
      " - 0s - loss: 0.4434 - acc: 0.8774 - val_loss: 1.6642 - val_acc: 0.7085\n",
      "Epoch 20/448\n",
      " - 0s - loss: 0.4427 - acc: 0.8766 - val_loss: 1.6703 - val_acc: 0.7114\n",
      "Epoch 21/448\n",
      " - 0s - loss: 0.4428 - acc: 0.8759 - val_loss: 1.6719 - val_acc: 0.7085\n",
      "Epoch 22/448\n",
      " - 0s - loss: 0.4399 - acc: 0.8759 - val_loss: 1.6667 - val_acc: 0.7085\n",
      "Epoch 23/448\n",
      " - 0s - loss: 0.4363 - acc: 0.8774 - val_loss: 1.6753 - val_acc: 0.7085\n",
      "Epoch 24/448\n",
      " - 0s - loss: 0.4362 - acc: 0.8781 - val_loss: 1.6774 - val_acc: 0.7085\n",
      "Epoch 25/448\n",
      " - 0s - loss: 0.4326 - acc: 0.8766 - val_loss: 1.6692 - val_acc: 0.7114\n",
      "Epoch 26/448\n",
      " - 0s - loss: 0.4298 - acc: 0.8774 - val_loss: 1.6772 - val_acc: 0.7085\n",
      "Epoch 27/448\n",
      " - 0s - loss: 0.4271 - acc: 0.8759 - val_loss: 1.6735 - val_acc: 0.7026\n",
      "Epoch 28/448\n",
      " - 0s - loss: 0.4260 - acc: 0.8796 - val_loss: 1.6821 - val_acc: 0.6997\n",
      "Epoch 29/448\n",
      " - 0s - loss: 0.4226 - acc: 0.8796 - val_loss: 1.6878 - val_acc: 0.6968\n",
      "Epoch 30/448\n",
      " - 0s - loss: 0.4222 - acc: 0.8796 - val_loss: 1.6952 - val_acc: 0.6997\n",
      "Epoch 31/448\n",
      " - 0s - loss: 0.4226 - acc: 0.8803 - val_loss: 1.6903 - val_acc: 0.6968\n",
      "Epoch 32/448\n",
      " - 0s - loss: 0.4179 - acc: 0.8803 - val_loss: 1.6972 - val_acc: 0.6910\n",
      "Epoch 33/448\n",
      " - 0s - loss: 0.4159 - acc: 0.8825 - val_loss: 1.7052 - val_acc: 0.6968\n",
      "Epoch 34/448\n",
      " - 0s - loss: 0.4172 - acc: 0.8796 - val_loss: 1.7035 - val_acc: 0.6968\n",
      "Epoch 35/448\n",
      " - 0s - loss: 0.4127 - acc: 0.8810 - val_loss: 1.7086 - val_acc: 0.6997\n",
      "Epoch 36/448\n",
      " - 0s - loss: 0.4153 - acc: 0.8781 - val_loss: 1.7075 - val_acc: 0.6968\n",
      "Epoch 37/448\n",
      " - 0s - loss: 0.4141 - acc: 0.8803 - val_loss: 1.7043 - val_acc: 0.6968\n",
      "Epoch 38/448\n",
      " - 0s - loss: 0.4094 - acc: 0.8825 - val_loss: 1.7169 - val_acc: 0.6997\n",
      "Epoch 39/448\n",
      " - 0s - loss: 0.4083 - acc: 0.8796 - val_loss: 1.7313 - val_acc: 0.6968\n",
      "Epoch 40/448\n",
      " - 0s - loss: 0.4073 - acc: 0.8810 - val_loss: 1.7211 - val_acc: 0.6968\n",
      "Epoch 41/448\n",
      " - 0s - loss: 0.4059 - acc: 0.8781 - val_loss: 1.7175 - val_acc: 0.6997\n",
      "Epoch 42/448\n",
      " - 0s - loss: 0.4039 - acc: 0.8803 - val_loss: 1.7266 - val_acc: 0.6997\n",
      "Epoch 43/448\n",
      " - 0s - loss: 0.4021 - acc: 0.8832 - val_loss: 1.7304 - val_acc: 0.6997\n",
      "Epoch 44/448\n",
      " - 0s - loss: 0.3987 - acc: 0.8839 - val_loss: 1.7392 - val_acc: 0.6997\n",
      "Epoch 45/448\n",
      " - 0s - loss: 0.3989 - acc: 0.8803 - val_loss: 1.7373 - val_acc: 0.6968\n",
      "Epoch 46/448\n",
      " - 0s - loss: 0.3981 - acc: 0.8832 - val_loss: 1.7400 - val_acc: 0.6997\n",
      "Epoch 47/448\n",
      " - 0s - loss: 0.3958 - acc: 0.8847 - val_loss: 1.7488 - val_acc: 0.6968\n",
      "Epoch 48/448\n",
      " - 0s - loss: 0.3942 - acc: 0.8832 - val_loss: 1.7357 - val_acc: 0.6968\n",
      "Epoch 49/448\n",
      " - 0s - loss: 0.3946 - acc: 0.8832 - val_loss: 1.7378 - val_acc: 0.7055\n",
      "Epoch 50/448\n",
      " - 0s - loss: 0.3933 - acc: 0.8825 - val_loss: 1.7478 - val_acc: 0.6997\n",
      "Epoch 51/448\n",
      " - 0s - loss: 0.3930 - acc: 0.8832 - val_loss: 1.7587 - val_acc: 0.6968\n",
      "Epoch 52/448\n",
      " - 0s - loss: 0.3903 - acc: 0.8854 - val_loss: 1.7580 - val_acc: 0.6997\n",
      "Epoch 53/448\n",
      " - 0s - loss: 0.3881 - acc: 0.8825 - val_loss: 1.7674 - val_acc: 0.6997\n",
      "Epoch 54/448\n",
      " - 0s - loss: 0.3883 - acc: 0.8818 - val_loss: 1.7704 - val_acc: 0.7055\n",
      "Epoch 55/448\n",
      " - 0s - loss: 0.3860 - acc: 0.8854 - val_loss: 1.7707 - val_acc: 0.7026\n",
      "Epoch 56/448\n",
      " - 0s - loss: 0.3851 - acc: 0.8825 - val_loss: 1.7687 - val_acc: 0.6968\n",
      "Epoch 57/448\n",
      " - 0s - loss: 0.3822 - acc: 0.8832 - val_loss: 1.7752 - val_acc: 0.6968\n",
      "Epoch 58/448\n",
      " - 0s - loss: 0.3817 - acc: 0.8839 - val_loss: 1.7784 - val_acc: 0.7026\n",
      "Epoch 59/448\n",
      " - 0s - loss: 0.3799 - acc: 0.8861 - val_loss: 1.7792 - val_acc: 0.7026\n",
      "Epoch 60/448\n",
      " - 0s - loss: 0.3815 - acc: 0.8818 - val_loss: 1.7803 - val_acc: 0.7026\n",
      "Epoch 61/448\n",
      " - 0s - loss: 0.3786 - acc: 0.8847 - val_loss: 1.7772 - val_acc: 0.7026\n",
      "Epoch 62/448\n",
      " - 0s - loss: 0.3780 - acc: 0.8810 - val_loss: 1.7924 - val_acc: 0.6997\n",
      "Epoch 63/448\n",
      " - 0s - loss: 0.3756 - acc: 0.8847 - val_loss: 1.7947 - val_acc: 0.6997\n",
      "Epoch 64/448\n",
      " - 0s - loss: 0.3768 - acc: 0.8839 - val_loss: 1.7963 - val_acc: 0.6997\n",
      "Epoch 65/448\n",
      " - 0s - loss: 0.3744 - acc: 0.8832 - val_loss: 1.7972 - val_acc: 0.7026\n",
      "Epoch 66/448\n",
      " - 0s - loss: 0.3743 - acc: 0.8847 - val_loss: 1.7943 - val_acc: 0.7055\n",
      "Epoch 67/448\n",
      " - 0s - loss: 0.3734 - acc: 0.8832 - val_loss: 1.7946 - val_acc: 0.7055\n",
      "Epoch 68/448\n",
      " - 0s - loss: 0.3737 - acc: 0.8825 - val_loss: 1.8037 - val_acc: 0.7026\n",
      "Epoch 69/448\n",
      " - 0s - loss: 0.3718 - acc: 0.8861 - val_loss: 1.8053 - val_acc: 0.7026\n",
      "Epoch 70/448\n",
      " - 0s - loss: 0.3706 - acc: 0.8832 - val_loss: 1.8125 - val_acc: 0.7026\n",
      "Epoch 71/448\n",
      " - 0s - loss: 0.3699 - acc: 0.8847 - val_loss: 1.8106 - val_acc: 0.7026\n",
      "Epoch 72/448\n",
      " - 0s - loss: 0.3669 - acc: 0.8861 - val_loss: 1.8175 - val_acc: 0.6997\n",
      "Epoch 73/448\n",
      " - 0s - loss: 0.3681 - acc: 0.8825 - val_loss: 1.8183 - val_acc: 0.6968\n",
      "Epoch 74/448\n",
      " - 0s - loss: 0.3682 - acc: 0.8847 - val_loss: 1.8237 - val_acc: 0.7026\n",
      "Epoch 75/448\n",
      " - 0s - loss: 0.3655 - acc: 0.8854 - val_loss: 1.8253 - val_acc: 0.7026\n",
      "Epoch 76/448\n",
      " - 0s - loss: 0.3640 - acc: 0.8869 - val_loss: 1.8260 - val_acc: 0.6939\n",
      "Epoch 77/448\n",
      " - 0s - loss: 0.3667 - acc: 0.8847 - val_loss: 1.8185 - val_acc: 0.7055\n",
      "Epoch 78/448\n",
      " - 0s - loss: 0.3644 - acc: 0.8854 - val_loss: 1.8284 - val_acc: 0.6968\n",
      "Epoch 79/448\n",
      " - 0s - loss: 0.3630 - acc: 0.8854 - val_loss: 1.8297 - val_acc: 0.6997\n",
      "Epoch 80/448\n",
      " - 0s - loss: 0.3621 - acc: 0.8854 - val_loss: 1.8350 - val_acc: 0.6968\n",
      "Epoch 81/448\n",
      " - 0s - loss: 0.3616 - acc: 0.8891 - val_loss: 1.8335 - val_acc: 0.6968\n",
      "Epoch 82/448\n",
      " - 0s - loss: 0.3595 - acc: 0.8839 - val_loss: 1.8413 - val_acc: 0.7055\n",
      "Epoch 83/448\n",
      " - 0s - loss: 0.3584 - acc: 0.8854 - val_loss: 1.8429 - val_acc: 0.7055\n",
      "Epoch 84/448\n",
      " - 0s - loss: 0.3572 - acc: 0.8847 - val_loss: 1.8462 - val_acc: 0.6997\n",
      "Epoch 85/448\n",
      " - 0s - loss: 0.3586 - acc: 0.8861 - val_loss: 1.8454 - val_acc: 0.7055\n",
      "Epoch 86/448\n",
      " - 0s - loss: 0.3572 - acc: 0.8854 - val_loss: 1.8505 - val_acc: 0.7085\n",
      "Epoch 87/448\n",
      " - 0s - loss: 0.3560 - acc: 0.8832 - val_loss: 1.8254 - val_acc: 0.7026\n",
      "Epoch 88/448\n",
      " - 0s - loss: 0.3556 - acc: 0.8869 - val_loss: 1.8396 - val_acc: 0.7055\n",
      "Epoch 89/448\n",
      " - 0s - loss: 0.3547 - acc: 0.8869 - val_loss: 1.8396 - val_acc: 0.7085\n",
      "Epoch 90/448\n",
      " - 0s - loss: 0.3562 - acc: 0.8832 - val_loss: 1.8725 - val_acc: 0.6851\n",
      "Epoch 91/448\n",
      " - 0s - loss: 0.3565 - acc: 0.8847 - val_loss: 1.8555 - val_acc: 0.7055\n",
      "Epoch 92/448\n",
      " - 0s - loss: 0.3642 - acc: 0.8839 - val_loss: 1.9096 - val_acc: 0.6997\n",
      "Epoch 93/448\n",
      " - 0s - loss: 0.3656 - acc: 0.8796 - val_loss: 1.8531 - val_acc: 0.6968\n",
      "Epoch 94/448\n",
      " - 0s - loss: 0.3575 - acc: 0.8861 - val_loss: 1.9327 - val_acc: 0.6939\n",
      "Epoch 95/448\n",
      " - 0s - loss: 0.3534 - acc: 0.8869 - val_loss: 1.8685 - val_acc: 0.6939\n",
      "Epoch 96/448\n",
      " - 0s - loss: 0.3475 - acc: 0.8883 - val_loss: 1.8703 - val_acc: 0.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/448\n",
      " - 0s - loss: 0.3483 - acc: 0.8847 - val_loss: 1.8774 - val_acc: 0.6968\n",
      "Epoch 98/448\n",
      " - 0s - loss: 0.3480 - acc: 0.8876 - val_loss: 1.8768 - val_acc: 0.6968\n",
      "Epoch 99/448\n",
      " - 0s - loss: 0.3476 - acc: 0.8839 - val_loss: 1.8764 - val_acc: 0.6939\n",
      "Epoch 100/448\n",
      " - 0s - loss: 0.3471 - acc: 0.8876 - val_loss: 1.8763 - val_acc: 0.7026\n",
      "Epoch 101/448\n",
      " - 0s - loss: 0.3464 - acc: 0.8810 - val_loss: 1.8741 - val_acc: 0.6997\n",
      "Epoch 102/448\n",
      " - 0s - loss: 0.3451 - acc: 0.8847 - val_loss: 1.8862 - val_acc: 0.6939\n",
      "Epoch 103/448\n",
      " - 0s - loss: 0.3432 - acc: 0.8920 - val_loss: 1.8827 - val_acc: 0.6997\n",
      "Epoch 104/448\n",
      " - 0s - loss: 0.3418 - acc: 0.8912 - val_loss: 1.8828 - val_acc: 0.6997\n",
      "Epoch 105/448\n",
      " - 0s - loss: 0.3454 - acc: 0.8898 - val_loss: 1.8826 - val_acc: 0.6997\n",
      "Epoch 106/448\n",
      " - 0s - loss: 0.3451 - acc: 0.8898 - val_loss: 1.8951 - val_acc: 0.6939\n",
      "Epoch 107/448\n",
      " - 0s - loss: 0.3427 - acc: 0.8832 - val_loss: 1.8829 - val_acc: 0.6968\n",
      "Epoch 108/448\n",
      " - 0s - loss: 0.3480 - acc: 0.8854 - val_loss: 1.9166 - val_acc: 0.6910\n",
      "Epoch 109/448\n",
      " - 0s - loss: 0.3493 - acc: 0.8861 - val_loss: 1.8995 - val_acc: 0.6880\n",
      "Epoch 110/448\n",
      " - 0s - loss: 0.3424 - acc: 0.8891 - val_loss: 1.8893 - val_acc: 0.7055\n",
      "Epoch 111/448\n",
      " - 0s - loss: 0.3409 - acc: 0.8876 - val_loss: 1.8952 - val_acc: 0.7026\n",
      "Epoch 112/448\n",
      " - 0s - loss: 0.3381 - acc: 0.8891 - val_loss: 1.8962 - val_acc: 0.7026\n",
      "Epoch 113/448\n",
      " - 0s - loss: 0.3399 - acc: 0.8832 - val_loss: 1.9001 - val_acc: 0.6968\n",
      "Epoch 114/448\n",
      " - 0s - loss: 0.3396 - acc: 0.8883 - val_loss: 1.9005 - val_acc: 0.6910\n",
      "Epoch 115/448\n",
      " - 0s - loss: 0.3370 - acc: 0.8869 - val_loss: 1.9050 - val_acc: 0.6997\n",
      "Epoch 116/448\n",
      " - 0s - loss: 0.3365 - acc: 0.8898 - val_loss: 1.9084 - val_acc: 0.6880\n",
      "Epoch 117/448\n",
      " - 0s - loss: 0.3351 - acc: 0.8912 - val_loss: 1.9050 - val_acc: 0.6968\n",
      "Epoch 118/448\n",
      " - 0s - loss: 0.3374 - acc: 0.8861 - val_loss: 1.9263 - val_acc: 0.6968\n",
      "Epoch 119/448\n",
      " - 0s - loss: 0.3355 - acc: 0.8891 - val_loss: 1.9303 - val_acc: 0.6939\n",
      "Epoch 120/448\n",
      " - 0s - loss: 0.3340 - acc: 0.8869 - val_loss: 1.9174 - val_acc: 0.6968\n",
      "Epoch 121/448\n",
      " - 0s - loss: 0.3315 - acc: 0.8905 - val_loss: 1.9223 - val_acc: 0.6968\n",
      "Epoch 122/448\n",
      " - 0s - loss: 0.3318 - acc: 0.8942 - val_loss: 1.9243 - val_acc: 0.7026\n",
      "Epoch 123/448\n",
      " - 0s - loss: 0.3304 - acc: 0.8905 - val_loss: 1.9219 - val_acc: 0.6968\n",
      "Epoch 124/448\n",
      " - 0s - loss: 0.3293 - acc: 0.8934 - val_loss: 1.9233 - val_acc: 0.6939\n",
      "Epoch 125/448\n",
      " - 0s - loss: 0.3309 - acc: 0.8891 - val_loss: 1.9162 - val_acc: 0.6939\n",
      "Epoch 126/448\n",
      " - 0s - loss: 0.3392 - acc: 0.8847 - val_loss: 1.9253 - val_acc: 0.6939\n",
      "Epoch 127/448\n",
      " - 0s - loss: 0.3313 - acc: 0.8876 - val_loss: 1.9321 - val_acc: 0.6939\n",
      "Epoch 128/448\n",
      " - 0s - loss: 0.3288 - acc: 0.8934 - val_loss: 1.9316 - val_acc: 0.6968\n",
      "Epoch 129/448\n",
      " - 0s - loss: 0.3300 - acc: 0.8920 - val_loss: 1.9268 - val_acc: 0.6939\n",
      "Epoch 130/448\n",
      " - 0s - loss: 0.3282 - acc: 0.8912 - val_loss: 1.9329 - val_acc: 0.7026\n",
      "Epoch 131/448\n",
      " - 0s - loss: 0.3249 - acc: 0.8912 - val_loss: 1.9342 - val_acc: 0.6997\n",
      "Epoch 132/448\n",
      " - 0s - loss: 0.3254 - acc: 0.8942 - val_loss: 1.9413 - val_acc: 0.6968\n",
      "Epoch 133/448\n",
      " - 0s - loss: 0.3266 - acc: 0.8942 - val_loss: 1.9378 - val_acc: 0.6939\n",
      "Epoch 134/448\n",
      " - 0s - loss: 0.3252 - acc: 0.8920 - val_loss: 1.9400 - val_acc: 0.6851\n",
      "Epoch 135/448\n",
      " - 0s - loss: 0.3234 - acc: 0.8905 - val_loss: 1.9395 - val_acc: 0.6939\n",
      "Epoch 136/448\n",
      " - 0s - loss: 0.3223 - acc: 0.8934 - val_loss: 1.9447 - val_acc: 0.7026\n",
      "Epoch 137/448\n",
      " - 0s - loss: 0.3220 - acc: 0.8934 - val_loss: 1.9525 - val_acc: 0.6968\n",
      "Epoch 138/448\n",
      " - 0s - loss: 0.3222 - acc: 0.8927 - val_loss: 1.9442 - val_acc: 0.6939\n",
      "Epoch 139/448\n",
      " - 0s - loss: 0.3233 - acc: 0.8942 - val_loss: 1.9493 - val_acc: 0.6939\n",
      "Epoch 140/448\n",
      " - 0s - loss: 0.3223 - acc: 0.8927 - val_loss: 1.9625 - val_acc: 0.6968\n",
      "Epoch 141/448\n",
      " - 0s - loss: 0.3227 - acc: 0.8920 - val_loss: 1.9507 - val_acc: 0.6910\n",
      "Epoch 142/448\n",
      " - 0s - loss: 0.3208 - acc: 0.8942 - val_loss: 1.9555 - val_acc: 0.6968\n",
      "Epoch 143/448\n",
      " - 0s - loss: 0.3209 - acc: 0.8912 - val_loss: 1.9533 - val_acc: 0.7026\n",
      "Epoch 144/448\n",
      " - 0s - loss: 0.3196 - acc: 0.8934 - val_loss: 1.9733 - val_acc: 0.6910\n",
      "Epoch 145/448\n",
      " - 0s - loss: 0.3194 - acc: 0.8942 - val_loss: 1.9654 - val_acc: 0.6910\n",
      "Epoch 146/448\n",
      " - 0s - loss: 0.3186 - acc: 0.8942 - val_loss: 1.9538 - val_acc: 0.6939\n",
      "Epoch 147/448\n",
      " - 0s - loss: 0.3176 - acc: 0.8956 - val_loss: 1.9695 - val_acc: 0.6997\n",
      "Epoch 148/448\n",
      " - 0s - loss: 0.3157 - acc: 0.8949 - val_loss: 1.9689 - val_acc: 0.7026\n",
      "Epoch 149/448\n",
      " - 0s - loss: 0.3159 - acc: 0.8985 - val_loss: 1.9781 - val_acc: 0.6939\n",
      "Epoch 150/448\n",
      " - 0s - loss: 0.3152 - acc: 0.8934 - val_loss: 1.9798 - val_acc: 0.6939\n",
      "Epoch 151/448\n",
      " - 0s - loss: 0.3163 - acc: 0.8876 - val_loss: 1.9762 - val_acc: 0.6968\n",
      "Epoch 152/448\n",
      " - 0s - loss: 0.3151 - acc: 0.8956 - val_loss: 1.9835 - val_acc: 0.6968\n",
      "Epoch 153/448\n",
      " - 0s - loss: 0.3153 - acc: 0.8942 - val_loss: 1.9783 - val_acc: 0.6939\n",
      "Epoch 154/448\n",
      " - 0s - loss: 0.3221 - acc: 0.8927 - val_loss: 2.0151 - val_acc: 0.6910\n",
      "Epoch 155/448\n",
      " - 0s - loss: 0.3409 - acc: 0.8883 - val_loss: 1.9870 - val_acc: 0.6997\n",
      "Epoch 156/448\n",
      " - 0s - loss: 0.3296 - acc: 0.8876 - val_loss: 2.0434 - val_acc: 0.6880\n",
      "Epoch 157/448\n",
      " - 0s - loss: 0.3262 - acc: 0.8883 - val_loss: 2.0255 - val_acc: 0.6880\n",
      "Epoch 158/448\n",
      " - 0s - loss: 0.3213 - acc: 0.8905 - val_loss: 1.9831 - val_acc: 0.7026\n",
      "Epoch 159/448\n",
      " - 0s - loss: 0.3171 - acc: 0.8920 - val_loss: 1.9904 - val_acc: 0.6997\n",
      "Epoch 160/448\n",
      " - 0s - loss: 0.3178 - acc: 0.8912 - val_loss: 2.0529 - val_acc: 0.6880\n",
      "Epoch 161/448\n",
      " - 0s - loss: 0.3119 - acc: 0.8912 - val_loss: 2.0473 - val_acc: 0.6880\n",
      "Epoch 162/448\n",
      " - 0s - loss: 0.3122 - acc: 0.8978 - val_loss: 2.0079 - val_acc: 0.6939\n",
      "Epoch 163/448\n",
      " - 0s - loss: 0.3110 - acc: 0.8956 - val_loss: 2.0105 - val_acc: 0.6851\n",
      "Epoch 164/448\n",
      " - 0s - loss: 0.3093 - acc: 0.8949 - val_loss: 2.0146 - val_acc: 0.6968\n",
      "Epoch 165/448\n",
      " - 0s - loss: 0.3083 - acc: 0.8949 - val_loss: 2.0261 - val_acc: 0.6880\n",
      "Epoch 166/448\n",
      " - 0s - loss: 0.3080 - acc: 0.8964 - val_loss: 2.0197 - val_acc: 0.6910\n",
      "Epoch 167/448\n",
      " - 0s - loss: 0.3080 - acc: 0.8956 - val_loss: 2.0193 - val_acc: 0.6968\n",
      "Epoch 168/448\n",
      " - 0s - loss: 0.3086 - acc: 0.8978 - val_loss: 2.0080 - val_acc: 0.6939\n",
      "Epoch 169/448\n",
      " - 0s - loss: 0.3052 - acc: 0.8993 - val_loss: 2.0281 - val_acc: 0.6851\n",
      "Epoch 170/448\n",
      " - 0s - loss: 0.3057 - acc: 0.8956 - val_loss: 2.0198 - val_acc: 0.6939\n",
      "Epoch 171/448\n",
      " - 0s - loss: 0.3052 - acc: 0.8956 - val_loss: 2.0258 - val_acc: 0.6910\n",
      "Epoch 172/448\n",
      " - 0s - loss: 0.3058 - acc: 0.8949 - val_loss: 2.0327 - val_acc: 0.6939\n",
      "Epoch 173/448\n",
      " - 0s - loss: 0.3042 - acc: 0.8949 - val_loss: 2.0219 - val_acc: 0.6968\n",
      "Epoch 174/448\n",
      " - 0s - loss: 0.3062 - acc: 0.8942 - val_loss: 2.0459 - val_acc: 0.6822\n",
      "Epoch 175/448\n",
      " - 0s - loss: 0.3194 - acc: 0.8891 - val_loss: 2.0497 - val_acc: 0.6910\n",
      "Epoch 176/448\n",
      " - 0s - loss: 0.3083 - acc: 0.8964 - val_loss: 2.0422 - val_acc: 0.6968\n",
      "Epoch 177/448\n",
      " - 0s - loss: 0.3133 - acc: 0.8920 - val_loss: 2.0349 - val_acc: 0.6997\n",
      "Epoch 178/448\n",
      " - 0s - loss: 0.3083 - acc: 0.8956 - val_loss: 2.0479 - val_acc: 0.6910\n",
      "Epoch 179/448\n",
      " - 0s - loss: 0.3069 - acc: 0.8883 - val_loss: 2.0544 - val_acc: 0.6880\n",
      "Epoch 180/448\n",
      " - 0s - loss: 0.3037 - acc: 0.8985 - val_loss: 2.0615 - val_acc: 0.6910\n",
      "Epoch 181/448\n",
      " - 0s - loss: 0.3055 - acc: 0.8949 - val_loss: 2.0312 - val_acc: 0.6968\n",
      "Epoch 182/448\n",
      " - 0s - loss: 0.3078 - acc: 0.8934 - val_loss: 2.0273 - val_acc: 0.6939\n",
      "Epoch 183/448\n",
      " - 0s - loss: 0.3025 - acc: 0.8985 - val_loss: 2.0332 - val_acc: 0.6939\n",
      "Epoch 184/448\n",
      " - 0s - loss: 0.3045 - acc: 0.8949 - val_loss: 2.0411 - val_acc: 0.6939\n",
      "Epoch 185/448\n",
      " - 0s - loss: 0.3012 - acc: 0.8964 - val_loss: 2.0495 - val_acc: 0.6880\n",
      "Epoch 186/448\n",
      " - 0s - loss: 0.3017 - acc: 0.8934 - val_loss: 2.0500 - val_acc: 0.6939\n",
      "Epoch 187/448\n",
      " - 0s - loss: 0.3001 - acc: 0.8978 - val_loss: 2.0499 - val_acc: 0.6968\n",
      "Epoch 188/448\n",
      " - 0s - loss: 0.3016 - acc: 0.9000 - val_loss: 2.0470 - val_acc: 0.6939\n",
      "Epoch 189/448\n",
      " - 0s - loss: 0.3005 - acc: 0.8985 - val_loss: 2.0558 - val_acc: 0.6910\n",
      "Epoch 190/448\n",
      " - 0s - loss: 0.2987 - acc: 0.8949 - val_loss: 2.0674 - val_acc: 0.6939\n",
      "Epoch 191/448\n",
      " - 0s - loss: 0.3001 - acc: 0.8942 - val_loss: 2.0630 - val_acc: 0.6968\n",
      "Epoch 192/448\n",
      " - 0s - loss: 0.2982 - acc: 0.8964 - val_loss: 2.0504 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/448\n",
      " - 0s - loss: 0.2978 - acc: 0.8985 - val_loss: 2.0540 - val_acc: 0.7026\n",
      "Epoch 194/448\n",
      " - 0s - loss: 0.2969 - acc: 0.9015 - val_loss: 2.0515 - val_acc: 0.6968\n",
      "Epoch 195/448\n",
      " - 0s - loss: 0.3000 - acc: 0.8942 - val_loss: 2.0674 - val_acc: 0.6851\n",
      "Epoch 196/448\n",
      " - 0s - loss: 0.2978 - acc: 0.8934 - val_loss: 2.0698 - val_acc: 0.6939\n",
      "Epoch 197/448\n",
      " - 0s - loss: 0.2962 - acc: 0.8985 - val_loss: 2.0588 - val_acc: 0.6997\n",
      "Epoch 198/448\n",
      " - 0s - loss: 0.2961 - acc: 0.8971 - val_loss: 2.0601 - val_acc: 0.6910\n",
      "Epoch 199/448\n",
      " - 0s - loss: 0.2962 - acc: 0.8993 - val_loss: 2.0602 - val_acc: 0.6910\n",
      "Epoch 200/448\n",
      " - 0s - loss: 0.2945 - acc: 0.9000 - val_loss: 2.0644 - val_acc: 0.6880\n",
      "Epoch 201/448\n",
      " - 0s - loss: 0.2937 - acc: 0.9029 - val_loss: 2.0664 - val_acc: 0.6939\n",
      "Epoch 202/448\n",
      " - 0s - loss: 0.2953 - acc: 0.9000 - val_loss: 2.0581 - val_acc: 0.6968\n",
      "Epoch 203/448\n",
      " - 0s - loss: 0.2930 - acc: 0.9036 - val_loss: 2.0688 - val_acc: 0.6939\n",
      "Epoch 204/448\n",
      " - 0s - loss: 0.2943 - acc: 0.8978 - val_loss: 2.0683 - val_acc: 0.6851\n",
      "Epoch 205/448\n",
      " - 0s - loss: 0.2932 - acc: 0.9000 - val_loss: 2.0839 - val_acc: 0.6939\n",
      "Epoch 206/448\n",
      " - 0s - loss: 0.2943 - acc: 0.9000 - val_loss: 2.0729 - val_acc: 0.6968\n",
      "Epoch 207/448\n",
      " - 0s - loss: 0.2922 - acc: 0.9015 - val_loss: 2.0715 - val_acc: 0.6910\n",
      "Epoch 208/448\n",
      " - 0s - loss: 0.2953 - acc: 0.8978 - val_loss: 2.0834 - val_acc: 0.6910\n",
      "Epoch 209/448\n",
      " - 0s - loss: 0.2919 - acc: 0.9029 - val_loss: 2.0858 - val_acc: 0.6851\n",
      "Epoch 210/448\n",
      " - 0s - loss: 0.2918 - acc: 0.9007 - val_loss: 2.0888 - val_acc: 0.6939\n",
      "Epoch 211/448\n",
      " - 0s - loss: 0.2924 - acc: 0.9015 - val_loss: 2.0809 - val_acc: 0.6939\n",
      "Epoch 212/448\n",
      " - 0s - loss: 0.2926 - acc: 0.8964 - val_loss: 2.0880 - val_acc: 0.6939\n",
      "Epoch 213/448\n",
      " - 0s - loss: 0.2913 - acc: 0.9007 - val_loss: 2.0900 - val_acc: 0.6939\n",
      "Epoch 214/448\n",
      " - 0s - loss: 0.2900 - acc: 0.8985 - val_loss: 2.0800 - val_acc: 0.6939\n",
      "Epoch 215/448\n",
      " - 0s - loss: 0.2903 - acc: 0.9015 - val_loss: 2.0888 - val_acc: 0.6910\n",
      "Epoch 216/448\n",
      " - 0s - loss: 0.2890 - acc: 0.9015 - val_loss: 2.0896 - val_acc: 0.6968\n",
      "Epoch 217/448\n",
      " - 0s - loss: 0.2885 - acc: 0.9000 - val_loss: 2.0838 - val_acc: 0.6939\n",
      "Epoch 218/448\n",
      " - 0s - loss: 0.2888 - acc: 0.9000 - val_loss: 2.1093 - val_acc: 0.6939\n",
      "Epoch 219/448\n",
      " - 0s - loss: 0.2898 - acc: 0.9000 - val_loss: 2.1048 - val_acc: 0.6939\n",
      "Epoch 220/448\n",
      " - 0s - loss: 0.2907 - acc: 0.8985 - val_loss: 2.1086 - val_acc: 0.6910\n",
      "Epoch 221/448\n",
      " - 0s - loss: 0.2903 - acc: 0.9000 - val_loss: 2.1028 - val_acc: 0.6939\n",
      "Epoch 222/448\n",
      " - 0s - loss: 0.2895 - acc: 0.9015 - val_loss: 2.1071 - val_acc: 0.6968\n",
      "Epoch 223/448\n",
      " - 0s - loss: 0.2883 - acc: 0.8993 - val_loss: 2.1060 - val_acc: 0.6910\n",
      "Epoch 224/448\n",
      " - 0s - loss: 0.2880 - acc: 0.9022 - val_loss: 2.1124 - val_acc: 0.6939\n",
      "Epoch 225/448\n",
      " - 0s - loss: 0.2860 - acc: 0.9029 - val_loss: 2.1087 - val_acc: 0.6968\n",
      "Epoch 226/448\n",
      " - 0s - loss: 0.2862 - acc: 0.9000 - val_loss: 2.1054 - val_acc: 0.6880\n",
      "Epoch 227/448\n",
      " - 0s - loss: 0.2866 - acc: 0.8993 - val_loss: 2.1085 - val_acc: 0.6939\n",
      "Epoch 228/448\n",
      " - 0s - loss: 0.2874 - acc: 0.9000 - val_loss: 2.1179 - val_acc: 0.6997\n",
      "Epoch 229/448\n",
      " - 0s - loss: 0.2857 - acc: 0.9029 - val_loss: 2.1285 - val_acc: 0.6880\n",
      "Epoch 230/448\n",
      " - 0s - loss: 0.2854 - acc: 0.8985 - val_loss: 2.1073 - val_acc: 0.6939\n",
      "Epoch 231/448\n",
      " - 0s - loss: 0.2885 - acc: 0.9000 - val_loss: 2.1292 - val_acc: 0.6968\n",
      "Epoch 232/448\n",
      " - 0s - loss: 0.3178 - acc: 0.8891 - val_loss: 2.1072 - val_acc: 0.6997\n",
      "Epoch 233/448\n",
      " - 0s - loss: 0.3209 - acc: 0.8920 - val_loss: 2.1021 - val_acc: 0.6997\n",
      "Epoch 234/448\n",
      " - 0s - loss: 0.3044 - acc: 0.8978 - val_loss: 2.1291 - val_acc: 0.6968\n",
      "Epoch 235/448\n",
      " - 0s - loss: 0.2920 - acc: 0.8964 - val_loss: 2.1070 - val_acc: 0.6851\n",
      "Epoch 236/448\n",
      " - 0s - loss: 0.2908 - acc: 0.8956 - val_loss: 2.1235 - val_acc: 0.6910\n",
      "Epoch 237/448\n",
      " - 0s - loss: 0.2907 - acc: 0.8993 - val_loss: 2.1460 - val_acc: 0.6910\n",
      "Epoch 238/448\n",
      " - 0s - loss: 0.2906 - acc: 0.9000 - val_loss: 2.1022 - val_acc: 0.6910\n",
      "Epoch 239/448\n",
      " - 0s - loss: 0.2876 - acc: 0.9036 - val_loss: 2.1132 - val_acc: 0.6939\n",
      "Epoch 240/448\n",
      " - 0s - loss: 0.2863 - acc: 0.9007 - val_loss: 2.1399 - val_acc: 0.6910\n",
      "Epoch 241/448\n",
      " - 0s - loss: 0.2916 - acc: 0.9007 - val_loss: 2.1338 - val_acc: 0.6939\n",
      "Epoch 242/448\n",
      " - 0s - loss: 0.2858 - acc: 0.9007 - val_loss: 2.1378 - val_acc: 0.6880\n",
      "Epoch 243/448\n",
      " - 0s - loss: 0.2858 - acc: 0.8985 - val_loss: 2.1472 - val_acc: 0.6910\n",
      "Epoch 244/448\n",
      " - 0s - loss: 0.2852 - acc: 0.9007 - val_loss: 2.1468 - val_acc: 0.6880\n",
      "Epoch 245/448\n",
      " - 0s - loss: 0.2869 - acc: 0.8985 - val_loss: 2.1400 - val_acc: 0.6939\n",
      "Epoch 246/448\n",
      " - 0s - loss: 0.2853 - acc: 0.9022 - val_loss: 2.1537 - val_acc: 0.6968\n",
      "Epoch 247/448\n",
      " - 0s - loss: 0.2825 - acc: 0.8985 - val_loss: 2.1496 - val_acc: 0.6910\n",
      "Epoch 248/448\n",
      " - 0s - loss: 0.2825 - acc: 0.9015 - val_loss: 2.1532 - val_acc: 0.6910\n",
      "Epoch 249/448\n",
      " - 0s - loss: 0.2801 - acc: 0.8985 - val_loss: 2.1391 - val_acc: 0.6939\n",
      "Epoch 250/448\n",
      " - 0s - loss: 0.2817 - acc: 0.9044 - val_loss: 2.1474 - val_acc: 0.6968\n",
      "Epoch 251/448\n",
      " - 0s - loss: 0.2793 - acc: 0.9000 - val_loss: 2.1510 - val_acc: 0.6939\n",
      "Epoch 252/448\n",
      " - 0s - loss: 0.2815 - acc: 0.9000 - val_loss: 2.1567 - val_acc: 0.6880\n",
      "Epoch 253/448\n",
      " - 0s - loss: 0.2813 - acc: 0.8971 - val_loss: 2.1588 - val_acc: 0.6939\n",
      "Epoch 254/448\n",
      " - 0s - loss: 0.2801 - acc: 0.9029 - val_loss: 2.1534 - val_acc: 0.6997\n",
      "Epoch 255/448\n",
      " - 0s - loss: 0.2794 - acc: 0.9058 - val_loss: 2.1613 - val_acc: 0.6880\n",
      "Epoch 256/448\n",
      " - 0s - loss: 0.2792 - acc: 0.8993 - val_loss: 2.1541 - val_acc: 0.6939\n",
      "Epoch 257/448\n",
      " - 0s - loss: 0.2800 - acc: 0.9015 - val_loss: 2.1606 - val_acc: 0.6997\n",
      "Epoch 258/448\n",
      " - 0s - loss: 0.2782 - acc: 0.9044 - val_loss: 2.1560 - val_acc: 0.6939\n",
      "Epoch 259/448\n",
      " - 0s - loss: 0.2781 - acc: 0.9007 - val_loss: 2.1628 - val_acc: 0.6939\n",
      "Epoch 260/448\n",
      " - 0s - loss: 0.2803 - acc: 0.8971 - val_loss: 2.1566 - val_acc: 0.6822\n",
      "Epoch 261/448\n",
      " - 0s - loss: 0.2783 - acc: 0.8993 - val_loss: 2.1626 - val_acc: 0.6939\n",
      "Epoch 262/448\n",
      " - 0s - loss: 0.2818 - acc: 0.8978 - val_loss: 2.1629 - val_acc: 0.6939\n",
      "Epoch 263/448\n",
      " - 0s - loss: 0.2808 - acc: 0.9000 - val_loss: 2.1669 - val_acc: 0.6910\n",
      "Epoch 264/448\n",
      " - 0s - loss: 0.2764 - acc: 0.9015 - val_loss: 2.1558 - val_acc: 0.6880\n",
      "Epoch 265/448\n",
      " - 0s - loss: 0.2757 - acc: 0.9044 - val_loss: 2.1603 - val_acc: 0.6939\n",
      "Epoch 266/448\n",
      " - 0s - loss: 0.2760 - acc: 0.9022 - val_loss: 2.1626 - val_acc: 0.6880\n",
      "Epoch 267/448\n",
      " - 0s - loss: 0.2774 - acc: 0.9044 - val_loss: 2.1609 - val_acc: 0.6910\n",
      "Epoch 268/448\n",
      " - 0s - loss: 0.2759 - acc: 0.9036 - val_loss: 2.1692 - val_acc: 0.6910\n",
      "Epoch 269/448\n",
      " - 0s - loss: 0.2764 - acc: 0.9036 - val_loss: 2.1585 - val_acc: 0.6968\n",
      "Epoch 270/448\n",
      " - 0s - loss: 0.2766 - acc: 0.9036 - val_loss: 2.1670 - val_acc: 0.6939\n",
      "Epoch 271/448\n",
      " - 0s - loss: 0.2750 - acc: 0.9000 - val_loss: 2.1636 - val_acc: 0.6910\n",
      "Epoch 272/448\n",
      " - 0s - loss: 0.2771 - acc: 0.9022 - val_loss: 2.1798 - val_acc: 0.6968\n",
      "Epoch 273/448\n",
      " - 0s - loss: 0.2768 - acc: 0.9022 - val_loss: 2.1581 - val_acc: 0.6880\n",
      "Epoch 274/448\n",
      " - 0s - loss: 0.2788 - acc: 0.8978 - val_loss: 2.1724 - val_acc: 0.6939\n",
      "Epoch 275/448\n",
      " - 0s - loss: 0.2748 - acc: 0.9051 - val_loss: 2.1618 - val_acc: 0.6939\n",
      "Epoch 276/448\n",
      " - 0s - loss: 0.2781 - acc: 0.9029 - val_loss: 2.1636 - val_acc: 0.6880\n",
      "Epoch 277/448\n",
      " - 0s - loss: 0.2761 - acc: 0.9015 - val_loss: 2.1623 - val_acc: 0.6910\n",
      "Epoch 278/448\n",
      " - 0s - loss: 0.2728 - acc: 0.9080 - val_loss: 2.1695 - val_acc: 0.6997\n",
      "Epoch 279/448\n",
      " - 0s - loss: 0.2732 - acc: 0.9036 - val_loss: 2.1641 - val_acc: 0.6939\n",
      "Epoch 280/448\n",
      " - 0s - loss: 0.2741 - acc: 0.9000 - val_loss: 2.1832 - val_acc: 0.6910\n",
      "Epoch 281/448\n",
      " - 0s - loss: 0.2733 - acc: 0.9036 - val_loss: 2.1710 - val_acc: 0.6997\n",
      "Epoch 282/448\n",
      " - 0s - loss: 0.2730 - acc: 0.9036 - val_loss: 2.1802 - val_acc: 0.6910\n",
      "Epoch 283/448\n",
      " - 0s - loss: 0.2721 - acc: 0.9051 - val_loss: 2.1764 - val_acc: 0.6910\n",
      "Epoch 284/448\n",
      " - 0s - loss: 0.2774 - acc: 0.9044 - val_loss: 2.1726 - val_acc: 0.7026\n",
      "Epoch 285/448\n",
      " - 0s - loss: 0.2760 - acc: 0.9058 - val_loss: 2.1959 - val_acc: 0.6910\n",
      "Epoch 286/448\n",
      " - 0s - loss: 0.2797 - acc: 0.9015 - val_loss: 2.1856 - val_acc: 0.6968\n",
      "Epoch 287/448\n",
      " - 0s - loss: 0.2763 - acc: 0.9022 - val_loss: 2.1826 - val_acc: 0.6939\n",
      "Epoch 288/448\n",
      " - 0s - loss: 0.2716 - acc: 0.9022 - val_loss: 2.1811 - val_acc: 0.6910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/448\n",
      " - 0s - loss: 0.2712 - acc: 0.9044 - val_loss: 2.1749 - val_acc: 0.6939\n",
      "Epoch 290/448\n",
      " - 0s - loss: 0.2722 - acc: 0.9029 - val_loss: 2.1888 - val_acc: 0.6880\n",
      "Epoch 291/448\n",
      " - 0s - loss: 0.2710 - acc: 0.9029 - val_loss: 2.1852 - val_acc: 0.6939\n",
      "Epoch 292/448\n",
      " - 0s - loss: 0.2694 - acc: 0.9058 - val_loss: 2.1764 - val_acc: 0.6968\n",
      "Epoch 293/448\n",
      " - 0s - loss: 0.2713 - acc: 0.9036 - val_loss: 2.1897 - val_acc: 0.6880\n",
      "Epoch 294/448\n",
      " - 0s - loss: 0.2685 - acc: 0.9066 - val_loss: 2.1887 - val_acc: 0.6968\n",
      "Epoch 295/448\n",
      " - 0s - loss: 0.2709 - acc: 0.9066 - val_loss: 2.1875 - val_acc: 0.6910\n",
      "Epoch 296/448\n",
      " - 0s - loss: 0.2682 - acc: 0.9051 - val_loss: 2.1884 - val_acc: 0.6939\n",
      "Epoch 297/448\n",
      " - 0s - loss: 0.2676 - acc: 0.9066 - val_loss: 2.1901 - val_acc: 0.6939\n",
      "Epoch 298/448\n",
      " - 0s - loss: 0.2689 - acc: 0.9051 - val_loss: 2.1934 - val_acc: 0.6910\n",
      "Epoch 299/448\n",
      " - 0s - loss: 0.2690 - acc: 0.9058 - val_loss: 2.1935 - val_acc: 0.6910\n",
      "Epoch 300/448\n",
      " - 0s - loss: 0.2695 - acc: 0.9022 - val_loss: 2.1960 - val_acc: 0.6910\n",
      "Epoch 301/448\n",
      " - 0s - loss: 0.2708 - acc: 0.9007 - val_loss: 2.1980 - val_acc: 0.6910\n",
      "Epoch 302/448\n",
      " - 0s - loss: 0.2709 - acc: 0.9073 - val_loss: 2.1883 - val_acc: 0.6997\n",
      "Epoch 303/448\n",
      " - 0s - loss: 0.2830 - acc: 0.8993 - val_loss: 2.2270 - val_acc: 0.6880\n",
      "Epoch 304/448\n",
      " - 0s - loss: 0.2782 - acc: 0.9015 - val_loss: 2.1994 - val_acc: 0.6910\n",
      "Epoch 305/448\n",
      " - 0s - loss: 0.2834 - acc: 0.8978 - val_loss: 2.1751 - val_acc: 0.6997\n",
      "Epoch 306/448\n",
      " - 0s - loss: 0.2889 - acc: 0.8978 - val_loss: 2.2154 - val_acc: 0.6793\n",
      "Epoch 307/448\n",
      " - 0s - loss: 0.2816 - acc: 0.8978 - val_loss: 2.1958 - val_acc: 0.6910\n",
      "Epoch 308/448\n",
      " - 0s - loss: 0.2752 - acc: 0.9036 - val_loss: 2.1983 - val_acc: 0.6851\n",
      "Epoch 309/448\n",
      " - 0s - loss: 0.2692 - acc: 0.9015 - val_loss: 2.2100 - val_acc: 0.6822\n",
      "Epoch 310/448\n",
      " - 0s - loss: 0.2679 - acc: 0.9044 - val_loss: 2.1929 - val_acc: 0.6910\n",
      "Epoch 311/448\n",
      " - 0s - loss: 0.2678 - acc: 0.9073 - val_loss: 2.1856 - val_acc: 0.6939\n",
      "Epoch 312/448\n",
      " - 0s - loss: 0.2673 - acc: 0.9044 - val_loss: 2.2004 - val_acc: 0.6939\n",
      "Epoch 313/448\n",
      " - 0s - loss: 0.2706 - acc: 0.9051 - val_loss: 2.2136 - val_acc: 0.6880\n",
      "Epoch 314/448\n",
      " - 0s - loss: 0.2696 - acc: 0.9022 - val_loss: 2.2363 - val_acc: 0.6939\n",
      "Epoch 315/448\n",
      " - 0s - loss: 0.2766 - acc: 0.9051 - val_loss: 2.1957 - val_acc: 0.6910\n",
      "Epoch 316/448\n",
      " - 0s - loss: 0.2725 - acc: 0.9044 - val_loss: 2.2068 - val_acc: 0.6910\n",
      "Epoch 317/448\n",
      " - 0s - loss: 0.2755 - acc: 0.8985 - val_loss: 2.2068 - val_acc: 0.6880\n",
      "Epoch 318/448\n",
      " - 0s - loss: 0.2681 - acc: 0.9022 - val_loss: 2.2290 - val_acc: 0.6880\n",
      "Epoch 319/448\n",
      " - 0s - loss: 0.2669 - acc: 0.9066 - val_loss: 2.2305 - val_acc: 0.6939\n",
      "Epoch 320/448\n",
      " - 0s - loss: 0.2640 - acc: 0.9058 - val_loss: 2.2213 - val_acc: 0.6851\n",
      "Epoch 321/448\n",
      " - 0s - loss: 0.2642 - acc: 0.9029 - val_loss: 2.2075 - val_acc: 0.6939\n",
      "Epoch 322/448\n",
      " - 0s - loss: 0.2633 - acc: 0.9036 - val_loss: 2.2075 - val_acc: 0.6968\n",
      "Epoch 323/448\n",
      " - 0s - loss: 0.2649 - acc: 0.9058 - val_loss: 2.2176 - val_acc: 0.6880\n",
      "Epoch 324/448\n",
      " - 0s - loss: 0.2644 - acc: 0.9051 - val_loss: 2.2153 - val_acc: 0.6880\n",
      "Epoch 325/448\n",
      " - 0s - loss: 0.2631 - acc: 0.9080 - val_loss: 2.2179 - val_acc: 0.6939\n",
      "Epoch 326/448\n",
      " - 0s - loss: 0.2612 - acc: 0.9058 - val_loss: 2.2203 - val_acc: 0.6880\n",
      "Epoch 327/448\n",
      " - 0s - loss: 0.2632 - acc: 0.9036 - val_loss: 2.2147 - val_acc: 0.6822\n",
      "Epoch 328/448\n",
      " - 0s - loss: 0.2634 - acc: 0.9058 - val_loss: 2.2189 - val_acc: 0.6910\n",
      "Epoch 329/448\n",
      " - 0s - loss: 0.2645 - acc: 0.9022 - val_loss: 2.2171 - val_acc: 0.6910\n",
      "Epoch 330/448\n",
      " - 0s - loss: 0.2631 - acc: 0.9073 - val_loss: 2.2187 - val_acc: 0.6910\n",
      "Epoch 331/448\n",
      " - 0s - loss: 0.2628 - acc: 0.9066 - val_loss: 2.2169 - val_acc: 0.6997\n",
      "Epoch 332/448\n",
      " - 0s - loss: 0.2636 - acc: 0.9029 - val_loss: 2.2220 - val_acc: 0.6968\n",
      "Epoch 333/448\n",
      " - 0s - loss: 0.2631 - acc: 0.9007 - val_loss: 2.2215 - val_acc: 0.6939\n",
      "Epoch 334/448\n",
      " - 0s - loss: 0.2629 - acc: 0.9044 - val_loss: 2.2282 - val_acc: 0.6939\n",
      "Epoch 335/448\n",
      " - 0s - loss: 0.2657 - acc: 0.9058 - val_loss: 2.2316 - val_acc: 0.6939\n",
      "Epoch 336/448\n",
      " - 0s - loss: 0.2684 - acc: 0.9036 - val_loss: 2.2214 - val_acc: 0.6939\n",
      "Epoch 337/448\n",
      " - 0s - loss: 0.2640 - acc: 0.9066 - val_loss: 2.2258 - val_acc: 0.6968\n",
      "Epoch 338/448\n",
      " - 0s - loss: 0.2660 - acc: 0.9058 - val_loss: 2.2287 - val_acc: 0.6910\n",
      "Epoch 339/448\n",
      " - 0s - loss: 0.2642 - acc: 0.9044 - val_loss: 2.2287 - val_acc: 0.6851\n",
      "Epoch 340/448\n",
      " - 0s - loss: 0.2630 - acc: 0.9051 - val_loss: 2.2299 - val_acc: 0.7026\n",
      "Epoch 341/448\n",
      " - 0s - loss: 0.2651 - acc: 0.9044 - val_loss: 2.2282 - val_acc: 0.6880\n",
      "Epoch 342/448\n",
      " - 0s - loss: 0.2648 - acc: 0.9073 - val_loss: 2.2356 - val_acc: 0.6968\n",
      "Epoch 343/448\n",
      " - 0s - loss: 0.2600 - acc: 0.9058 - val_loss: 2.2279 - val_acc: 0.6939\n",
      "Epoch 344/448\n",
      " - 0s - loss: 0.2603 - acc: 0.9095 - val_loss: 2.2292 - val_acc: 0.6968\n",
      "Epoch 345/448\n",
      " - 0s - loss: 0.2598 - acc: 0.9066 - val_loss: 2.2265 - val_acc: 0.6968\n",
      "Epoch 346/448\n",
      " - 0s - loss: 0.2591 - acc: 0.9080 - val_loss: 2.2335 - val_acc: 0.6968\n",
      "Epoch 347/448\n",
      " - 0s - loss: 0.2600 - acc: 0.9022 - val_loss: 2.2351 - val_acc: 0.6880\n",
      "Epoch 348/448\n",
      " - 0s - loss: 0.2581 - acc: 0.9073 - val_loss: 2.2413 - val_acc: 0.6968\n",
      "Epoch 349/448\n",
      " - 0s - loss: 0.2605 - acc: 0.9088 - val_loss: 2.2390 - val_acc: 0.6939\n",
      "Epoch 350/448\n",
      " - 0s - loss: 0.2602 - acc: 0.9066 - val_loss: 2.2349 - val_acc: 0.6968\n",
      "Epoch 351/448\n",
      " - 0s - loss: 0.2595 - acc: 0.9109 - val_loss: 2.2401 - val_acc: 0.6910\n",
      "Epoch 352/448\n",
      " - 0s - loss: 0.2602 - acc: 0.9029 - val_loss: 2.2435 - val_acc: 0.6968\n",
      "Epoch 353/448\n",
      " - 0s - loss: 0.2601 - acc: 0.9058 - val_loss: 2.2503 - val_acc: 0.6939\n",
      "Epoch 354/448\n",
      " - 0s - loss: 0.2575 - acc: 0.9088 - val_loss: 2.2393 - val_acc: 0.6968\n",
      "Epoch 355/448\n",
      " - 0s - loss: 0.2564 - acc: 0.9066 - val_loss: 2.2631 - val_acc: 0.6910\n",
      "Epoch 356/448\n",
      " - 0s - loss: 0.2607 - acc: 0.9073 - val_loss: 2.2572 - val_acc: 0.6880\n",
      "Epoch 357/448\n",
      " - 0s - loss: 0.2567 - acc: 0.9066 - val_loss: 2.2400 - val_acc: 0.6910\n",
      "Epoch 358/448\n",
      " - 0s - loss: 0.2546 - acc: 0.9109 - val_loss: 2.2444 - val_acc: 0.6968\n",
      "Epoch 359/448\n",
      " - 0s - loss: 0.2552 - acc: 0.9117 - val_loss: 2.2481 - val_acc: 0.6968\n",
      "Epoch 360/448\n",
      " - 0s - loss: 0.2562 - acc: 0.9058 - val_loss: 2.2442 - val_acc: 0.6880\n",
      "Epoch 361/448\n",
      " - 0s - loss: 0.2563 - acc: 0.9088 - val_loss: 2.2511 - val_acc: 0.7026\n",
      "Epoch 362/448\n",
      " - 0s - loss: 0.2533 - acc: 0.9073 - val_loss: 2.2469 - val_acc: 0.6968\n",
      "Epoch 363/448\n",
      " - 0s - loss: 0.2527 - acc: 0.9117 - val_loss: 2.2596 - val_acc: 0.6910\n",
      "Epoch 364/448\n",
      " - 0s - loss: 0.2554 - acc: 0.9080 - val_loss: 2.2527 - val_acc: 0.6997\n",
      "Epoch 365/448\n",
      " - 0s - loss: 0.2537 - acc: 0.9066 - val_loss: 2.2568 - val_acc: 0.6880\n",
      "Epoch 366/448\n",
      " - 0s - loss: 0.2554 - acc: 0.9117 - val_loss: 2.2574 - val_acc: 0.6968\n",
      "Epoch 367/448\n",
      " - 0s - loss: 0.2542 - acc: 0.9102 - val_loss: 2.2564 - val_acc: 0.6910\n",
      "Epoch 368/448\n",
      " - 0s - loss: 0.2546 - acc: 0.9080 - val_loss: 2.2510 - val_acc: 0.6968\n",
      "Epoch 369/448\n",
      " - 0s - loss: 0.2560 - acc: 0.9080 - val_loss: 2.2566 - val_acc: 0.6822\n",
      "Epoch 370/448\n",
      " - 0s - loss: 0.2593 - acc: 0.9058 - val_loss: 2.2334 - val_acc: 0.6910\n",
      "Epoch 371/448\n",
      " - 0s - loss: 0.2567 - acc: 0.9095 - val_loss: 2.2348 - val_acc: 0.6910\n",
      "Epoch 372/448\n",
      " - 0s - loss: 0.2548 - acc: 0.9066 - val_loss: 2.2424 - val_acc: 0.6968\n",
      "Epoch 373/448\n",
      " - 0s - loss: 0.2548 - acc: 0.9102 - val_loss: 2.2654 - val_acc: 0.6910\n",
      "Epoch 374/448\n",
      " - 0s - loss: 0.2581 - acc: 0.9044 - val_loss: 2.2618 - val_acc: 0.6939\n",
      "Epoch 375/448\n",
      " - 0s - loss: 0.2552 - acc: 0.9095 - val_loss: 2.2742 - val_acc: 0.6910\n",
      "Epoch 376/448\n",
      " - 0s - loss: 0.2559 - acc: 0.9088 - val_loss: 2.2533 - val_acc: 0.6910\n",
      "Epoch 377/448\n",
      " - 0s - loss: 0.2564 - acc: 0.9095 - val_loss: 2.2407 - val_acc: 0.6997\n",
      "Epoch 378/448\n",
      " - 0s - loss: 0.2533 - acc: 0.9109 - val_loss: 2.2864 - val_acc: 0.6939\n",
      "Epoch 379/448\n",
      " - 0s - loss: 0.2586 - acc: 0.9095 - val_loss: 2.2725 - val_acc: 0.6939\n",
      "Epoch 380/448\n",
      " - 0s - loss: 0.2546 - acc: 0.9051 - val_loss: 2.2694 - val_acc: 0.6939\n",
      "Epoch 381/448\n",
      " - 0s - loss: 0.2541 - acc: 0.9088 - val_loss: 2.2578 - val_acc: 0.6910\n",
      "Epoch 382/448\n",
      " - 0s - loss: 0.2534 - acc: 0.9073 - val_loss: 2.2742 - val_acc: 0.6910\n",
      "Epoch 383/448\n",
      " - 0s - loss: 0.2535 - acc: 0.9044 - val_loss: 2.2640 - val_acc: 0.6968\n",
      "Epoch 384/448\n",
      " - 0s - loss: 0.2533 - acc: 0.9051 - val_loss: 2.2682 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/448\n",
      " - 0s - loss: 0.2504 - acc: 0.9095 - val_loss: 2.2719 - val_acc: 0.6968\n",
      "Epoch 386/448\n",
      " - 0s - loss: 0.2486 - acc: 0.9109 - val_loss: 2.2600 - val_acc: 0.6939\n",
      "Epoch 387/448\n",
      " - 0s - loss: 0.2500 - acc: 0.9088 - val_loss: 2.2688 - val_acc: 0.6968\n",
      "Epoch 388/448\n",
      " - 0s - loss: 0.2487 - acc: 0.9109 - val_loss: 2.2716 - val_acc: 0.6910\n",
      "Epoch 389/448\n",
      " - 0s - loss: 0.2480 - acc: 0.9139 - val_loss: 2.2711 - val_acc: 0.6939\n",
      "Epoch 390/448\n",
      " - 0s - loss: 0.2485 - acc: 0.9080 - val_loss: 2.2766 - val_acc: 0.6968\n",
      "Epoch 391/448\n",
      " - 0s - loss: 0.2493 - acc: 0.9058 - val_loss: 2.2624 - val_acc: 0.6939\n",
      "Epoch 392/448\n",
      " - 0s - loss: 0.2472 - acc: 0.9073 - val_loss: 2.2773 - val_acc: 0.6968\n",
      "Epoch 393/448\n",
      " - 0s - loss: 0.2466 - acc: 0.9102 - val_loss: 2.2774 - val_acc: 0.6910\n",
      "Epoch 394/448\n",
      " - 0s - loss: 0.2465 - acc: 0.9095 - val_loss: 2.2812 - val_acc: 0.6968\n",
      "Epoch 395/448\n",
      " - 0s - loss: 0.2489 - acc: 0.9109 - val_loss: 2.2838 - val_acc: 0.6997\n",
      "Epoch 396/448\n",
      " - 0s - loss: 0.2499 - acc: 0.9109 - val_loss: 2.2732 - val_acc: 0.6939\n",
      "Epoch 397/448\n",
      " - 0s - loss: 0.2479 - acc: 0.9080 - val_loss: 2.2768 - val_acc: 0.6880\n",
      "Epoch 398/448\n",
      " - 0s - loss: 0.2470 - acc: 0.9080 - val_loss: 2.2761 - val_acc: 0.6968\n",
      "Epoch 399/448\n",
      " - 0s - loss: 0.2474 - acc: 0.9095 - val_loss: 2.2837 - val_acc: 0.6968\n",
      "Epoch 400/448\n",
      " - 0s - loss: 0.2474 - acc: 0.9124 - val_loss: 2.2796 - val_acc: 0.6910\n",
      "Epoch 401/448\n",
      " - 0s - loss: 0.2463 - acc: 0.9139 - val_loss: 2.2806 - val_acc: 0.6910\n",
      "Epoch 402/448\n",
      " - 0s - loss: 0.2468 - acc: 0.9124 - val_loss: 2.2865 - val_acc: 0.6997\n",
      "Epoch 403/448\n",
      " - 0s - loss: 0.2482 - acc: 0.9117 - val_loss: 2.2844 - val_acc: 0.6910\n",
      "Epoch 404/448\n",
      " - 0s - loss: 0.2464 - acc: 0.9088 - val_loss: 2.2875 - val_acc: 0.6997\n",
      "Epoch 405/448\n",
      " - 0s - loss: 0.2454 - acc: 0.9095 - val_loss: 2.2883 - val_acc: 0.6997\n",
      "Epoch 406/448\n",
      " - 0s - loss: 0.2484 - acc: 0.9146 - val_loss: 2.2898 - val_acc: 0.6910\n",
      "Epoch 407/448\n",
      " - 0s - loss: 0.2459 - acc: 0.9109 - val_loss: 2.2822 - val_acc: 0.6939\n",
      "Epoch 408/448\n",
      " - 0s - loss: 0.2470 - acc: 0.9124 - val_loss: 2.2780 - val_acc: 0.6939\n",
      "Epoch 409/448\n",
      " - 0s - loss: 0.2440 - acc: 0.9146 - val_loss: 2.2817 - val_acc: 0.6968\n",
      "Epoch 410/448\n",
      " - 0s - loss: 0.2446 - acc: 0.9124 - val_loss: 2.2952 - val_acc: 0.6910\n",
      "Epoch 411/448\n",
      " - 0s - loss: 0.2435 - acc: 0.9124 - val_loss: 2.2872 - val_acc: 0.6939\n",
      "Epoch 412/448\n",
      " - 0s - loss: 0.2471 - acc: 0.9146 - val_loss: 2.2966 - val_acc: 0.6939\n",
      "Epoch 413/448\n",
      " - 0s - loss: 0.2441 - acc: 0.9131 - val_loss: 2.2925 - val_acc: 0.6997\n",
      "Epoch 414/448\n",
      " - 0s - loss: 0.2464 - acc: 0.9124 - val_loss: 2.2972 - val_acc: 0.6939\n",
      "Epoch 415/448\n",
      " - 0s - loss: 0.2438 - acc: 0.9175 - val_loss: 2.2946 - val_acc: 0.6910\n",
      "Epoch 416/448\n",
      " - 0s - loss: 0.2447 - acc: 0.9109 - val_loss: 2.2920 - val_acc: 0.6997\n",
      "Epoch 417/448\n",
      " - 0s - loss: 0.2449 - acc: 0.9124 - val_loss: 2.3027 - val_acc: 0.6880\n",
      "Epoch 418/448\n",
      " - 0s - loss: 0.2503 - acc: 0.9095 - val_loss: 2.3147 - val_acc: 0.6910\n",
      "Epoch 419/448\n",
      " - 0s - loss: 0.2458 - acc: 0.9117 - val_loss: 2.2992 - val_acc: 0.6939\n",
      "Epoch 420/448\n",
      " - 0s - loss: 0.2431 - acc: 0.9139 - val_loss: 2.3030 - val_acc: 0.6910\n",
      "Epoch 421/448\n",
      " - 0s - loss: 0.2433 - acc: 0.9146 - val_loss: 2.2986 - val_acc: 0.6939\n",
      "Epoch 422/448\n",
      " - 0s - loss: 0.2456 - acc: 0.9117 - val_loss: 2.3001 - val_acc: 0.6910\n",
      "Epoch 423/448\n",
      " - 0s - loss: 0.2452 - acc: 0.9124 - val_loss: 2.2981 - val_acc: 0.6939\n",
      "Epoch 424/448\n",
      " - 0s - loss: 0.2449 - acc: 0.9146 - val_loss: 2.2982 - val_acc: 0.6880\n",
      "Epoch 425/448\n",
      " - 0s - loss: 0.2566 - acc: 0.9109 - val_loss: 2.3190 - val_acc: 0.6880\n",
      "Epoch 426/448\n",
      " - 0s - loss: 0.2524 - acc: 0.9109 - val_loss: 2.3599 - val_acc: 0.6910\n",
      "Epoch 427/448\n",
      " - 0s - loss: 0.2569 - acc: 0.9088 - val_loss: 2.2649 - val_acc: 0.6968\n",
      "Epoch 428/448\n",
      " - 0s - loss: 0.2626 - acc: 0.9066 - val_loss: 2.3868 - val_acc: 0.6851\n",
      "Epoch 429/448\n",
      " - 0s - loss: 0.2591 - acc: 0.9058 - val_loss: 2.3169 - val_acc: 0.6851\n",
      "Epoch 430/448\n",
      " - 0s - loss: 0.2615 - acc: 0.9080 - val_loss: 2.3647 - val_acc: 0.6880\n",
      "Epoch 431/448\n",
      " - 0s - loss: 0.2712 - acc: 0.9058 - val_loss: 2.3810 - val_acc: 0.6851\n",
      "Epoch 432/448\n",
      " - 0s - loss: 0.2538 - acc: 0.9044 - val_loss: 2.2761 - val_acc: 0.6968\n",
      "Epoch 433/448\n",
      " - 0s - loss: 0.2555 - acc: 0.9058 - val_loss: 2.2831 - val_acc: 0.6939\n",
      "Epoch 434/448\n",
      " - 0s - loss: 0.2455 - acc: 0.9117 - val_loss: 2.3044 - val_acc: 0.6968\n",
      "Epoch 435/448\n",
      " - 0s - loss: 0.2456 - acc: 0.9124 - val_loss: 2.3170 - val_acc: 0.6939\n",
      "Epoch 436/448\n",
      " - 0s - loss: 0.2448 - acc: 0.9131 - val_loss: 2.2995 - val_acc: 0.6939\n",
      "Epoch 437/448\n",
      " - 0s - loss: 0.2433 - acc: 0.9146 - val_loss: 2.2947 - val_acc: 0.6939\n",
      "Epoch 438/448\n",
      " - 0s - loss: 0.2424 - acc: 0.9146 - val_loss: 2.3187 - val_acc: 0.6910\n",
      "Epoch 439/448\n",
      " - 0s - loss: 0.2424 - acc: 0.9139 - val_loss: 2.3037 - val_acc: 0.6939\n",
      "Epoch 440/448\n",
      " - 0s - loss: 0.2404 - acc: 0.9146 - val_loss: 2.3039 - val_acc: 0.6939\n",
      "Epoch 441/448\n",
      " - 0s - loss: 0.2437 - acc: 0.9146 - val_loss: 2.3177 - val_acc: 0.6939\n",
      "Epoch 442/448\n",
      " - 0s - loss: 0.2413 - acc: 0.9153 - val_loss: 2.3212 - val_acc: 0.6822\n",
      "Epoch 443/448\n",
      " - 0s - loss: 0.2410 - acc: 0.9168 - val_loss: 2.3115 - val_acc: 0.6968\n",
      "Epoch 444/448\n",
      " - 0s - loss: 0.2405 - acc: 0.9153 - val_loss: 2.3097 - val_acc: 0.6968\n",
      "Epoch 445/448\n",
      " - 0s - loss: 0.2399 - acc: 0.9168 - val_loss: 2.3074 - val_acc: 0.6910\n",
      "Epoch 446/448\n",
      " - 0s - loss: 0.2415 - acc: 0.9168 - val_loss: 2.3191 - val_acc: 0.6939\n",
      "Epoch 447/448\n",
      " - 0s - loss: 0.2385 - acc: 0.9131 - val_loss: 2.3100 - val_acc: 0.6968\n",
      "Epoch 448/448\n",
      " - 0s - loss: 0.2396 - acc: 0.9153 - val_loss: 2.3167 - val_acc: 0.6968\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_history = model.fit(X_train, Y_train, \n",
    "                          batch_size = 100, \n",
    "                          epochs = 448, \n",
    "                          verbose = 2,\n",
    "                          validation_split = 0.2,\n",
    "                          #callbacks = [es]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history, 'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 32us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.33566435650512"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before saving: are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_10_10_20_tanh_100_1000_50.h5\")\n",
    "#for this\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST-SEE: \n",
    "* https://www.kaggle.com/randyrose2017/for-beginners-using-keras-to-build-models\n",
    "* https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d\n",
    "* https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n",
    "## Just liked:\n",
    "* https://missinglink.ai/guides/neural-network-concepts/classification-neural-networks-neural-network-right-choice/\n",
    "## Full-house:\n",
    "https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why rerunning with same configuration gives different output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = Sequential()\n",
    "model_load.add(Dense(units = 10, \n",
    "                input_dim = 71, \n",
    "                activation = 'tanh',))\n",
    "model_load.add(Dense(units = 10, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 20, \n",
    "                activation = 'tanh'))\n",
    "model_load.add(Dense(units = 42, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_weights('/home/amanzhol/Documents/Capstone/MAIN Work/models/model_10_10_20_tanh_100_1000_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need to compile before evaluating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_load.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.35198137976907"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Ms. Asma Salem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='AsmaSalemResults.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "predictions = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing confustion matrix from source:\n",
    "https://stackoverflow.com/questions/50920908/get-confusion-matrix-from-a-keras-multiclass-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0, ...,  0,  0,  0],\n",
       "       [ 2,  6,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 13, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  0,  0, ...,  6,  0,  0],\n",
       "       [ 2,  0,  0, ...,  0,  5,  0],\n",
       "       [ 6,  0,  0, ...,  0,  0,  3]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 FAR, FRR and EER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stats.stackexchange.com/questions/272962/are-far-and-frr-the-same-as-fpr-and-fnr-respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ConfusionMatrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='PerformanceMetrics.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Edit:\n",
    "this is the format for confusion_matrix():\n",
    "[[TP,FN]\n",
    "[FP,TN]]\n",
    "And classification report gives all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 11, 67)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_measure(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus\n",
    "TP = 6\n",
    "FP = 1\n",
    "TN = 11\n",
    "FN = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAR(FP, TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FRR(FN, TP):\n",
    "    return FN/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333332"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAR(FP, TN) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-of-the-art on this dataset (Performance Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ms. Asma Results\n",
    "* FAR = 0.3%\n",
    "* FRR = 1.5%\n",
    "* EER = 0.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* How to have several FAR, FRR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read for Confusion Matrix - Get Items FP/FN/TP/TN - Python\n",
    "* https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python\n",
    "* https://classeval.wordpress.com/introduction/basic-evaluation-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
